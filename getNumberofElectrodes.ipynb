{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "task = 'GlobalLocal'\n",
    "LAB_root = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0057\n"
     ]
    }
   ],
   "source": [
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "\n",
    "stim_filename = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
    "stim_sig_chans = load_sig_chans(stim_filename)\n",
    "\n",
    "stim_filename_0to0point5 = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_0.2sec_window_0to0.5.json'\n",
    "stim_sig_chans_0to0point5 = load_sig_chans(stim_filename_0to0point5)\n",
    "\n",
    "stim_filename_0point5to1 = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_0.2sec_window_0.5to1.json'\n",
    "stim_sig_chans_0point5to1 = load_sig_chans(stim_filename_0point5to1)\n",
    "\n",
    "stim_filename_0to1 = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_0.2sec_window_0to1.json'\n",
    "stim_sig_chans_0to1 = load_sig_chans(stim_filename_0to1)\n",
    "\n",
    "stim_sig_chans_all_windows = stim_sig_chans_0to0point5 + stim_sig_chans_0point5to1 + stim_sig_chans_0to1\n",
    "stim_sig_chans_all_windows = np.unique(stim_sig_chans_all_windows)\n",
    "\n",
    "# Initialize an empty dictionary to store significant channels per subject\n",
    "sig_chans_per_subject = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0057\n",
      "Subject D0057: Filt Channels = 179, Good Channels = 176, Sig channels time perm cluster = 87, Sig channels 0 to 0.5 = 98, Sig channels 0.5 to 1 = 176, Sig channels 0 to 1 = 97, Sig Channels across windows = 176\n",
      "Loaded significant channels for subject D0059\n",
      "Loaded significant channels for subject D0059\n",
      "Loaded significant channels for subject D0059\n",
      "Loaded significant channels for subject D0059\n",
      "Subject D0059: Filt Channels = 185, Good Channels = 174, Sig channels time perm cluster = 88, Sig channels 0 to 0.5 = 65, Sig channels 0.5 to 1 = 174, Sig channels 0 to 1 = 65, Sig Channels across windows = 174\n",
      "Loaded significant channels for subject D0063\n",
      "Loaded significant channels for subject D0063\n",
      "Loaded significant channels for subject D0063\n",
      "Loaded significant channels for subject D0063\n",
      "Subject D0063: Filt Channels = 241, Good Channels = 235, Sig channels time perm cluster = 43, Sig channels 0 to 0.5 = 31, Sig channels 0.5 to 1 = 235, Sig channels 0 to 1 = 30, Sig Channels across windows = 235\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Define the subjects list\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', \n",
    "            'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "\n",
    "# Initialize a dictionary to hold the counts\n",
    "counts = {\n",
    "    'total_filt_channels': 0,\n",
    "    'total_good_channels': 0,\n",
    "    'total_sig_channels_timepermcluster': 0,\n",
    "    'total_sig_channels_0to0point5': 0,\n",
    "    'total_sig_channels_0point5to1': 0,\n",
    "    'total_sig_channels_0to1': 0,\n",
    "    'total_sig_channels_all_windows': 0\n",
    "}\n",
    "\n",
    "# Define the base path for your files\n",
    "base_path = 'C:/Users/jz421/Box/CoganLab/BIDS-1.1_GlobalLocal/BIDS/derivatives/'\n",
    "\n",
    "# Initialize an empty dictionary to store significant channels per subject\n",
    "sig_chans_per_subject = {}\n",
    "\n",
    "# Loop through each subject to gather data\n",
    "for sub in subjects:\n",
    "    # Load the 'good' channels\n",
    "    good_channels_path = os.path.join(base_path, 'freqFilt', 'figs', sub, f'channels_{sub}_GlobalLocal.txt')\n",
    "    with open(good_channels_path, 'r') as file:\n",
    "        good_channels = file.readlines()  # Adjust this line if the data is stored in a different format (e.g., JSON)\n",
    "    num_good_channels = len(good_channels)\n",
    "    \n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "\n",
    "    stim_filename = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
    "    stim_sig_chans = load_sig_chans(stim_filename)\n",
    "\n",
    "    stim_filename_0to0point5 = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_0.2sec_window_0to0.5.json'\n",
    "    stim_sig_chans_0to0point5 = load_sig_chans(stim_filename_0to0point5)\n",
    "\n",
    "    stim_filename_0point5to1 = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_0.2sec_window_0.5to1.json'\n",
    "    stim_sig_chans_0point5to1 = load_sig_chans(stim_filename_0point5to1)\n",
    "\n",
    "    stim_filename_0to1 = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_0.2sec_window_0to1.json'\n",
    "    stim_sig_chans_0to1 = load_sig_chans(stim_filename_0to1)\n",
    "\n",
    "    stim_sig_chans_all_windows = stim_sig_chans_0to0point5 + stim_sig_chans_0point5to1 + stim_sig_chans_0to1\n",
    "    stim_sig_chans_all_windows = np.unique(stim_sig_chans_all_windows)\n",
    "\n",
    "    sig_chans_per_subject['stim_sig_chans_timepermcluster'] = {}\n",
    "    sig_chans_per_subject['stim_sig_chans_0to0point5'] = {}\n",
    "    sig_chans_per_subject['stim_sig_chans_0point5to1'] = {}\n",
    "    sig_chans_per_subject['stim_sig_chans_0to1'] = {}\n",
    "    sig_chans_per_subject['stim_sig_chans_all_windows'] = {}\n",
    "\n",
    "    sig_chans_per_subject['stim_sig_chans_timepermcluster'][sub] = stim_sig_chans\n",
    "    sig_chans_per_subject['stim_sig_chans_0to0point5'][sub] = stim_sig_chans_0to0point5\n",
    "    sig_chans_per_subject['stim_sig_chans_0point5to1'][sub] = stim_sig_chans_0point5to1\n",
    "    sig_chans_per_subject['stim_sig_chans_0to1'][sub] = stim_sig_chans_0to1\n",
    "    sig_chans_per_subject['stim_sig_chans_all_windows'][sub] = stim_sig_chans_all_windows\n",
    "\n",
    "    num_sig_channels = {}\n",
    "    num_sig_channels['stim_sig_chans_timepermcluster'] = len(sig_chans_per_subject['stim_sig_chans_timepermcluster'][sub])\n",
    "    num_sig_channels['stim_sig_chans_0to0point5'] = len(sig_chans_per_subject['stim_sig_chans_0to0point5'][sub])\n",
    "    num_sig_channels['stim_sig_chans_0point5to1'] = len(sig_chans_per_subject['stim_sig_chans_0point5to1'][sub])\n",
    "    num_sig_channels['stim_sig_chans_0to1'] = len(sig_chans_per_subject['stim_sig_chans_0to1'][sub])\n",
    "    num_sig_channels['stim_sig_chans_all_windows'] = len(sig_chans_per_subject['stim_sig_chans_all_windows'][sub])\n",
    "\n",
    "    filt_channels_path = os.path.join(base_path, 'clean', f'sub-{sub}', 'ieeg', f'sub-{sub}_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv')\n",
    "    with open(filt_channels_path, 'r') as file:\n",
    "        filt_channels = file.readlines()  # Adjust this line if the data is stored in a different format (e.g., JSON)\n",
    "    num_filt_channels = len(filt_channels) - 1\n",
    "\n",
    "    # Update the counts\n",
    "    counts['total_filt_channels'] += num_filt_channels\n",
    "    counts['total_good_channels'] += num_good_channels\n",
    "\n",
    "    counts['total_sig_channels_timepermcluster'] += num_sig_channels['stim_sig_chans_timepermcluster']\n",
    "    counts['total_sig_channels_0to0point5'] += num_sig_channels['stim_sig_chans_0to0point5']\n",
    "    counts['total_sig_channels_0point5to1'] += num_sig_channels['stim_sig_chans_0point5to1']\n",
    "    counts['total_sig_channels_0to1'] += num_sig_channels['stim_sig_chans_0to1']\n",
    "    counts['total_sig_channels_all_windows'] += num_sig_channels['stim_sig_chans_all_windows']\n",
    "\n",
    "\n",
    "    # Print the counts for the current subject\n",
    "    print(f\"Subject {sub}: Filt Channels = {num_filt_channels}, Good Channels = {num_good_channels}, Sig channels time perm cluster = {num_sig_channels['stim_sig_chans_timepermcluster']}, Sig channels 0 to 0.5 = {num_sig_channels['stim_sig_chans_0to0point5']}, Sig channels 0.5 to 1 = {num_sig_channels['stim_sig_chans_0point5to1']}, Sig channels 0 to 1 = {num_sig_channels['stim_sig_chans_0to1']}, Sig Channels across windows = {num_sig_channels['stim_sig_chans_all_windows']}\")\n",
    "\n",
    "# Print total counts across all subjects\n",
    "print(\"Total across all subjects:\", counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D0103': ['LTAS1',\n",
       "  'LTMS7',\n",
       "  'LTPS13',\n",
       "  'LTPS16',\n",
       "  'LFAM8',\n",
       "  'LFAM11',\n",
       "  'LFAM12',\n",
       "  'LFAM13',\n",
       "  'LFAM14',\n",
       "  'LAI1',\n",
       "  'LAI4',\n",
       "  'LAI6',\n",
       "  'LAI7',\n",
       "  'LAI8',\n",
       "  'LPI2',\n",
       "  'LPI3',\n",
       "  'LPI5',\n",
       "  'LPI6',\n",
       "  'LPI7',\n",
       "  'LPI15',\n",
       "  'LPI16',\n",
       "  'LPI17',\n",
       "  'LTP2',\n",
       "  'LTP3',\n",
       "  'LTP4',\n",
       "  'LTPM6',\n",
       "  'LTPM9',\n",
       "  'LTPM10',\n",
       "  'LPPI7',\n",
       "  'LPPI8',\n",
       "  'LPPI9',\n",
       "  'LPPI18',\n",
       "  'LTLI8',\n",
       "  'LTLI9',\n",
       "  'LTPI2',\n",
       "  'LTPI5',\n",
       "  'LTPI7',\n",
       "  'LFO1',\n",
       "  'LFO2',\n",
       "  'LFO3',\n",
       "  'LFO4',\n",
       "  'LFO5',\n",
       "  'LFO6',\n",
       "  'LFO7',\n",
       "  'LFO8',\n",
       "  'LFO9',\n",
       "  'LFO10',\n",
       "  'LFO12',\n",
       "  'LFO14',\n",
       "  'LFO15',\n",
       "  'LFAI1',\n",
       "  'LFAI2',\n",
       "  'LFAI3',\n",
       "  'LFAI4']}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_chans_per_subject['stim_sig_chans_0to0point5']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
