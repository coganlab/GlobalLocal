{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "\n",
    "from scipy.ndimage import label\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# rsa toolbox imports\n",
    "from rsatoolbox.io.mne import read_epochs\n",
    "from rsatoolbox.data.ops import merge_datasets\n",
    "from rsatoolbox.rdm import calc_rdm_movie\n",
    "from rsatoolbox.rdm.calc import _parse_input\n",
    "from rsatoolbox.util.build_rdm import _build_rdms\n",
    "from rsatoolbox.rdm import compare\n",
    "from rsatoolbox.vis import show_rdm\n",
    "from rsatoolbox.vis.timecourse import plot_timecourse\n",
    "\n",
    "from os.path import join, expanduser, basename\n",
    "import glob, json\n",
    "import numpy, tqdm, mne, pandas\n",
    "import rsatoolbox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "# load in subjects electrodes to rois dict. If it doesn't already exist, make it and then load it.\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "subjects_electrodestoROIs_dict = make_or_load_subjects_electrodes_to_rois_dict(filename, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_experiment_conditions = {\n",
    "    \"Stimulus/i25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/i25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# congruency_conditions = {\n",
    "#     \"Stimulus_c\": {\n",
    "#         \"BIDS_events\": [\"Stimulus/c25/s25\", \"Stimulus/c25/s75\", \"Stimulus/c75/s25\", \"Stimulus/c75/s75\", \"Stimulus/c25/r25\", \"Stimulus/c25/r75\", \"Stimulus/c75/r25\", \"Stimulus/c75/r75\"],\n",
    "#         \"congruency\": \"c\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "stimulus_conditions = {\n",
    "    \"Stimulus/BigLetters/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetters/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Stimulus/BigLetters/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetters/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response_experiment_conditions = {\n",
    "    \"Response/i25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/i75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/i25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/i75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response_conditions = {\n",
    "    \"Response/BigLetters/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetters/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Response/BigLetters/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetters/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epochs_root_file_for_selected_conditions(selected_conditions):\n",
    "    \"\"\"\n",
    "    Determines the appropriate epochs root file based on the selected conditions. THIS WILL \n",
    "\n",
    "    Parameters:\n",
    "    selected_conditions (dict): The conditions dictionary used for selecting the epochs root file.\n",
    "        This can be one of the predefined dictionaries like `stimulus_conditions`, `stimulus_experiment_conditions`,\n",
    "        `response_conditions`, or `response_experiment_conditions`.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - selected_conditions (dict): The input conditions dictionary.\n",
    "        - epochs_root_file (str): The name of the epochs root file corresponding to the selected conditions.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: If the selected_conditions do not match any of the predefined condition dictionaries.\n",
    "    \"\"\"\n",
    "    if selected_conditions == stimulus_conditions or stimulus_experiment_conditions:\n",
    "        epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8\"\n",
    "\n",
    "    elif conditions == response_conditions or response_experiment_conditions:\n",
    "        epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8\"\n",
    "    else:\n",
    "        raise ValueError(\"Unknown condition type.\")\n",
    "    \n",
    "    return selected_conditions, epochs_root_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_root_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task='GlobalLocal'\n",
    "\n",
    "# conditions, epochs_root_file = get_epochs_root_file_for_selected_conditions(stimulus_experiment_conditions)\n",
    "conditions, epochs_root_file = get_epochs_root_file_for_selected_conditions(stimulus_conditions)\n",
    "\n",
    "condition_names = list(conditions.keys()) # get the condition names as a list\n",
    "\n",
    "# This breaks if just_HG_ev1_rescaled is set to False currently. Fix this! 8/11\n",
    "subjects_mne_objects = create_subjects_mne_objects_dict(subjects=subjects, epochs_root_file=epochs_root_file, conditions=conditions, task=\"GlobalLocal\", just_HG_ev1_rescaled=True, acc_trials_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_names = list(conditions.keys()) # get the condition names as a list\n",
    "condition_names_bids = [condition['BIDS_events'] for condition in conditions.values()] # get the condition names in bids format\n",
    "condition_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get significant channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_chans_per_subject = get_sig_chans_per_subject(subjects, epochs_root_file, task='GlobalLocal', LAB_root=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of subjects\n",
    "root_dir = rf\"C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your ROIs dictionary and other parameters\n",
    "rois_dict = {\n",
    "    'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    'v1': [\"G_oc-temp_med-Lingual\", \"S_calcarine\", \"G_cuneus\"],\n",
    "    'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"],\n",
    "    'occ_filtered': [],\n",
    "    'occ_best_filtered': []\n",
    "}\n",
    "\n",
    "rois = list(rois_dict.keys())\n",
    "# Assuming you have subjects_electrodestoROIs_dict and sig_chans_per_subject dictionaries\n",
    "electrodes_per_subject_roi, sig_electrodes_per_subject_roi, = make_sig_electrodes_per_subject_and_roi_dict(\n",
    "    rois_dict, subjects_electrodestoROIs_dict, sig_chans_per_subject\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's manually make the occ filtered sig electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_electrodes_per_subject_roi['occ_filtered'] = {\n",
    "    'D0057': [],\n",
    "    'D0059': [],\n",
    "    'D0071': ['RO1', 'RO10'], #RO10 is iffy, big drop from fix onset\n",
    "    'D0077': ['ROPM1', 'ROPM8'],\n",
    "    'D0090': ['RTPO1', 'RTPI1'],\n",
    "    'D0100': ['LOAI12', 'LOAI13', 'LOAI14', 'LOAI15', 'LOMI9', 'LOMI11', 'LOPI8', 'LOPI9', 'LOPM8', 'LOPM9', 'LPPI7', 'LPPI8', 'LPPI9'],\n",
    "    'D0102': ['RTPI1'],\n",
    "    'D0103': ['LTPI2', 'LTPI3', 'LTPI4']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now make the best of the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_electrodes_per_subject_roi['occ_best_filtered'] = {\n",
    "    'D0057': [],\n",
    "    'D0059': [],\n",
    "    'D0071': [],\n",
    "    'D0077': [],\n",
    "    'D0090': [],\n",
    "    'D0100': ['LOAI12', 'LOMI9', 'LOPI8', 'LOPI9', 'LOPM8', 'LOPM9'],\n",
    "    'D0102': ['RTPI1'],\n",
    "    'D0103': ['LTPI2', 'LTPI3', 'LTPI4']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the file path where you want to save the dictionary\n",
    "save_path = 'sig_electrodes_per_subject_roi.json'\n",
    "\n",
    "# Use json to save the dictionary\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(sig_electrodes_per_subject_roi, file, indent=4)\n",
    "\n",
    "print(f\"Dictionary saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get electrode counts for each roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_electrodes_info = calculate_total_electrodes(sig_electrodes_per_subject_roi, electrodes_per_subject_roi)\n",
    "for roi, counts in total_electrodes_info.items():\n",
    "    print(f\"Total number of {roi} electrodes across all subjects:\", counts['total_electrodes'])\n",
    "    print(f\"Total number of significant {roi} electrodes across all subjects:\", counts['total_significant_electrodes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if any subjects have a weird sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'subjects_mne_objects' is your dictionary containing MNE objects for each subject\n",
    "sampling_rate = 256\n",
    "subject_rates = check_sampling_rates(subjects_mne_objects, expected_sampling_rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dat dict like in the Temporal example from rsatoolbox 7/19  \n",
    "#### Data Dictionary (dat) Structure\n",
    "- **roi1**\n",
    "  - **data**: 3D data array for this ROI\n",
    "  - **channel_names**: List of significant channels for this ROI\n",
    "  - **cond_names**: Dictionary where keys are condition names and values are integer indices\n",
    "  - **cond_idx**: 1D array where each entry is an integer index corresponding to a cond_name\n",
    "  - **times**: 1D array of times, corresponding to each sample\n",
    "- **roi2**\n",
    "  - **data**: 3D data array for this ROI\n",
    "  - **channel_names**: List of significant channels for this ROI\n",
    "  - **cond_names**: Dictionary where keys are condition names and values are integer indices\n",
    "  - **cond_idx**: 1D array where each entry is an integer index corresponding to a cond_name\n",
    "  - **times**: 1D array of times, corresponding to each sample\n",
    "- **roiX**\n",
    "  - **data**: 3D data array for this ROI\n",
    "  - **channel_names**: List of significant channels for this ROI\n",
    "  - **cond_names**: Dictionary where keys are condition names and values are integer indices\n",
    "  - **cond_idx**: 1D array where each entry is an integer index corresponding to a cond_name\n",
    "  - **times**: 1D array of times, corresponding to each sample\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_temporal_dataset(subjects_mne_objects, condition_names, rois, subjects, sig_electrodes_per_subject_roi):\n",
    "    # returns dat\n",
    "    dat = {}\n",
    "    overall_electrode_mapping = []\n",
    "    electrode_mapping_per_roi = {roi: [] for roi in rois}  # Reinitialize for each processing run\n",
    "    print('subjects: ', subjects)\n",
    "    for roi in rois:\n",
    "        dat[roi] = {}  # make a dict for each roi\n",
    "        dat[roi]['channel_names'] = []  # initialize a list to hold channel names\n",
    "        dat[roi]['channel_rois'] = [] # initialize a list to hold what roi each channel is a part of\n",
    "        dat[roi]['condition_names'] = {}  # initialize dict where keys are condition names and values are integer indices\n",
    "        dat[roi]['cond_idx'] = np.array([], dtype=int)  # initialize an empty 1D array for condition indices for each trial\n",
    "        dat[roi]['sub_idx'] = np.array([], dtype=int) # initialize an empty 1D array for subject for each trial\n",
    "        dat[roi]['times'] = np.array([])  # initialize an empty 1D array for time points\n",
    "\n",
    "        # Determine all unique channels across subjects for this ROI, maintaining order\n",
    "        all_channels = []\n",
    "        for sub in subjects:\n",
    "            sig_electrodes = sig_electrodes_per_subject_roi[roi].get(sub, [])\n",
    "            sub_channel_names = [sub + '-' + sig_electrode for sig_electrode in sig_electrodes]\n",
    "            for chan in sub_channel_names:\n",
    "                if chan not in all_channels:\n",
    "                    all_channels.append(chan)\n",
    "                    dat[roi]['channel_rois'].append(roi) # append roi for each channel\n",
    "        dat[roi]['channel_names'] = all_channels\n",
    "        num_channels = len(all_channels)\n",
    "        print('num channels: ', num_channels)\n",
    "\n",
    "        # Initialize the data array with the number of trials and total channels\n",
    "        dat[roi]['data'] = np.empty((0, num_channels, 0))  # initialize an empty 3D array for trials x channels x time points\n",
    "        total_roi_trials = 0\n",
    "        for sub in subjects:\n",
    "            total_sub_trials = 0  # Initialize counter for total trials across all conditions\n",
    "            sig_electrodes = sig_electrodes_per_subject_roi[roi].get(sub, [])\n",
    "            sub_channel_names = [sub + '-' + sig_electrode for sig_electrode in sig_electrodes]\n",
    "            if not sig_electrodes:\n",
    "                continue\n",
    "\n",
    "            cond_idx = 0  # the example uses indexing from 1, but let's start from 0 because python\n",
    "            for condition_name in condition_names:\n",
    "                print(f'Processing {sub} for {condition_name} in {roi}')\n",
    "                epochs = subjects_mne_objects[sub][condition_name]['HG_ev1_rescaled'].copy().pick(sig_electrodes)\n",
    "                dat[roi]['condition_names'][condition_name] = cond_idx\n",
    "\n",
    "                epochs_data = epochs.get_data(copy=True)\n",
    "                num_trials, num_sub_channels, num_timepoints = epochs_data.shape\n",
    "\n",
    "                print(f'Number of trials for {sub} in {condition_name}: {num_trials}')\n",
    "                total_sub_trials += num_trials\n",
    "                total_roi_trials += num_trials\n",
    "\n",
    "                # Initialize data array time dimension if it is empty\n",
    "                if dat[roi]['data'].shape[2] == 0:\n",
    "                    dat[roi]['data'] = np.empty((0, num_channels, num_timepoints))\n",
    "                    dat[roi]['times'] = epochs.times\n",
    "\n",
    "                # Create an array filled with NaNs for the current subject's data\n",
    "                sub_data = np.full((num_trials, num_channels, num_timepoints), np.nan)\n",
    "\n",
    "                # Find the indices for the subject's channels in the total list of channels\n",
    "                channel_indices = [all_channels.index(chan) for chan in sub_channel_names]\n",
    "                print('sub: ', sub)\n",
    "                print(\"channel indices: \", channel_indices)\n",
    "                \n",
    "                # Place the subject's data in the correct indices\n",
    "                sub_data[:, channel_indices, :] = epochs_data\n",
    "\n",
    "                # Concatenate the new data along the first axis (trials)\n",
    "                dat[roi]['data'] = np.concatenate((dat[roi]['data'], sub_data), axis=0)\n",
    "\n",
    "                # Extend the cond_idx array\n",
    "                dat[roi]['cond_idx'] = np.concatenate((dat[roi]['cond_idx'], np.full(num_trials, cond_idx)))\n",
    "\n",
    "                # extend the sub_idx array by this number of trials with this subject\n",
    "                dat[roi]['sub_idx'] = np.concatenate((dat[roi]['sub_idx'], np.full(num_trials, sub)))\n",
    "                cond_idx += 1  # increment cond_idx\n",
    "\n",
    "            print(f'Total number of trials for {sub} across all conditions: {total_sub_trials}')\n",
    "        print(f'total number of trials in {roi} is {total_roi_trials}')\n",
    "    return dat\n",
    "\n",
    "# Example call to the function (you need to replace the arguments with actual data)\n",
    "dat = prepare_data_for_temporal_dataset(subjects_mne_objects, condition_names, rois, subjects, sig_electrodes_per_subject_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot condition averages for two channels in occ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for the model names\n",
    "colors = {\n",
    "    'congruency': 'red',\n",
    "    'switchType': 'blue',\n",
    "    'congruencyProportion': 'pink',\n",
    "    'switchProportion': 'skyblue',\n",
    "    'congruency_congruencyProportion': 'hotpink',\n",
    "    'congruency_congruency_proportion': 'hotpink',\n",
    "    'switchType_switchProportion': 'gray',\n",
    "    'switch_type_switch_proportion': 'gray',\n",
    "    'bigLetter': 'green',\n",
    "    'big_letter': 'green',\n",
    "    'smallLetter': 'orange',\n",
    "    'small_letter': 'orange',\n",
    "    'task': 'gray',\n",
    "    'c75.0': 'pink',\n",
    "    'i75.0': 'pink',\n",
    "    'c25.0': 'gold',\n",
    "    'i25.0': 'gold',\n",
    "    'r25.0': 'lightblue',\n",
    "    's25.0': 'lightblue',\n",
    "    'r75.0': 'purple',\n",
    "    's75.0': 'purple'\n",
    "}\n",
    "\n",
    "# Define linestyles for the model names\n",
    "linestyles = {\n",
    "    'big letter S': '-',\n",
    "    'BigLetters': '-',\n",
    "\n",
    "    'big letter H': '--',\n",
    "    'BigLetterh': '--',\n",
    "\n",
    "    'small letter S': '-',\n",
    "    'SmallLetters': '-',\n",
    "\n",
    "    'small letter H': '--',\n",
    "    'SmallLetterh': '--',\n",
    "\n",
    "    'task G': '-',\n",
    "    'Taskg': '-',\n",
    "\n",
    "    'task L': '--',\n",
    "    'Taskl': '--',\n",
    "\n",
    "    'congruent': '-',\n",
    "    'c': '-',\n",
    "\n",
    "    'incongruent': '--',\n",
    "    'i': '--',\n",
    "\n",
    "    'repeat': '-',\n",
    "    'r': '-',\n",
    "\n",
    "    'switch': '--',\n",
    "    's': '--',\n",
    "\n",
    "    'c25.0': '-',\n",
    "    'c75.0': '-',\n",
    "    'i25.0': '--',\n",
    "    'i75.0': '--'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the visual conditions for each electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conditions == stimulus_conditions:\n",
    "    for roi in rois:\n",
    "        # Extract the relevant data from the dictionary\n",
    "        chan_names = dat[roi]['channel_names']\n",
    "        data = dat[roi]['data']\n",
    "        cond_idx = dat[roi]['cond_idx']\n",
    "        times = dat[roi]['times']\n",
    "        cond_names = [x for x in dat[roi]['condition_names'].keys()]\n",
    "\n",
    "        # Split condition names to get big letter, small letter, and task info\n",
    "        big_letters = np.array([cond_name.split('/')[1] for cond_name in cond_names])\n",
    "        small_letters = np.array([cond_name.split('/')[2] for cond_name in cond_names])\n",
    "        tasks = np.array([cond_name.split('/')[3] for cond_name in cond_names])\n",
    "\n",
    "        # Dynamically determine the groups based on unique entries\n",
    "        unique_big_letters = np.unique(big_letters)\n",
    "        unique_small_letters = np.unique(small_letters)\n",
    "        unique_tasks = np.unique(tasks)\n",
    "\n",
    "        groups = {\n",
    "            'big_letter': unique_big_letters,\n",
    "            'small_letter': unique_small_letters,\n",
    "            'task': unique_tasks\n",
    "        }\n",
    "\n",
    "        # Loop over each group\n",
    "        for group_name, unique_entries in groups.items():\n",
    "            # Ensure there are exactly two unique entries for each group\n",
    "            if len(unique_entries) != 2:\n",
    "                raise ValueError(f\"Expected exactly 2 unique entries for {group_name}, but got {len(unique_entries)}\")\n",
    "\n",
    "            cond1, cond2 = unique_entries\n",
    "\n",
    "            # Initialize plot index\n",
    "            plot_index = 1\n",
    "\n",
    "            # Loop over each channel in chunks of 16\n",
    "            for start_idx in range(0, len(chan_names), 16):\n",
    "                fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
    "                ax = ax.flatten()\n",
    "\n",
    "                # Loop over the current chunk of channels\n",
    "                for jj, chan_idx in enumerate(range(start_idx, min(start_idx + 16, len(chan_names)))):\n",
    "                    chan = chan_names[chan_idx]\n",
    "\n",
    "                    # Find condition indices for each group\n",
    "                    if group_name == 'big_letter':\n",
    "                        cond1_indices = np.where(big_letters == cond1)[0]\n",
    "                        cond2_indices = np.where(big_letters == cond2)[0]\n",
    "                    elif group_name == 'small_letter':\n",
    "                        cond1_indices = np.where(small_letters == cond1)[0]\n",
    "                        cond2_indices = np.where(small_letters == cond2)[0]\n",
    "                    elif group_name == 'task':\n",
    "                        cond1_indices = np.where(tasks == cond1)[0]\n",
    "                        cond2_indices = np.where(tasks == cond2)[0]\n",
    "\n",
    "                    # Compute the mean and SEM for each condition\n",
    "                    cond1_data = data[np.isin(cond_idx, cond1_indices), chan_idx, :]\n",
    "                    cond2_data = data[np.isin(cond_idx, cond2_indices), chan_idx, :]\n",
    "                    cond1_mean = np.nanmean(cond1_data, axis=0).squeeze()\n",
    "                    cond2_mean = np.nanmean(cond2_data, axis=0).squeeze()\n",
    "                    cond1_sem = np.nanstd(cond1_data, axis=0).squeeze() / np.sqrt(cond1_data.shape[0])\n",
    "                    cond2_sem = np.nanstd(cond2_data, axis=0).squeeze() / np.sqrt(cond2_data.shape[0])\n",
    "\n",
    "                    # Determine color and linestyle\n",
    "                    cond1_label = f'{cond1}'\n",
    "                    cond2_label = f'{cond2}'\n",
    "                    cond1_color = colors.get(group_name, 'black')\n",
    "                    cond2_color = colors.get(group_name, 'black')\n",
    "                    cond1_linestyle = linestyles.get(f'{cond1}', '-')\n",
    "                    cond2_linestyle = linestyles.get(f'{cond2}', '--')\n",
    "\n",
    "                    # Plot the mean measurements against time\n",
    "                    ax[jj].plot(times, cond1_mean, label=cond1_label, color=cond1_color, linestyle=cond1_linestyle)\n",
    "                    ax[jj].plot(times, cond2_mean, label=cond2_label, color=cond2_color, linestyle=cond2_linestyle)\n",
    "                    \n",
    "                    # Add error bar shading\n",
    "                    ax[jj].fill_between(times, cond1_mean - cond1_sem, cond1_mean + cond1_sem, alpha=0.2, color=cond1_color)\n",
    "                    ax[jj].fill_between(times, cond2_mean - cond2_sem, cond2_mean + cond2_sem, alpha=0.2, color=cond2_color)\n",
    "\n",
    "                    ax[jj].set_title(f'{chan}')\n",
    "                    ax[jj].legend()\n",
    "\n",
    "                fig.suptitle(f'{roi} {group_name.capitalize()} conditions - Plot {plot_index}')\n",
    "                plt.tight_layout()\n",
    "                plt.subplots_adjust(top=0.95)  # Adjust title space\n",
    "                plt.savefig(os.path.join(save_dir, f'{roi}_{group_name}_single_channel_power_traces_plot_{plot_index}.png'))\n",
    "                plt.close()\n",
    "                plot_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the raw cognitive control conditions for each electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conditions == stimulus_experiment_conditions:\n",
    "    for roi in rois:\n",
    "        # Extract the relevant data from the dictionary\n",
    "        chan_names = dat[roi]['channel_names']\n",
    "        data = dat[roi]['data']\n",
    "        cond_idx = dat[roi]['cond_idx']\n",
    "        times = dat[roi]['times']\n",
    "        cond_names = [x for x in dat[roi]['condition_names'].keys()]\n",
    "\n",
    "        # Split condition names to get big letter, small letter, and task info\n",
    "        congruency_congruency_proportion = np.array([cond_name.split('/')[1] for cond_name in cond_names])\n",
    "        switch_type_switch_proportion = np.array([cond_name.split('/')[2] for cond_name in cond_names])\n",
    "\n",
    "        # Dynamically determine the groups based on unique entries\n",
    "        unique_congruency_congruency_proportions = np.unique(congruency_congruency_proportion)\n",
    "        unique_switch_type_switch_proportions = np.unique(switch_type_switch_proportion)\n",
    "\n",
    "        groups = {\n",
    "            'congruency_congruency_proportion': unique_congruency_congruency_proportions,\n",
    "            'switch_type_switch_proportion': unique_switch_type_switch_proportions\n",
    "        }\n",
    "\n",
    "        # Loop over each group\n",
    "        for group_name, unique_entries in groups.items():\n",
    "            # Ensure there are exactly two unique entries for each group\n",
    "            if len(unique_entries) != 4:\n",
    "                raise ValueError(f\"Expected exactly 4 unique entries for {group_name}, but got {len(unique_entries)}\")\n",
    "\n",
    "            cond1, cond2, cond3, cond4 = unique_entries\n",
    "\n",
    "            # Initialize plot index\n",
    "            plot_index = 1\n",
    "\n",
    "            # Loop over each channel in chunks of 16\n",
    "            for start_idx in range(0, len(chan_names), 16):\n",
    "                fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
    "                ax = ax.flatten()\n",
    "\n",
    "                # Loop over the current chunk of channels\n",
    "                for jj, chan_idx in enumerate(range(start_idx, min(start_idx + 16, len(chan_names)))):\n",
    "                    chan = chan_names[chan_idx]\n",
    "\n",
    "                    # Find condition indices for each group\n",
    "                    if group_name == 'congruency_congruency_proportion':\n",
    "                        cond1_indices = np.where(congruency_congruency_proportion == cond1)[0]\n",
    "                        cond2_indices = np.where(congruency_congruency_proportion == cond2)[0]\n",
    "                        cond3_indices = np.where(congruency_congruency_proportion == cond3)[0]\n",
    "                        cond4_indices = np.where(congruency_congruency_proportion == cond4)[0]\n",
    "                    elif group_name == 'switch_type_switch_proportion':\n",
    "                        cond1_indices = np.where(switch_type_switch_proportion == cond1)[0]\n",
    "                        cond2_indices = np.where(switch_type_switch_proportion == cond2)[0]\n",
    "                        cond3_indices = np.where(switch_type_switch_proportion == cond3)[0]\n",
    "                        cond4_indices = np.where(switch_type_switch_proportion == cond4)[0]\n",
    "                        \n",
    "                    # Compute the mean and SEM for each condition\n",
    "                    cond1_data = data[np.isin(cond_idx, cond1_indices), chan_idx, :]\n",
    "                    cond2_data = data[np.isin(cond_idx, cond2_indices), chan_idx, :]\n",
    "                    cond3_data = data[np.isin(cond_idx, cond3_indices), chan_idx, :]\n",
    "                    cond4_data = data[np.isin(cond_idx, cond4_indices), chan_idx, :]\n",
    "                    cond1_mean = np.nanmean(cond1_data, axis=0).squeeze()\n",
    "                    cond2_mean = np.nanmean(cond2_data, axis=0).squeeze()\n",
    "                    cond3_mean = np.nanmean(cond3_data, axis=0).squeeze()\n",
    "                    cond4_mean = np.nanmean(cond4_data, axis=0).squeeze()\n",
    "                    cond1_sem = np.nanstd(cond1_data, axis=0).squeeze() / np.sqrt(cond1_data.shape[0])\n",
    "                    cond2_sem = np.nanstd(cond2_data, axis=0).squeeze() / np.sqrt(cond2_data.shape[0])\n",
    "                    cond3_sem = np.nanstd(cond3_data, axis=0).squeeze() / np.sqrt(cond3_data.shape[0])\n",
    "                    cond4_sem = np.nanstd(cond4_data, axis=0).squeeze() / np.sqrt(cond4_data.shape[0])\n",
    "\n",
    "                    # Determine color and linestyle\n",
    "                    cond1_label = f'{cond1}'\n",
    "                    cond2_label = f'{cond2}'\n",
    "                    cond3_label = f'{cond3}'\n",
    "                    cond4_label = f'{cond4}'\n",
    "                    cond1_color = colors.get(cond1, 'black')\n",
    "                    cond2_color = colors.get(cond2, 'black')\n",
    "                    cond3_color = colors.get(cond3, 'black')\n",
    "                    cond4_color = colors.get(cond4, 'black')\n",
    "                    cond1_linestyle = linestyles.get(f'{cond1}', '-')\n",
    "                    cond2_linestyle = linestyles.get(f'{cond2}', '--')\n",
    "                    cond3_linestyle = linestyles.get(f'{cond3}', '-')\n",
    "                    cond4_linestyle = linestyles.get(f'{cond4}', '--')\n",
    "\n",
    "                    # Plot the mean measurements against time\n",
    "                    ax[jj].plot(times, cond1_mean, label=cond1_label, color=cond1_color, linestyle=cond1_linestyle)\n",
    "                    ax[jj].plot(times, cond2_mean, label=cond2_label, color=cond2_color, linestyle=cond2_linestyle)\n",
    "                    ax[jj].plot(times, cond3_mean, label=cond3_label, color=cond3_color, linestyle=cond3_linestyle)\n",
    "                    ax[jj].plot(times, cond4_mean, label=cond4_label, color=cond4_color, linestyle=cond4_linestyle)\n",
    "                    \n",
    "                    # Add error bar shading\n",
    "                    ax[jj].fill_between(times, cond1_mean - cond1_sem, cond1_mean + cond1_sem, alpha=0.2, color=cond1_color)\n",
    "                    ax[jj].fill_between(times, cond2_mean - cond2_sem, cond2_mean + cond2_sem, alpha=0.2, color=cond2_color)\n",
    "                    ax[jj].fill_between(times, cond3_mean - cond3_sem, cond3_mean + cond3_sem, alpha=0.2, color=cond3_color)\n",
    "                    ax[jj].fill_between(times, cond4_mean - cond4_sem, cond4_mean + cond4_sem, alpha=0.2, color=cond4_color)\n",
    "\n",
    "                    ax[jj].set_title(f'{chan}')\n",
    "                    ax[jj].legend()\n",
    "\n",
    "                fig.suptitle(f'{roi} {group_name.capitalize()} conditions - Plot {plot_index}')\n",
    "                plt.tight_layout()\n",
    "                plt.subplots_adjust(top=0.95)  # Adjust title space\n",
    "                plt.savefig(os.path.join(save_dir, f'{roi}_{group_name}_single_channel_amplitude_traces_plot_{plot_index}.png'))\n",
    "                plt.close()\n",
    "                plot_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot the cognitive control conditions but grouped by congruency or switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conditions == stimulus_experiment_conditions:\n",
    "    for roi in rois:\n",
    "        # Extract the relevant data from the dictionary\n",
    "        chan_names = dat[roi]['channel_names']\n",
    "        data = dat[roi]['data']\n",
    "        cond_idx = dat[roi]['cond_idx']\n",
    "        times = dat[roi]['times']\n",
    "        cond_names = [x for x in dat[roi]['condition_names'].keys()]\n",
    "\n",
    "        congruency = np.array(['c' if 'c' in cond_name.split('/')[1] else 'i' for cond_name in cond_names])\n",
    "        switch_type = np.array(['s' if 's' in cond_name.split('/')[2] else 'r' for cond_name in cond_names])\n",
    "\n",
    "        # Define groups\n",
    "        groups = {\n",
    "            'congruency': congruency,\n",
    "            'switchType': switch_type\n",
    "        }\n",
    "\n",
    "        # Loop over each group\n",
    "        for group_name, group_values in groups.items():\n",
    "            unique_entries = np.unique(group_values)\n",
    "\n",
    "            # Ensure there are exactly two unique entries for each group\n",
    "            if len(unique_entries) != 2:\n",
    "                raise ValueError(f\"Expected exactly 2 unique entries for {group_name}, but got {len(unique_entries)}\")\n",
    "\n",
    "            cond1, cond2 = unique_entries\n",
    "\n",
    "            # Initialize plot index\n",
    "            plot_index = 1\n",
    "\n",
    "            # Loop over each channel in chunks of 16\n",
    "            for start_idx in range(0, len(chan_names), 16):\n",
    "                fig, ax = plt.subplots(4, 4, figsize=(20, 20))\n",
    "                ax = ax.flatten()\n",
    "\n",
    "                # Loop over the current chunk of channels\n",
    "                for jj, chan_idx in enumerate(range(start_idx, min(start_idx + 16, len(chan_names)))):\n",
    "                    chan = chan_names[chan_idx]\n",
    "\n",
    "                    # Find condition indices for each group\n",
    "                    cond1_indices = np.where(group_values == cond1)[0]\n",
    "                    cond2_indices = np.where(group_values == cond2)[0]\n",
    "\n",
    "                    # Compute the mean and SEM for each condition\n",
    "                    cond1_data = data[np.isin(cond_idx, cond1_indices), chan_idx, :]\n",
    "                    cond2_data = data[np.isin(cond_idx, cond2_indices), chan_idx, :]\n",
    "                    cond1_mean = np.nanmean(cond1_data, axis=0).squeeze()\n",
    "                    cond2_mean = np.nanmean(cond2_data, axis=0).squeeze()\n",
    "                    cond1_sem = np.nanstd(cond1_data, axis=0).squeeze() / np.sqrt(cond1_data.shape[0])\n",
    "                    cond2_sem = np.nanstd(cond2_data, axis=0).squeeze() / np.sqrt(cond2_data.shape[0])\n",
    "\n",
    "                    # Determine color and linestyle\n",
    "                    cond1_label = f'{cond1}'\n",
    "                    cond2_label = f'{cond2}'\n",
    "                    cond1_color = colors.get(group_name, 'black')\n",
    "                    cond2_color = colors.get(group_name, 'black')\n",
    "                    cond1_linestyle = linestyles.get(f'{cond1}', '-')\n",
    "                    cond2_linestyle = linestyles.get(f'{cond2}', '--')\n",
    "\n",
    "                    # Plot the mean measurements against time\n",
    "                    ax[jj].plot(times, cond1_mean, label=cond1_label, color=cond1_color, linestyle=cond1_linestyle)\n",
    "                    ax[jj].plot(times, cond2_mean, label=cond2_label, color=cond2_color, linestyle=cond2_linestyle)\n",
    "                    \n",
    "                    # Add error bar shading\n",
    "                    ax[jj].fill_between(times, cond1_mean - cond1_sem, cond1_mean + cond1_sem, alpha=0.2, color=cond1_color)\n",
    "                    ax[jj].fill_between(times, cond2_mean - cond2_sem, cond2_mean + cond2_sem, alpha=0.2, color=cond2_color)\n",
    "\n",
    "                    ax[jj].set_title(f'{chan}')\n",
    "                    ax[jj].legend()\n",
    "\n",
    "                fig.suptitle(f'{roi} {group_name.capitalize()} conditions - Plot {plot_index}')\n",
    "                plt.tight_layout()\n",
    "                plt.subplots_adjust(top=0.95)  # Adjust title space\n",
    "                plt.savefig(os.path.join(save_dir, f'{roi}_{group_name}_single_channel_amplitude_traces_plot_{plot_index}.png'))\n",
    "                plt.close()\n",
    "                plot_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn the amplitude trace plotting into a function 7/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare conditions and save the plots\n",
    "\n",
    "def compare_conditions_and_save(dat, rois, save_dir, colors, linestyles, conditions_to_be_plotted, metric_type='amplitude'):\n",
    "    \"\"\"\n",
    "    Compare conditions within specified ROIs and save the resulting plots.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dat : dict\n",
    "        Dictionary containing data for different regions of interest (ROIs). \n",
    "        Each ROI should have associated 'channel_names', 'data', 'cond_idx', \n",
    "        'times', and 'condition_names'.\n",
    "\n",
    "    rois : list of str\n",
    "        List of regions of interest (ROIs) to be analyzed and plotted.\n",
    "\n",
    "    save_dir : str\n",
    "        Directory where the plots will be saved.\n",
    "\n",
    "    colors : dict\n",
    "        Dictionary mapping condition labels to colors for plotting.\n",
    "\n",
    "    linestyles : dict\n",
    "        Dictionary mapping condition names to line styles for plotting.\n",
    "\n",
    "    conditions_to_be_plotted : dict\n",
    "        Dictionary specifying the conditions to be plotted for each label. \n",
    "        The keys represent the label, and the values are dictionaries where \n",
    "        keys are condition names and values are lists of strings that identify \n",
    "        the conditions to be grouped.\n",
    "\n",
    "    metric_type : str, optional\n",
    "        Specifies the metric to be plotted. Can be 'amplitude' or 'power'. \n",
    "        Default is 'amplitude'. If 'power' is selected, the amplitude data \n",
    "        will be squared before plotting.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        The function saves the plots to the specified directory and does not \n",
    "        return any values.\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function assumes that the input `dat` dictionary has the necessary \n",
    "      structure, with each ROI containing its own data, condition indices, and \n",
    "      condition names.\n",
    "    - The y-axis of the plots will be labeled 'Z-score amplitude' for amplitude \n",
    "      data and 'Power' for power data.\n",
    "    - The plots will be saved with filenames that reflect the ROI, condition \n",
    "      label, and whether amplitude or power was plotted.\n",
    "    \"\"\"\n",
    "    for roi in rois:\n",
    "        # Extract the relevant data for the current ROI\n",
    "        roi_chan_names = dat[roi]['channel_names']\n",
    "        roi_data = dat[roi]['data']\n",
    "        roi_cond_idx = dat[roi]['cond_idx']\n",
    "        roi_times = dat[roi]['times']\n",
    "        roi_cond_names = [x for x in dat[roi]['condition_names'].keys()]\n",
    "\n",
    "        for label, condition_dict in conditions_to_be_plotted.items():\n",
    "            plt.figure(figsize=(12,6))\n",
    "            for cond_name, cond_values in condition_dict.items():\n",
    "                if isinstance(cond_values, str):\n",
    "                    cond_values = [cond_values]\n",
    "                    \n",
    "                # Group condition indices by whether they contain any of the specified strings in the list\n",
    "                conditions = [name for name in roi_cond_names if any(c in name for c in cond_values)]\n",
    "                condition_indices = [dat[roi]['condition_names'][name] for name in conditions]\n",
    "\n",
    "                # Calculate the mean and standard error over conditions for each group\n",
    "                condition_data = np.concatenate([roi_data[roi_cond_idx == idx, :, :] for idx in condition_indices], axis=0)\n",
    "\n",
    "                if metric_type == 'power':\n",
    "                    # Convert amplitude to power\n",
    "                    condition_data = condition_data ** 2\n",
    "\n",
    "                # Calculate the mean over trials for each group and channel\n",
    "                mean_condition = np.nanmean(condition_data, axis=0)\n",
    "\n",
    "                # Calculate standard error over the trials for each channel and time point\n",
    "                sem_condition = np.nanstd(condition_data, axis=0, ddof=1) / np.sqrt(condition_data.shape[0])\n",
    "\n",
    "                # Average the mean and SEM across channels for plotting\n",
    "                mean_condition = np.nanmean(mean_condition, axis=0)\n",
    "                sem_condition = np.nanmean(sem_condition, axis=0)\n",
    "\n",
    "                # Plot the results with standard error shading\n",
    "                plt.plot(roi_times, mean_condition, label=cond_name, color=colors[label], linestyle=linestyles[cond_name])\n",
    "                plt.fill_between(roi_times, mean_condition - sem_condition, mean_condition + sem_condition, color=colors[label], alpha=0.3)\n",
    "\n",
    "            plt.xlabel('Time from Stim Onset (s)')\n",
    "            plt.ylabel('Z-score power' if metric_type == 'power' else 'Z-score amplitude')\n",
    "            plt.title(f'{roi} Average over conditions')\n",
    "            plt.legend()\n",
    "            plt.ylim([-1, 1])\n",
    "\n",
    "            # Save the figure with the appropriate metric type in the filename\n",
    "            filename = f'{roi}_{label}_rsatoolbox_{metric_type}_plot.png'\n",
    "            plt.savefig(os.path.join(save_dir, filename))\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "save_dir = os.path.join(LAB_root, 'BIDS-1.1_GlobalLocal', 'BIDS', 'derivatives', 'RSA', 'figs')\n",
    "print(save_dir)\n",
    "\n",
    "if conditions == stimulus_conditions:\n",
    "    conditions_to_be_plotted = {\n",
    "        'bigLetter': {'big letter S': 'BigLetters', 'big letter H': 'BigLetterh'},\n",
    "        'smallLetter': {'small letter S': 'SmallLetters', 'small letter H': 'SmallLetterh'},\n",
    "        'task': {'task G': 'Taskg', 'task L': 'Taskl'},\n",
    "    }\n",
    "elif conditions == stimulus_experiment_conditions:\n",
    "\n",
    "    conditions_to_be_plotted = {\n",
    "        'congruency': {'congruent': ['c25', 'c75'], 'incongruent': ['i25', 'i75']},\n",
    "        'switchType': {'switch': ['s25', 's75'], 'repeat': ['r25', 'r75']}\n",
    "    }\n",
    "\n",
    "compare_conditions_and_save(dat, rois, save_dir, colors, linestyles, conditions_to_be_plotted, metric_type='power')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up TemporalDataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_datasets = {}\n",
    "\n",
    "for roi in rois:\n",
    "    measurements = dat[roi]['data']\n",
    "    des = {'roi': roi}\n",
    "    obs_des = {'cond_idx': dat[roi]['cond_idx'], 'sub_idx': dat[roi]['sub_idx']}\n",
    "    chn_des = {'channel_names': dat[roi]['channel_names'], 'channel_rois': dat[roi]['channel_rois']}\n",
    "    tim_des = {'time': dat[roi]['times']}\n",
    "\n",
    "    temporal_datasets[roi] = rsatoolbox.data.TemporalDataset(measurements, \n",
    "                                             descriptors = des, \n",
    "                                             obs_descriptors = obs_des, \n",
    "                                             channel_descriptors = chn_des,\n",
    "                                             time_descriptors = tim_des)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bin the times, untested function method 8/21. Commented code is no function method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_bins(time_points, bin_size=0.1):\n",
    "    \"\"\"\n",
    "    Create time bins from the given time points array.\n",
    "\n",
    "    Parameters:\n",
    "    - time_points: 1D numpy array of time points.\n",
    "    - bin_size: The size of each time bin in seconds (default is 0.1s, which is 100 ms).\n",
    "\n",
    "    Returns:\n",
    "    - bins: A list of numpy arrays, where each array contains the time points within that bin.\n",
    "    \"\"\"\n",
    "    bins = []\n",
    "    start_time = np.min(time_points)\n",
    "    end_time = np.max(time_points)\n",
    "    current_time = start_time\n",
    "    \n",
    "    while current_time < end_time:\n",
    "        next_time = current_time + bin_size\n",
    "        if next_time > end_time:\n",
    "            next_time = end_time\n",
    "        bins.append(time_points[(time_points >= current_time) & (time_points < next_time)])\n",
    "        current_time = next_time\n",
    "\n",
    "    # Ensure that the last bin includes the endpoint\n",
    "    if time_points[-1] not in bins[-1]:\n",
    "        bins[-1] = np.append(bins[-1], time_points[-1])\n",
    "\n",
    "    return bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming temporal_datasets is a dictionary\n",
    "first_roi = next(iter(temporal_datasets.keys()))\n",
    "time_points = temporal_datasets[first_roi].time_descriptors['time']\n",
    "\n",
    "# Create time bins\n",
    "bins = create_time_bins(time_points, bin_size=0.1)\n",
    "\n",
    "\n",
    "# # Define the bins: 100 ms each\n",
    "# bin_size = 0.1  # 100 ms\n",
    "# bins = []\n",
    "\n",
    "# # Find the start and end times from the time_points array\n",
    "# start_time = np.min(time_points)\n",
    "# end_time = np.max(time_points)\n",
    "\n",
    "# current_time = start_time\n",
    "# while current_time < end_time:\n",
    "#     next_time = current_time + bin_size\n",
    "#     if next_time > end_time:\n",
    "#         next_time = end_time\n",
    "#     bins.append(time_points[(time_points >= current_time) & (time_points < next_time)])\n",
    "#     current_time = next_time\n",
    "\n",
    "# # Ensure that the last bin includes the endpoint\n",
    "# if time_points[-1] not in bins[-1]:\n",
    "#     bins[-1] = np.append(bins[-1], time_points[-1])\n",
    "\n",
    "\n",
    "# print(\"First bin:\", bins[0])\n",
    "# print(\"Last bin:\", bins[-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try make rdm (just do occ for testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average the dissimilarities in whatever groups you want (i.e., congruent vs congruent, incongruent vs congruent, incongruent vs incongruent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rdms_occ_data = calc_rdm_movie(temporal_datasets['occ'], method='correlation', descriptor='cond_idx', bins=bins, unbalanced=True)\n",
    "\n",
    "neural_rdms = {}\n",
    "\n",
    "for roi in rois:\n",
    "    # try method='rho-a' and update the save_name  to include rho-a\n",
    "    neural_rdms[roi] = calc_rdm_movie(temporal_datasets[roi], method='correlation', descriptor='cond_idx', bins=bins, unbalanced=True)\n",
    "\n",
    "    plt.figure(figsize=(10,15))\n",
    "\n",
    "    # add formatted time as rdm_descriptor\n",
    "    neural_rdms[roi].rdm_descriptors['time_formatted'] = ['%0.0f ms' % (np.round(x*1000,2)) for x in neural_rdms[roi].rdm_descriptors['time']]\n",
    "\n",
    "    show_rdm(neural_rdms[roi], \n",
    "                    pattern_descriptor='cond_idx',\n",
    "                    rdm_descriptor='time_formatted', \n",
    "                    vmin=-1, vmax=1,\n",
    "                    show_colorbar='figure')\n",
    "    \n",
    "    if conditions == stimulus_conditions:\n",
    "        save_name = f'rsatoolbox_stim_locked_visual_rdms_{roi}.png'\n",
    "    elif conditions == stimulus_experiment_conditions:\n",
    "        save_name = f'rsatoolbox_stim_locked_cog_control_rdms_{roi}.png'\n",
    "\n",
    "    plt.savefig(os.path.join(save_dir, save_name))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate the neural rdms into its different comparisons and plot over time 7/29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each integer\n",
    "unique, counts = np.unique(dat['lpfc']['cond_idx'], return_counts=True)\n",
    "counts_dict = dict(zip(unique, counts))\n",
    "\n",
    "# Print the counts\n",
    "counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_conditions = {}\n",
    "\n",
    "if conditions == stimulus_conditions:\n",
    "    big_letter = np.array([condition_name.split('/')[1] for condition_name in condition_names])\n",
    "    small_letter = np.array([condition_name.split('/')[2] for condition_name in condition_names])\n",
    "    task = np.array([condition_name.split('/')[3] for condition_name in condition_names])\n",
    "\n",
    "    colored_conditions['big_letter'] = big_letter\n",
    "    colored_conditions['small_letter'] = small_letter\n",
    "    colored_conditions['task'] = task\n",
    "\n",
    "if conditions == stimulus_experiment_conditions:\n",
    "    congruency = np.array(['c' if 'c' in cond_name.split('/')[1] else 'i' for cond_name in cond_names])\n",
    "    switch_type = np.array(['s' if 's' in cond_name.split('/')[2] else 'r' for cond_name in cond_names])\n",
    "\n",
    "    colored_conditions['congruency'] = congruency\n",
    "    colored_conditions['switch_type'] = switch_type\n",
    "\n",
    "for roi in rois:\n",
    "    for colored_condition_name, data in colored_conditions.items():\n",
    "        fig, ax = plot_timecourse(\n",
    "            neural_rdms[roi], \n",
    "            descriptor='cond_idx', \n",
    "            n_t_display=10, \n",
    "            fig_width=20,\n",
    "            colored_conditions=data\n",
    "        )\n",
    "\n",
    "        # Ensure `ax` is a list or array of axes\n",
    "        if isinstance(ax, (list, np.ndarray)):\n",
    "            for a in ax:\n",
    "                a.set_ylim([-1, 1])\n",
    "            ax[0].set_title(f'dissimilarity over time in {roi} grouped by {colored_condition_name}')\n",
    "        else:\n",
    "            ax.set_ylim([-1, 1])\n",
    "            ax.set_title(f'dissimilarity over time in {roi} grouped by {colored_condition_name}')\n",
    "        # update this to include rho-a in the save name if i use the rho-a method instead\n",
    "        plt.savefig(os.path.join(save_dir, f'{roi}_{colored_condition_name}_neural_rdm_over_time.png'))\n",
    "        plt.close()\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make model rdms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions\n",
    "def make_model_rdms():\n",
    "    experiment_conditions_list = [\"i25s25\", \"i25s75\", \"i75s25\", \"i75s75\", \"i25r25\", \"i25r75\", \"i75r25\", \"i75r75\",\n",
    "                \"c25s25\", \"c25s75\", \"c75s25\", \"c75s75\", \"c25r25\", \"c25r75\", \"c75r25\", \"c75r75\"]\n",
    "    stimulus_conditions_list = [\"bigSsmallHtaskG\", \"bigSsmallHtaskL\", \"bigSsmallStaskG\", \"bigSsmallStaskL\", \n",
    "                        \"bigHsmallHtaskG\", \"bigHsmallHtaskL\", \"bigHsmallStaskG\", \"bigHsmallStaskL\"]\n",
    "\n",
    "    # Extract specific features from each condition\n",
    "    congruency = [cond[0] for cond in experiment_conditions_list]\n",
    "    switchTypes = [cond[-3] for cond in experiment_conditions_list]\n",
    "    congruencyProportion = [int(cond[1:3]) for cond in experiment_conditions_list]\n",
    "    switchProportion = [int(cond[-2:]) for cond in experiment_conditions_list]\n",
    "\n",
    "    bigLetter = [cond[3] for cond in stimulus_conditions_list]\n",
    "    smallLetter = [cond[9] for cond in stimulus_conditions_list]\n",
    "    task = [cond[-1] for cond in stimulus_conditions_list]\n",
    "\n",
    "    # Number of conditions\n",
    "    e = len(experiment_conditions_list)\n",
    "    s = len(stimulus_conditions_list)\n",
    "\n",
    "    experiment_model_rdms_np = {'congruency': np.ones((e,e)), 'switchType': np.ones((e,e)),\n",
    "                'congruencyProportion': np.ones((e,e)), 'switchProportion': np.ones((e,e)), \n",
    "                'congruency_congruencyProportion': np.ones((e,e)), 'switchType_switchProportion': np.ones((e,e))}\n",
    "\n",
    "    stimulus_model_rdms_np = {'bigLetter': np.ones((s,s)), 'smallLetter': np.ones((s,s)), 'task': np.ones((s,s))}\n",
    "\n",
    "    # Populate RDMs based on feature comparisons for experimental conditions\n",
    "    for i in range(e):\n",
    "        for j in range(e):\n",
    "            if congruency[i] == congruency[j]:\n",
    "                experiment_model_rdms_np['congruency'][i,j] = 0\n",
    "            if switchTypes[i] == switchTypes[j]:\n",
    "                experiment_model_rdms_np['switchType'][i,j] = 0\n",
    "            if congruencyProportion[i] == congruencyProportion[j]:\n",
    "                experiment_model_rdms_np['congruencyProportion'][i,j] = 0\n",
    "            if switchProportion[i] == switchProportion[j]:\n",
    "                experiment_model_rdms_np['switchProportion'][i,j] = 0\n",
    "            if congruency[i] == congruency[j] and congruencyProportion[i] == congruencyProportion[j]:\n",
    "                experiment_model_rdms_np['congruency_congruencyProportion'][i,j] = 0\n",
    "            if switchTypes[i] == switchTypes[j] and switchProportion[i] == switchProportion[j]:\n",
    "                experiment_model_rdms_np['switchType_switchProportion'][i,j] = 0\n",
    "            # if congruency[i] == congruency[j] and switchProportion[i] == switchProportion[j]:\n",
    "            #     model_rdms_np['congruency_switchProportion'][i,j] = 0\n",
    "            # if switchTypes[i] == switchTypes[j] and congruencyProportion[i] == congruencyProportion[j]:\n",
    "            #     model_rdms_np['switchType_congruencyProportion'][i,j] = 0\n",
    "\n",
    "    # make model rdms for stimulus details\n",
    "    for i in range(s):\n",
    "        for j in range(s):\n",
    "            if bigLetter[i] == bigLetter[j]:\n",
    "                stimulus_model_rdms_np['bigLetter'][i,j] = 0\n",
    "            if smallLetter[i] == smallLetter[j]:\n",
    "                stimulus_model_rdms_np['smallLetter'][i,j] = 0\n",
    "            if task[i] == task[j]:\n",
    "                stimulus_model_rdms_np['task'][i,j] = 0\n",
    "                \n",
    "    return experiment_model_rdms_np, stimulus_model_rdms_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_model_rdms_np, stimulus_model_rdms_np = make_model_rdms()\n",
    "\n",
    "experiment_model_rdms_list = []\n",
    "for model_name, model_rdm in experiment_model_rdms_np.items():\n",
    "    experiment_model_rdms_list.append(rsatoolbox.model.ModelFixed(model_name, model_rdm))\n",
    "\n",
    "stimulus_model_rdms_list = []\n",
    "for model_name, model_rdm in stimulus_model_rdms_np.items():\n",
    "    stimulus_model_rdms_list.append(rsatoolbox.model.ModelFixed(model_name, model_rdm)) \n",
    "\n",
    "\n",
    "# stimulus_model_rdms_list[0].name\n",
    "# pred = stimulus_model_rdms_list[0].predict()\n",
    "# pred\n",
    "# # pred = model.predict()\n",
    "# # pred_rdm = model.predict_rdm()\n",
    "\n",
    "# # pred_rdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do model rdm vs neural rdm similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rsa_results(model_rdms_list, neural_rdms, rois, method='corr'):\n",
    "    '''\n",
    "    Compute RSA (Representational Similarity Analysis) results for each ROI using a specified method.\n",
    "\n",
    "    Parameters:\n",
    "    - model_rdms_list (list): List of model RDMs to compare against neural RDMs.\n",
    "    - neural_rdms (dict): Dictionary where keys are ROIs and values are neural RDMs.\n",
    "    - rois (list): List of ROIs to analyze.\n",
    "    - method (str): Method to use for RSA (default is 'corr' for correlation).\n",
    "\n",
    "    Returns:\n",
    "    - rsa_results (dict): Dictionary with ROIs as keys and RSA results as values.\n",
    "    - rsa_results_squeezed (dict): Dictionary with ROIs as keys and RSA results with the 0th dimension squeezed out.\n",
    "    '''\n",
    "    rsa_results = {}\n",
    "    rsa_results_squeezed = {}\n",
    "\n",
    "    for roi in rois:\n",
    "        rsa_results[roi] = rsatoolbox.inference.eval_fixed(model_rdms_list, neural_rdms[roi], method=method)\n",
    "        rsa_results_squeezed[roi] = np.mean(rsa_results[roi].evaluations, axis=0).squeeze()\n",
    "\n",
    "    return rsa_results, rsa_results_squeezed\n",
    "\n",
    "def plot_rsa_results(model_rdms_list, neural_rdms, rsa_results_squeezed, rois, save_dir, models_filename):\n",
    "    '''\n",
    "    Plot RSA results for each ROI and save the plots with the correct model filename.\n",
    "\n",
    "    Parameters:\n",
    "    - model_rdms_list (list): List of model RDMs used in the analysis.\n",
    "    - neural_rdms (dict): Dictionary where keys are ROIs and values are neural RDMs.\n",
    "    - rsa_results_squeezed (dict): Dictionary with ROIs as keys and squeezed RSA results as values.\n",
    "    - rois (list): List of ROIs to plot.\n",
    "    - save_dir (str): Directory where the plots will be saved.\n",
    "    - models_filename (str): Filename to use for saving the plots.\n",
    "    '''\n",
    "    for roi in rois:\n",
    "        \n",
    "        # Create a new plot to avoid any residual plotting issues\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(20, 6))\n",
    "        times = neural_rdms[roi].rdm_descriptors['time'] # this assumes all rois have the same times. Will break if not.\n",
    "\n",
    "        # Plot each model's mean similarity over time\n",
    "        for i, ev in enumerate(rsa_results_squeezed[roi]):\n",
    "            model_name = model_rdms_list[i].name\n",
    "            color = colors.get(model_name, 'black')  # Use black as a default color if not specified\n",
    "            ax.plot(times, ev, color=color, label=f\"model: {model_name}\", linewidth=3)\n",
    "\n",
    "        # Set y-axis limits\n",
    "        ax.set_ylim(-1, 1)\n",
    "\n",
    "        # Set plot labels and legend\n",
    "        ax.legend()\n",
    "        ax.set_ylabel(f'{roi} Neural RDM to Model RDM Similarity (Corr)')\n",
    "        ax.set_xlabel('Time')\n",
    "        ax.set_title(f'{roi} Model-Neural Similarity Over Time')\n",
    "\n",
    "        # Construct the filename for saving\n",
    "        filename = f'{roi}_{models_filename}.png'\n",
    "        plt.savefig(os.path.join(save_dir, filename))\n",
    "        plt.close()\n",
    "\n",
    "def get_and_plot_rsa_results(model_rdms_list, neural_rdms, rois, save_dir, models_filename, method='corr'):\n",
    "    '''\n",
    "    Get and plot the RSA results for each ROI and save the plots with the correct model filename.\n",
    "\n",
    "    Parameters:\n",
    "    - model_rdms_list (list): List of model RDMs used in the analysis.\n",
    "    - neural_rdms (dict): Dictionary where keys are ROIs and values are neural RDMs.\n",
    "    - rois (list): List of ROIs to plot.\n",
    "    - save_dir (str): Directory where the plots will be saved.\n",
    "    - models_filename (str): Filename to use for saving the plots.\n",
    "    - method (str): Method to use for RSA (default is 'corr' for correlation).\n",
    "\n",
    "    Returns:\n",
    "    - rsa_results (dict): Dictionary with ROIs as keys and RSA results as values.\n",
    "    - rsa_results_squeezed (dict): Dictionary with ROIs as keys and RSA results with the 0th dimension squeezed out.\n",
    "    '''\n",
    "    rsa_results, rsa_results_squeezed = get_rsa_results(model_rdms_list, neural_rdms, rois, method=method)\n",
    "    plot_rsa_results(model_rdms_list, neural_rdms, rsa_results_squeezed, rois, save_dir, models_filename)\n",
    "    return rsa_results, rsa_results_squeezed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conditions == stimulus_conditions:\n",
    "    models_filename = 'stimulus_models_rsatoolbox_rsa_results'\n",
    "    rsa_results, rsa_results_squeezed = get_and_plot_rsa_results(stimulus_model_rdms_list, neural_rdms, rois, save_dir, models_filename)\n",
    "\n",
    "elif conditions == stimulus_experiment_conditions:\n",
    "    models_filename = 'stimulus_experiment_models_rsatoolbox_rsa_results'\n",
    "    rsa_results, rsa_results_squeezed = get_and_plot_rsa_results(experiment_model_rdms_list, neural_rdms, rois, save_dir, models_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rsatoolbox.vis.plot_model_comparison(stimulus_rsa_results['occ'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debugger_test():\n",
    "    print('line 1')\n",
    "    print('line 2')\n",
    "\n",
    "debugger_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
