{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### working version 12/1/23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try gregs suggestion of using make_data_same to destroy the fixation cross"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from IPython.display import clear_output\n",
        "# clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0094']\n",
        "\n",
        "for sub in subjects:\n",
        "\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "    # fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1), picks=sig_chans) #this line is not finishing...\n",
        "\n",
        "    # fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore_sigChans.png')\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loop through everyone and do congruency "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 225 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 219 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "good channels before dropping bads: 134\n",
            "filt channels before dropping bads: 134\n",
            "outlier round 1 channels: ['ROAM8']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good': ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good' after dropping once: []\n",
            "good channels after dropping bads: 131\n",
            "filt channels after dropping bads: 131\n",
            "Reading 0 ... 3671172  =      0.000 ...  1792.564 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 4097 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [03:09<00:00,  2.36it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "19 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 19 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "8 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 8 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "10 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 10 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "17 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 17 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "63 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 63 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "20 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 20 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "23 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 23 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "60 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 60 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:125: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  all_trials = mne.concatenate_epochs(all_epochs_list)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not setting metadata\n",
            "220 matching events found\n",
            "No baseline correction applied\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 220/220 [02:13<00:00,  1.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HG_ev1 before crop_pad:  -1.5 2.0\n",
            "HG_ev1 after crop_pad:  -1.0 1.5\n",
            "Applying baseline correction (mode: zscore)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:135: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:136: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_ev1.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:138: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:138: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:139: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:139: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Shape of HG_ev1._data: (220, 131, 2561)\n",
            "Shape of HG_base._data: (448, 131, 1025)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:172: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_s25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:175: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_s25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke_rescaled-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of sig1: (220, 131, 2561)\n",
            "Shape of sig2: (448, 131, 1025)\n",
            "Shape of sig3: (448, 131, 1026)\n",
            "Shape of sig4: (448, 131, 1025)\n",
            "Shape of sig5: (448, 131, 2561)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   30.1s\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:   30.4s\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:   30.4s\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   30.5s\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   30.6s\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   30.6s\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:   56.5s\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:   57.0s\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:   57.0s\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:   57.0s\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:   57.1s\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:   57.4s\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed:  7.2min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed:  8.0min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed:  8.3min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  8.3min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=6)]: Done 120 tasks      | elapsed:  8.4min\n",
            "[Parallel(n_jobs=6)]: Done 124 out of 131 | elapsed:  8.8min remaining:   29.6s\n",
            "[Parallel(n_jobs=6)]: Done 128 out of 131 | elapsed:  9.1min remaining:   12.6s\n",
            "[Parallel(n_jobs=6)]: Done 131 out of 131 | elapsed:  9.1min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved channel names and indices to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\channels_D0077_GlobalLocal.txt\n",
            "Saved significant channels for subject D0077 and mask Stimulus_s25and75_fixationCrossBase_1sec_mirror to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\sig_chans_D0077_Stimulus_s25and75_fixationCrossBase_1sec_mirror.json\n",
            "Loaded significant channels for subject D0077\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 225 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 219 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "good channels before dropping bads: 134\n",
            "filt channels before dropping bads: 134\n",
            "outlier round 1 channels: ['ROAM8']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good': ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good' after dropping once: []\n",
            "good channels after dropping bads: 131\n",
            "filt channels after dropping bads: 131\n",
            "Reading 0 ... 3671172  =      0.000 ...  1792.564 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 4097 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [02:53<00:00,  2.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "65 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 65 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "19 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 19 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "18 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 18 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "66 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 66 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "20 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 20 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "8 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 8 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "5 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 5 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "23 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 23 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:293: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  all_trials = mne.concatenate_epochs(all_epochs_list)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not setting metadata\n",
            "224 matching events found\n",
            "No baseline correction applied\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 224/224 [02:05<00:00,  1.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HG_ev1 before crop_pad:  -1.5 2.0\n",
            "HG_ev1 after crop_pad:  -1.0 1.5\n",
            "Applying baseline correction (mode: zscore)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:303: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:304: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_ev1.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:306: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:306: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:307: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:307: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Shape of HG_ev1._data: (224, 131, 2561)\n",
            "Shape of HG_base._data: (448, 131, 1025)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:340: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_r25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\698385093.py:343: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_r25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke_rescaled-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of sig1: (224, 131, 2561)\n",
            "Shape of sig2: (448, 131, 1025)\n",
            "Shape of sig3: (448, 131, 1026)\n",
            "Shape of sig4: (448, 131, 1025)\n",
            "Shape of sig5: (448, 131, 2561)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   27.0s\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:   27.1s\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:   27.2s\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   27.2s\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   27.3s\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   27.4s\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:   50.6s\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:   50.7s\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:   50.8s\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:   50.9s\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:   51.0s\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:   51.2s\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed:  6.4min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 120 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 124 out of 131 | elapsed:  8.3min remaining:   28.1s\n",
            "[Parallel(n_jobs=6)]: Done 128 out of 131 | elapsed:  8.6min remaining:   12.1s\n",
            "[Parallel(n_jobs=6)]: Done 131 out of 131 | elapsed:  8.7min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved channel names and indices to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\channels_D0077_GlobalLocal.txt\n",
            "Saved significant channels for subject D0077 and mask Stimulus_r25and75_fixationCrossBase_1sec_mirror to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\sig_chans_D0077_Stimulus_r25and75_fixationCrossBase_1sec_mirror.json\n",
            "Loaded significant channels for subject D0077\n"
          ]
        }
      ],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0077']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/s25\", \"Stimulus/c75/s25\", \"Stimulus/i25/s25\", \"Stimulus/c25/s25\", \"Stimulus/i75/s75\", \"Stimulus/c75/s75\", \"Stimulus/i25/s75\", \"Stimulus/c25/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0077']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_r25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/r25\", \"Stimulus/c75/r25\", \"Stimulus/i25/r25\", \"Stimulus/c25/r25\", \"Stimulus/i75/r75\", \"Stimulus/c75/r75\", \"Stimulus/i25/r75\", \"Stimulus/c25/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 225 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 219 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "good channels before dropping bads: 134\n",
            "filt channels before dropping bads: 134\n",
            "outlier round 1 channels: ['ROAM8']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good': ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good' after dropping once: []\n",
            "good channels after dropping bads: 131\n",
            "filt channels after dropping bads: 131\n",
            "Reading 0 ... 3671172  =      0.000 ...  1792.564 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 4097 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [02:52<00:00,  2.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "168 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 168 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "56 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 56 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:125: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  all_trials = mne.concatenate_epochs(all_epochs_list)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not setting metadata\n",
            "224 matching events found\n",
            "No baseline correction applied\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 224/224 [02:03<00:00,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HG_ev1 before crop_pad:  -1.5 2.0\n",
            "HG_ev1 after crop_pad:  -1.0 1.5\n",
            "Applying baseline correction (mode: zscore)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:135: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:136: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_ev1.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:138: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:138: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:139: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:139: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:172: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting existing file.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:175: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke_rescaled-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of HG_ev1._data: (224, 131, 2561)\n",
            "Shape of HG_base._data: (448, 131, 1025)\n",
            "Shape of sig1: (224, 131, 2561)\n",
            "Shape of sig2: (448, 131, 1025)\n",
            "Shape of sig3: (448, 131, 1026)\n",
            "Shape of sig4: (448, 131, 1025)\n",
            "Shape of sig5: (448, 131, 2561)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   26.5s\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:   26.6s\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   26.8s\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   26.9s\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   27.1s\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:   49.3s\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:   49.5s\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:   49.7s\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:   49.8s\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:   49.9s\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:   50.3s\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  2.7min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed:  6.2min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 120 tasks      | elapsed:  7.9min\n",
            "[Parallel(n_jobs=6)]: Done 124 out of 131 | elapsed:  8.2min remaining:   27.7s\n",
            "[Parallel(n_jobs=6)]: Done 128 out of 131 | elapsed:  8.5min remaining:   11.9s\n",
            "[Parallel(n_jobs=6)]: Done 131 out of 131 | elapsed:  8.6min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved channel names and indices to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\channels_D0077_GlobalLocal.txt\n",
            "Saved significant channels for subject D0077 and mask Stimulus_c25and75_fixationCrossBase_1sec_mirror to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\sig_chans_D0077_Stimulus_c25and75_fixationCrossBase_1sec_mirror.json\n",
            "Loaded significant channels for subject D0077\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 225 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0077\\ieeg\\sub-D0077_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 219 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (135) does not match the number of channels in the raw data file (134). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "good channels before dropping bads: 134\n",
            "filt channels before dropping bads: 134\n",
            "outlier round 1 channels: ['ROAM8']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1']\n",
            "outlier round 2 channels: ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good': ['ROAM8', 'RTAM1', 'ROPM7']\n",
            "Bad channels in 'good' after dropping once: []\n",
            "good channels after dropping bads: 131\n",
            "filt channels after dropping bads: 131\n",
            "Reading 0 ... 3671172  =      0.000 ...  1792.564 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 4097 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [02:54<00:00,  2.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "56 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 56 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "168 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 168 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:293: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  all_trials = mne.concatenate_epochs(all_epochs_list)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not setting metadata\n",
            "224 matching events found\n",
            "No baseline correction applied\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 224/224 [02:02<00:00,  1.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HG_ev1 before crop_pad:  -1.5 2.0\n",
            "HG_ev1 after crop_pad:  -1.0 1.5\n",
            "Applying baseline correction (mode: zscore)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:303: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:304: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_ev1.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:306: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:306: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:307: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:307: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Overwriting existing file.\n",
            "Shape of HG_ev1._data: (224, 131, 2561)"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:340: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_17268\\3187175733.py:343: RuntimeWarning: This filename (C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1_evoke_rescaled-epo.fif) does not conform to MNE naming conventions. All evoked files should end with -ave.fif, -ave.fif.gz, _ave.fif or _ave.fif.gz\n",
            "  HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of HG_base._data: (448, 131, 1025)\n",
            "Shape of sig1: (224, 131, 2561)\n",
            "Shape of sig2: (448, 131, 1025)\n",
            "Shape of sig3: (448, 131, 1026)\n",
            "Shape of sig4: (448, 131, 1025)\n",
            "Shape of sig5: (448, 131, 2561)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   27.1s\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:   27.2s\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:   27.2s\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   27.2s\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   27.2s\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   27.4s\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:   50.2s\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:   50.3s\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:   50.4s\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:   50.4s\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:   50.5s\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:   50.6s\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  1.2min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  1.6min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  3.2min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  3.6min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  4.0min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:  5.9min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed:  7.0min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:  7.1min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed:  7.5min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 120 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 124 out of 131 | elapsed:  8.2min remaining:   27.7s\n",
            "[Parallel(n_jobs=6)]: Done 128 out of 131 | elapsed:  8.5min remaining:   11.9s\n",
            "[Parallel(n_jobs=6)]: Done 131 out of 131 | elapsed:  8.5min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved channel names and indices to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\channels_D0077_GlobalLocal.txt\n",
            "Saved significant channels for subject D0077 and mask Stimulus_i25and75_fixationCrossBase_1sec_mirror to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\sig_chans_D0077_Stimulus_i25and75_fixationCrossBase_1sec_mirror.json\n",
            "Loaded significant channels for subject D0077\n"
          ]
        }
      ],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0077']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25\", \"Stimulus/c75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0077']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25\", \"Stimulus/i75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### do interaction effects (is, ir, cs, cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0071', 'D0077', 'D0090', 'D0094']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_is_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/s25\", \"Stimulus/i25/s75\", \"Stimulus/i75/s25\", \"Stimulus/i75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0071', 'D0077', 'D0090', 'D0094']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_ir_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/r25\", \"Stimulus/i25/r75\", \"Stimulus/i75/r25\", \"Stimulus/i75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0071', 'D0077', 'D0090', 'D0094']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cs_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/s25\", \"Stimulus/c25/s75\", \"Stimulus/c75/s25\", \"Stimulus/c75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0071', 'D0077', 'D0090', 'D0094']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cr_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/r25\", \"Stimulus/c25/r75\", \"Stimulus/c75/r25\", \"Stimulus/c75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to load in previously generated hg ev1 and hg base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load HG_ev1\n",
        "loaded_HG_ev1 = mne.read_epochs(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif')\n",
        "\n",
        "# Load HG_base\n",
        "loaded_HG_base = mne.read_epochs(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot each significant channel with its trace and timepoints of significance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# print(sys.path)\n",
        "# sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "# from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "#     outliers_to_nan\n",
        "# from ieeg.io import raw_from_layout, get_data\n",
        "# from ieeg.timefreq.utils import crop_pad\n",
        "# from ieeg.timefreq import gamma\n",
        "# from ieeg.calc.scaling import rescale\n",
        "# import mne\n",
        "# import os\n",
        "# import numpy as np\n",
        "# from ieeg.calc.reshape import make_data_same\n",
        "# from ieeg.calc.stats import time_perm_cluster\n",
        "\n",
        "# from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# subjects = ['D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
        "\n",
        "# for sub in subjects:\n",
        "#     # sub = 'D0057'\n",
        "#     task = 'GlobalLocal'\n",
        "#     output_name = \"Stimulus_fixationCrossBase_1sec_mirror\"\n",
        "#     events = [\"Stimulus\"]\n",
        "#     times = (-1,1.5)\n",
        "#     base_times = [-1,0]\n",
        "#     LAB_root = None\n",
        "#     channels = None\n",
        "#     full_trial_base = False\n",
        "\n",
        "#     if LAB_root is None:\n",
        "#         HOME = os.path.expanduser(\"~\")\n",
        "#         if os.name == 'nt':  # windows\n",
        "#             LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "#         else:  # mac\n",
        "#             LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "#                                     \"CoganLab\")\n",
        "\n",
        "#     layout = get_data(task, root=LAB_root)\n",
        "#     filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "#                         extension='.edf', desc='clean', preload=False)\n",
        "#     save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "#     if not os.path.exists(save_dir):\n",
        "#         os.makedirs(save_dir)\n",
        "\n",
        "#     good = crop_empty_data(filt)\n",
        "#     # %%\n",
        "\n",
        "#     print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "#     print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "#     good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "#     print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "#     filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "#     good.drop_channels(good.info['bads'])\n",
        "\n",
        "#     print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "#     print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "#     print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "#     good.load_data()\n",
        "\n",
        "#     # If channels is None, use all channels\n",
        "#     if channels is None:\n",
        "#         channels = good.ch_names\n",
        "#     else:\n",
        "#         # Validate the provided channels\n",
        "#         invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "#         if invalid_channels:\n",
        "#             raise ValueError(\n",
        "#                 f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "#         # Use only the specified channels\n",
        "#         good.pick_channels(channels)\n",
        "\n",
        "#     ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "#     good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "#     # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "#     adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "#     trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "#     outliers_to_nan(trials, outliers=10)\n",
        "#     HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "#     crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "#     all_epochs_list = []\n",
        "\n",
        "#     for event in events:\n",
        "#     # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "#         times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "#         trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "#                             reject_by_annotation=False)\n",
        "#         all_epochs_list.append(trials)\n",
        "\n",
        "#     # Concatenate all trials\n",
        "#     all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "#     outliers_to_nan(all_trials, outliers=10)\n",
        "#     HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "#     print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "#     crop_pad(HG_ev1, \"0.5s\")\n",
        "#     print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "#     HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "#     HG_base.decimate(2)\n",
        "#     HG_ev1.decimate(2)\n",
        "\n",
        "#     HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "#     HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "#     HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "#     HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "#     if event == \"Stimulus\":\n",
        "#         print('plotting stimulus')\n",
        "#         fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "#         print('plotted')\n",
        "#         # for ax in fig.axes:\n",
        "#         #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "#         print('about to save')\n",
        "#         fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "#         print('saved')\n",
        "#     else:\n",
        "#         print('about to plot if not stimulus')\n",
        "#         fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "#         print('plotted non stimulus')\n",
        "#         fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "#     ###\n",
        "#     print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "#     print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "#     sig1 = HG_ev1._data\n",
        "#     sig2 = HG_base._data\n",
        "#     sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "#     sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "#     sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "#     print(f\"Shape of sig1: {sig1.shape}\")\n",
        "#     print(f\"Shape of sig2: {sig2.shape}\")\n",
        "#     print(f\"Shape of sig3: {sig3.shape}\")\n",
        "#     print(f\"Shape of sig4: {sig4.shape}\")\n",
        "#     print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "#     sig2 = sig5\n",
        "\n",
        "#     mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "#     fig = plt.figure()\n",
        "#     plt.imshow(mat, aspect='auto')\n",
        "#     fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "#     channels = good.ch_names\n",
        "\n",
        "#     #save channels with their indices \n",
        "#     save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "#     # save significant channels to a json\n",
        "#     save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "#     base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "#     sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
        "#     sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "#     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1), picks=sig_chans) #this line is not finishing...\n",
        "\n",
        "#     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore_sigChans.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ok make greg significance and high gamma combined plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageChops\n",
        "\n",
        "def trim_whitespace(image):\n",
        "    \"\"\"\n",
        "    Trims the whitespace from an image.\n",
        "    \"\"\"\n",
        "    bg = Image.new(image.mode, image.size, image.getpixel((0, 0)))\n",
        "    diff = ImageChops.difference(image, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return image.crop(bbox)\n",
        "    return image  # If no change\n",
        "\n",
        "channel_to_index = {}\n",
        "\n",
        "# maybe make this not so dependent on the previous code...\n",
        "\n",
        "channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') #maybe make this less dependent on previous code?\n",
        "with open(channel_file, 'r') as f:\n",
        "    for line in f:\n",
        "        index, channel = line.strip().split(': ')\n",
        "        channel_to_index[channel] = int(index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### new code that tries to plot 6x6 grid of 36 channels on one plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### z-scored signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming all imports and previous definitions are in place\n",
        "\n",
        "def plot_channels_on_grid(channels_subset):\n",
        "    fig, axes = plt.subplots(6, 10, figsize=(20, 33))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = HG_ev1_evoke_rescaled_stderr.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / 1000  # Assuming 1kHz sample rate\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(HG_ev1_evoke_rescaled.times, HG_ev1_evoke_rescaled.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(HG_ev1_evoke_rescaled.times, HG_ev1_evoke_rescaled.data[channel_to_index[channel], :] - stderr, HG_ev1_evoke_rescaled.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(HG_ev1_evoke_rescaled.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "# Iterate over all channels in chunks of 60 and plot them\n",
        "for i in range(0, len(sig_chans), 60):\n",
        "    channels_subset = channels[i:i+60]\n",
        "    fig = plot_channels_on_grid(channels_subset)\n",
        "    combined_plot_path = os.path.join(save_dir, f'{sub}_zscore_{output_name}_combinedChannelTracesAndSignificance_Page_{i//36 + 1}.png')\n",
        "    fig.savefig(combined_plot_path)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for raw traces, just plot HG_ev1_evoke instead of HG_ev1_evoke_rescaled. And for the standard error, use the HG_ev1_evoke_stderr instead of HG_ev1_evoke_rescaled_stderr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### raw traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming all imports and previous definitions are in place\n",
        "\n",
        "def plot_channels_on_grid(channels_subset):\n",
        "    fig, axes = plt.subplots(6, 10, figsize=(20, 33))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = HG_ev1_evoke_stderr.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / 1000  # Assuming 1kHz sample rate\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :] - stderr, HG_ev1_evoke.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "# Iterate over all channels in chunks of 60 and plot them\n",
        "for i in range(0, len(sig_chans), 60):\n",
        "    channels_subset = channels[i:i+60]\n",
        "    fig = plot_channels_on_grid(channels_subset)\n",
        "    combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndSignificance_Page_{i//36 + 1}.png')\n",
        "    fig.savefig(combined_plot_path)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
