{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### working version 12/1/23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try gregs suggestion of using make_data_same to destroy the fixation cross"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use window stats with perm testing (0 to 0.5, 0.5 to 1, 0 to 1 sec relative to stim onset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans, channel_names_to_indices, \\\n",
        "    filter_and_average_epochs, permutation_test, perform_permutation_test_across_electrodes, \\\n",
        "    perform_permutation_test_within_electrodes, add_accuracy_to_epochs, save_sig_chans_with_reject\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Directory where your .npy files are saved\n",
        "npy_directory = r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\accArrays'  # Replace with your directory path\n",
        "\n",
        "# Dictionary to hold the data\n",
        "acc_array = {}\n",
        "\n",
        "# Iterate over each file in the directory\n",
        "for file in os.listdir(npy_directory):\n",
        "    if file.endswith('.npy'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(npy_directory, file)\n",
        "        # Load the numpy array from the file\n",
        "        acc_array[file.split('_')[0]] = np.load(file_path)\n",
        "\n",
        "# Now you have a dictionary where each key is the subject ID\n",
        "# and the value is the numpy array of accuracies for that subject.\n",
        "        \n",
        "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')\n",
        "\n",
        "# subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
        "subjects = ['D0069']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### after loading in HG_ev1_rescaled, then grab only the correct trials. Think I need to load in combined_data here too?\n",
        "### then load in the perm testing functions (put these into misc functions now that they work, and just load them into roi analysis and this too)\n",
        "###\n",
        "\n",
        "\n",
        "time_windows = {\n",
        "    \"Stimulus_fixationCrossBase_0.2sec_window_0to0.5\": (2048,3072), #do these based on the sample rate, so need to load in filt before looping over windows. Kind of annoying honestly.\n",
        "    \"Stimulus_fixationCrossBase_0.2sec_window_0.5to1\": (3072,4096),\n",
        "    \"Stimulus_fixationCrossBase_0.2sec_window_0to1\": (2048,4096)\n",
        "}\n",
        "\n",
        "for window in time_windows:\n",
        "    for sub in subjects:\n",
        "        start_idx, end_idx = int(time_windows[window][0]), int(time_windows[window][1]) # i think these need to be ints 2/27\n",
        "        task = 'GlobalLocal'\n",
        "        output_name = window #prob turn this into a function where i can set the window length as an input and it'll get added to the output name\n",
        "        events = [\"Stimulus\"]\n",
        "        times = (-1,1.5)\n",
        "        base_times = [-0.2,0]\n",
        "        LAB_root = None\n",
        "        channels = None\n",
        "        full_trial_base = False\n",
        "\n",
        "        if LAB_root is None:\n",
        "            HOME = os.path.expanduser(\"~\")\n",
        "            if os.name == 'nt':  # windows\n",
        "                LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "            else:  # mac\n",
        "                LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                        \"CoganLab\")\n",
        "\n",
        "        layout = get_data(task, root=LAB_root)\n",
        "        filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                            extension='.edf', desc='clean', preload=False)\n",
        "        # Access the sampling frequency\n",
        "        sampling_frequency = filt.info['sfreq']\n",
        "    \n",
        "        # Print the sampling frequency\n",
        "        print(f\"Subject {sub} has a sampling frequency of {sampling_frequency} Hz.\")\n",
        "        \n",
        "        save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        good = crop_empty_data(filt)\n",
        "        # %%\n",
        "\n",
        "        print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "        print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "        good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "        print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "        filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "        good.drop_channels(good.info['bads'])\n",
        "\n",
        "        print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "        print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "        print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "        good.load_data()\n",
        "\n",
        "        # If channels is None, use all channels\n",
        "        if channels is None:\n",
        "            channels = good.ch_names\n",
        "        else:\n",
        "            # Validate the provided channels\n",
        "            invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "            if invalid_channels:\n",
        "                raise ValueError(\n",
        "                    f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "            # Use only the specified channels\n",
        "            good.pick_channels(channels)\n",
        "\n",
        "        ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "        good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "        # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "        adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "        outliers_to_nan(trials, outliers=10)\n",
        "        HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "        crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "        all_epochs_list = []\n",
        "\n",
        "        for event in events:\n",
        "        # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "            times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "            trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                                reject_by_annotation=False)\n",
        "            all_epochs_list.append(trials)\n",
        "\n",
        "        # Concatenate all trials\n",
        "        all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "        outliers_to_nan(all_trials, outliers=10)\n",
        "        HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "        print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "        crop_pad(HG_ev1, \"0.5s\")\n",
        "        print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "        ###\n",
        "        print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "        print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "        # sig1 = HG_ev1._data\n",
        "        # sig2 = HG_base._data\n",
        "        # sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "        # sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "        # sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "        # print(f\"Shape of sig1: {sig1.shape}\")\n",
        "        # print(f\"Shape of sig2: {sig2.shape}\")\n",
        "        # print(f\"Shape of sig3: {sig3.shape}\")\n",
        "        # print(f\"Shape of sig4: {sig4.shape}\")\n",
        "        # print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "        # sig2 = sig5\n",
        "        # # Directly reassign the modified signal data to the HG_base._data attribute (THIS MAY BREAK THINGS BUT ITS CORRECT 2/13)\n",
        "        # HG_base._data = sig2\n",
        "\n",
        "        ### filter for accurate trials in HG ev1 \n",
        "        # Build the filtering condition\n",
        "        sub_without_zeroes = \"D\" + sub[1:].lstrip('0') \n",
        "        sub_behavioral_rows = (combined_data['subject_ID'] == sub_without_zeroes) # this indexes using the subject without zeroes in the name. Confusing. I know.\n",
        "\n",
        "        # Filter combinedData for the specific subject and conditions\n",
        "        sub_behavioral_data = combined_data[sub_behavioral_rows]\n",
        "\n",
        "        if sub in acc_array:\n",
        "            trial_counts = sub_behavioral_data['trialCount'].values.astype(int)\n",
        "            accuracy_data = [acc_array[sub][i-1] for i in trial_counts if i-1 < len(acc_array[sub])] # Subtract 1 here for zero-based indexing in acc array.\n",
        "            \n",
        "            # Now pass trial_counts along with accuracy_data to raw HG_ev1\n",
        "            HG_ev1 = add_accuracy_to_epochs(HG_ev1, accuracy_data)\n",
        "            \n",
        "        # Separate accurate and all trials data\n",
        "        accurate_HG_ev1_data = HG_ev1[HG_ev1.metadata['accuracy'] == 1.0].get_data()\n",
        "        all_HG_ev1_data = HG_ev1.get_data().copy()\n",
        "\n",
        "        # Mark inaccurate trials as NaNs in the all_epochs_data\n",
        "        inaccurate_indices = HG_ev1.metadata['accuracy'] != 1.0\n",
        "        all_HG_ev1_data[inaccurate_indices, :, :] = np.nan\n",
        "        \n",
        "        # do stats stuff here. 2/22 I think we need to do this before we decimate.\n",
        "        # Calculate time average within the specified window\n",
        "        time_avg_signal = np.nanmean(all_HG_ev1_data[:, :, start_idx:end_idx], axis=2) #average across specified time window for data\n",
        "        time_avg_base = np.nanmean(HG_base.get_data().copy()[:,:,:], axis=2) #average across all time for baseline. Use a copy of the baseline so we don't mess it up.\n",
        "        p_values = perform_permutation_test_within_electrodes([time_avg_signal], [time_avg_base], one_tailed=True) #update these functions to not need list inputs later.\n",
        "        reject, p_values_adjusted = multipletests(p_values, alpha=0.05, method='fdr_bh')[:2] # reject is a boolean array of whether each channel passed significance threshold after adjusting for multiple comparisons. Adjusted_p_values are the actual adjusted p values.\n",
        "        # check p_values_adjusted after lab meeting! 2/13\n",
        "\n",
        "        HG_base.decimate(2)\n",
        "        HG_ev1.decimate(2)\n",
        "\n",
        "        HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "        HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "        HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "        HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "        HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        " \n",
        "        # Determine which channels are significant based on the reject array\n",
        "        channels = good.ch_names\n",
        "        save_sig_chans_with_reject(output_name, reject, channels, sub, save_dir)\n",
        "\n",
        "        #save all channels with their indices \n",
        "        save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "        # Save HG_ev1\n",
        "        HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_base\n",
        "        HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_rescaled\n",
        "        HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_evoke\n",
        "        HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_evoke_rescaled\n",
        "        HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use time point cluster stats for determining stimulus significance (old method as of 2/13/24)\n",
        "\n",
        "updated this one 2/29, once it's tested and works, then turn into a function and delete other cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "uncomment things and delete the subjects variable once we get the mat shape 3/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_fixationCrossBase_1sec_mirror_0to1Test\"\n",
        "    events = [\"Stimulus\"]\n",
        "    times = (0,1)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "\n",
        "    sig_chans_filename = os.path.join(save_dir, f'sig_chans_{sub}_{output_name}.json')\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "    # Assuming `mat` is your array and `save_dir` is the directory where you want to save it\n",
        "    mat_save_path = os.path.join(save_dir, f'{output_name}_mat.npy')\n",
        "\n",
        "    # Save the mat array\n",
        "    np.save(mat_save_path, mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loop through everyone and do congruency "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/s25\", \"Stimulus/c75/s25\", \"Stimulus/i25/s25\", \"Stimulus/c25/s25\", \"Stimulus/i75/s75\", \"Stimulus/c75/s75\", \"Stimulus/i25/s75\", \"Stimulus/c25/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_r25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/r25\", \"Stimulus/c75/r25\", \"Stimulus/i25/r25\", \"Stimulus/c25/r25\", \"Stimulus/i75/r75\", \"Stimulus/c75/r75\", \"Stimulus/i25/r75\", \"Stimulus/c25/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_c75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_i75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### do interaction effects (is, ir, cs, cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_is_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/s25\", \"Stimulus/i25/s75\", \"Stimulus/i75/s25\", \"Stimulus/i75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_ir_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/r25\", \"Stimulus/i25/r75\", \"Stimulus/i75/r25\", \"Stimulus/i75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cs_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/s25\", \"Stimulus/c25/s75\", \"Stimulus/c75/s25\", \"Stimulus/c75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cr_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/r25\", \"Stimulus/c25/r75\", \"Stimulus/c75/r25\", \"Stimulus/c75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "do switch type proportions by block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_s75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/s75\", \"Stimulus/i75/s75\", \"Stimulus/c25/s75\", \"Stimulus/c75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_r75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/r75\", \"Stimulus/i75/r75\", \"Stimulus/c25/r75\", \"Stimulus/c75/r75\"]    \n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot each significant channel with its trace and timepoints of significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "first, load in previously generated hg ev1 and hg base for stimulus significance from baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "turn this into a loop over all three time windows and all 12 subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageChops\n",
        "\n",
        "def trim_whitespace(image):\n",
        "    \"\"\"\n",
        "    Trims the whitespace from an image.\n",
        "    \"\"\"\n",
        "    bg = Image.new(image.mode, image.size, image.getpixel((0, 0)))\n",
        "    diff = ImageChops.difference(image, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return image.crop(bbox)\n",
        "    return image  # If no change\n",
        "\n",
        "def plot_channels_on_grid_windows(evoke_data, std_err_data, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim=6, plot_y_dim=6):\n",
        "    \"\"\"\n",
        "    Plots evoked EEG/MEG data for a subset of channels on a grid, overlaying significance markers for specified time windows.\n",
        "\n",
        "    Parameters:\n",
        "    - evoke_data: mne.Evoked object\n",
        "        The evoked data to be plotted. This object contains the averaged EEG/MEG data over epochs.\n",
        "    - std_err_data: \n",
        "        The standard error of the evoked data to be plotted\n",
        "    - channels_subset: list of str\n",
        "        A list of channel names to be plotted. Each channel name must correspond to a channel in `evoke_data`.\n",
        "    - time_windows: dict\n",
        "        A dictionary where keys are strings representing the names of the time windows of interest, and values are tuples\n",
        "        indicating the start and end indices (in samples) of these windows.\n",
        "    - sig_chans: dict\n",
        "        A dictionary where keys are the names of the time windows (matching those in `time_windows`) and values are lists\n",
        "        of channel names (str) that are significant within those windows.\n",
        "    - sample_rate: float\n",
        "        The sampling rate of the data, in Hz. Used to convert sample indices in `time_windows` to time in seconds.\n",
        "    - plot_x_dim: int, optional (default=6)\n",
        "        The number of columns in the grid layout for plotting the channels.\n",
        "    - plot_y_dim: int, optional (default=6)\n",
        "        The number of rows in the grid layout for plotting the channels.\n",
        "\n",
        "    Returns:\n",
        "    - fig: matplotlib.figure.Figure object\n",
        "        The figure object containing the grid of plots. Each plot shows the evoked data for a channel, with significance\n",
        "        markers overlaid for the specified time windows.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(plot_y_dim, plot_x_dim, figsize=(20, 12))  # Adjusted to match your desired layout\n",
        "    fig.suptitle(\"Channels with Significance Overlay for Different Time Windows\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    # Define colors for each time window\n",
        "    colors = ['red', 'green', 'blue']\n",
        "    window_names = list(time_windows.keys())\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = stderr_data.data[channel_to_index[channel], :]\n",
        "        # Plot the channel data with times in seconds\n",
        "        ax.plot(evoke_data.times, evoke_data.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(evoke_data.times, evoke_data.data[channel_to_index[channel], :] - stderr, evoke_data.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        max_y_value = np.max(evoke_data.data[channel_to_index[channel], :])  # Find max y-value for significance lines\n",
        "        # Assuming the epochs start 1 second before the stimulus/event\n",
        "        epoch_start_time = -1  # Start time of epochs in seconds\n",
        "\n",
        "        for window_index, window_name in enumerate(window_names):\n",
        "            if channel in sig_chans[window_name]:\n",
        "                start_idx, end_idx = time_windows[window_name]\n",
        "                # Convert sample indices to times in seconds\n",
        "                start_time = (start_idx / sample_rate) + epoch_start_time\n",
        "                end_time = (end_idx / sample_rate) + epoch_start_time\n",
        "                # Determine y-position for the significance line, adjusting to avoid overlap\n",
        "                y_position = max_y_value - (window_index * 0.02 * max_y_value)  # Adjust overlap offset here\n",
        "\n",
        "                # Cycle through colors for each time window\n",
        "                color = colors[window_index % len(colors)]\n",
        "                ax.hlines(y=y_position, xmin=start_time, xmax=end_time, color=color, linewidth=2, label=f\"{window_name}: {color}\")\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    # Create a legend for the first subplot (if desired) to explain the colors\n",
        "    if len(axes_flat) > 0 and len(window_names) > 0:\n",
        "        handles, labels = axes_flat[0].get_legend_handles_labels()\n",
        "        fig.legend(handles, labels, loc='upper right', title=\"Time Windows & Colors\")\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make space for the legend\n",
        "    return fig\n",
        "\n",
        "sig_chans = {}\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    LAB_root = None\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    sample_rate = filt.info['sfreq'] # get sampling rate, should be 2048 Hz\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    time_windows = {\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0to0.5\": (sample_rate,1.5*sample_rate), #actually grab from 1 to 1.5 because the epochs start at -1 second before stim onset\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0.5to1\": (1.5*sample_rate,2*sample_rate),\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0to1\": (sample_rate,2*sample_rate)\n",
        "    }\n",
        "\n",
        "    for window in time_windows:\n",
        "        output_name = window\n",
        "\n",
        "        # Define file paths\n",
        "        HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
        "        HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
        "        HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
        "\n",
        "        # Load the epochs and evoked objects\n",
        "        HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
        "        HG_base = mne.read_epochs(HG_base_file)\n",
        "        HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "        HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "        channels = [] # load in all channels\n",
        "        channel_to_index = {}\n",
        "        channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') \n",
        "        with open(channel_file, 'r') as f:\n",
        "            for line in f:\n",
        "                index, channel = line.strip().split(': ')\n",
        "                channels.append(channel)\n",
        "                channel_to_index[channel] = int(index)\n",
        "\n",
        "        sig_chans_filename = os.path.join(save_dir, f'sig_chans_{sub}_{output_name}.json') # load in sig channels\n",
        "        sig_chans[window] = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "    # now plot 6x6 grid of 36 channels on one plot, for the z-scored signal\n",
        "    plot_x_dim = 6\n",
        "    plot_y_dim = 6\n",
        "    channels_per_fig = plot_x_dim * plot_y_dim\n",
        "\n",
        "    # Iterate over all channels in chunks and plot them with z-scored signal\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_windows(HG_ev1_evoke_rescaled, HG_ev1_evoke_rescaled_stderr, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim, plot_y_dim)\n",
        "        combined_plot_path_rescaled = os.path.join(save_dir, f'{sub}_zscore_{output_name}_combinedChannelTracesAndWindowsSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path_rescaled)\n",
        "        plt.close(fig)\n",
        "\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_windows(HG_ev1_evoke, HG_ev1_evoke_stderr, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim, plot_y_dim)\n",
        "        combined_plot_path_rescaled = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndWindowsSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path_rescaled)\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "this below code is for when using the time perm cluster stats to determine significance timepoint by timepoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UNTESTED 2/29, NEED TO RERUN STATS TO SAVE MAT FIRST.\n",
        "def plot_channels_on_grid_time_perm_cluster(evoke_data, std_err_data, channels_subset, mat, sample_rate=2048, plot_x_dim=6, plot_y_dim=6):\n",
        "    \"\"\"\n",
        "    Plots evoked EEG/MEG data for a subset of channels on a grid, overlaying significance markers for specified time windows.\n",
        "\n",
        "    Parameters:\n",
        "    - evoke_data: mne.Evoked object\n",
        "        The evoked data to be plotted. This object contains the averaged EEG/MEG data over epochs.\n",
        "    - std_err_data: \n",
        "        The standard error of the evoked data to be plotted\n",
        "    - channels_subset: list of str\n",
        "        A list of channel names to be plotted. Each channel name must correspond to a channel in `evoke_data`.\n",
        "    - mat: numpy.array\n",
        "        A binary matrix (same shape as evoke_data) indicating significant data points (1 for significant, 0 for non-significant).\n",
        "    - sample_rate: float\n",
        "    - sample_rate: float\n",
        "        The sampling rate of the data, in Hz. Used to convert sample indices in `time_windows` to time in seconds.\n",
        "    - plot_x_dim: int, optional (default=6)\n",
        "        The number of columns in the grid layout for plotting the channels.\n",
        "    - plot_y_dim: int, optional (default=6)\n",
        "        The number of rows in the grid layout for plotting the channels.\n",
        "\n",
        "    Returns:\n",
        "    - fig: matplotlib.figure.Figure object\n",
        "        The figure object containing the grid of plots. Each plot shows the evoked data for a channel, with significance\n",
        "        markers overlaid for the specified time windows.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(plot_x_dim, plot_y_dim, figsize=(20, 12))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = std_err_data.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / sample_rate  # Should be 2048 Hz sample rate\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(evoke_data.times, evoke_data.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(evoke_data.times, evoke_data.data[channel_to_index[channel], :] - stderr, evoke_data.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(evoke_data.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "plot_x_dim = 6\n",
        "plot_y_dim = 6\n",
        "channels_per_fig = plot_x_dim * plot_y_dim\n",
        "\n",
        "sig_chans = {}\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    LAB_root = None\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    sample_rate = filt.info['sfreq'] # get sampling rate, should be 2048 Hz\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    output_name = 'Stimulus_fixationCrossBase_1sec_mirror_0to1test'\n",
        "\n",
        "    # Define file paths\n",
        "    HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
        "    HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
        "    HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
        "\n",
        "    # Load the epochs and evoked objects\n",
        "    HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
        "    HG_base = mne.read_epochs(HG_base_file)\n",
        "    HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    mat_save_path = os.path.join(save_dir, f'{output_name}_mat.npy')\n",
        "    mat = np.load(mat_save_path)\n",
        "\n",
        "    channels = [] # load in all channels\n",
        "    channel_to_index = {}\n",
        "    channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') \n",
        "    with open(channel_file, 'r') as f:\n",
        "        for line in f:\n",
        "            index, channel = line.strip().split(': ')\n",
        "            channels.append(channel)\n",
        "            channel_to_index[channel] = int(index)\n",
        "    \n",
        "    # Iterate over all channels in chunks of channels_per_fig (plot_x_dim * plot_y_dim) and plot them\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_time_perm_cluster(HG_ev1_evoke_rescaled, HG_ev1_evoke_rescaled_stderr, channels_subset, mat, plot_x_dim, plot_y_dim, sample_rate=sample_rate)\n",
        "        combined_plot_path = os.path.join(save_dir, f'{sub}_zscore_{output_name}_combinedChannelTracesAndTimePermClusterSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path)\n",
        "        plt.close(fig)\n",
        "\n",
        "        # Iterate over all channels in chunks of channels_per_fig (plot_x_dim * plot_y_dim) and plot them\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_time_perm_cluster(HG_ev1_evoke, HG_ev1_evoke_stderr, channels_subset, mat, plot_x_dim, plot_y_dim, sample_rate=sample_rate)\n",
        "        combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndTimePermClusterSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path)\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### z-scored signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for raw traces, just plot HG_ev1_evoke instead of HG_ev1_evoke_rescaled. And for the standard error, use the HG_ev1_evoke_stderr instead of HG_ev1_evoke_rescaled_stderr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### raw traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming all imports and previous definitions are in place\n",
        "\n",
        "def plot_channels_on_grid_time_perm_cluster_raw(channels_subset):\n",
        "    fig, axes = plt.subplots(6, 10, figsize=(20, 33))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = HG_ev1_evoke_stderr.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / sample_rate  # should be 2048 Hz sample rate. Need mat though..should i save this somehow?\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :] - stderr, HG_ev1_evoke.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "# Iterate over all channels in chunks of 60 and plot them\n",
        "for i in range(0, len(sig_chans), 60):\n",
        "    channels_subset = channels[i:i+60]\n",
        "    fig = plot_channels_on_grid_time_perm_cluster_raw(channels_subset)\n",
        "    combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndTimePermClusterSignificance_Page_{i//36 + 1}.png')\n",
        "    fig.savefig(combined_plot_path)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
