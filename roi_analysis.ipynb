{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster, window_averaged_shuffle\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "# from utils import make_subjects_electrodestoROIs_dict, load_subjects_electrodestoROIs_dict, load_acc_arrays, calculate_RTs, save_channels_to_file, save_sig_chans, \\\n",
    "#       load_sig_chans, channel_names_to_indices, filter_and_average_epochs, permutation_test, perform_permutation_test_across_electrodes, perform_permutation_test_within_electrodes, \\\n",
    "#       add_accuracy_to_epochs, load_mne_objects, create_subjects_mne_objects_dict, extract_significant_effects, convert_dataframe_to_serializable_format, \\\n",
    "#       perform_modular_anova, make_plotting_parameters, plot_significance\n",
    "import utils\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "# still need to test if the permutation test functions load in properly.\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOVE ALL FUNCTIONS TO THE TOP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make subjects rois to electrodes dict. Don't need to run this more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "# subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0071', 'D0077', 'D0090', 'D0100', 'D0102', 'D0103']\n",
    "# subjects = ['D0103'] #testing cuz d0065 being weird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load subjects electrodes to rois dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from subjects_electrodestoROIs_dict.json\n"
     ]
    }
   ],
   "source": [
    "# load in subjects electrodes to rois dict. If it doesn't already exist, make it and then load it.\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "subjects_electrodestoROIs_dict = utils.load_subjects_electrodestoROIs_dict(filename)\n",
    "\n",
    "if subjects_electrodestoROIs_dict is None:\n",
    "    subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "    utils.make_subjects_electrodestoROIs_dict(subjects)\n",
    "    subjects_electrodestoROIs_dict = utils.load_subjects_electrodestoROIs_dict(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load accuracy arrays so we can filter by only accurate trials  \n",
    "combine this code into add_accuracy_to_epochs later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this makes numpy arrays for each subject that are 0 or 1 for each trial based on accuracy\n",
    "from makeRawBehavioralData import main\n",
    "main()\n",
    "\n",
    "# Directory where your .npy files are saved\n",
    "npy_directory = r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\accArrays'  # Replace with your directory path if you're not Jim\n",
    "\n",
    "acc_array = utils.load_acc_arrays(npy_directory, skip_subjects=['D107'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a function to map blockType to congruencyProportion and switchProportion\n",
    "# def map_block_type(row):\n",
    "#     if row['blockType'] == 'A':\n",
    "#         return pd.Series(['25%', '25%'])\n",
    "#     elif row['blockType'] == 'B':\n",
    "#         return pd.Series(['25%', '75%'])\n",
    "#     elif row['blockType'] == 'C':\n",
    "#         return pd.Series(['75%', '25%'])\n",
    "#     elif row['blockType'] == 'D':\n",
    "#         return pd.Series(['75%', '75%'])\n",
    "#     else:\n",
    "#         return pd.Series([None, None])\n",
    "\n",
    "# Apply the function to each row and create new columns\n",
    "combined_data[['congruencyProportion', 'switchProportion']] = combined_data.apply(utils.map_block_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load evoked and stuff for all subjects in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for subject: D0057\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "103 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "103 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0059\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "107 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "107 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0063\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "116 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "116 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0065\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "119 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "103 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "103 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0069\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0071\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0077\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "116 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "116 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0090\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0094\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "112 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "112 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "108 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "112 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "112 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "112 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "112 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0100\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0102\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "107 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "107 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0103\n",
      "  Loading output: Stimulus_ir_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_ir_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_is_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'i', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "107 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_is_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_is_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "107 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n"
     ]
    }
   ],
   "source": [
    "# # example of how to use this with multiple conditions, even matching any value in a list. Although I only ever have two conditions of a type so not super necessary.\n",
    "# # make sure to use the correct column names and values that match with what combinedData uses.\n",
    "\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "\n",
    "# congruency\n",
    "# output_names = [\"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#     },\n",
    "#     \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# switch type\n",
    "# output_names = [\"Stimulus_r25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_r25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"r\",\n",
    "#     },\n",
    "#     \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"s\",\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  ir vs is\n",
    "# output_names = [\"Stimulus_ir_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     },\n",
    "#     \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  cr vs cs\n",
    "# output_names = [\"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_cs_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     },\n",
    "#     \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  is vs cs\n",
    "# output_names = [\"Stimulus_cs_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     },\n",
    "#     \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  ir vs cr\n",
    "# output_names = [\"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_ir_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     },\n",
    "#     \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # all interaction effects (run this with the anova code. Ugh make everything more modular later.)\n",
    "output_names = [\"Stimulus_ir_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\", \"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_cs_fixationCrossBase_1sec_mirror\"]\n",
    "\n",
    "output_names_conditions = {\n",
    "    \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"s\"\n",
    "    },\n",
    "    \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# # block interaction contrasts for lwpc\n",
    "# output_names = [\"Stimulus_c25_fixationCrossBase_1sec_mirror\", \"Stimulus_c75_fixationCrossBase_1sec_mirror\",  \\\n",
    "#                 \"Stimulus_i25_fixationCrossBase_1sec_mirror\", \"Stimulus_i75_fixationCrossBase_1sec_mirror\"]\n",
    "\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_c25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"congruencyProportion\": \"75%\" #this is flipped because the BIDS events are saved in terms of incongruency proportion\n",
    "#     },\n",
    "#     \"Stimulus_c75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"congruencyProportion\": \"25%\"\n",
    "#     },\n",
    "#     \"Stimulus_i25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"congruencyProportion\": \"75%\"\n",
    "#     },\n",
    "#     \"Stimulus_i75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"congruencyProportion\": \"25%\"\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # block interaction contrasts for lwps\n",
    "# output_names = [\"Stimulus_s25_fixationCrossBase_1sec_mirror\", \"Stimulus_s75_fixationCrossBase_1sec_mirror\",  \\\n",
    "#                 \"Stimulus_r25_fixationCrossBase_1sec_mirror\", \"Stimulus_r75_fixationCrossBase_1sec_mirror\"]\n",
    "\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_s25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"s\",\n",
    "#         \"switchProportion\": \"25%\"\n",
    "#     },\n",
    "#     \"Stimulus_s75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"s\",\n",
    "#         \"switchProportion\": \"75%\"\n",
    "#     },\n",
    "#     \"Stimulus_r25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"r\",\n",
    "#         \"switchProportion\": \"25%\"\n",
    "#     },\n",
    "#     \"Stimulus_r75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"r\",\n",
    "#         \"switchProportion\": \"75%\"\n",
    "#     },\n",
    "# }\n",
    "\n",
    "task='GlobalLocal'\n",
    "\n",
    "# Assuming 'combined_data' is your DataFrame and 'subjects' is your list of subject IDs\n",
    "subjects_mne_objects = utils.create_subjects_mne_objects_dict(subjects, output_names_conditions, task=\"GlobalLocal\", combined_data=combined_data, acc_array=acc_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0059\n",
      "Loaded significant channels for subject D0063\n",
      "Loaded significant channels for subject D0065\n",
      "Loaded significant channels for subject D0069\n",
      "Loaded significant channels for subject D0071\n",
      "Loaded significant channels for subject D0077\n",
      "Loaded significant channels for subject D0090\n",
      "Loaded significant channels for subject D0094\n",
      "Loaded significant channels for subject D0100\n",
      "Loaded significant channels for subject D0102\n",
      "Loaded significant channels for subject D0103\n"
     ]
    }
   ],
   "source": [
    "# def get_sig_chans(sub, task, LAB_root=None):\n",
    "#     \"\"\"\n",
    "#     Retrieves the significant channels for a given subject and task from a stored JSON file.\n",
    "    \n",
    "#     Parameters:\n",
    "#         sub (str): Subject ID for which significant channels are retrieved.\n",
    "#         task (str): The specific task for which data is being processed.\n",
    "#         LAB_root (str, optional): The root directory where the data is stored. If None, determines the path based on the OS.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary containing significant channels loaded from the JSON file.\n",
    "#     \"\"\"\n",
    "#     # Determine LAB_root based on the operating system\n",
    "#     if LAB_root is None:\n",
    "#         HOME = os.path.expanduser(\"~\")\n",
    "#         LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "#     # Get data layout\n",
    "#     layout = get_data(task, root=LAB_root)\n",
    "#     save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "\n",
    "#     stim_filename = os.path.join(save_dir, f'sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json')\n",
    "#     stim_sig_chans = load_sig_chans(stim_filename)\n",
    "#     return stim_sig_chans\n",
    "\n",
    "# def get_sig_chans_per_subject(subjects, task='GlobalLocal', LAB_root=None):\n",
    "#     \"\"\"\n",
    "#     Retrieves significant channels for a list of subjects for a specified task.\n",
    "    \n",
    "#     Parameters:\n",
    "#         subjects (list of str): List of subject IDs to process.\n",
    "#         task (str, optional): The specific task for which data is being processed. Defaults to 'GlobalLocal'.\n",
    "#         LAB_root (str, optional): The root directory where the data is stored. If None, determines the path based on the OS.\n",
    "\n",
    "#     Returns:\n",
    "#         dict: A dictionary where keys are subject IDs and values are dictionaries of significant channels for each subject.\n",
    "#     \"\"\"\n",
    "#     # Initialize an empty dictionary to store significant channels per subject\n",
    "#     sig_chans_per_subject = {}\n",
    "\n",
    "#     # Populate the dictionary using get_sig_chans for each subject\n",
    "#     for sub in subjects:\n",
    "#         sig_chans_per_subject[sub] = get_sig_chans(sub, task, LAB_root)\n",
    "\n",
    "#     return sig_chans_per_subject\n",
    "\n",
    "\n",
    "sig_chans_per_subject = utils.get_sig_chans_per_subject(subjects, task='GlobalLocal', LAB_root=None)\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the significant electrodes across subjects for each ROI of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup\n",
    "ACC based on Destrieux et al 2010 definition is G_and_S_cingul-Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def filter_electrodes_by_roi(subjects_electrodes_dict, sig_chans_per_subject, roi_list):\n",
    "#     \"\"\"\n",
    "#     Filters electrodes based on specified ROIs and returns significant electrodes for each subject.\n",
    "\n",
    "#     Args:\n",
    "#     subjects_electrodes_dict (dict): A dictionary with subjects as keys and electrode-to-ROI mappings as values.\n",
    "#     sig_chans_per_subject (dict): A dictionary with subjects as keys and lists of significant channels as values.\n",
    "#     roi_list (list): A list of ROIs to filter electrodes.\n",
    "\n",
    "#     Returns:\n",
    "#     dict: A dictionary with subjects as keys and lists of significant electrodes in specified ROIs as values.\n",
    "#     \"\"\"\n",
    "#     filtered_electrodes_per_subject = {}\n",
    "\n",
    "#     for sub, electrodes_dict in subjects_electrodes_dict.items():\n",
    "#         filtered = {key: value for key, value in electrodes_dict['filtROI_dict'].items() \n",
    "#                     if any(roi in key for roi in roi_list)}\n",
    "\n",
    "#         # Aggregate electrodes into a list for each subject\n",
    "#         filtered_electrodes = []\n",
    "#         for electrodes in filtered.values():\n",
    "#             filtered_electrodes.extend(electrodes)\n",
    "\n",
    "#         filtered_electrodes_per_subject[sub] = filtered_electrodes\n",
    "#         print(f'For subject {sub}, {\", \".join(roi_list)} electrodes are: {filtered_electrodes}')\n",
    "\n",
    "#     # Now filter for significant electrodes\n",
    "#     sig_filtered_electrodes_per_subject = {}\n",
    "\n",
    "#     for sub, filtered_electrodes in filtered_electrodes_per_subject.items():\n",
    "#         # Retrieve the list of significant channels for the subject\n",
    "#         sig_chans = sig_chans_per_subject.get(sub, [])\n",
    "\n",
    "#         # Find the intersection of filtered electrodes and significant channels for the subject\n",
    "#         sig_filtered_electrodes = [elec for elec in filtered_electrodes if elec in sig_chans]\n",
    "\n",
    "#         # Store the significant filtered electrodes for the subject\n",
    "#         sig_filtered_electrodes_per_subject[sub] = sig_filtered_electrodes\n",
    "#         print(f\"Subject {sub} significant {', '.join(roi_list)} electrodes: {sig_filtered_electrodes}\")\n",
    "\n",
    "#     return filtered_electrodes_per_subject, sig_filtered_electrodes_per_subject\n",
    "\n",
    "# # Example usage:\n",
    "# dlpfc_rois = [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"] #dorsolateral prefrontal cortex\n",
    "# acc_rois = [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"] #anterior cingulate cortex\n",
    "# parietal_rois = [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"] #superior parietal lobule, intraparietal sulcus, and inferior parietal lobule (split into angular gyrus and supramarginal gyrus)\n",
    "\n",
    "# dlpfc_electrodes_per_subject, sig_dlpfc_electrodes_per_subject = utils.filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, dlpfc_rois)\n",
    "# # acc_electrodes_per_subject, sig_acc_electrodes_per_subject = utils.filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, acc_rois)\n",
    "# # parietal_electrodes_per_subject, sig_parietal_electrodes_per_subject = utils.filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, parietal_rois)\n",
    "\n",
    "# sig_electrodes_per_subject_roi = {}\n",
    "# sig_electrodes_per_subject_roi['dlpfc'] = sig_dlpfc_electrodes_per_subject\n",
    "# sig_electrodes_per_subject_roi['acc'] = sig_acc_electrodes_per_subject\n",
    "# sig_electrodes_per_subject_roi['parietal'] = sig_parietal_electrodes_per_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_sig_electrodes_per_subject_and_roi_dict(rois_dict, subjects_electrodestoROIs_dict, sig_chans_per_subject):\n",
    "#     \"\"\"\n",
    "#     Processes electrodes by ROI and filters significant electrodes.\n",
    "\n",
    "#     Parameters:\n",
    "#     - rois_dict: A dictionary mapping each region of interest (ROI) to a list of brain regions.\n",
    "#     - subjects_electrodestoROIs_dict: A dictionary mapping subjects to their electrode-to-ROI assignments.\n",
    "#     - sig_chans_per_subject: A dictionary indicating significant channels per subject.\n",
    "\n",
    "#     Returns:\n",
    "#     - A tuple of two dictionaries:\n",
    "#       1. electrodes_per_subject_roi: Electrodes per subject for each ROI.\n",
    "#       2. sig_electrodes_per_subject_roi: Significant electrodes per subject for each ROI.\n",
    "#     \"\"\"\n",
    "#     electrodes_per_subject_roi = {}\n",
    "#     sig_electrodes_per_subject_roi = {}\n",
    "\n",
    "#     for roi_name, roi_regions in rois_dict.items():\n",
    "#         # Apply the filter_electrodes_by_roi function for each set of ROI regions\n",
    "#         electrodes_per_subject, sig_electrodes_per_subject = filter_electrodes_by_roi(\n",
    "#             subjects_electrodestoROIs_dict, sig_chans_per_subject, roi_regions)\n",
    "        \n",
    "#         # Store the results in the respective dictionaries\n",
    "#         electrodes_per_subject_roi[roi_name] = electrodes_per_subject\n",
    "#         sig_electrodes_per_subject_roi[roi_name] = sig_electrodes_per_subject\n",
    "\n",
    "#     return electrodes_per_subject_roi, sig_electrodes_per_subject_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject D0057, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RAI6', 'RAI12', 'RAI13', 'RAI15', 'RAI16', 'RPI14', 'RAMF10', 'RAMF11', 'RAMF12', 'RAIF11', 'RAIF12', 'RAIF13', 'RAIF14']\n",
      "For subject D0059, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LMMF9', 'LMMF11', 'LMMF12', 'LPSF16']\n",
      "For subject D0063, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LOF16', 'LASF10', 'LASF14', 'LASF15', 'LASF16', 'LMSF5', 'LMSF6', 'LMSF12', 'LPSF10', 'LPSF12', 'RAI4', 'RAI6', 'RAI5', 'RAI10', 'RAI11', 'RAI16', 'RAMF11', 'RAMF12', 'RAMF13', 'RMMF13', 'RMMF14', 'RASF15', 'RMSF8', 'RMSF9', 'RMSF10', 'RMSF7', 'RAMF8', 'RAMF9', 'RAMF10', 'RMMF9', 'RMMF10']\n",
      "For subject D0065, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RASF13', 'RASF14', 'RASF15', 'RMSF11', 'RMSF12', 'RMSF13', 'RMSF14', 'RI7']\n",
      "For subject D0069, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LOF8']\n",
      "For subject D0071, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO14', 'RIA4', 'RIP6', 'RIA5', 'RIA11', 'RIA12', 'RIA14', 'RIA16', 'RIP14', 'RIP15']\n",
      "For subject D0077, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0090, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RIA6', 'RIA12', 'RIA14', 'RIA15', 'RIP7']\n",
      "For subject D0094, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFO13', 'LFO15', 'LFAM8', 'LFAM9', 'LFAM10', 'LFAM13', 'LFAM14', 'LFPM10', 'LFPM12', 'LFAI3', 'LFAI5', 'LFPI10', 'LPAI9', 'LPAI10', 'LIA4', 'LIA5', 'LFAI9', 'LFAI10', 'LIA11', 'LIA14', 'LIA16']\n",
      "For subject D0100, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0102, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO13', 'RFO14', 'RFAM15', 'RFAI2', 'RFAI3']\n",
      "For subject D0103, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LFAM15', 'LAI4', 'LFAI4']\n",
      "Subject D0057 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RAI6', 'RPI14']\n",
      "Subject D0059 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LMMF9', 'LMMF11', 'LMMF12', 'LPSF16']\n",
      "Subject D0063 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LMSF5', 'LPSF12', 'RAI4', 'RAI6', 'RAMF12', 'RMMF13', 'RMMF14', 'RMMF10']\n",
      "Subject D0065 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RASF14']\n",
      "Subject D0069 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0071 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RFO14', 'RIA4', 'RIP6', 'RIA5', 'RIA11', 'RIA12', 'RIA14', 'RIA16']\n",
      "Subject D0077 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0090 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RIA6', 'RIA12']\n",
      "Subject D0094 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LFAM8', 'LFAM9', 'LFAM10', 'LFPM10', 'LFPM12', 'LFAI5', 'LPAI9', 'LFAI9', 'LFAI10', 'LIA11']\n",
      "Subject D0100 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0102 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RFO13', 'RFO14', 'RFAM15']\n",
      "Subject D0103 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LAI4', 'LFAI4']\n"
     ]
    }
   ],
   "source": [
    "rois_dict = {\n",
    "    # 'dlpfc': [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    # 'acc': [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"],\n",
    "    # 'parietal': [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"],\n",
    "    'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"]\n",
    "}\n",
    "\n",
    "rois = list(rois_dict.keys())\n",
    "electrodes_per_subject_roi, sig_electrodes_per_subject_roi = utils.make_sig_electrodes_per_subject_and_roi_dict(rois_dict, subjects_electrodestoROIs_dict, sig_chans_per_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D0057': ['RAI6', 'RPI14'],\n",
       " 'D0059': ['LMMF9', 'LMMF11', 'LMMF12', 'LPSF16'],\n",
       " 'D0063': ['LMSF5',\n",
       "  'LPSF12',\n",
       "  'RAI4',\n",
       "  'RAI6',\n",
       "  'RAMF12',\n",
       "  'RMMF13',\n",
       "  'RMMF14',\n",
       "  'RMMF10'],\n",
       " 'D0065': ['RASF14'],\n",
       " 'D0069': [],\n",
       " 'D0071': ['RFO14',\n",
       "  'RIA4',\n",
       "  'RIP6',\n",
       "  'RIA5',\n",
       "  'RIA11',\n",
       "  'RIA12',\n",
       "  'RIA14',\n",
       "  'RIA16'],\n",
       " 'D0077': [],\n",
       " 'D0090': ['RIA6', 'RIA12'],\n",
       " 'D0094': ['LFAM8',\n",
       "  'LFAM9',\n",
       "  'LFAM10',\n",
       "  'LFPM10',\n",
       "  'LFPM12',\n",
       "  'LFAI5',\n",
       "  'LPAI9',\n",
       "  'LFAI9',\n",
       "  'LFAI10',\n",
       "  'LIA11'],\n",
       " 'D0100': [],\n",
       " 'D0102': ['RFO13', 'RFO14', 'RFAM15'],\n",
       " 'D0103': ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LAI4', 'LFAI4']}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_electrodes_per_subject_roi['lpfc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get total number of electrodes (make this modular with roi later once everything works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_total_electrodes(sig_electrodes_per_subject_roi, electrodes_per_subject_roi):\n",
    "#     \"\"\"\n",
    "#     Calculates the total number of significant and total electrodes for each ROI across all subjects.\n",
    "\n",
    "#     Parameters:\n",
    "#     - sig_electrodes_per_subject_roi: A dictionary containing significant electrodes per subject for each ROI.\n",
    "#     - electrodes_per_subject_roi: A dictionary containing all electrodes per subject for each ROI.\n",
    "\n",
    "#     Returns:\n",
    "#     - A dictionary containing the counts of significant and total electrodes for each ROI.\n",
    "#     \"\"\"\n",
    "#     total_electrodes_info = {}\n",
    "\n",
    "#     for roi in sig_electrodes_per_subject_roi:\n",
    "#         # Calculate total significant electrodes for the current ROI\n",
    "#         total_sig_entries = sum(len(sig_electrodes_per_subject_roi[roi][sub]) for sub in sig_electrodes_per_subject_roi[roi])\n",
    "#         # Calculate total electrodes for the current ROI\n",
    "#         total_entries = sum(len(electrodes_per_subject_roi[roi][sub]) for sub in electrodes_per_subject_roi[roi])\n",
    "\n",
    "#         # Store the results in the dictionary\n",
    "#         total_electrodes_info[roi] = {\n",
    "#             'total_significant_electrodes': total_sig_entries,\n",
    "#             'total_electrodes': total_entries\n",
    "#         }\n",
    "\n",
    "#     return total_electrodes_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of significant lpfc electrodes across all subjects: 44\n",
      "Total number of lpfc electrodes across all subjects: 105\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "total_electrodes_info = utils.calculate_total_electrodes(sig_electrodes_per_subject_roi, electrodes_per_subject_roi)\n",
    "for roi, counts in total_electrodes_info.items():\n",
    "    print(f\"Total number of significant {roi} electrodes across all subjects:\", counts['total_significant_electrodes'])\n",
    "    print(f\"Total number of {roi} electrodes across all subjects:\", counts['total_electrodes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do stats\n",
    "\n",
    "current approach is to run time_perm_cluster on significant dlpfc electrodes for each subject, comparing congruent and incongruent conditions. Then, average p-values across all subjects. Discuss this with Greg, probably wrong approach.\n",
    "\n",
    "**1/23 new approach is to average across all trials for sig dlpfc electrodes, comparing incongruent and congruent conditions. Then, run stats on this new avg electrode value x time array.\n",
    "\n",
    "Also, I'm using HG_ev1_rescaled instead of HG_ev1 to compare congruent and incongruent, so that they're normalized with a common baseline. I think this is better than comparing the raw HG traces directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is 1/23 old approach of avg across trials first. Time perm cluster stats.\n",
    "\n",
    "do stats and plotting together. Stats needs trial avg data, plotting just needs congruent_data without trial averaging (initially at least)  \n",
    "this code is so bad right now, turn into a function later  \n",
    "\n",
    "trialAvg is for the time perm cluster stats  \n",
    "timeAvg_firstHalfSecond_firstHalfSecond_firstHalfSecond_firstHalfSecond_firstHalfSecond is for the window stats (not sure if this is even right)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/30 try to make time perm stats more modular, and reusable  \n",
    "also remember that time perm cluster stats only compares two output names. Currently it just grabs the first two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_output_data(rois, output_names):\n",
    "    \"\"\"\n",
    "    Initialize dictionaries for storing data across different outputs and ROIs.\n",
    "    \"\"\"\n",
    "    return {output_name: {roi: [] for roi in rois} for output_name in output_names}\n",
    "\n",
    "# Correctly call and use the functions\n",
    "def process_data_for_roi(subjects_mne_objects, output_names, rois, subjects, sig_electrodes_per_subject_roi, time_indices):\n",
    "    \"\"\"\n",
    "    Process data by ROI, calculating averages for different time windows for either the first two outputs or all outputs, depending on the analysis purpose.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize data structures for trial averages, trial standard deviations, and time averages\n",
    "    data_trialAvg_lists = initialize_data_structures(rois, output_names)\n",
    "    data_trialStd_lists = initialize_data_structures(rois, output_names)\n",
    "    data_timeAvg_lists = {suffix: initialize_data_structures(rois, output_names) for suffix in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']}\n",
    "    overall_electrode_mapping = []\n",
    "    electrode_mapping_per_roi = {roi: [] for roi in rois}  # Reinitialize for each processing run\n",
    "\n",
    "    for sub in subjects:\n",
    "        for roi in rois:\n",
    "            sig_electrodes = sig_electrodes_per_subject_roi[roi].get(sub, [])\n",
    "            print(f\"Subject: {sub}, ROI: {roi}, Num of Sig Electrodes: {len(sig_electrodes)}\")  # Debug print\n",
    "\n",
    "            if not sig_electrodes:\n",
    "                continue\n",
    "\n",
    "            for output_name in output_names:\n",
    "                epochs = subjects_mne_objects[sub][output_name]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "\n",
    "                # Append mapping information for use in ANOVA.\n",
    "                for electrode in sig_electrodes:\n",
    "                    index = len(overall_electrode_mapping)\n",
    "                    overall_electrode_mapping.append((sub, roi, electrode, index))\n",
    "                    index_roi = len(electrode_mapping_per_roi[roi])\n",
    "                    electrode_mapping_per_roi[roi].append((sub, electrode, index_roi))\n",
    "\n",
    "                # Compute trial averages and standard deviations once per output per subject per ROI\n",
    "                trial_avg, trial_std, _ = filter_and_average_epochs(epochs, start_idx=None, end_idx=None)\n",
    "                data_trialAvg_lists[output_name][roi].append(trial_avg)\n",
    "                data_trialStd_lists[output_name][roi].append(trial_std)\n",
    "\n",
    "                # compute time average for each output per subject per roi for each time window. But why don't we look at standard deviation? 4/30\n",
    "                for suffix, (start_idx, end_idx) in time_indices.items():\n",
    "                    _, _, time_avg = filter_and_average_epochs(epochs, start_idx, end_idx)\n",
    "                    data_timeAvg_lists[suffix][output_name][roi].append(time_avg)\n",
    "\n",
    "    return data_trialAvg_lists, data_trialStd_lists, data_timeAvg_lists, overall_electrode_mapping, electrode_mapping_per_roi\n",
    "\n",
    "def concatenate_data(data_lists, rois, output_names):\n",
    "    \"\"\"\n",
    "    Concatenate data across subjects for each ROI and condition.\n",
    "    \"\"\"\n",
    "    concatenated_data = {output_name: {roi: np.concatenate(data_lists[output_name][roi], axis=0) for roi in rois} for output_name in output_names}\n",
    "    return concatenated_data\n",
    "\n",
    "def calculate_mean_and_sem(concatenated_data, rois, output_names):\n",
    "    \"\"\"\n",
    "    Calculate mean and SEM across electrodes for all time windows and rois\n",
    "    \"\"\"\n",
    "    mean_and_sem = {roi: {output_name: {} for output_name in output_names} for roi in rois}\n",
    "    for roi in rois:\n",
    "        for output_name in output_names:\n",
    "            trial_data = concatenated_data[output_name][roi]\n",
    "            mean = np.nanmean(trial_data, axis=0)\n",
    "            sem = np.std(trial_data, axis=0, ddof=1) / np.sqrt(trial_data.shape[0])\n",
    "            mean_and_sem[roi][output_name] = {'mean': mean, 'sem': sem}\n",
    "    return mean_and_sem\n",
    "\n",
    "def calculate_time_perm_cluster_for_each_roi(concatenated_data, rois, output_names, alpha=0.05, n_jobs=6):\n",
    "    \"\"\"\n",
    "    Perform time permutation cluster tests between the first two outputs for each ROI.\n",
    "    Assumes that there are at least two output conditions to compare.\n",
    "    \"\"\"\n",
    "    time_perm_cluster_results = {}\n",
    "    for roi in rois:\n",
    "        time_perm_cluster_results[roi] = time_perm_cluster(\n",
    "            concatenated_data[output_names[0]][roi],\n",
    "            concatenated_data[output_names[1]][roi], alpha, n_jobs=n_jobs\n",
    "        )\n",
    "    return time_perm_cluster_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: D0057, ROI: lpfc, Num of Sig Electrodes: 2\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jz421\\Desktop\\GlobalLocal\\misc_functions.py:130: RuntimeWarning: Mean of empty slice\n",
      "  time_avg_data = np.nanmean(all_epochs_data[:, :, start_idx:end_idx], axis=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0059, ROI: lpfc, Num of Sig Electrodes: 4\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0063, ROI: lpfc, Num of Sig Electrodes: 8\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0065, ROI: lpfc, Num of Sig Electrodes: 1\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0069, ROI: lpfc, Num of Sig Electrodes: 0\n",
      "Subject: D0071, ROI: lpfc, Num of Sig Electrodes: 8\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0077, ROI: lpfc, Num of Sig Electrodes: 0\n",
      "Subject: D0090, ROI: lpfc, Num of Sig Electrodes: 2\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0094, ROI: lpfc, Num of Sig Electrodes: 10\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0100, ROI: lpfc, Num of Sig Electrodes: 0\n",
      "Subject: D0102, ROI: lpfc, Num of Sig Electrodes: 3\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Subject: D0103, ROI: lpfc, Num of Sig Electrodes: 6\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    }
   ],
   "source": [
    "# Define time indices as in your original code\n",
    "time_indices = {\n",
    "    'firstHalfSecond': (2048, 3072),\n",
    "    'secondHalfSecond': (3072, 4096),\n",
    "    'fullSecond': (2048, 4096)\n",
    "}\n",
    "\n",
    "# Select output names based on whether the processing is for a permutation test (first two outputs) or ANOVA (all outputs).\n",
    "for_perm_test = True\n",
    "relevant_output_names = output_names[:2] if for_perm_test else output_names\n",
    "\n",
    "# Process the data\n",
    "data_trialAvg_lists, data_trialStd_lists, data_timeAvg_lists, overall_electrode_mapping, electrode_mapping_per_roi = process_data_for_roi(\n",
    "    subjects_mne_objects, relevant_output_names, rois, subjects, sig_electrodes_per_subject_roi, time_indices)\n",
    "\n",
    "# Concatenate the data\n",
    "concatenated_trialAvg_data = concatenate_data(data_trialAvg_lists, rois, relevant_output_names)\n",
    "\n",
    "# Calculate means and sems\n",
    "mean_and_sem = calculate_mean_and_sem(concatenated_trialAvg_data, rois, relevant_output_names)\n",
    "\n",
    "# Perform statistical tests\n",
    "time_perm_cluster_results = calculate_time_perm_cluster_for_each_roi(concatenated_trialAvg_data, rois, relevant_output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full pipeline analysis for time perm cluster stats, untested 5/4. Replaces the above cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_time_perm_cluster_stats(subjects_mne_objects, output_names, rois, subjects, sig_electrodes_per_subject_roi, for_perm_test=True):\n",
    "    \"\"\"\n",
    "    Execute the full time perm cluster stats pipeline, from data processing to statistical testing.\n",
    "\n",
    "    Parameters:\n",
    "    subjects_mne_objects: Dictionary with MNE data objects for each subject.\n",
    "    output_names: List of output condition names.\n",
    "    rois: List of regions of interest.\n",
    "    subjects: List of subject identifiers.\n",
    "    sig_electrodes_per_subject_roi: Mapping of significant electrodes per subject per ROI.\n",
    "    for_perm_test: Boolean flag to determine which outputs to process for testing.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary with trial averages, trial standard deviations, time averages, and time perm cluster results.\n",
    "    \"\"\"\n",
    "    print(\"Starting the analysis... Let's crunch some numbers!\")\n",
    "    \n",
    "    # Define time indices. Should probably replace these magic numbers with sampling rate calc...5/4\n",
    "    time_indices = {\n",
    "        'firstHalfSecond': (2048, 3072),\n",
    "        'secondHalfSecond': (3072, 4096),\n",
    "        'fullSecond': (2048, 4096)\n",
    "    }\n",
    "\n",
    "    # Select output names based on whether the processing is for a permutation test (first two outputs) or ANOVA (all outputs).\n",
    "    relevant_output_names = output_names[:2] if for_perm_test else output_names\n",
    "\n",
    "    # Process the data\n",
    "    data_trialAvg_lists, data_trialStd_lists, data_timeAvg_lists, overall_electrode_mapping, electrode_mapping_per_roi = process_data_for_roi(\n",
    "        subjects_mne_objects, relevant_output_names, rois, subjects, sig_electrodes_per_subject_roi, time_indices)\n",
    "\n",
    "    print(\"Data processing complete. Now let's concatenate the results and see what we've got!\")\n",
    "\n",
    "    # Concatenate the data\n",
    "    concatenated_trialAvg_data = concatenate_data(data_trialAvg_lists, rois, relevant_output_names)\n",
    "\n",
    "    # Calculate means and sems\n",
    "    mean_and_sem = calculate_mean_and_sem(concatenated_trialAvg_data, rois, relevant_output_names)\n",
    "\n",
    "    print(\"Mean and SEM calculation done. It's time for some statistical action!\")\n",
    "\n",
    "    # Perform statistical tests\n",
    "    if for_perm_test:\n",
    "        print(\"Running permutation tests...\")\n",
    "        time_perm_cluster_results = calculate_time_perm_cluster_for_each_roi(concatenated_trialAvg_data, rois, relevant_output_names)\n",
    "    else:\n",
    "        print(\"No permutation test specified. Moving on...\")\n",
    "        time_perm_cluster_results = None\n",
    "\n",
    "    print(\"Analysis complete! Returning all the juicy details now.\")\n",
    "\n",
    "    return {\n",
    "        'Trial Averages': data_trialAvg_lists,\n",
    "        'Trial Standard Deviations': data_trialStd_lists,\n",
    "        'Time Averages': data_timeAvg_lists,\n",
    "        'Overall Electrode Mapping': overall_electrode_mapping,\n",
    "        'Electrode Mapping per ROI': electrode_mapping_per_roi,\n",
    "        'Mean and SEM': mean_and_sem,\n",
    "        'Permutation Test Results': time_perm_cluster_results\n",
    "    }\n",
    "\n",
    "# Usage:\n",
    "time_perm_cluster_results = run_time_perm_cluster_stats(subjects_mne_objects, output_names, rois, subjects, sig_electrodes_per_subject_roi, for_perm_test=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do window stats  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle test (perm test). This basically time perm cluster but avg across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select output names based on whether the processing is for a permutation test (first two outputs) or ANOVA (all outputs).\n",
    "for_perm_test = True\n",
    "relevant_output_names = output_names[:2] if for_perm_test else output_names\n",
    "\n",
    "# Process the data\n",
    "data_trialAvg_lists, data_trialStd_lists, data_timeAvg_lists, overall_electrode_mapping, electrode_mapping_per_roi = process_data_for_roi(\n",
    "    subjects_mne_objects, relevant_output_names, rois, subjects, sig_electrodes_per_subject_roi, time_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this code is old as of 5/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming the functions perform_permutation_test_within_electrodes and perform_permutation_test_across_electrodes return lists of p-values (and get loaded in properly)\n",
    "# p_values = {}\n",
    "# for roi in rois:\n",
    "#     # Initialize p_values[roi] as a dictionary. Initialize dicts for all time windows.\n",
    "#     p_values[roi] = {}\n",
    "#     p_values[roi]['firstHalfSecond'] = {}\n",
    "#     p_values[roi]['secondHalfSecond'] = {}\n",
    "#     p_values[roi]['fullSecond'] = {}\n",
    "\n",
    "#     # Perform the tests and store results\n",
    "#     p_values[roi]['firstHalfSecond']['within'] = perform_permutation_test_within_electrodes(output_0_data_timeAvg_firstHalfSecond_list[roi], output_1_data_timeAvg_firstHalfSecond_list[roi], n_permutations=10000)\n",
    "#     p_values[roi]['firstHalfSecond']['across'] = perform_permutation_test_across_electrodes(output_0_data_timeAvg_firstHalfSecond_list[roi], output_1_data_timeAvg_firstHalfSecond_list[roi], n_permutations=10000)\n",
    "\n",
    "#     p_values[roi]['secondHalfSecond']['within'] = perform_permutation_test_within_electrodes(output_0_data_timeAvg_secondHalfSecond_list[roi], output_1_data_timeAvg_secondHalfSecond_list[roi], n_permutations=10000)\n",
    "#     p_values[roi]['secondHalfSecond']['across'] = perform_permutation_test_across_electrodes(output_0_data_timeAvg_secondHalfSecond_list[roi], output_1_data_timeAvg_secondHalfSecond_list[roi], n_permutations=10000)\n",
    "\n",
    "#     p_values[roi]['fullSecond']['within'] = perform_permutation_test_within_electrodes(output_0_data_timeAvg_fullSecond_list[roi], output_1_data_timeAvg_fullSecond_list[roi], n_permutations=10000)\n",
    "#     p_values[roi]['fullSecond']['across'] = perform_permutation_test_across_electrodes(output_0_data_timeAvg_fullSecond_list[roi], output_1_data_timeAvg_fullSecond_list[roi], n_permutations=10000)\n",
    "\n",
    "\n",
    "# # I'm pretty sure we should only do within electrode and not across electrodes for the all_p_values list. So don't iterate over test_types here. 3/11.\n",
    "# all_p_values = {}\n",
    "# all_p_values['firstHalfSecond'] = []\n",
    "# all_p_values['secondHalfSecond'] = []\n",
    "# all_p_values['fullSecond'] = []\n",
    "\n",
    "# for roi in p_values:\n",
    "#     for test_type in p_values[roi]['firstHalfSecond']:\n",
    "#         p = p_values[roi]['firstHalfSecond'][test_type]\n",
    "#         if isinstance(p, list):\n",
    "#             all_p_values['firstHalfSecond'].extend(p)\n",
    "#         else:  # Assume it's a single float value\n",
    "#             all_p_values['firstHalfSecond'].append(p)\n",
    "\n",
    "#     for test_type in p_values[roi]['secondHalfSecond']:\n",
    "#         p = p_values[roi]['secondHalfSecond'][test_type]\n",
    "#         if isinstance(p, list):\n",
    "#             all_p_values['secondHalfSecond'].extend(p)\n",
    "#         else:  # Assume it's a single float value\n",
    "#             all_p_values['secondHalfSecond'].append(p)\n",
    "\n",
    "#     for test_type in p_values[roi]['fullSecond']:\n",
    "#         p = p_values[roi]['fullSecond'][test_type]\n",
    "#         if isinstance(p, list):\n",
    "#             all_p_values['fullSecond'].extend(p)\n",
    "#         else:  # Assume it's a single float value\n",
    "#             all_p_values['fullSecond'].append(p)\n",
    "\n",
    "# # Apply FDR correction\n",
    "# _, adjusted_p_values_firstHalfSecond = multipletests(all_p_values['firstHalfSecond'], alpha=0.05, method='fdr_bh')[:2]\n",
    "# _, adjusted_p_values_secondHalfSecond = multipletestsload(all_p_values['secondHalfSecond'], alpha=0.05, method='fdr_bh')[:2]\n",
    "# _, adjusted_p_values_fullSecond = multipletests(all_p_values['fullSecond'], alpha=0.05, method='fdr_bh')[:2]\n",
    "\n",
    "# # Incorporating adjusted p-values back into the structure is a bit more complex and depends on how you want to use them next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_window_perm_tests(data_timeAvg_lists, relevant_output_names, rois, n_permutations=10000):\n",
    "    p_values = {}\n",
    "    for time_window in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']:\n",
    "        p_values[time_window] = {}\n",
    "        for roi in rois:\n",
    "            p_values[time_window][roi] = {}\n",
    "            output_data_lists = data_timeAvg_lists[time_window]\n",
    "            if relevant_output_names[0] in output_data_lists and relevant_output_names[1] in output_data_lists:\n",
    "                p_values[time_window][roi]['within'] = perform_permutation_test_within_electrodes(\n",
    "                    output_data_lists[relevant_output_names[0]][roi], \n",
    "                    output_data_lists[relevant_output_names[1]][roi], \n",
    "                    n_permutations=n_permutations\n",
    "                )\n",
    "                p_values[time_window][roi]['across'] = perform_permutation_test_across_electrodes(\n",
    "                    output_data_lists[relevant_output_names[0]][roi], \n",
    "                    output_data_lists[relevant_output_names[1]][roi], \n",
    "                    n_permutations=n_permutations\n",
    "                )\n",
    "    return p_values\n",
    "\n",
    "def apply_fdr_correction_window_perm_test(p_values):\n",
    "    all_p_values = {time_window: [] for time_window in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']}\n",
    "    index_map = {time_window: [] for time_window in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']}\n",
    "\n",
    "    for time_window, roi_data in p_values.items():\n",
    "        for roi, tests in roi_data.items():\n",
    "            for test_type, p in tests.items():\n",
    "                p_list = p if isinstance(p, list) else [p]\n",
    "                all_p_values[time_window].extend(p_list)\n",
    "                index_map[time_window].extend([(roi, test_type)] * len(p_list))\n",
    "\n",
    "    adjusted_p_values = {}\n",
    "    for time_window, p_values_list in all_p_values.items():\n",
    "        _, corrected_p_values = multipletests(p_values_list, alpha=0.05, method='fdr_bh')[:2]\n",
    "        adjusted_p_values[time_window] = corrected_p_values\n",
    "\n",
    "    return adjusted_p_values, index_map\n",
    "\n",
    "def integrate_adjusted_p_values(p_values, adjusted_p_values, index_map):\n",
    "    for time_window in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']:\n",
    "        for i, adjusted_p in enumerate(adjusted_p_values[time_window]):\n",
    "            roi, test_type = index_map[time_window][i]\n",
    "            if 'adjusted' not in p_values[time_window][roi]:\n",
    "                p_values[time_window][roi]['adjusted'] = {}\n",
    "            if test_type not in p_values[time_window][roi]['adjusted']:\n",
    "                p_values[time_window][roi]['adjusted'][test_type] = []\n",
    "            p_values[time_window][roi]['adjusted'][test_type].append(adjusted_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0 - Condition 0 shape: (103, 2), Condition 1 shape: (118, 2)\n",
      "Subject 1 - Condition 0 shape: (114, 4), Condition 1 shape: (107, 4)\n",
      "Subject 2 - Condition 0 shape: (106, 8), Condition 1 shape: (116, 8)\n",
      "Subject 3 - Condition 0 shape: (119, 1), Condition 1 shape: (103, 1)\n",
      "Subject 4 - Condition 0 shape: (115, 8), Condition 1 shape: (109, 8)\n",
      "Subject 5 - Condition 0 shape: (113, 2), Condition 1 shape: (109, 2)\n",
      "Subject 6 - Condition 0 shape: (112, 10), Condition 1 shape: (108, 10)\n",
      "Subject 7 - Condition 0 shape: (107, 3), Condition 1 shape: (114, 3)\n",
      "Subject 8 - Condition 0 shape: (114, 6), Condition 1 shape: (107, 6)\n",
      "Subject 0 - Condition 0 shape: (103, 2), Condition 1 shape: (118, 2)\n",
      "Subject 1 - Condition 0 shape: (114, 4), Condition 1 shape: (107, 4)\n",
      "Subject 2 - Condition 0 shape: (106, 8), Condition 1 shape: (116, 8)\n",
      "Subject 3 - Condition 0 shape: (119, 1), Condition 1 shape: (103, 1)\n",
      "Subject 4 - Condition 0 shape: (115, 8), Condition 1 shape: (109, 8)\n",
      "Subject 5 - Condition 0 shape: (113, 2), Condition 1 shape: (109, 2)\n",
      "Subject 6 - Condition 0 shape: (112, 10), Condition 1 shape: (108, 10)\n",
      "Subject 7 - Condition 0 shape: (107, 3), Condition 1 shape: (114, 3)\n",
      "Subject 8 - Condition 0 shape: (114, 6), Condition 1 shape: (107, 6)\n",
      "Subject 0 - Condition 0 shape: (103, 2), Condition 1 shape: (118, 2)\n",
      "Subject 1 - Condition 0 shape: (114, 4), Condition 1 shape: (107, 4)\n",
      "Subject 2 - Condition 0 shape: (106, 8), Condition 1 shape: (116, 8)\n",
      "Subject 3 - Condition 0 shape: (119, 1), Condition 1 shape: (103, 1)\n",
      "Subject 4 - Condition 0 shape: (115, 8), Condition 1 shape: (109, 8)\n",
      "Subject 5 - Condition 0 shape: (113, 2), Condition 1 shape: (109, 2)\n",
      "Subject 6 - Condition 0 shape: (112, 10), Condition 1 shape: (108, 10)\n",
      "Subject 7 - Condition 0 shape: (107, 3), Condition 1 shape: (114, 3)\n",
      "Subject 8 - Condition 0 shape: (114, 6), Condition 1 shape: (107, 6)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Perform the permutation tests\n",
    "p_values = perform_window_perm_tests(data_timeAvg_lists, relevant_output_names, rois)\n",
    "\n",
    "# Step 2: Apply FDR correction and get the index map\n",
    "adjusted_p_values, index_map = apply_fdr_correction_window_perm_test(p_values)\n",
    "\n",
    "# Step 3: Reintegrate the adjusted p-values\n",
    "integrate_adjusted_p_values(p_values, adjusted_p_values, index_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'within': [0.2619,\n",
       "  0.6322,\n",
       "  0.3152,\n",
       "  0.4441,\n",
       "  0.1199,\n",
       "  0.9227,\n",
       "  0.8936,\n",
       "  0.0346,\n",
       "  0.5904,\n",
       "  0.1598,\n",
       "  0.3105,\n",
       "  0.9758,\n",
       "  0.4072,\n",
       "  0.1786,\n",
       "  0.5858,\n",
       "  0.0,\n",
       "  0.3179,\n",
       "  0.3552,\n",
       "  0.0005,\n",
       "  0.0037,\n",
       "  0.044,\n",
       "  0.0203,\n",
       "  0.1662,\n",
       "  0.4445,\n",
       "  0.9832,\n",
       "  0.7989,\n",
       "  0.3331,\n",
       "  0.12,\n",
       "  0.0887,\n",
       "  0.1274,\n",
       "  0.8001,\n",
       "  0.4971,\n",
       "  0.2895,\n",
       "  0.1721,\n",
       "  0.7462,\n",
       "  0.2492,\n",
       "  0.8879,\n",
       "  0.1852,\n",
       "  0.7772,\n",
       "  0.7768,\n",
       "  0.8209,\n",
       "  0.753,\n",
       "  0.565,\n",
       "  0.9631],\n",
       " 'across': 0.4728,\n",
       " 'adjusted': {'within': [0.6812142857142858,\n",
       "   0.8890312499999999,\n",
       "   0.6812142857142858,\n",
       "   0.7693269230769232,\n",
       "   0.5556000000000001,\n",
       "   0.9832,\n",
       "   0.980780487804878,\n",
       "   0.3114,\n",
       "   0.8570322580645162,\n",
       "   0.5556000000000001,\n",
       "   0.6812142857142858,\n",
       "   0.9832,\n",
       "   0.7635000000000001,\n",
       "   0.5556000000000001,\n",
       "   0.8570322580645162,\n",
       "   0.0,\n",
       "   0.6812142857142858,\n",
       "   0.6949565217391305,\n",
       "   0.01125,\n",
       "   0.0555,\n",
       "   0.32999999999999996,\n",
       "   0.22837499999999997,\n",
       "   0.5556000000000001,\n",
       "   0.7693269230769232,\n",
       "   0.9832,\n",
       "   0.9471923076923077,\n",
       "   0.6813409090909092,\n",
       "   0.5556000000000001,\n",
       "   0.5556000000000001,\n",
       "   0.5556000000000001,\n",
       "   0.9471923076923077,\n",
       "   0.7989107142857143,\n",
       "   0.6812142857142858,\n",
       "   0.5556000000000001,\n",
       "   0.9471923076923077,\n",
       "   0.6812142857142858,\n",
       "   0.980780487804878,\n",
       "   0.5556000000000001,\n",
       "   0.9471923076923077,\n",
       "   0.9471923076923077,\n",
       "   0.9471923076923077,\n",
       "   0.9471923076923077,\n",
       "   0.8570322580645162,\n",
       "   0.9832],\n",
       "  'across': [0.788]}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values['firstHalfSecond']['lpfc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do 2x2 anova for interaction effects \n",
    "this requires reloading in all four conditions (four this time cuz interaction contrasts).  \n",
    "ONLY RUN THIS WHEN LOADING IN THE FOUR INTERACTION CONTRASTS RIGHT NOW.  \n",
    "Integrate with other stats and plotting and stuff later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time windows\n",
    "# define these based on epoch start and also sampling rate\n",
    "start_idx_firstHalfSecond, end_idx_firstHalfSecond = 2048, 3072\n",
    "start_idx_secondHalfSecond, end_idx_secondHalfSecond = 3072, 4096\n",
    "start_idx_fullSecond, end_idx_fullSecond = 2048, 4096\n",
    "# Function to create a nested dictionary for each output_name with ROIs as keys\n",
    "def initialize_output_data(rois, output_names):\n",
    "    return {output_name: {roi: [] for roi in rois} for output_name in output_names}\n",
    "\n",
    "# Assuming output_names contains all four conditions\n",
    "# Initializing dictionaries\n",
    "output_data_trialAvg_lists = initialize_output_data(rois, output_names)\n",
    "output_data_trialStd_lists = initialize_output_data(rois, output_names)\n",
    "output_data_timeAvg_firstHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "output_data_timeAvg_secondHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "output_data_timeAvg_fullSecond_lists = initialize_output_data(rois, output_names)\n",
    "\n",
    "# Initialize a dictionary to hold mappings\n",
    "overall_electrode_mapping = []\n",
    "\n",
    "# Initialize a dictionary to hold mappings for each ROI\n",
    "electrode_mapping_per_roi = {roi: [] for roi in rois}\n",
    "for sub in subjects:\n",
    "    for roi in rois:\n",
    "        for output_name in output_names:\n",
    "            # Determine significant electrodes for the current ROI and subject\n",
    "            # sig_electrodes = sig_dlpfc_electrodes_per_subject.get(sub, []) if roi == 'dlpfc' else sig_acc_electrodes_per_subject.get(sub, []) if roi == 'acc' else sig_parietal_electrodes_per_subject.get(sub, [])\n",
    "            \n",
    "            sig_electrodes = sig_electrodes_per_subject_roi[roi].get(sub, [])\n",
    "            print('sub', sub)\n",
    "            print('sig elecs:', sig_electrodes)\n",
    "            \n",
    "            if not sig_electrodes:  # Skip if no significant electrodes\n",
    "                continue\n",
    "                        \n",
    "            for electrode in sig_electrodes:\n",
    "                # For each significant electrode, append a tuple to the mapping list\n",
    "                # Tuple format: (Subject ID, ROI, Electrode Name, Index in List)\n",
    "                # The index can be the current length of the list before appending\n",
    "                index = len(overall_electrode_mapping)\n",
    "                overall_electrode_mapping.append((sub, roi, electrode, output_name, index))  \n",
    "\n",
    "                # For each significant electrode, append a tuple to the mapping list of the corresponding ROI\n",
    "                # Tuple format: (Subject ID, Electrode Name, Index in List for this ROI)\n",
    "                index = len(electrode_mapping_per_roi[roi])  # Get the current length of the list for this ROI\n",
    "                electrode_mapping_per_roi[roi].append((sub, electrode, output_name, index))\n",
    "                \n",
    "            # Load trial-level data for the current condition and pick significant electrodes\n",
    "            epochs = subjects_mne_objects[sub][output_name]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "            # print(epochs.get_data().shape)\n",
    "            # Calculate averages for each time window\n",
    "            trial_avg, trial_std, time_avg_firstHalfSecond = utils.filter_and_average_epochs(epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "            _, _, time_avg_secondHalfSecond = utils.filter_and_average_epochs(epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "            _, _, time_avg_fullSecond = utils.filter_and_average_epochs(epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "            print('time avg full second shape:', time_avg_fullSecond.shape)\n",
    "\n",
    "            # Append the results to their respective lists\n",
    "            output_data_trialAvg_lists[output_name][roi].append(trial_avg)\n",
    "            output_data_trialStd_lists[output_name][roi].append(trial_std)\n",
    "            output_data_timeAvg_firstHalfSecond_lists[output_name][roi].append(time_avg_firstHalfSecond)\n",
    "            output_data_timeAvg_secondHalfSecond_lists[output_name][roi].append(time_avg_secondHalfSecond)\n",
    "            output_data_timeAvg_fullSecond_lists[output_name][roi].append(time_avg_fullSecond)\n",
    "\n",
    "\n",
    "# After collecting all data, concatenate across subjects for each roi and condition\n",
    "concatenated_trialAvg_data = {}\n",
    "concatenated_trialStd_data = {}\n",
    "\n",
    "for roi in rois:\n",
    "    concatenated_trialAvg_data[roi] = {}\n",
    "    concatenated_trialStd_data[roi] = {}\n",
    "\n",
    "    for output_name in output_names:\n",
    "        concatenated_trialAvg_data[roi][output_name] = np.concatenate(output_data_trialAvg_lists[output_name][roi], axis=0)\n",
    "        concatenated_trialStd_data[roi][output_name] = np.concatenate(output_data_trialStd_lists[output_name][roi], axis=0)\n",
    "\n",
    "\n",
    "# Calculate mean and SEM across electrodes for all time windows and rois\n",
    "overall_averages = {}\n",
    "overall_sems = {}\n",
    "for roi in rois:\n",
    "    overall_averages[roi] = {}\n",
    "    overall_sems[roi] = {}\n",
    "    for output_name in output_names:\n",
    "        trialAvg_data = concatenated_trialAvg_data[roi][output_name]\n",
    "        overall_averages[roi][output_name] = np.nanmean(trialAvg_data, axis=0)\n",
    "        overall_sems[roi][output_name] = np.std(trialAvg_data, axis=0, ddof=1) / np.sqrt(trialAvg_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the subject indexing is being thrown off by the subjects that DONT have electrodes in this roi. Maybe skip those subjects for the index? Or make subject index consistent across variables.. 4/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get subjects that have data so that indexing isn't thrown off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_electrodes_per_subject_roi['lpfc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "# Determine LAB_root based on the operating system\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "# Example structure for organizing data for ANOVA with four conditions\n",
    "data_for_anova = []\n",
    "\n",
    "\n",
    "# Function to process and append data for ANOVA from time-averaged lists\n",
    "# Adapted function to include Congruency and SwitchType\n",
    "# modifying this to include time windows as another factor 4/4! Use code before 4/4 if don't want to include time windows.\n",
    "def process_and_append_data_for_anova(time_averaged_lists_dict):\n",
    "    for time_window, lists in time_averaged_lists_dict.items():\n",
    "        for output_name in output_names:\n",
    "            print('output name:', output_name)\n",
    "            # Dynamically get condition types and their values for the current output_name\n",
    "            conditions = output_names_conditions[output_name]\n",
    "            \n",
    "            for roi in rois: #this is good cuz it loops through rois 3/6, the trial level one should copy this logic\n",
    "                sig_electrodes_per_subject = sig_electrodes_per_subject_roi[roi]\n",
    "                subjects_with_data = [subject for subject, electrodes in sig_electrodes_per_subject.items() if electrodes] # add this line to skip over subjects without data 4/1\n",
    "                for subject_index, subject_data in enumerate(lists[output_name][roi]):\n",
    "                    subject_id = subjects_with_data[subject_index]\n",
    "\n",
    "                    # Skip this subject if there are no significant electrodes for them in this ROI\n",
    "                    if subject_id not in sig_electrodes_per_subject or not sig_electrodes_per_subject[subject_id]:\n",
    "                        continue\n",
    "\n",
    "                    # Calculate the mean across trials for each electrode\n",
    "                    mean_activity_per_electrode = np.nanmean(subject_data, axis=0)\n",
    "                    # untested making this more modular 2/27\n",
    "                    for electrode_index, mean_activity in enumerate(mean_activity_per_electrode):\n",
    "                        print('electrode index:', electrode_index)\n",
    "                        electrode_name = sig_electrodes_per_subject[subject_id][electrode_index]\n",
    "                        print(electrode_name)\n",
    "                        # Prepare data dictionary, starting with fixed attributes\n",
    "                        data_dict = {\n",
    "                            'SubjectID': subject_id,\n",
    "                            'Electrode': electrode_name,\n",
    "                            'ROI': roi,\n",
    "                            'TimeWindow': time_window,\n",
    "                            'MeanActivity': mean_activity\n",
    "                        }\n",
    "\n",
    "                        # Dynamically add condition types and their values\n",
    "                        data_dict.update(conditions)\n",
    "\n",
    "                        # Append the organized data to the list\n",
    "                        data_for_anova.append(data_dict)\n",
    "\n",
    "# Create a time averaged lists dictionary to pass in to the process and append data for anova function\n",
    "                    \n",
    "# use this one to compare early vs late vs all time\n",
    "# time_averaged_lists = {\n",
    "#         \"FirstHalfSecond\": output_data_timeAvg_firstHalfSecond_lists,\n",
    "#         \"SecondHalfSecond\": output_data_timeAvg_secondHalfSecond_lists,\n",
    "#         \"FullSecond\": output_data_timeAvg_fullSecond_lists\n",
    "# }\n",
    "                    \n",
    "# use this one to just compare early and late time\n",
    "time_averaged_lists_dict = {\n",
    "        \"FirstHalfSecond\": output_data_timeAvg_firstHalfSecond_lists,\n",
    "        \"SecondHalfSecond\": output_data_timeAvg_secondHalfSecond_lists\n",
    "}\n",
    "\n",
    "process_and_append_data_for_anova(time_averaged_lists_dict)\n",
    "# Convert to DataFrame\n",
    "df_for_anova = pd.DataFrame(data_for_anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now actually run anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_modular_anova_all_time_windows(df, output_names_conditions, save_dir, save_name_prefix):\n",
    "    # Dynamically construct the model formula based on condition keys and include TimeWindow\n",
    "    condition_keys = [key for key in output_names_conditions[next(iter(output_names_conditions))].keys()]\n",
    "    formula_terms = ' + '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "    interaction_terms = ' * '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "    formula = f'MeanActivity ~ {formula_terms} + {interaction_terms}'\n",
    "\n",
    "    # Define the model\n",
    "    model = ols(formula, data=df).fit()\n",
    "\n",
    "    # Perform the ANOVA\n",
    "    anova_results = anova_lm(model, typ=2)\n",
    "\n",
    "    # Define the base part of the results file name\n",
    "    results_file_path = os.path.join(save_dir, f\"{save_name_prefix}_ANOVAacrossElectrodes_allTimeWindows.txt\")\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(results_file_path, 'w') as file:\n",
    "        file.write(anova_results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"ANOVA results for all time windows saved to: {results_file_path}\")\n",
    "\n",
    "    # Print the results\n",
    "    print(anova_results)\n",
    "\n",
    "    return anova_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the ROIs with '_' as the separator\n",
    "rois_suffix = '_'.join(rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency vs congruency proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    perform_modular_anova_all_time_windows(df_for_anova, output_names_conditions, save_dir, f'congruency_congruencyProportion_{rois_suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do switch type vs switch proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    perform_modular_anova_all_time_windows(df_for_anova, output_names_conditions, save_dir, f'switchType_switchProportion_{rois_suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do congruency vs switch type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the new across time windows anova 4/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cs_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    perform_modular_anova_all_time_windows(df_for_anova, output_names_conditions, save_dir, f'congruency_switchType_{rois_suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay now do within-electrode anova too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_anova = []\n",
    "\n",
    "def process_and_append_trial_data_for_anova(time_averaged_lists, output_names_conditions):\n",
    "    for time_window, lists in time_averaged_lists.items():\n",
    "        for output_name, conditions in output_names_conditions.items():\n",
    "            for roi in rois:\n",
    "                sig_electrodes_per_subject = sig_electrodes_per_subject_roi[roi]\n",
    "                subjects_with_data = [subject for subject, electrodes in sig_electrodes_per_subject.items() if electrodes] # Skip over subjects without data\n",
    "                for subject_index, subject_data in enumerate(lists[output_name][roi]):\n",
    "                    subject_id = subjects_with_data[subject_index]\n",
    "\n",
    "                    if subject_id not in sig_electrodes_per_subject or not sig_electrodes_per_subject[subject_id]:\n",
    "                        continue\n",
    "\n",
    "                    for trial_index, trial_data in enumerate(subject_data):\n",
    "                        # Skip trials with any missing data or incorrect length\n",
    "                        if np.any(np.isnan(trial_data)) or len(trial_data) != len(sig_electrodes_per_subject[subject_id]):\n",
    "                            continue\n",
    "\n",
    "                        for electrode_index, electrode_name in enumerate(sig_electrodes_per_subject[subject_id]):\n",
    "                            activity = trial_data[electrode_index] if electrode_index < len(trial_data) else np.nan\n",
    "\n",
    "                            # Prepare the data dictionary\n",
    "                            data_dict = {\n",
    "                                'SubjectID': subject_id,\n",
    "                                'Electrode': electrode_name,\n",
    "                                'ROI': roi,\n",
    "                                'TimeWindow': time_window,\n",
    "                                'Trial': trial_index + 1,\n",
    "                                'Activity': activity\n",
    "                            }\n",
    "\n",
    "                            # Dynamically add condition types and their values\n",
    "                            data_dict.update(conditions)\n",
    "\n",
    "                            data_for_anova.append(data_dict)\n",
    "\n",
    "# Example usage with the `time_averaged_lists` dictionary\n",
    "time_averaged_lists = {\n",
    "    \"FirstHalfSecond\": output_data_timeAvg_firstHalfSecond_lists,\n",
    "    \"SecondHalfSecond\": output_data_timeAvg_secondHalfSecond_lists,\n",
    "    # \"FullSecond\": output_data_timeAvg_fullSecond_lists  # Uncomment or comment based on your needs\n",
    "}\n",
    "\n",
    "process_and_append_trial_data_for_anova(time_averaged_lists, output_names_conditions)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_for_trial_level_anova = pd.DataFrame(data_for_anova)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_for_trial_level_anova is your DataFrame and it includes a 'SubjectID' column\n",
    "def perform_modular_within_electrode_anova_roi(df, output_names_conditions, save_dir, save_name):\n",
    "    '''\n",
    "    This gets if an electrode is significant for specific time windows. It does not get their interaction.\n",
    "    '''\n",
    "    import json\n",
    "    results = []\n",
    "    significant_effects_structure = {}\n",
    "\n",
    "    for subject_id in df['SubjectID'].unique():\n",
    "        for electrode in df['Electrode'].unique(): #this is wrong cuz then it only does dlpfc, fix this 4/1\n",
    "            for time_window in df['TimeWindow'].unique():\n",
    "                df_filtered = df[(df['SubjectID'] == subject_id) & \n",
    "                                 (df['Electrode'] == electrode) & \n",
    "                                 (df['TimeWindow'] == time_window)]\n",
    "                \n",
    "                if df_filtered.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Dynamically construct the formula based on condition keys present in the DataFrame\n",
    "                condition_keys = [key for key in output_names_conditions[next(iter(output_names_conditions))].keys()]\n",
    "                formula_terms = ' + '.join([f'C({key})' for key in condition_keys])\n",
    "                interaction_terms = ' * '.join([f'C({key})' for key in condition_keys])\n",
    "                formula = f'Activity ~ {formula_terms} + {interaction_terms}'\n",
    "\n",
    "                # Perform the ANOVA\n",
    "                model = ols(formula, data=df_filtered).fit()\n",
    "                anova_results = anova_lm(model, typ=2)\n",
    "                \n",
    "                # Append the results\n",
    "                results.append({\n",
    "                    'SubjectID': subject_id,\n",
    "                    'Electrode': electrode,\n",
    "                    'TimeWindow': time_window,\n",
    "                    'ANOVA_Results': anova_results\n",
    "                })\n",
    "    \n",
    "    # Join all the ROIs with '_' as the separator\n",
    "    rois_suffix = '_'.join(rois)\n",
    "\n",
    "    # Add the suffix '_onlySigElectrodes' to the base filename\n",
    "    allElectrodesFilename = f\"{save_name}_allElectrodes_{rois_suffix}.txt\"\n",
    "    onlySigElectrodesFilename = f\"{save_name}_onlySigElectrodes_{rois_suffix}.txt\"\n",
    "    significantEffectsStructureFilename = f\"{save_name}_significantEffectsStructure_{rois_suffix}.txt\"\n",
    "\n",
    "    # Define the full path for the results file\n",
    "    results_file_path = os.path.join(save_dir, allElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(results_file_path, 'w') as file:\n",
    "        file.write(results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"results saved to: {results_file_path}\")\n",
    "\n",
    "    # Now process the significant results, including the subject ID in the output\n",
    "    significant_results = []\n",
    "\n",
    "    for result in results:\n",
    "        anova_table = result['ANOVA_Results']\n",
    "        subject_id = result['SubjectID']\n",
    "        electrode = result['Electrode']\n",
    "        time_window = result['TimeWindow']\n",
    "        \n",
    "        significant_effects = anova_table[anova_table['PR(>F)'] < 0.05]\n",
    "        \n",
    "        if not significant_effects.empty:\n",
    "            print(f\"Significant effects found for Subject: {subject_id}, Electrode: {electrode}, Time Window: {time_window}\")\n",
    "            print(significant_effects)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            significant_results.append({\n",
    "                'SubjectID': subject_id,\n",
    "                'Electrode': electrode,\n",
    "                'TimeWindow': time_window,\n",
    "                'SignificantEffects': significant_effects\n",
    "            })\n",
    "\n",
    "        # Extract significant effects for the current result. Basically just get the p-value. 3/19.\n",
    "        sig_effects_just_p_values = utils.extract_significant_effects(anova_table)\n",
    "        \n",
    "        if sig_effects_just_p_values:\n",
    "            # Ensure subject_id and electrode keys exist\n",
    "            if subject_id not in significant_effects_structure:\n",
    "                significant_effects_structure[subject_id] = {}\n",
    "            if electrode not in significant_effects_structure[subject_id]:\n",
    "                significant_effects_structure[subject_id][electrode] = {}\n",
    "            \n",
    "            # Assign the significant effects and their p-values to the correct structure\n",
    "            significant_effects_structure[subject_id][electrode][time_window] = sig_effects_just_p_values    \n",
    "\n",
    "    # Define the full path for the results file\n",
    "    significant_results_file_path = os.path.join(save_dir, onlySigElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(significant_results_file_path, 'w') as file:\n",
    "        file.write(significant_results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_results saved to: {significant_results_file_path}\")\n",
    "\n",
    "    significant_effects_structure_file_path = os.path.join(save_dir, significantEffectsStructureFilename)\n",
    "    # Save the ANOVA results to a json file (if this works, change the others to json files too)\n",
    "    with open(significant_effects_structure_file_path, 'w') as file:\n",
    "        json.dump(significant_effects_structure, file, indent=4)\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_effects_structure saved to: {significant_effects_structure_file_path}\")\n",
    "\n",
    "    return results, significant_results, significant_effects_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_for_trial_level_anova is your DataFrame and it includes a 'SubjectID' column\n",
    "def perform_modular_within_electrode_anova_roi_timeWindowInteractions(df, output_names_conditions, save_dir, save_name):\n",
    "    '''\n",
    "    This gets if the main and interaction effect of time window is significant for an electrode. AKA is overall or condition-specific activity different across differnet time windows?\n",
    "    It does not tell you which time windows are significant. \n",
    "    '''\n",
    "    import json\n",
    "    results = []\n",
    "    significant_effects_structure = {}\n",
    "\n",
    "    for subject_id in df['SubjectID'].unique():\n",
    "        for electrode in df['Electrode'].unique(): #this is wrong cuz then it only does dlpfc, fix this 4/1\n",
    "                df_filtered = df[(df['SubjectID'] == subject_id) & \n",
    "                                 (df['Electrode'] == electrode)]\n",
    "                \n",
    "                if df_filtered.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Dynamically construct the formula based on condition keys present in the DataFrame\n",
    "                condition_keys = [key for key in output_names_conditions[next(iter(output_names_conditions))].keys()]\n",
    "                formula_terms = ' + '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "                interaction_terms = ' * '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "                formula = f'Activity ~ {formula_terms} + {interaction_terms}'\n",
    "\n",
    "                # Perform the ANOVA\n",
    "                model = ols(formula, data=df_filtered).fit()\n",
    "                anova_results = anova_lm(model, typ=2)\n",
    "                \n",
    "                # Append the results\n",
    "                results.append({\n",
    "                    'SubjectID': subject_id,\n",
    "                    'Electrode': electrode,\n",
    "                    'ANOVA_Results': anova_results\n",
    "                })\n",
    "    \n",
    "    # Join all the ROIs with '_' as the separator\n",
    "    rois_suffix = '_'.join(rois)\n",
    "\n",
    "    # Add the suffix '_onlySigElectrodes' to the base filename\n",
    "    allElectrodesFilename = f\"{save_name}_allElectrodes_{rois_suffix}.txt\"\n",
    "    onlySigElectrodesFilename = f\"{save_name}_onlySigElectrodes_{rois_suffix}.txt\"\n",
    "    significantEffectsStructureFilename = f\"{save_name}_significantEffectsStructure_{rois_suffix}.txt\"\n",
    "\n",
    "    # Define the full path for the results file\n",
    "    results_file_path = os.path.join(save_dir, allElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(results_file_path, 'w') as file:\n",
    "        file.write(results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"results saved to: {results_file_path}\")\n",
    "\n",
    "    # Now process the significant results, including the subject ID in the output\n",
    "    significant_results = []\n",
    "\n",
    "    for result in results:\n",
    "        anova_table = result['ANOVA_Results']\n",
    "        subject_id = result['SubjectID']\n",
    "        electrode = result['Electrode']\n",
    "        \n",
    "        significant_effects = anova_table[anova_table['PR(>F)'] < 0.05]\n",
    "        \n",
    "        if not significant_effects.empty:\n",
    "            print(f\"Significant effects found for Subject: {subject_id}, Electrode: {electrode}\")\n",
    "            print(significant_effects)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            significant_results.append({\n",
    "                'SubjectID': subject_id,\n",
    "                'Electrode': electrode,\n",
    "                'SignificantEffects': significant_effects\n",
    "            })\n",
    "\n",
    "        # Extract significant effects for the current result. Basically just get the p-value. 3/19.\n",
    "        sig_effects_just_p_values = utils.extract_significant_effects(anova_table)\n",
    "        \n",
    "        if sig_effects_just_p_values:\n",
    "            # Ensure subject_id and electrode keys exist\n",
    "            if subject_id not in significant_effects_structure:\n",
    "                significant_effects_structure[subject_id] = {}\n",
    "            if electrode not in significant_effects_structure[subject_id]:\n",
    "                significant_effects_structure[subject_id][electrode] = {}\n",
    "            \n",
    "            # Assign the significant effects and their p-values to the correct structure\n",
    "            significant_effects_structure[subject_id][electrode] = sig_effects_just_p_values    \n",
    "\n",
    "    # Define the full path for the results file\n",
    "    significant_results_file_path = os.path.join(save_dir, onlySigElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(significant_results_file_path, 'w') as file:\n",
    "        file.write(significant_results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_results saved to: {significant_results_file_path}\")\n",
    "\n",
    "    significant_effects_structure_file_path = os.path.join(save_dir, significantEffectsStructureFilename)\n",
    "    # Save the ANOVA results to a json file (if this works, change the others to json files too)\n",
    "    with open(significant_effects_structure_file_path, 'w') as file:\n",
    "        json.dump(significant_effects_structure, file, indent=4)\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_effects_structure saved to: {significant_effects_structure_file_path}\")\n",
    "\n",
    "    return results, significant_results, significant_effects_structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency as function of congruency proportion  \n",
    "maybe make the save_name based on the conditions..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results, significant_results, significant_effects_structure = perform_modular_within_electrode_anova_roi(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_congruencyProportion_ANOVAwithinElectrodes')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results_timeWindowInteraction, significant_results_timeWindowInteraction, significant_effects_structure_timeWindowInteraction = perform_modular_within_electrode_anova_roi_timeWindowInteractions(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_congruencyProportion_ANOVAwithinElectrodes_timeWindowInteractions')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switch type as function of switch proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results, significant_results. significant_effects_structure = perform_modular_within_electrode_anova_roi(df_for_trial_level_anova, output_names_conditions, save_dir, 'switchType_switchProportion_ANOVAwithinElectrodes')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_s25_fixationCrossBase_1sec_mirror' is not in output_names.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results_timeWindowInteraction, significant_results_timeWindowInteraction, significant_effects_structure_timeWindowInteraction = perform_modular_within_electrode_anova_roi_timeWindowInteractions(df_for_trial_level_anova, output_names_conditions, save_dir, 'switchType_switchProportion_ANOVAwithinElectrodes_timeWindowInteractions')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_s25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency as function of switch type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/4 do both perform_modular_within_electrode_anova_roi and perform_modular_within_electrode_anova_roi_timeWindowInteractions. This will tell us which time windows have significant activity in an electrode AND if there is significant differences in activity across time windows in an electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results, significant_results, significant_effects_structure = perform_modular_within_electrode_anova_roi(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_switchType_ANOVAwithinElectrodes')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results_timeWindowInteraction, significant_results_timeWindowInteraction, significant_effects_structure_timeWindowInteraction = perform_modular_within_electrode_anova_roi_timeWindowInteractions(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_switchType_ANOVAwithinElectrodes_timeWindowInteractions')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot and QC stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot time perm cluster stats (don't run this immediately below cell if didn't do time perm cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(time_perm_cluster_results['dlpfc'])\n",
    "# plt.xlabel('Timepoints')\n",
    "# plt.ylabel('Significance (0 or 1)')\n",
    "# plt.title('Permutation Test Significance Over Time')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot interaction effects (only do this when load in all four of them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://matplotlib.org/stable/gallery/color/named_colors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the other conditions and give them condition names and colors too\n",
    "plotting_parameters = {\n",
    "    'Stimulus_r25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'repeat',\n",
    "        'color': 'red',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    'Stimulus_s25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'switch',\n",
    "        'color': 'green',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    'Stimulus_c25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'congruent',\n",
    "        'color': 'blue',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    'Stimulus_i25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'incongruent',\n",
    "        'color': 'orange',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"IR\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"IS\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"CR\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"CS\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_c25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"c25\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_c75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"c75\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_i25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"i25\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_i75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"i75\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_s25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"s25\",\n",
    "        \"color\": \"green\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_s75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"s75\",\n",
    "        \"color\": \"green\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_r25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"r25\",\n",
    "        \"color\": \"pink\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_r75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"r75\",\n",
    "        \"color\": \"pink\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "# # Save the dictionary to a file\n",
    "# with open('plotting_parameters.json', 'w') as file:\n",
    "#     json.dump(plotting_parameters, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.make_plotting_parameters() #make plotting parameters. Modify colors and line types in misc_functions.\n",
    "\n",
    "# Load the dictionary from the file\n",
    "with open('plotting_parameters.json', 'r') as file:\n",
    "    plotting_parameters = json.load(file)\n",
    "\n",
    "print(plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "# Determine LAB_root based on the operating system\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "def plot_interact_effects_modular_roi(roi, save_dir, save_name, overall_averages, overall_sems, output_names, plotting_parameters):\n",
    "    # Base setup for directories and file paths\n",
    "    save_path = os.path.join(save_dir, f'avg_{roi}_{save_name}_interactEffects_zscore_roi.png')\n",
    "\n",
    "    # Initialize plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Dynamically select the first subject and use it to extract times\n",
    "    first_subject_id = next(iter(subjects_mne_objects))\n",
    "    example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "    times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "    overall_averages_for_plotting = {}\n",
    "    overall_sem_for_plotting = {}\n",
    "    # Initialize variables to store the global min and max values\n",
    "    global_min_val = float('inf')  # Set to infinity initially\n",
    "    global_max_val = float('-inf')  # Set to negative infinity initially\n",
    "    \n",
    "    # Generate labels and plot each condition\n",
    "    for index, output_name in enumerate(output_names):\n",
    "        # label = output_name.split(\"_\")[1]  # OR extract label from output name instead of plotting parameters dict. Up to you.\n",
    "        overall_averages_for_plotting[output_name] = overall_averages[roi][output_name]\n",
    "        overall_sem_for_plotting[output_name] = overall_sems[roi][output_name]\n",
    "\n",
    "        # Calculate the minimum value for this condition, including SEM\n",
    "        current_min_val = min(overall_averages_for_plotting[output_name] - overall_sem_for_plotting[output_name])\n",
    "        # Calculate the maximum value for this condition, including SEM\n",
    "        current_max_val = max(overall_averages_for_plotting[output_name] + overall_sem_for_plotting[output_name])\n",
    "\n",
    "        # Update the global min and max values if necessary\n",
    "        global_min_val = min(global_min_val, current_min_val)\n",
    "        global_max_val = max(global_max_val, current_max_val)\n",
    "\n",
    "        # Optionally, add a small margin to the range\n",
    "        margin = (global_max_val - global_min_val) * 0.05  # 5% of the range as margin\n",
    "        global_min_val -= margin\n",
    "        global_max_val += margin\n",
    "\n",
    "        label = plotting_parameters[output_name]['condition_name'] # extract label from plotting parameters dict\n",
    "        color = plotting_parameters[output_name]['color']\n",
    "        line_style = plotting_parameters[output_name]['line_style']\n",
    "\n",
    "        plt.plot(times, overall_averages_for_plotting[output_name], label=f'Average {roi} {label}', linestyle=line_style, color=color)\n",
    "        plt.fill_between(times, overall_averages_for_plotting[output_name] - overall_sem_for_plotting[output_name], overall_averages_for_plotting[output_name] + overall_sem_for_plotting[output_name], alpha=0.3, color=color)\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Z-score')\n",
    "    plt.title(f'Average {roi} Signal with Standard Error for {save_name}')\n",
    "    plt.legend()\n",
    "    # Adjust the y-axis limits\n",
    "    plt.ylim([global_min_val, global_max_val])\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just for congruent vs congruency proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('dlpfc', save_dir, 'congruency_congruencyProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('acc', save_dir, 'congruency_congruencyProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('parietal', save_dir, 'congruency_congruencyProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('dlpfc', save_dir, 'switchType_switchProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('acc', save_dir, 'switchType_switchProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('parietal', save_dir, 'switchType_switchProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this just for congruency vs switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('dlpfc', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('acc', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('parietal', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to plot different groups of electrodes based on significance for effects 4/4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_electrodes_by_effect(effect_structure, effect_type):\n",
    "    '''\n",
    "    Extracts electrodes with significant specified effects.\n",
    "\n",
    "    :param effect_structure: Dictionary containing significant effects for each electrode and subject.\n",
    "    :param effect_type: Single string or list of strings specifying the effect(s) of interest (\"congruency\", \"switchType\", \"congruency:switchType\", etc).\n",
    "    :return: A dictionary mapping subject IDs to lists of electrodes with the specified significant effect(s).\n",
    "    '''\n",
    "    significant_electrodes = {}\n",
    "\n",
    "    # Ensure effect_type is a list to simplify the logic\n",
    "    if isinstance(effect_type, str):\n",
    "        effect_type = [effect_type]\n",
    "\n",
    "    for subject_id, electrodes in effect_structure.items():\n",
    "        significant_electrodes_for_subject = []  # Temporary list to hold significant electrodes for a subject\n",
    "        for electrode, effects in electrodes.items():\n",
    "            for effect, p_value in effects:  # Directly unpacking the tuples here\n",
    "                if effect in effect_type and p_value < 0.05:  # Check if effect is among those of interest\n",
    "                    significant_electrodes_for_subject.append(electrode)\n",
    "                    break  # Stop checking once a significant effect is found for this electrode\n",
    "        if significant_electrodes_for_subject:  # Only add to the dict if there are significant electrodes for the subject\n",
    "            significant_electrodes[subject_id] = significant_electrodes_for_subject\n",
    "    return significant_electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySigElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, 'congruency')\n",
    "switchTypeSigElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, 'switchType')\n",
    "congruencySwitchTypeInteractionSigElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, 'congruency:switchType')\n",
    "allEffectSensitiveElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, ['congruency', 'switchType', 'congruency:switchType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allEffectSensitiveElectrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remake overall averages but just for the chosen electrodes. I wonder if I should make this a function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time windows\n",
    "# define these based on epoch start and also sampling rate\n",
    "start_idx_firstHalfSecond, end_idx_firstHalfSecond = 2048, 3072 #define these based on the actual sampling rate variable in the future...i think i do this in another script somewhere.\n",
    "start_idx_secondHalfSecond, end_idx_secondHalfSecond = 3072, 4096\n",
    "start_idx_fullSecond, end_idx_fullSecond = 2048, 4096\n",
    "# Function to create a nested dictionary for each output_name with ROIs as keys\n",
    "def initialize_output_data(rois, output_names):\n",
    "    return {output_name: {roi: [] for roi in rois} for output_name in output_names}\n",
    "\n",
    "def is_dict_of_dicts(d):\n",
    "    \"\"\"Check if the input is a dictionary of dictionaries.\"\"\"\n",
    "    return isinstance(d, dict) and all(isinstance(val, dict) for val in d.values())\n",
    "\n",
    "def get_sig_electrodes(sig_electrodes, roi, sub):\n",
    "    \"\"\"Get significant electrodes based on the structure of sig_electrodes. Significant effects structure removes roi info, but sig_electrodes_per_subject_roi keeps it.\n",
    "    maybe I should make these consistent... 4/5\"\"\"\n",
    "    if is_dict_of_dicts(sig_electrodes):\n",
    "        return sig_electrodes[roi].get(sub, [])\n",
    "    else:\n",
    "        return sig_electrodes.get(sub, [])\n",
    "    \n",
    "# this massive function needs to be split up and replace its above non-function form once it works 4/5.\n",
    "def get_average_data_for_specific_electrodes(subjects, rois, output_names, sig_electrodes):\n",
    "    # Assuming output_names contains all four conditions\n",
    "    # Initializing dictionaries\n",
    "    output_data_trialAvg_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_trialStd_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_timeAvg_firstHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_timeAvg_secondHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_timeAvg_fullSecond_lists = initialize_output_data(rois, output_names)\n",
    "\n",
    "    # Initialize a dictionary to hold mappings\n",
    "    overall_electrode_mapping = []\n",
    "\n",
    "    # Initialize a dictionary to hold mappings for each ROI\n",
    "    electrode_mapping_per_roi = {roi: [] for roi in rois}\n",
    "    for sub in subjects:\n",
    "        for roi in rois:\n",
    "            for output_name in output_names:\n",
    "                # Determine significant electrodes for the current ROI and subject. Hmm not sure if this will work if I have more than one ROI for the \n",
    "                # get_significant_electrodes_by_effect electrodes.. 4/5\n",
    "                sig_electrodes_this_sub = get_sig_electrodes(sig_electrodes, roi, sub)\n",
    "                print('sub', sub)\n",
    "                print('sig elecs:', sig_electrodes_this_sub)\n",
    "                \n",
    "                if not sig_electrodes_this_sub:  # Skip if no significant electrodes\n",
    "                    continue\n",
    "                            \n",
    "                for electrode in sig_electrodes_this_sub:\n",
    "                    # For each significant electrode, append a tuple to the mapping list\n",
    "                    # Tuple format: (Subject ID, ROI, Electrode Name, Index in List)\n",
    "                    # The index can be the current length of the list before appending\n",
    "                    index = len(overall_electrode_mapping)\n",
    "                    overall_electrode_mapping.append((sub, roi, electrode, output_name, index))  \n",
    "\n",
    "                    # For each significant electrode, append a tuple to the mapping list of the corresponding ROI\n",
    "                    # Tuple format: (Subject ID, Electrode Name, Index in List for this ROI)\n",
    "                    index = len(electrode_mapping_per_roi[roi])  # Get the current length of the list for this ROI\n",
    "                    electrode_mapping_per_roi[roi].append((sub, electrode, output_name, index))\n",
    "                    \n",
    "                # Load trial-level data for the current condition and pick significant electrodes\n",
    "                epochs = subjects_mne_objects[sub][output_name]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes_this_sub)\n",
    "                # print(epochs.get_data().shape)\n",
    "                # Calculate averages for each time window\n",
    "                trial_avg, trial_std, time_avg_firstHalfSecond = utils.filter_and_average_epochs(epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "                _, _, time_avg_secondHalfSecond = utils.filter_and_average_epochs(epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "                _, _, time_avg_fullSecond = utils.filter_and_average_epochs(epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "                print('time avg full second shape:', time_avg_fullSecond.shape)\n",
    "\n",
    "                # Append the results to their respective lists\n",
    "                output_data_trialAvg_lists[output_name][roi].append(trial_avg)\n",
    "                output_data_trialStd_lists[output_name][roi].append(trial_std)\n",
    "                output_data_timeAvg_firstHalfSecond_lists[output_name][roi].append(time_avg_firstHalfSecond)\n",
    "                output_data_timeAvg_secondHalfSecond_lists[output_name][roi].append(time_avg_secondHalfSecond)\n",
    "                output_data_timeAvg_fullSecond_lists[output_name][roi].append(time_avg_fullSecond)\n",
    "\n",
    "\n",
    "    # After collecting all data, concatenate across subjects for each roi and condition\n",
    "    concatenated_trialAvg_data = {}\n",
    "    concatenated_trialStd_data = {}\n",
    "\n",
    "    for roi in rois:\n",
    "        concatenated_trialAvg_data[roi] = {}\n",
    "        concatenated_trialStd_data[roi] = {}\n",
    "\n",
    "        for output_name in output_names:\n",
    "            concatenated_trialAvg_data[roi][output_name] = np.concatenate(output_data_trialAvg_lists[output_name][roi], axis=0)\n",
    "            concatenated_trialStd_data[roi][output_name] = np.concatenate(output_data_trialStd_lists[output_name][roi], axis=0)\n",
    "\n",
    "\n",
    "    # Calculate mean and SEM across electrodes for all time windows and rois\n",
    "    overall_averages = {}\n",
    "    overall_sems = {}\n",
    "    for roi in rois:\n",
    "        overall_averages[roi] = {}\n",
    "        overall_sems[roi] = {}\n",
    "        for output_name in output_names:\n",
    "            trialAvg_data = concatenated_trialAvg_data[roi][output_name]\n",
    "            overall_averages[roi][output_name] = np.nanmean(trialAvg_data, axis=0)\n",
    "            overall_sems[roi][output_name] = np.std(trialAvg_data, axis=0, ddof=1) / np.sqrt(trialAvg_data.shape[0])\n",
    "    \n",
    "    return concatenated_trialAvg_data, concatenated_trialStd_data, overall_averages, overall_sems, output_data_timeAvg_fullSecond_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_trialAvg_data_congruencySigElectrodes, concatenated_trialStd_data_congruencySigElectrodes, congruencySigElectrodesAverage, congruencySigElectrodesSEM, congruencySigElectrodes_timeAvg_fullSecondLists = get_average_data_for_specific_electrodes(subjects, rois, output_names, congruencySigElectrodes)\n",
    "concatenated_trialAvg_data_switchTypeSigElectrodes, concatenated_trialStd_data_switchTypeSigElectrodes, switchTypeSigElectrodesAverage, switchTypeSigElectrodesSEM, switchTypeSigElectrodes_timeAvg_fullSecondLists = get_average_data_for_specific_electrodes(subjects, rois, output_names, switchTypeSigElectrodes)\n",
    "concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes, concatenated_trialStd_data_congruencySwitchTypeInteractionSigElectrodes, congruencySwitchTypeInteractionSigElectrodesAverage, congruencySwitchTypeInteractionSigElectrodesSEM, congruencySwitchTypeInteractionSigElectrodes_timeAvg_fullSecondLists = get_average_data_for_specific_electrodes(subjects, rois, output_names, congruencySwitchTypeInteractionSigElectrodes)\n",
    "concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes, concatenated_trialStd_data_congruencySwitchTypeInteractionSigElectrodes, allEffectSensitiveElectrodesAverage, allEffectSensitiveElectrodesSEM, allEffectSensitiveElectrodes_timeAvg_fullSecondLists = get_average_data_for_specific_electrodes(subjects, rois, output_names, allEffectSensitiveElectrodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally plot the average traces for each output name for these chosen electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_congruencySigElectrodes', congruencySigElectrodesAverage, congruencySigElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_switchTypeSigElectrodes', switchTypeSigElectrodesAverage, switchTypeSigElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_congruencySwitchTypeInteractionSigElectrodes', congruencySwitchTypeInteractionSigElectrodesAverage, switchTypeSigElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_allEffectSensitiveElectrodes', allEffectSensitiveElectrodesAverage, allEffectSensitiveElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot (ir - cr) vs (is - cs)  \n",
    "4/5 - functionize this stuff later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEM diff = sqrt(SEM1^2 + SEM2^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ir_cr = {}  # Difference between IR and CR\n",
    "diff_is_cs = {}  # Difference between IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    diff_ir_cr[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "    diff_is_cs[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "sem_diff_ir_cr = {}\n",
    "sem_diff_is_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    sem_diff_ir_cr[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2))\n",
    "    sem_diff_is_cs[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2))\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, diff_ir_cr[roi], label='IR - CR', color='black', linestyle='-')\n",
    "ax.plot(times, diff_is_cs[roi], label='IS - CS', color='black', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, diff_ir_cr[roi] - sem_diff_ir_cr[roi], diff_ir_cr[roi] + sem_diff_ir_cr[roi], alpha=0.2, color='black')\n",
    "ax.fill_between(times, diff_is_cs[roi] - sem_diff_is_cs[roi], diff_is_cs[roi] + sem_diff_is_cs[roi], alpha=0.2, color='black')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "# ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "# ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's do switch cost as a function of congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySwitchTypeInteractionSigElectrodesAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_is_ir = {}  # Difference between IR and CR\n",
    "diff_cs_cr = {}  # Difference between IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    diff_is_ir[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror']\n",
    "    diff_cs_cr[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "sem_diff_is_ir = {}\n",
    "sem_diff_cs_cr = {}\n",
    "\n",
    "for roi in rois:\n",
    "    sem_diff_is_ir[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2))\n",
    "    sem_diff_cs_cr[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2))\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, diff_is_ir[roi], label='IS - IR', color='black', linestyle='-')\n",
    "ax.plot(times, diff_cs_cr[roi], label='CS - CR', color='black', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, diff_is_ir[roi] - sem_diff_is_ir[roi], diff_is_ir[roi] + sem_diff_is_ir[roi], alpha=0.2, color='black')\n",
    "ax.fill_between(times, diff_cs_cr[roi] - sem_diff_cs_cr[roi], diff_cs_cr[roi] + sem_diff_cs_cr[roi], alpha=0.2, color='black')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's also plot i vs c 4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_is = {}  # Average of IR and IS\n",
    "avg_cr_cs = {}  # Average of CR and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_is[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_cr_cs[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_is = {}\n",
    "avg_sem_cr_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_is[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_cr_cs[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_cr_cs[roi], label='Congruent', color='red', linestyle='-')\n",
    "ax.plot(times, avg_ir_is[roi], label='Incongruent', color='red', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_is[roi] - avg_sem_ir_is[roi], avg_ir_is[roi] + avg_sem_ir_is[roi], alpha=0.2, color='red')\n",
    "ax.fill_between(times, avg_cr_cs[roi] - avg_sem_cr_cs[roi], avg_cr_cs[roi] + avg_sem_cr_cs[roi], alpha=0.2, color='red')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "# ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "# ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets do i - c for the switch type main effect electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_is = {}  # Average of IR and IS\n",
    "avg_cr_cs = {}  # Average of CR and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_is[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_cr_cs[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_is = {}\n",
    "avg_sem_cr_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_is[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_cr_cs[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_ir_is[roi], label='Congruent', color='red', linestyle='-')\n",
    "ax.plot(times, avg_cr_cs[roi], label='Incongruent', color='red', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_is[roi] - avg_sem_ir_is[roi], avg_ir_is[roi] + avg_sem_ir_is[roi], alpha=0.2, color='red')\n",
    "ax.fill_between(times, avg_cr_cs[roi] - avg_sem_cr_cs[roi], avg_cr_cs[roi] + avg_sem_cr_cs[roi], alpha=0.2, color='red')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's plot switch vs repeat for the switch type main effect electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_cr = {}  # Average of IR and CR\n",
    "avg_is_cs = {}  # Average of IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_cr[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_is_cs[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_cr = {}\n",
    "avg_sem_is_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_cr[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_is_cs[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_ir_cr[roi], label='Repeat', color='blue', linestyle='-')\n",
    "ax.plot(times, avg_is_cs[roi], label='Switch', color='blue', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_cr[roi] - avg_sem_ir_cr[roi], avg_ir_cr[roi] + avg_sem_ir_cr[roi], alpha=0.2, color='blue')\n",
    "ax.fill_between(times, avg_is_cs[roi] - avg_sem_is_cs[roi], avg_is_cs[roi] + avg_sem_is_cs[roi], alpha=0.2, color='blue')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "# ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "# ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interestingly, the switch vs repeat for congruency main effect electrodes is quite different too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_cr = {}  # Average of IR and CR\n",
    "avg_is_cs = {}  # Average of IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_cr[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_is_cs[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_cr = {}\n",
    "avg_sem_is_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_cr[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_is_cs[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_ir_cr[roi], label='repeat', color='blue', linestyle='-')\n",
    "ax.plot(times, avg_is_cs[roi], label='switch', color='blue', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_cr[roi] - avg_sem_ir_cr[roi], avg_ir_cr[roi] + avg_sem_ir_cr[roi], alpha=0.2, color='blue')\n",
    "ax.fill_between(times, avg_is_cs[roi] - avg_sem_is_cs[roi], avg_is_cs[roi] + avg_sem_is_cs[roi], alpha=0.2, color='blue')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make bar plots windowed from 0 to 1 s of my two conditions 4/9  \n",
    "greg wants to see these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first get mean and sem across electrodes from 0 to 1 for various conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_means_sems_from_fullSecond_averages(timeAvg_fullSecond_lists, rois, output_names):\n",
    "    means = {}\n",
    "    sems = {}\n",
    "    \n",
    "    for roi in rois:\n",
    "        means[roi] = {}\n",
    "        sems[roi] = {}\n",
    "        for output_name in output_names:\n",
    "            # Handle each electrode's full-second average individually\n",
    "            full_second_averages = timeAvg_fullSecond_lists[output_name][roi]\n",
    "            # Assuming full_second_averages is a list of numpy arrays, one per electrode\n",
    "            \n",
    "            # Initialize lists to store the mean for each electrode\n",
    "            electrode_means = []\n",
    "            \n",
    "            for electrode_data in full_second_averages:\n",
    "                # Calculate the mean for this electrode in the full second window\n",
    "                electrode_mean = np.nanmean(electrode_data)\n",
    "                electrode_means.append(electrode_mean)\n",
    "            \n",
    "            # Convert the list of means to a NumPy array for further calculation\n",
    "            electrode_means = np.array(electrode_means)\n",
    "            \n",
    "            # Calculate the overall mean and SEM across electrodes\n",
    "            condition_mean = np.nanmean(electrode_means)\n",
    "            condition_sem = np.std(electrode_means, ddof=1) / np.sqrt(len(electrode_means))\n",
    "            \n",
    "            means[roi][output_name] = condition_mean\n",
    "            sems[roi][output_name] = condition_sem\n",
    "    \n",
    "    return means, sems\n",
    "\n",
    "# Now, calculate the means and SEMs\n",
    "means_windowed_full_second, sems_windowed_full_second = calculate_means_sems_from_fullSecond_averages(congruencySwitchTypeInteractionSigElectrodes_timeAvg_fullSecondLists, rois, output_names)\n",
    "congruency_means_windowed_full_second, congruency_sems_windowed_full_second = calculate_means_sems_from_fullSecond_averages(congruencySigElectrodes_timeAvg_fullSecondLists, rois, output_names)\n",
    "switchType_means_windowed_full_second, switchType_sems_windowed_full_second = calculate_means_sems_from_fullSecond_averages(switchTypeSigElectrodes_timeAvg_fullSecondLists, rois, output_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now plot all four conditions as bars on one plot for the interaction effect 4/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Corrected condition names based on your dataset\n",
    "conditions = [\n",
    "    'Stimulus_cr_fixationCrossBase_1sec_mirror',  # Congruent Repeat\n",
    "    'Stimulus_ir_fixationCrossBase_1sec_mirror',  # Incongruent Repeat\n",
    "    'Stimulus_cs_fixationCrossBase_1sec_mirror',  # Congruent Switch\n",
    "    'Stimulus_is_fixationCrossBase_1sec_mirror'   # Incongruent Switch\n",
    "]\n",
    "\n",
    "# Retrieve the means and SEMs for each condition for plotting\n",
    "means = [means_windowed_full_second[roi][cond] for cond in conditions]\n",
    "sems = [sems_windowed_full_second[roi][cond] for cond in conditions]\n",
    "\n",
    "# Colors for each condition for plotting\n",
    "group_colors = ['pink', 'red', 'pink', 'red']  # Mapping colors to Congruent/Incongruent\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35  # Width of the bars\n",
    "index = np.arange(2)  # Two groups: Repeat and Switch\n",
    "\n",
    "# Creating bars for each group\n",
    "for i, (mean, sem, color) in enumerate(zip(means, sems, group_colors)):\n",
    "    position = index[i // 2] + (i % 2 - 0.5) * bar_width\n",
    "    ax.bar(position, mean, yerr=sem, capsize=5, color=color, width=bar_width)\n",
    "\n",
    "# Ensure no labels or ticks are shown on the x-axis\n",
    "ax.set_xticks([])  # No x-tick marks\n",
    "ax.tick_params(axis='x', which='both', length=0)  # No x-tick marks\n",
    "ax.tick_params(axis='y', labelsize=32)  # Adjust y-tick label size as needed\n",
    "\n",
    "# Customizing the plot (commented sections are optional customizations)\n",
    "# ax.set_ylabel('Average Z-score', fontsize=14)\n",
    "# ax.set_title('Average Z-score From Baseline by Condition and Type (Full Second)', fontsize=16)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now plot congruent vs incongruent 4/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming roi, congruency_means_windowed_full_second, and congruency_sems_windowed_full_second are defined\n",
    "\n",
    "# Conditions based on your specification\n",
    "conditions = [\n",
    "    'Stimulus_cr_fixationCrossBase_1sec_mirror',  # Congruent Repeat\n",
    "    'Stimulus_ir_fixationCrossBase_1sec_mirror',  # Incongruent Repeat\n",
    "    'Stimulus_cs_fixationCrossBase_1sec_mirror',  # Congruent Switch\n",
    "    'Stimulus_is_fixationCrossBase_1sec_mirror'   # Incongruent Switch\n",
    "]\n",
    "\n",
    "# Calculating combined means and SEMs for Congruent and Incongruent conditions\n",
    "combined_means = [\n",
    "    np.mean([\n",
    "        congruency_means_windowed_full_second[roi][conditions[0]],  # CR mean\n",
    "        congruency_means_windowed_full_second[roi][conditions[2]]   # CS mean\n",
    "    ]),\n",
    "    np.mean([\n",
    "        congruency_means_windowed_full_second[roi][conditions[1]],  # IR mean\n",
    "        congruency_means_windowed_full_second[roi][conditions[3]]   # IS mean\n",
    "    ])\n",
    "]\n",
    "\n",
    "combined_sems = [\n",
    "    np.sqrt(np.mean([\n",
    "        congruency_sems_windowed_full_second[roi][conditions[0]]**2,  # CR SEM^2\n",
    "        congruency_sems_windowed_full_second[roi][conditions[2]]**2   # CS SEM^2\n",
    "    ])),\n",
    "    np.sqrt(np.mean([\n",
    "        congruency_sems_windowed_full_second[roi][conditions[1]]**2,  # IR SEM^2\n",
    "        congruency_sems_windowed_full_second[roi][conditions[3]]**2   # IS SEM^2\n",
    "    ]))\n",
    "]\n",
    "\n",
    "# Plotting adjustments for the first plot\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.015  # Narrower bars\n",
    "\n",
    "# Adjust the index to create slight separation\n",
    "index = np.array([0.4375, 0.4625])  # Adjusted for slight separation\n",
    "\n",
    "bars = ax.bar(index, combined_means, yerr=combined_sems, capsize=5, color=['pink', 'red'], width=bar_width)\n",
    "\n",
    "# Customizing the plot\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(['Congruent', 'Incongruent'], fontsize=24)\n",
    "ax.tick_params(axis='y', labelsize=24)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting adjustments for the second plot with same formatting\n",
    "fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size as needed\n",
    "\n",
    "# Reusing the same bar width and indices for consistency\n",
    "bars = ax.bar(index, combined_means, \n",
    "              yerr=combined_sems, capsize=5, \n",
    "              color=['pink', 'red'], width=bar_width)\n",
    "\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(['Congruent', 'Incongruent'], fontsize=32)\n",
    "ax.tick_params(axis='y', labelsize=32)\n",
    "\n",
    "# Optional: Uncomment the next line if you want to see the effect without plt.tight_layout()\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now plot switch vs repeat windowed from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_means_switch_repeat = [\n",
    "    np.mean([\n",
    "        switchType_means_windowed_full_second[roi][conditions[0]],  # CR mean\n",
    "        switchType_means_windowed_full_second[roi][conditions[1]]   # IR mean\n",
    "    ]),\n",
    "    np.mean([\n",
    "        switchType_means_windowed_full_second[roi][conditions[2]],  # CS mean\n",
    "        switchType_means_windowed_full_second[roi][conditions[3]]   # IS mean\n",
    "    ])\n",
    "]\n",
    "\n",
    "combined_sems_switch_repeat = [\n",
    "    np.sqrt(np.mean([\n",
    "        switchType_sems_windowed_full_second[roi][conditions[0]]**2,  # CR SEM^2\n",
    "        switchType_sems_windowed_full_second[roi][conditions[1]]**2   # IR SEM^2\n",
    "    ])),\n",
    "    np.sqrt(np.mean([\n",
    "        switchType_sems_windowed_full_second[roi][conditions[2]]**2,  # CS SEM^2\n",
    "        switchType_sems_windowed_full_second[roi][conditions[3]]**2   # IS SEM^2\n",
    "    ]))\n",
    "]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))  # Adjust figure size as needed\n",
    "bar_width = 0.015  # Even narrower bars\n",
    "\n",
    "# Closer indices, but ensure they're distinct enough to not overlap\n",
    "index_switch_repeat = np.array([0.4375, 0.4625])\n",
    "\n",
    "bars = ax.bar(index_switch_repeat, combined_means_switch_repeat, \n",
    "              yerr=combined_sems_switch_repeat, capsize=5, \n",
    "              color=['lightblue', 'blue'], width=bar_width)\n",
    "\n",
    "ax.set_xticks(index_switch_repeat)\n",
    "ax.set_xticklabels(['Repeat', 'Switch'], fontsize=24)\n",
    "ax.tick_params(axis='y', labelsize=24)\n",
    "\n",
    "# Uncomment the next line if you want to see the effect without plt.tight_layout()\n",
    "# plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot individual electrodes for interaction effects\n",
    "i think this will just work regardless of the output names 3/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test this new plot significance function that offsets for each significance bar 4/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_significance(ax, times, sig_effects, y_offset=0.1):\n",
    "#     \"\"\"\n",
    "#     Plot significance bars for the effects on top of the existing axes, adjusted for time windows.\n",
    "\n",
    "#     Parameters:\n",
    "#     - ax: The matplotlib Axes object to plot on.\n",
    "#     - times: Array of time points for the x-axis.\n",
    "#     - sig_effects: Dictionary with time windows as keys and lists of tuples (effect, p-value) as values.\n",
    "#     - y_offset: The vertical offset between different time window significance bars.\n",
    "#     \"\"\"\n",
    "#     y_pos_base = ax.get_ylim()[1]  # Get the top y-axis limit to place significance bars\n",
    "\n",
    "#     time_windows = {\n",
    "#         'FirstHalfSecond': (0, 0.5),\n",
    "#         'SecondHalfSecond': (0.5, 1),\n",
    "#         'FullSecond': (0, 1)\n",
    "#     }\n",
    "\n",
    "#     window_offsets = {window: 0 for window in time_windows}  # Initialize offsets for each time window\n",
    "\n",
    "#     # Sort time windows to ensure 'FullSecond' bars are plotted last (on top)\n",
    "#     for time_window, effects in sorted(sig_effects.items(), key=lambda x: x[0] == 'FullSecond'):\n",
    "#         base_y_pos = y_pos_base + y_offset * list(time_windows).index(time_window)\n",
    "#         for effect, p_value in effects:\n",
    "#             start_time, end_time = time_windows[time_window]\n",
    "#             # Adjust y_pos based on how many bars have already been plotted in this window\n",
    "#             y_pos = base_y_pos + y_offset * window_offsets[time_window]\n",
    "\n",
    "#             # Update the color selection logic as per your requirement\n",
    "#             color = 'black'  # Default color for unmatched conditions\n",
    "                        \n",
    "#             if 'congruency' in effect:\n",
    "#                 color = 'red'\n",
    "#             elif 'congruencyProportion' in effect:\n",
    "#                 color = 'green'\n",
    "#             elif 'switchType' in effect:\n",
    "#                 color = 'blue'\n",
    "#             elif 'switchProportion' in effect:\n",
    "#                 color = 'yellow'\n",
    "#             elif 'congruency:congruencyProportion' in effect:\n",
    "#                 color = 'purple'\n",
    "#             elif 'switchType:switchProportion' in effect:\n",
    "#                 color = 'yellowgreen'\n",
    "#             elif 'congruency:switchType' in effect:\n",
    "#                 color = 'black'\n",
    "\n",
    "#             num_asterisks = '*' * (1 if p_value < 0.05 else 2 if p_value < 0.01 else 3)\n",
    "#             ax.plot([start_time, end_time], [y_pos, y_pos], color=color, lw=4)\n",
    "#             ax.text((start_time + end_time) / 2, y_pos, num_asterisks, ha='center', va='bottom', color=color)\n",
    "\n",
    "#             window_offsets[time_window] += 1  # Increment the offset for this time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1):\n",
    "    \"\"\"\n",
    "    Plot significance bars for the effects on top of the existing axes, adjusted for time windows.\n",
    "\n",
    "    Parameters:\n",
    "    - ax: The matplotlib Axes object to plot on.\n",
    "    - times: Array of time points for the x-axis.\n",
    "    - sig_effects: Dictionary with time windows as keys and lists of tuples (effect, p-value) as values.\n",
    "    - y_offset: The vertical offset between different time window significance bars.\n",
    "    \"\"\"\n",
    "    y_pos_base = ax.get_ylim()[1]  # Get the top y-axis limit to place significance bars\n",
    "\n",
    "    time_windows = {\n",
    "        'FirstHalfSecond': (0, 0.5),\n",
    "        'SecondHalfSecond': (0.5, 1),\n",
    "        'FullSecond': (0, 1)\n",
    "    }\n",
    "\n",
    "    window_offsets = {window: 0 for window in time_windows}  # Initialize offsets for each time window\n",
    "\n",
    "    # Sort time windows to ensure 'FullSecond' bars are plotted last (on top)\n",
    "    for time_window, effects in sorted(sig_effects.items(), key=lambda x: x[0] == 'FullSecond'):\n",
    "        base_y_pos = y_pos_base + y_offset * list(time_windows).index(time_window)\n",
    "        y_pos = base_y_pos\n",
    "        for effect, p_value in effects:\n",
    "            if 'congruency:switchType' in effect:\n",
    "                start_time, end_time = time_windows[time_window]\n",
    "                # Adjust y_pos based on how many bars have already been plotted in this window\n",
    "                y_pos = base_y_pos + y_offset * window_offsets[time_window]\n",
    "\n",
    "                # Update the color selection logic as per your requirement\n",
    "                color = 'black'  # Default color for unmatched conditions\n",
    "\n",
    "                num_asterisks = '*' * (1 if p_value < 0.05 else 2 if p_value < 0.01 else 3)\n",
    "                ax.plot([start_time, end_time], [y_pos, y_pos], color=color, lw=4)\n",
    "                ax.text((start_time + end_time) / 2, y_pos, num_asterisks, ha='center', va='bottom', color=color)\n",
    "\n",
    "                window_offsets[time_window] += 1  # Increment the offset for this time window\n",
    "            else:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySwitchTypeInteractionSigElectrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "channels = None\n",
    "\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    if os.name == 'nt':  # windows\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "    else:  # mac\n",
    "        LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                \"CoganLab\")\n",
    "\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "# # Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "# times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "\n",
    "# port over the plot_electrodes_grid_whole_brain_analysis here, but replace wherever the save name is wholebrainanalysis with the roi names. 3/25.\n",
    "def plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        for output_name in output_names:\n",
    "            color = plotting_parameters[output_name]['color']\n",
    "            line_style = plotting_parameters[output_name]['line_style']\n",
    "            ax.plot(times, data[output_name], label=f'{roi}_{output_name}', color=color, linestyle=line_style)\n",
    "            ax.fill_between(times, \n",
    "                            data[output_name] - np.std(data[output_name], ddof=1) / np.sqrt(len(data[output_name])),\n",
    "                            data[output_name] + np.std(data[output_name], ddof=1) / np.sqrt(len(data[output_name])), alpha=0.3)\n",
    "\n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Z-score')\n",
    "\n",
    "        # Retrieve significant effects for the current subject and electrode\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            # Adjust y_offset based on plotting needs. This used to not be assigned to a variable. 3/20.\n",
    "            utils.plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test looping over subjects and electrodes as a function 4/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, roi, concatenated_trialAvg_data, output_names, grid_size, save_dir, save_name, times, plotting_parameters):\n",
    "    electrodes_data = []\n",
    "    electrode_counter = 0\n",
    "    grid_num = 0\n",
    "\n",
    "    # Load in significant effects structure\n",
    "    significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "    with open(significant_effects_structure_file_path, 'r') as file:\n",
    "        significant_effects_structure = json.load(file)\n",
    "\n",
    "    for sub in subjects:\n",
    "        if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "            for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "                electrode_data = {}\n",
    "                for output_name in output_names:\n",
    "                    # Ensure the index is correctly used here for your data structure\n",
    "                    electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "                electrodes_data.append((electrode_data, sub, electrode))\n",
    "                electrode_counter += 1\n",
    "                if len(electrodes_data) == grid_size:\n",
    "                    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                    electrodes_data = []  # Reset for the next grid\n",
    "                    grid_num += 1\n",
    "\n",
    "    # Plot remaining electrodes in the last grid\n",
    "    if electrodes_data:\n",
    "        plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'dlpfc', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'acc', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parietal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'parietal', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'lpfc', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awful godforsaken code to get individual electrode plots for congruency main effects, switch main effects, and interaction effects for lpfc 4/8  \n",
    "replace with function later after CNS...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "channels = None\n",
    "\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    if os.name == 'nt':  # windows\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "    else:  # mac\n",
    "        LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                \"CoganLab\")\n",
    "\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "def plot_electrodes_grid_roi_switchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate S and R for the electrode\n",
    "        avg_ir_cr = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "        avg_is_cs = (data['Stimulus_is_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "        # avg_sem_is_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "        # avg_sem_cr_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "        # Plotting S and R\n",
    "        ax.plot(times, avg_ir_cr, label='repeat', color='blue', linestyle='-')\n",
    "        ax.plot(times, avg_is_cs, label='switch', color='blue', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            utils.plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_electrodes_grid_roi_congruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate I-C for the electrode\n",
    "        avg_ir_is = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "        avg_cr_cs = (data['Stimulus_cr_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "        # avg_sem_is_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "        # avg_sem_cr_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "        # Plotting I-C difference\n",
    "        ax.plot(times, avg_cr_cs, label='congruent', color='red', linestyle='-')\n",
    "        ax.plot(times, avg_ir_is, label='incongruent', color='red', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_electrodes_grid_roi_congruencyEffectSwitchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate congruency effect as a function of switch type for the electrode\n",
    "\n",
    "        avg_diff_ir_cr = data['Stimulus_ir_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "        avg_diff_is_cs = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "\n",
    "        ax.plot(times, avg_diff_ir_cr, label='IR - CR', color='black', linestyle='-')\n",
    "        ax.plot(times, avg_diff_is_cs, label='IS - CS', color='black', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1) #change back to plot_significance after poster 4/8\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_electrodes_grid_roi_switchCostCongruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate congruency effect as a function of switch type for the electrode\n",
    "\n",
    "        avg_diff_is_ir = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_ir_fixationCrossBase_1sec_mirror']\n",
    "        avg_diff_cs_cr = data['Stimulus_cs_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "\n",
    "        ax.plot(times, avg_diff_is_ir, label='IS - IR', color='black', linestyle='-')\n",
    "        ax.plot(times, avg_diff_cs_cr, label='CS - CR', color='black', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1) #change back to plot_significance after poster 4/8\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try this for lpfc 4/8  \n",
    "just for poster, clean this up!! this is hella hard-coded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySigElectrodesCongruencyComparison'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access congruencySigElectrodes for sub\n",
    "    # If sub is not a key, congruencySigElectrodes_for_sub will be None\n",
    "    congruencySigElectrodes_for_sub = congruencySigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if congruencySigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in congruencySigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_congruencySigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_congruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_congruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay now do individual for switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'switchTypeSigElectrodesSwitchTypeComparison'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access switchType for sub\n",
    "    # If sub is not a key, switchTypeSigElectrodes_for_sub will be None\n",
    "    switchTypeSigElectrodes_for_sub = switchTypeSigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if switchTypeSigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in switchTypeSigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_switchTypeSigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_switchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_switchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now do individual for interaction (congruency effect by switch type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySwitchTypeInteractionSigElectrodesSwitchTypeComparison'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access switchType for sub\n",
    "    # If sub is not a key, switchTypeSigElectrodes_for_sub will be None\n",
    "    congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if congruencySwitchTypeInteractionSigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in congruencySwitchTypeInteractionSigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_congruencyEffectSwitchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_congruencyEffectSwitchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now do individual for interaction (switch cost by congruency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'switchCostCongruencyInteractionSigElectrodes'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access switchType for sub\n",
    "    # If sub is not a key, switchTypeSigElectrodes_for_sub will be None\n",
    "    congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if congruencySwitchTypeInteractionSigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in congruencySwitchTypeInteractionSigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_switchCostCongruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_switchCostCongruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay once we choose the electrodes we want, plot the single example electrode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_congruency(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "    avg_ir_is = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_cr_cs = (data['Stimulus_cr_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "    \n",
    "    ax.plot(times, avg_cr_cs, label='Congruent', color='red', linestyle='-')\n",
    "    ax.plot(times, avg_ir_is, label='Incongruent', color='red', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    # ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    # ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        utils.plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0063', 'RMMF13'\n",
    "roi = 'lpfc'\n",
    "electrode_index = 5 # right now just manually count this from the grid plot BUT make this real after CNS 4/9\n",
    "\n",
    "save_name = 'congruencySigElectrodesCongruencyComparison'\n",
    "congruencySigElectrodes_for_sub = congruencySigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_congruencySigElectrodes[roi][output_name][electrode_index]\n",
    "\n",
    "plot_single_electrode_data_congruency(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for switchType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_switchType(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "    avg_ir_cr = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_is_cs = (data['Stimulus_is_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "    \n",
    "    ax.plot(times, avg_ir_cr, label='Repeat', color='blue', linestyle='-')\n",
    "    ax.plot(times, avg_is_cs, label='Switch', color='blue', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    # ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    # ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0059', 'LMMF9'\n",
    "roi = 'lpfc'\n",
    "electrode_index = 1 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "\n",
    "save_name = 'switchTypeSigElectrodesCongruencyComparison'\n",
    "switchTypeSigElectrodes_for_sub = switchTypeSigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_switchTypeSigElectrodes[roi][output_name][electrode_index]\n",
    "\n",
    "plot_single_electrode_data_switchType(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for interaction effect, congruency effect by switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_interaction_effect(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "\n",
    "    avg_diff_ir_cr = data['Stimulus_ir_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "    avg_diff_is_cs = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "    ax.plot(times, avg_diff_ir_cr, label='IR - CR', color='black', linestyle='-')\n",
    "    ax.plot(times, avg_diff_is_cs, label='IS - CS', color='black', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    # ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    # ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0094', 'LFAI9'\n",
    "electrode_index = 8 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySwitchTypeInteractionSigElectrodesSwitchTypeComparison'\n",
    "congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_index]\n",
    "plot_single_electrode_data_interaction_effect(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySwitchTypeInteractionSigElectrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interaction effect for switch cost by congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_interaction_effect(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "\n",
    "    avg_diff_is_ir = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_ir_fixationCrossBase_1sec_mirror']\n",
    "    avg_diff_cs_cr = data['Stimulus_cs_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "    ax.plot(times, avg_diff_is_ir, label='IS - IR', color='black', linestyle='-')\n",
    "    ax.plot(times, avg_diff_cs_cr, label='CS - CR', color='black', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0094', 'LFAI9'\n",
    "electrode_index = 8 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySwitchTypeInteractionSigElectrodesSwitchTypeComparison'\n",
    "congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_index]\n",
    "plot_single_electrode_data_interaction_effect(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot example electrode with all four conditions  \n",
    "note this index is in the overall sig electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_interaction_effect_all_four_conditions(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "\n",
    "    avg_is = data['Stimulus_is_fixationCrossBase_1sec_mirror']\n",
    "    avg_ir = data['Stimulus_ir_fixationCrossBase_1sec_mirror']\n",
    "    avg_cs = data['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "    avg_cr = data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "    ax.plot(times, avg_is, label='IS', color='red', linestyle='--')\n",
    "    ax.plot(times, avg_ir, label='IR', color='red', linestyle='-')\n",
    "    ax.plot(times, avg_cs, label='CS', color='pink', linestyle='--')\n",
    "    ax.plot(times, avg_cr, label='CR', color='pink', linestyle='-')\n",
    "\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    # ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    # ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0094', 'LPAI9'\n",
    "electrode_index = 31 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "roi = 'lpfc'\n",
    "save_name = 'sigElectrodesPerSubjectROI_D0094LPAI9'\n",
    "sig_electrodes_for_sub = sig_electrodes_per_subject_roi.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_index]\n",
    "plot_single_electrode_data_interaction_effect_all_four_conditions(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage setup\n",
    "sub, example_elec = 'D0065', 'RASF14'\n",
    "electrode_index = 14 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "roi = 'lpfc'\n",
    "save_name = 'sigElectrodesPerSubjectROI_D0065_RASF14'\n",
    "sig_electrodes_for_sub = sig_electrodes_per_subject_roi.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_index]\n",
    "plot_single_electrode_data_interaction_effect_all_four_conditions(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old way of looping without a function 4/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'dlpfc'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# DUDE MAKE THE SIG ELECTRODES PER SUBJECT INTO A DICTIONARY. Bad code is bad.\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'acc'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# DUDE MAKE THE SIG ELECTRODES PER SUBJECT INTO A DICTIONARY. Bad code is bad.\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parietal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'parietal'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# DUDE MAKE THE SIG ELECTRODES PER SUBJECT INTO A DICTIONARY. Bad code is bad.\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
