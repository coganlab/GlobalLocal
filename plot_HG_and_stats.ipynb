{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### working version 12/1/23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try gregs suggestion of using make_data_same to destroy the fixation cross"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use window stats with perm testing (0 to 0.5, 0.5 to 1, 0 to 1 sec relative to stim onset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "import json\n",
        "\n",
        "from utils import *\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Directory where your .npy files are saved\n",
        "npy_directory = r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\accArrays'  # Replace with your directory path\n",
        "\n",
        "# Dictionary to hold the data\n",
        "acc_array = {}\n",
        "\n",
        "# Iterate over each file in the directory\n",
        "for file in os.listdir(npy_directory):\n",
        "    if file.endswith('.npy'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(npy_directory, file)\n",
        "        # Load the numpy array from the file\n",
        "        acc_array[file.split('_')[0]] = np.load(file_path)\n",
        "\n",
        "# Now you have a dictionary where each key is the subject ID\n",
        "# and the value is the numpy array of accuracies for that subject.\n",
        "        \n",
        "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "define subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sig_electrodes_per_subject_roi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103', 'D0107A', 'D0110', 'D0116', 'D0117', 'D0121']\n",
        "# subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
        "# subjects = ['D0116', 'D0117', 'D0121']\n",
        "subjects = ['D0057', 'D0059']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use time point cluster stats for determining stimulus significance (old method as of 2/13/24)\n",
        "\n",
        "updated this one 2/29, once it's tested and works, then turn into a function and delete other cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "uncomment things and delete the subjects variable once we get the mat shape 3/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mne.utils import fill_doc, verbose\n",
        "import random\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "def trial_ieeg_rand_offset(raw: mne.io.Raw, event: str | list[str, ...], within_times: tuple[float,float], times_length: float, pad_length: float,\n",
        "               verbose=None, **kwargs) -> mne.Epochs:\n",
        "    \"\"\"Epochs data from a mne Raw iEEG instance.\n",
        "\n",
        "    Takes a mne Raw instance and randomly epochs the data around a specified event, for each instance of the event,\n",
        "    for a duration of times_length, within a range of within_times.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    raw : mne.io.Raw\n",
        "        The raw data to epoch.\n",
        "    event : str\n",
        "        The event to epoch around.\n",
        "    within_times : tuple[float, float]\n",
        "        The time window within which to randomly select intervals for each event.\n",
        "    times_length : float,\n",
        "        The length of the time intervals to randomly select within `within_times`.\n",
        "    pad_length : float,\n",
        "        The length to pad each time interval. Will be removed later.\n",
        "    %(picks_all)s\n",
        "    %(reject_epochs)s\n",
        "    %(flat)s\n",
        "    %(decim)s\n",
        "    %(epochs_reject_tmin_tmax)s\n",
        "    %(detrend_epochs)s\n",
        "    %(proj_epochs)s\n",
        "    %(on_missing_epochs)s\n",
        "    %(verbose)s\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    mne.Epochs\n",
        "        The epoched data.\n",
        "    \"\"\"\n",
        "\n",
        "    sfreq = raw.info['sfreq'] #raw.info in function\n",
        "\n",
        "\n",
        "    # get padded within times and times_length\n",
        "    within_times_padded = [within_times[0] - pad_length, within_times[1] + pad_length]\n",
        "    times_length_padded = times_length + 2 * pad_length\n",
        "\n",
        "    # Convert times to samples\n",
        "    within_times_samples = [int(t * sfreq) for t in within_times_padded]\n",
        "    times_length_samples = int((times_length_padded) * sfreq)\n",
        "\n",
        "    # Shift the indices to be positive\n",
        "    shift = abs(within_times_samples[0])\n",
        "    within_times_samples_pos = [s + shift for s in within_times_samples]\n",
        "\n",
        "    trials = trial_ieeg(raw, event, within_times_padded, preload=True, reject_by_annotation=False)\n",
        "\n",
        "    rand_offset_data = []\n",
        "\n",
        "    # Randomly select subsets for each trial\n",
        "    for trial in trials.get_data():\n",
        "        start_sample = random.randint(within_times_samples_pos[0], within_times_samples_pos[1] - times_length_samples)\n",
        "        end_sample = start_sample + times_length_samples\n",
        "        rand_offset_data.append(trial[:, start_sample:end_sample+1]) #across all channels, grab this time subset\n",
        "\n",
        "    # Reassign data to rand_offset_trials and adjust the times in rand_offset_trials\n",
        "    new_tmin = within_times_padded[0]\n",
        "    new_tmax = new_tmin + times_length_padded\n",
        "    rand_offset_trials = trial_ieeg(raw, event, [new_tmin, new_tmax], preload=True, reject_by_annotation=False)\n",
        "    rand_offset_trials._data = np.array(rand_offset_data)\n",
        "\n",
        "    return rand_offset_trials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from utils import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans, plot_HG_and_stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mne.utils import fill_doc, verbose\n",
        "import random\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "# Define a function to shuffle an array\n",
        "def shuffle_array(arr):\n",
        "    arr = np.random.shuffle(arr)\n",
        "    return arr\n",
        "\n",
        "def plot_HG_and_stats(sub, task='GlobalLocal', times=(-1, 1.5),\n",
        "                      within_base_times=(-1, 0), base_times_length=0.5, pad_length = 0.5, LAB_root=None, channels=None, dec_factor=10, outliers=10, passband=(70,150), stat_func='mean_diff'):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for event processing. Defaults to (-1, 1.5).\n",
        "    - times (tuple [float, float]): The time window to epoch around the event.\n",
        "    - within_base_times (tuple [float, float]): The time window within which to randomly select intervals for each event, for baseline.\n",
        "    - base_times_length (float): The length of the time intervals to randomly select within `within_base_times`. \n",
        "    - pad_length (float): The length to pad each time interval. Will be removed later.\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - decimation_factor (int, optional): The factor by which to subsample the data. Default is 10, so should be 2048 Hz down to 204.8 Hz.\n",
        "    - outliers (int, optional): How many standard deviations above the mean for a trial to be considered an outlier. Default is 10.\n",
        "    - passband (tuple, optional): The frequency range for the frequency band of interest. Default is (70, 150).\n",
        "    - stat_func (str, optional): The statistical function to use for time permutation cluster stats. Default is 'mean_diff'.\n",
        "    \n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "    within_times_duration = abs(within_base_times[1] - within_base_times[0]) #grab the duration as a string for naming\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event. For each trial, will randomly grab a segment of duration base_times_length from the within_base_times range. This offsets the fix cross. 6/15.\n",
        "    trials = trial_ieeg_rand_offset(good, \"Stimulus\", within_base_times, base_times_length, pad_length, preload=True)\n",
        "    outliers_to_nan(trials, outliers=outliers)\n",
        "    HG_base = gamma.extract(trials, passband=passband, copy=False, n_jobs=1)\n",
        "    pad_length_string = f\"{pad_length}s\" # define pad_length as a string so can use it as input to crop_pad\n",
        "    crop_pad(HG_base, pad_length_string) # need to change this if pad length changes\n",
        "    HG_base.decimate(dec_factor)\n",
        "    \n",
        "    # Square the data to get power from amplitude\n",
        "    HG_base_power = HG_base.copy()\n",
        "    HG_base_power._data = HG_base._data ** 2  # Square amplitude to get power\n",
        "\n",
        "    output_name_base = f\"{base_times_length}sec_within{within_times_duration}sec_randoffset_preStimulusBase_decFactor_{dec_factor}_outliers_{outliers}_passband_{passband[0]}-{passband[1]}_padLength_{pad_length}s_stat_func_{stat_func}\"\n",
        "\n",
        "    for event in [\"Stimulus\", \"Response\"]:\n",
        "        output_name = f'{event}_{output_name_base}'\n",
        "        times_adj = [times[0] - pad_length, times[1] + pad_length]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "\n",
        "        outliers_to_nan(trials, outliers=outliers)\n",
        "        HG_ev1 = gamma.extract(trials, passband=passband, copy=True, n_jobs=1)\n",
        "        print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "        crop_pad(HG_ev1, pad_length_string) #change this if pad length changes\n",
        "        print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "        HG_ev1.decimate(dec_factor)\n",
        "\n",
        "        # Square the data to get power from amplitude\n",
        "        HG_ev1_power = HG_ev1.copy()\n",
        "        HG_ev1_power._data = HG_ev1._data ** 2 # Square amplitude to get power\n",
        "\n",
        "        # get the rescaled amplitude\n",
        "        HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "        # get the rescaled power\n",
        "        HG_ev1_power_rescaled = rescale(HG_ev1_power, HG_base_power, copy=True, mode='zscore')\n",
        "\n",
        "        # get the evoke and evoke rescaled amplitude\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "        # get the evoke and evoke power rescaled amplitude\n",
        "        HG_ev1_evoke_power = HG_ev1_power.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "        HG_ev1_evoke_power_rescaled = HG_ev1_power_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "        # Save HG_ev1\n",
        "        HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "        HG_ev1_power.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_power-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_base (the shuffled version)\n",
        "        HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "        HG_base_power.save(f'{save_dir}/{sub}_{output_name}_HG_base_power-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_rescaled\n",
        "        HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "        HG_ev1_power_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_power_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_evoke\n",
        "        HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "        HG_ev1_evoke_power.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_power-epo.fif', overwrite=True)\n",
        "        \n",
        "        # Save HG_ev1_evoke_rescaled\n",
        "        HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "        HG_ev1_evoke_power_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_power_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "        ###\n",
        "        print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "        print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "        \n",
        "        # oh this changed and returns both the significant clusters matrix and the p values now\n",
        "        mat = time_perm_cluster(HG_ev1._data, HG_base._data, 0.05, n_jobs=6, ignore_adjacency=1, stat_func=stat_func)[0]\n",
        "\n",
        "        #save channels with their indices \n",
        "        save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "        # save significant channels to a json\n",
        "        save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "        \n",
        "        # Assuming `mat` is your array and `save_dir` is the directory where you want to save it\n",
        "        mat_save_path = os.path.join(save_dir, f'{output_name}_mat.npy')\n",
        "\n",
        "        # Save the mat array\n",
        "        np.save(mat_save_path, mat)\n",
        "\n",
        "        # Plot the matrix as one figure. This broken for some reason 9/28.\n",
        "        # fig, ax = plt.subplots()\n",
        "        # cax = ax.imshow(mat, aspect='auto', cmap='viridis')\n",
        "        # ax.set_title(f'Statistical Matrix for {sub}_{output_name}')\n",
        "        # ax.set_xlabel('Samples (204.8 Hz after decimation, 0 is -1 sec)')\n",
        "        # ax.set_ylabel('Channels')\n",
        "        # plt.show()\n",
        "\n",
        "        # # Save the figure\n",
        "        # plot_save_path = os.path.join(save_dir, f'{output_name}_stats.png')\n",
        "        # fig.savefig(plot_save_path, dpi=300)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot the time perm cluster results outside of the function cuz it seems broken right now 6/6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "LAB_root = None\n",
        "\n",
        "task='GlobalLocal'\n",
        "# output_name = 'Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind'\n",
        "\n",
        "output_name = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind\"\n",
        "if LAB_root is None:\n",
        "    HOME = os.path.expanduser(\"~\")\n",
        "    if os.name == 'nt':  # windows\n",
        "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "    else:  # mac\n",
        "        LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                \"CoganLab\")\n",
        "\n",
        "layout = get_data(task, root=LAB_root)\n",
        "\n",
        "for sub in subjects:\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    # Load the matrix\n",
        "    mat_save_path = os.path.join(save_dir, f'{output_name}_mat.npy')\n",
        "    mat = np.load(mat_save_path)\n",
        "    # Plot the matrix as one figure\n",
        "    fig, ax = plt.subplots()\n",
        "    cax = ax.imshow(mat, aspect='auto', cmap='viridis')\n",
        "    ax.set_title(f'Statistical Matrix for {sub}_{output_name}')\n",
        "    ax.set_xlabel('Samples (204.8 Hz after decimation, 0 is -1 sec)')\n",
        "    ax.set_ylabel('Channels')\n",
        "    # fig.colorbar(cax)\n",
        "    # plt.show()\n",
        "\n",
        "    # Save the figure\n",
        "    plot_save_path = os.path.join(save_dir, f'{output_name}_stats.png')\n",
        "    fig.savefig(plot_save_path, dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5/2 do this for each subject, for stimulus and response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "8/5 run this after tobias greg meeting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "times = (-1,1.5)\n",
        "within_base_times = (-1,0)\n",
        "base_times_length = 0.5\n",
        "pad_length = 0.5\n",
        "\n",
        "for sub in subjects:\n",
        "    plot_HG_and_stats(sub=sub, task='GlobalLocal', times=times,\n",
        "                      within_base_times=within_base_times, base_times_length = 0.5, pad_length = 0.5, dec_factor=8, outliers=10, passband=(70,150))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "time shuffled baseline vs non-shuffled HG ev1 rescaled plotting 6/4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import mne\n",
        "\n",
        "# # Set global font size\n",
        "# plt.rcParams.update({'font.size': 16})\n",
        "\n",
        "# # subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
        "\n",
        "# subjects = ['D0057']\n",
        "# # Load your data\n",
        "# for sub in subjects:\n",
        "#     root_dir = rf\"C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\{sub}\"\n",
        "#     randoffset_base_filename = rf\"{sub}_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers2_HG_ev1_rescaled-epo.fif\"\n",
        "#     randoffset_base_filepath = os.path.join(root_dir, randoffset_base_filename)\n",
        "#     randoffset_base = mne.read_epochs(randoffset_base_filepath)\n",
        "#     old_base_filename = rf\"{sub}_Stimulus_1sec_preStimulusBase_decFactor_10_HG_ev1_rescaled-epo.fif\"\n",
        "#     old_base_filepath = os.path.join(root_dir, old_base_filename)\n",
        "#     old_base = mne.read_epochs(old_base_filepath)\n",
        "\n",
        "#     # Extract data and compute the means\n",
        "#     randoffset_base_data = randoffset_base.get_data()\n",
        "#     old_base_data = old_base.get_data()\n",
        "\n",
        "#     shuffled_avg = np.nanmean(randoffset_base_data, axis=(0, 1))\n",
        "#     unshuffled_avg = np.nanmean(old_base_data, axis=(0, 1))\n",
        "\n",
        "#     # Sampling rates\n",
        "#     sfreq_shuffled = 256  # Hz for shuffled baseline\n",
        "#     sfreq_unshuffled = 204.8  # Hz for unshuffled baseline\n",
        "\n",
        "#     # Create time axes for each signal based on their respective sampling rates\n",
        "#     time_shuffled = np.arange(shuffled_avg.shape[0]) / sfreq_shuffled\n",
        "#     time_unshuffled = np.arange(unshuffled_avg.shape[0]) / sfreq_unshuffled\n",
        "\n",
        "#     # Find the maximum time to ensure both signals can be plotted over the same time scale\n",
        "#     max_time = max(time_shuffled[-1], time_unshuffled[-1])\n",
        "\n",
        "#     # Pad the shorter time axis with NaNs\n",
        "#     if time_shuffled[-1] < max_time:\n",
        "#         extra_time = np.arange(time_shuffled[-1], max_time, 1/sfreq_shuffled)\n",
        "#         time_shuffled = np.concatenate((time_shuffled, extra_time))\n",
        "#         shuffled_avg = np.pad(shuffled_avg, (0, len(extra_time)), mode='constant', constant_values=np.nan)\n",
        "#     else:\n",
        "#         extra_time = np.arange(time_unshuffled[-1], max_time, 1/sfreq_unshuffled)\n",
        "#         time_unshuffled = np.concatenate((time_unshuffled, extra_time))\n",
        "#         unshuffled_avg = np.pad(unshuffled_avg, (0, len(extra_time)), mode='constant', constant_values=np.nan)\n",
        "\n",
        "#     # Plot the averaged data\n",
        "#     time_shuffled = time_shuffled - 1\n",
        "#     time_unshuffled = time_unshuffled - 1 # adjust for baseline starting 1 sec before stim onset\n",
        "#     plt.figure(figsize=(10, 5))\n",
        "\n",
        "#     plt.plot(time_shuffled, shuffled_avg, label='Trial+Channel Avg HG rescaled with Rand Offset Baseline')\n",
        "#     plt.plot(time_unshuffled, unshuffled_avg, label='Trial+Channel Avg HG rescaled with Unshuffled Baseline')\n",
        "\n",
        "#     plt.xlabel('Time from stim onset (s)')\n",
        "#     plt.ylabel('Z-Score')\n",
        "#     plt.title(f'{sub} high gamma signal rescaled')\n",
        "#     plt.legend(fontsize=14)\n",
        "\n",
        "#     # Save the plot\n",
        "#     plot_filename = f'{sub}_randoffset_unshuffled_base_HG_ev1_rescaled_comparison.png'\n",
        "#     plot_filepath = os.path.join(root_dir, plot_filename)\n",
        "#     plt.savefig(plot_filepath)\n",
        "#     plt.close()  # Close the figure to free up memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "outlier threshold with channel x trial matrix to see which trials got dropped 7/7  \n",
        "no longer necessary, this normalizes within electrodes so its wrong somehow 8/5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "import pickle\n",
        "\n",
        "# Set global font size\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "\n",
        "# Function to plot the presence of NaNs across trials and channels\n",
        "def plot_nan_matrix(epochs, title, save_path):\n",
        "    data = epochs.get_data()\n",
        "    nan_matrix = np.isnan(data).any(axis=2).astype(int)  # Mark NaNs as 0, valid as 1\n",
        "    nan_matrix = 1 - nan_matrix  # Invert to have 1 for valid and 0 for NaNs\n",
        "    nan_matrix = nan_matrix.T  # Transpose to have channels as rows and trials as columns\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    cax = ax.imshow(nan_matrix, aspect='auto', cmap='viridis')\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Trials')\n",
        "    ax.set_ylabel('Channels')\n",
        "    fig.colorbar(cax, ax=ax, orientation='vertical', label='Data Presence (1: Valid, 0: NaN)')\n",
        "    \n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "# Function to plot the number of trial outliers per channel\n",
        "def plot_trial_outlier_count_per_channel(epochs, title, save_path):\n",
        "    data = epochs.get_data()\n",
        "    trial_outlier_count = np.isnan(data).any(axis=2).sum(axis=0)  # Count trial outliers per channel\n",
        "    channel_names = epochs.ch_names\n",
        "\n",
        "    # Create a dictionary to store the number of trial outliers for each channel\n",
        "    trial_outlier_count_dict = dict(zip(channel_names, trial_outlier_count))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 8))\n",
        "    ax.bar(np.arange(len(channel_names)), trial_outlier_count)\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel('Channel Index')\n",
        "    ax.set_ylabel('Number of Trial Outliers')\n",
        "    # ax.set_xticks(np.arange(len(channel_names)))\n",
        "    # ax.set_xticklabels(np.arange(len(channel_names)), rotation=90)\n",
        "    \n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "    return trial_outlier_count_dict\n",
        "\n",
        "def process_and_plot_for_subject(subject, root_dir, outlier_thresholds, sfreq=256):\n",
        "    outlier_counts = {}\n",
        "\n",
        "    for threshold in outlier_thresholds:\n",
        "        if threshold == 10:\n",
        "            filename = rf\"{subject}_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_HG_ev1_rescaled-epo.fif\"\n",
        "        else:\n",
        "            filename = rf\"{subject}_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_{threshold}_HG_ev1_rescaled-epo.fif\"\n",
        "        \n",
        "        filepath = os.path.join(root_dir, filename)\n",
        "        epochs = mne.read_epochs(filepath)\n",
        "\n",
        "        # Extract data and compute the means\n",
        "        data = epochs.get_data()\n",
        "        print(f'This many trials left for {subject} after {threshold} stdev outlier threshold: {data.shape[0]}')\n",
        "\n",
        "        avg_data = np.nanmean(data, axis=(0, 1))\n",
        "\n",
        "        # Create time axes for each signal based on their respective sampling rates\n",
        "        time = np.arange(avg_data.shape[0]) / sfreq\n",
        "        time = time - 1\n",
        "\n",
        "        # Plot the averaged data\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.plot(time, avg_data, label=f'HG rescaled with Rand Offset Baseline, {threshold} stdev trial outlier thresh')\n",
        "        plt.xlabel('Time from stim onset (s)')\n",
        "        plt.ylabel('Z-Score')\n",
        "        plt.title(f'{subject} high gamma signal rescaled')\n",
        "        plt.legend(fontsize=14)\n",
        "\n",
        "        # Save the plot\n",
        "        plot_filename = f'{subject}_{threshold}stdev_trial_outlier_HG_ev1_rescaled_comparison.png'\n",
        "        plot_filepath = os.path.join(root_dir, plot_filename)\n",
        "        plt.savefig(plot_filepath)\n",
        "        plt.close()  # Close the figure to free up memory\n",
        "\n",
        "        # Plot NaN matrix\n",
        "        nan_matrix_title = f'{subject} Trial Outlier Matrix ({threshold} stdev outlier threshold)'\n",
        "        nan_matrix_filepath = os.path.join(root_dir, f'{subject}_{threshold}stdev_trial_outlier_matrix.png')\n",
        "        plot_nan_matrix(epochs, nan_matrix_title, nan_matrix_filepath)\n",
        "\n",
        "        # Plot trial outlier count per channel and get the trial outlier count dictionary\n",
        "        trial_outlier_count_title = f'{subject} Trial Outlier Count Per Channel ({threshold} stdev outlier threshold)'\n",
        "        trial_outlier_count_filepath = os.path.join(root_dir, f'{subject}_{threshold}stdev_trial_outlier_count_per_channel.png')\n",
        "        trial_outlier_count_dict = plot_trial_outlier_count_per_channel(epochs, trial_outlier_count_title, trial_outlier_count_filepath)\n",
        "\n",
        "        # Store the trial outlier count dictionary for this subject and threshold\n",
        "        outlier_counts[f'{threshold}_stdev'] = trial_outlier_count_dict\n",
        "\n",
        "    # Save the trial outlier count dictionary to a pickle file\n",
        "    pickle_filepath = os.path.join(root_dir, f'{subject}_trial_outlier_counts.pkl')\n",
        "    with open(pickle_filepath, 'wb') as pickle_file:\n",
        "        pickle.dump(outlier_counts, pickle_file)\n",
        "\n",
        "    return outlier_counts\n",
        "\n",
        "outlier_thresholds = [2, 8, 10]\n",
        "\n",
        "# Load your data and process each subject\n",
        "for sub in subjects:\n",
        "    root_dir = rf\"C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\{sub}\"\n",
        "    outlier_counts = process_and_plot_for_subject(sub, root_dir, outlier_thresholds)\n",
        "    \n",
        "    # Print the outlier counts for each subject\n",
        "    print(f\"Outlier counts for subject {sub}:\")\n",
        "    for threshold, counts in outlier_counts.items():\n",
        "        print(f\"{threshold}: {counts}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "read in the trial outlier counts per channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "# Function to read and print the trial outlier counts from a pickle file\n",
        "def read_trial_outlier_counts(subject, root_dir):\n",
        "    pickle_filepath = os.path.join(root_dir, f'{subject}_trial_outlier_counts.pkl')\n",
        "    with open(pickle_filepath, 'rb') as pickle_file:\n",
        "        outlier_counts = pickle.load(pickle_file)\n",
        "    return outlier_counts\n",
        "\n",
        "# Specify the subject you want to read the pickle file for\n",
        "subject = 'D0057'\n",
        "root_dir = rf\"C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\{subject}\"\n",
        "\n",
        "# Read the trial outlier counts\n",
        "outlier_counts = read_trial_outlier_counts(subject, root_dir)\n",
        "\n",
        "# Print the outlier counts for the specified subject\n",
        "print(f\"Outlier counts for subject {subject}:\")\n",
        "for threshold, counts in outlier_counts.items():\n",
        "    print(f\"{threshold}: {counts}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "time shuffled vs non shuffled baseline HG base plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "\n",
        "# Set global font size\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "\n",
        "# Load your data\n",
        "for sub in subjects:\n",
        "    root_dir = rf\"C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\{sub}\"\n",
        "    randoffset_base_filename = rf\"{sub}_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_HG_base-epo.fif\"\n",
        "    randoffset_base_filepath = os.path.join(root_dir, randoffset_base_filename)\n",
        "    randoffset_base = mne.read_epochs(randoffset_base_filepath)\n",
        "    old_base_filename = rf\"{sub}_Stimulus_1sec_preStimulusBase_decFactor_10_HG_base-epo.fif\"\n",
        "    old_base_filepath = os.path.join(root_dir, old_base_filename)\n",
        "    old_base = mne.read_epochs(old_base_filepath)\n",
        "\n",
        "    # Extract data and compute the means\n",
        "    randoffset_base_data = randoffset_base.get_data()\n",
        "    old_base_data = old_base.get_data()\n",
        "\n",
        "    shuffled_avg = np.nanmean(randoffset_base_data, axis=(0, 1))\n",
        "    unshuffled_avg = np.nanmean(old_base_data, axis=(0, 1))\n",
        "\n",
        "    # Sampling rates\n",
        "    sfreq_shuffled = 256  # Hz for shuffled baseline\n",
        "    sfreq_unshuffled = 204.8  # Hz for unshuffled baseline\n",
        "\n",
        "    # Create time axes for each signal based on their respective sampling rates\n",
        "    time_shuffled = np.arange(shuffled_avg.shape[0]) / sfreq_shuffled\n",
        "    time_unshuffled = np.arange(unshuffled_avg.shape[0]) / sfreq_unshuffled\n",
        "\n",
        "    # Find the maximum time to ensure both signals can be plotted over the same time scale\n",
        "    max_time = max(time_shuffled[-1], time_unshuffled[-1])\n",
        "\n",
        "    # Pad the shorter time axis with NaNs\n",
        "    if time_shuffled[-1] < max_time:\n",
        "        extra_time = np.arange(time_shuffled[-1], max_time, 1/sfreq_shuffled)\n",
        "        time_shuffled = np.concatenate((time_shuffled, extra_time))\n",
        "        shuffled_avg = np.pad(shuffled_avg, (0, len(extra_time)), mode='constant', constant_values=np.nan)\n",
        "    else:\n",
        "        extra_time = np.arange(time_unshuffled[-1], max_time, 1/sfreq_unshuffled)\n",
        "        time_unshuffled = np.concatenate((time_unshuffled, extra_time))\n",
        "        unshuffled_avg = np.pad(unshuffled_avg, (0, len(extra_time)), mode='constant', constant_values=np.nan)\n",
        "\n",
        "    # Plot the averaged data\n",
        "    time_shuffled = time_shuffled - 1\n",
        "    time_unshuffled = time_unshuffled - 1 # adjust for baseline starting 1 sec before stim onset\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(time_shuffled, shuffled_avg, label='Trial+Channel Avg Rand Offset Baseline (0.5 sec within [-1,0])')\n",
        "    plt.plot(time_unshuffled, unshuffled_avg, label='Trial+Channel Avg Unshuffled Baseline')\n",
        "\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.title(f'{sub} high gamma baseline')\n",
        "    plt.legend(fontsize=14)\n",
        "\n",
        "    # Save the plot\n",
        "    plot_filename = f'{sub}_randoffset_unshuffled_base_HG_base_comparison.png'\n",
        "    plot_filepath = os.path.join(root_dir, plot_filename)\n",
        "    plt.savefig(plot_filepath)\n",
        "    plt.close()  # Close the figure to free up memory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot evoked old baseline and new baseline hg ev1 rescaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import mne\n",
        "import os\n",
        "\n",
        "# Set global font size\n",
        "plt.rcParams.update({'font.size': 16})\n",
        "\n",
        "# Load your data\n",
        "for sub in subjects:\n",
        "    root_dir = rf\"C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\{sub}\"\n",
        "    randoffset_base_filename = rf\"{sub}_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_HG_ev1_rescaled-epo.fif\"\n",
        "    randoffset_base_filepath = os.path.join(root_dir, randoffset_base_filename)\n",
        "    randoffset_base = mne.read_epochs(randoffset_base_filepath)\n",
        "    old_base_filename = rf\"{sub}_Stimulus_1sec_preStimulusBase_decFactor_10_HG_ev1_rescaled-epo.fif\"\n",
        "    old_base_filepath = os.path.join(root_dir, old_base_filename)\n",
        "    old_base = mne.read_epochs(old_base_filepath)\n",
        "\n",
        "    # Extract data and compute the nan-mean\n",
        "    randoffset_base_data = randoffset_base.get_data()\n",
        "    old_base_data = old_base.get_data()\n",
        "\n",
        "    randoffset_base_data = np.nanmean(randoffset_base_data, axis=0)\n",
        "    old_base_data = np.nanmean(old_base_data, axis=0)\n",
        "\n",
        "    # Create Evoked objects\n",
        "    randoffset_evoked = mne.EvokedArray(randoffset_base_data, randoffset_base.info, tmin=randoffset_base.times[0])\n",
        "    old_base_evoked = mne.EvokedArray(old_base_data, old_base.info, tmin=old_base.times[0])\n",
        "\n",
        "    # Plot the evoked data for randoffset_evoked\n",
        "    fig1, ax1 = plt.subplots(figsize=(10, 5))\n",
        "    randoffset_evoked.plot(axes=ax1, show=False, time_unit='s', spatial_colors=True)\n",
        "    ax1.set_xlabel('Time from stim onset (s)')\n",
        "    ax1.set_ylabel('Z-score')\n",
        "    ax1.set_title(f'{sub} High Gamma Signal Rescaled Evoked with Rand Offset Baseline')\n",
        "    ax1.legend(['Trial Avg HG rescaled evoked with Rand Offset Baseline'], fontsize=14)\n",
        "    plot_filename1 = f'{sub}_randoffset_HG_ev1_rescaled_evoked.png'\n",
        "    plot_filepath1 = os.path.join(root_dir, plot_filename1)\n",
        "    fig1.savefig(plot_filepath1)\n",
        "    plt.close(fig1)  # Close the figure to free up memory\n",
        "\n",
        "    # Plot the evoked data for old_base_evoked\n",
        "    fig2, ax2 = plt.subplots(figsize=(10, 5))\n",
        "    old_base_evoked.plot(axes=ax2, show=False, time_unit='s', spatial_colors=True)\n",
        "    ax2.set_xlabel('Time from stim onset (s)')\n",
        "    ax2.set_ylabel('Z-score')\n",
        "    ax2.set_title(f'{sub} High Gamma Signal Rescaled Evoked with Unshuffled Baseline')\n",
        "    ax2.legend(['Trial Avg HG rescaled evoked with Unshuffled Baseline'], fontsize=14)\n",
        "    plot_filename2 = f'{sub}_unshuffled_HG_ev1_rescaled_evoked.png'\n",
        "    plot_filepath2 = os.path.join(root_dir, plot_filename2)\n",
        "    fig2.savefig(plot_filepath2)\n",
        "    plt.close(fig2)  # Close the figure to free up memory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "turn this into a loop over all three time windows and all 12 subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageChops\n",
        "\n",
        "def trim_whitespace(image):\n",
        "    \"\"\"\n",
        "    Trims the whitespace from an image.\n",
        "    \"\"\"\n",
        "    bg = Image.new(image.mode, image.size, image.getpixel((0, 0)))\n",
        "    diff = ImageChops.difference(image, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return image.crop(bbox)\n",
        "    return image  # If no change\n",
        "\n",
        "def plot_channels_on_grid_windows(evoke_data, std_err_data, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim=6, plot_y_dim=6):\n",
        "    \"\"\"\n",
        "    Plots evoked EEG/MEG data for a subset of channels on a grid, overlaying significance markers for specified time windows.\n",
        "\n",
        "    Parameters:\n",
        "    - evoke_data: mne.Evoked object\n",
        "        The evoked data to be plotted. This object contains the averaged EEG/MEG data over epochs.\n",
        "    - std_err_data: \n",
        "        The standard error of the evoked data to be plotted\n",
        "    - channels_subset: list of str\n",
        "        A list of channel names to be plotted. Each channel name must correspond to a channel in `evoke_data`.\n",
        "    - time_windows: dict\n",
        "        A dictionary where keys are strings representing the names of the time windows of interest, and values are tuples\n",
        "        indicating the start and end indices (in samples) of these windows.\n",
        "    - sig_chans: dict\n",
        "        A dictionary where keys are the names of the time windows (matching those in `time_windows`) and values are lists\n",
        "        of channel names (str) that are significant within those windows.\n",
        "    - sample_rate: float\n",
        "        The sampling rate of the data, in Hz. Used to convert sample indices in `time_windows` to time in seconds.\n",
        "    - plot_x_dim: int, optional (default=6)\n",
        "        The number of columns in the grid layout for plotting the channels.\n",
        "    - plot_y_dim: int, optional (default=6)\n",
        "        The number of rows in the grid layout for plotting the channels.\n",
        "\n",
        "    Returns:\n",
        "    - fig: matplotlib.figure.Figure object\n",
        "        The figure object containing the grid of plots. Each plot shows the evoked data for a channel, with significance\n",
        "        markers overlaid for the specified time windows.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(plot_y_dim, plot_x_dim, figsize=(20, 12))  # Adjusted to match your desired layout\n",
        "    fig.suptitle(\"Channels with Significance Overlay for Different Time Windows\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    # Define colors for each time window\n",
        "    colors = ['red', 'green', 'blue']\n",
        "    window_names = list(time_windows.keys())\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = stderr_data.data[channel_to_index[channel], :]\n",
        "        # Plot the channel data with times in seconds\n",
        "        ax.plot(evoke_data.times, evoke_data.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(evoke_data.times, evoke_data.data[channel_to_index[channel], :] - stderr, evoke_data.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        max_y_value = np.max(evoke_data.data[channel_to_index[channel], :])  # Find max y-value for significance lines\n",
        "        # Assuming the epochs start 1 second before the stimulus/event\n",
        "        epoch_start_time = -1  # Start time of epochs in seconds\n",
        "\n",
        "        for window_index, window_name in enumerate(window_names):\n",
        "            if channel in sig_chans[window_name]:\n",
        "                start_idx, end_idx = time_windows[window_name]\n",
        "                # Convert sample indices to times in seconds\n",
        "                start_time = (start_idx / sample_rate) + epoch_start_time\n",
        "                end_time = (end_idx / sample_rate) + epoch_start_time\n",
        "                # Determine y-position for the significance line, adjusting to avoid overlap\n",
        "                y_position = max_y_value - (window_index * 0.02 * max_y_value)  # Adjust overlap offset here\n",
        "\n",
        "                # Cycle through colors for each time window\n",
        "                color = colors[window_index % len(colors)]\n",
        "                ax.hlines(y=y_position, xmin=start_time, xmax=end_time, color=color, linewidth=2, label=f\"{window_name}: {color}\")\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    # Create a legend for the first subplot (if desired) to explain the colors\n",
        "    if len(axes_flat) > 0 and len(window_names) > 0:\n",
        "        handles, labels = axes_flat[0].get_legend_handles_labels()\n",
        "        fig.legend(handles, labels, loc='upper right', title=\"Time Windows & Colors\")\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make space for the legend\n",
        "    return fig\n",
        "\n",
        "sig_chans = {}\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    LAB_root = None\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    sample_rate = filt.info['sfreq'] # get sampling rate, should be 2048 Hz\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    time_windows = {\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0to0.5\": (sample_rate,1.5*sample_rate), #actually grab from 1 to 1.5 because the epochs start at -1 second before stim onset\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0.5to1\": (1.5*sample_rate,2*sample_rate),\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0to1\": (sample_rate,2*sample_rate)\n",
        "    }\n",
        "\n",
        "    for window in time_windows:\n",
        "        output_name = window\n",
        "\n",
        "        # Define file paths\n",
        "        HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
        "        HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
        "        HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
        "\n",
        "        # Load the epochs and evoked objects\n",
        "        HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
        "        HG_base = mne.read_epochs(HG_base_file)\n",
        "        HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "        HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "        channels = [] # load in all channels\n",
        "        channel_to_index = {}\n",
        "        channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') \n",
        "        with open(channel_file, 'r') as f:\n",
        "            for line in f:\n",
        "                index, channel = line.strip().split(': ')\n",
        "                channels.append(channel)\n",
        "                channel_to_index[channel] = int(index)\n",
        "\n",
        "        sig_chans_filename = os.path.join(save_dir, f'sig_chans_{sub}_{output_name}.json') # load in sig channels\n",
        "        sig_chans[window] = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "    # now plot 6x6 grid of 36 channels on one plot, for the z-scored signal\n",
        "    plot_x_dim = 6\n",
        "    plot_y_dim = 6\n",
        "    channels_per_fig = plot_x_dim * plot_y_dim\n",
        "\n",
        "    # Iterate over all channels in chunks and plot them with z-scored signal\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_windows(HG_ev1_evoke_rescaled, HG_ev1_evoke_rescaled_stderr, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim, plot_y_dim)\n",
        "        combined_plot_path_rescaled = os.path.join(save_dir, f'{sub}_zscore_{output_name}_combinedChannelTracesAndWindowsSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path_rescaled)\n",
        "        plt.close(fig)\n",
        "\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_windows(HG_ev1_evoke, HG_ev1_evoke_stderr, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim, plot_y_dim)\n",
        "        combined_plot_path_rescaled = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndWindowsSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path_rescaled)\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "this below code is for when using the time perm cluster stats to determine significance timepoint by timepoint  \n",
        "it will plot the z-scored trace and the raw trace for each subject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_channels_on_grid_time_perm_cluster(evoke_data, std_err_data, channels_subset, mat, sample_rate=2048, dec_factor=8, plot_x_dim=6, plot_y_dim=6):\n",
        "    \"\"\"\n",
        "    Plots evoked EEG/MEG data for a subset of channels on a grid, overlaying significance markers for specified time windows.\n",
        "\n",
        "    Parameters:\n",
        "    - evoke_data: mne.Evoked object\n",
        "        The evoked data to be plotted. This object contains the averaged EEG/MEG data over epochs.\n",
        "    - std_err_data: \n",
        "        The standard error of the evoked data to be plotted\n",
        "    - channels_subset: list of str\n",
        "        A list of channel names to be plotted. Each channel name must correspond to a channel in `evoke_data`.\n",
        "    - mat: numpy.array\n",
        "        A binary matrix (same shape as evoke_data) indicating significant data points (1 for significant, 0 for non-significant).\n",
        "    - sample_rate: float\n",
        "        The sampling rate of the data, in Hz. Used to convert sample indices in `time_windows` to time in seconds.\n",
        "    - dec_factor: int\n",
        "        the decimation factor by which to downsample the sampling rate.\n",
        "    - plot_x_dim: int, optional (default=6)\n",
        "        The number of columns in the grid layout for plotting the channels.\n",
        "    - plot_y_dim: int, optional (default=6)\n",
        "        The number of rows in the grid layout for plotting the channels.\n",
        "\n",
        "    Returns:\n",
        "    - fig: matplotlib.figure.Figure object\n",
        "        The figure object containing the grid of plots. Each plot shows the evoked data for a channel, with significance\n",
        "        markers overlaid for the specified time windows.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(plot_x_dim, plot_y_dim, figsize=(20, 12))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = std_err_data.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / (sample_rate / dec_factor)  # Should be 2048 Hz sample rate\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(evoke_data.times, evoke_data.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(evoke_data.times, evoke_data.data[channel_to_index[channel], :] - stderr, evoke_data.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(evoke_data.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "plot_x_dim = 6\n",
        "plot_y_dim = 6\n",
        "channels_per_fig = plot_x_dim * plot_y_dim\n",
        "\n",
        "sig_chans = {}\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    LAB_root = None\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    sample_rate = filt.info['sfreq'] # get sampling rate, should be 2048 Hz\n",
        "    dec_factor = 8 # set this\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    output_names = ['Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False',\n",
        "    'Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_0.0-30.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False',\n",
        "    'Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False',\n",
        "    'Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10'\n",
        "    ]\n",
        "    \n",
        "    for output_name in output_names:\n",
        "        # Define file paths\n",
        "        HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
        "        HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
        "        HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
        "\n",
        "        # Load the epochs and evoked objects\n",
        "        HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
        "        HG_base = mne.read_epochs(HG_base_file)\n",
        "        HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "        HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "        mat_save_path = os.path.join(save_dir, f'{output_name}_mat.npy')\n",
        "        mat = np.load(mat_save_path)\n",
        "\n",
        "        channels = [] # load in all channels\n",
        "        channel_to_index = {}\n",
        "        channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') \n",
        "        with open(channel_file, 'r') as f:\n",
        "            for line in f:\n",
        "                index, channel = line.strip().split(': ')\n",
        "                channels.append(channel)\n",
        "                channel_to_index[channel] = int(index)\n",
        "        \n",
        "        # Iterate over all channels in chunks of channels_per_fig (plot_x_dim * plot_y_dim) and plot them\n",
        "        for i in range(0, len(channels), channels_per_fig):\n",
        "            channels_subset = channels[i:i+channels_per_fig]\n",
        "            fig = plot_channels_on_grid_time_perm_cluster(HG_ev1_evoke_rescaled, HG_ev1_evoke_rescaled_stderr, channels_subset, mat, sample_rate=sample_rate, dec_factor=dec_factor, plot_x_dim=plot_x_dim, plot_y_dim=plot_y_dim)\n",
        "            combined_plot_path = os.path.join(save_dir, f'{sub}_zscore_{output_name}_channel_traces_page_{i//channels_per_fig + 1}.png')\n",
        "            fig.savefig(combined_plot_path)\n",
        "            plt.close(fig)\n",
        "\n",
        "            # Iterate over all channels in chunks of channels_per_fig (plot_x_dim * plot_y_dim) and plot them\n",
        "        for i in range(0, len(channels), channels_per_fig):\n",
        "            channels_subset = channels[i:i+channels_per_fig]\n",
        "            fig = plot_channels_on_grid_time_perm_cluster(HG_ev1_evoke, HG_ev1_evoke_stderr, channels_subset, mat, sample_rate=sample_rate, dec_factor=dec_factor, plot_x_dim=plot_x_dim, plot_y_dim=plot_y_dim)\n",
        "            combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_channel_traces_page_{i//channels_per_fig + 1}.png')\n",
        "            fig.savefig(combined_plot_path)\n",
        "            plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now plot some chosen electrodes across subjects, like for a specific roi. 8/11. First make a function to do this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_channels_across_subjects(electrode_dict, data_dict, std_err_dict, mat_dict, channel_to_index_dict, plot_x_dim=6, plot_y_dim=6, sample_rate=2048, dec_factor=8, y_label=\"Amplitude\"):\n",
        "    \"\"\"\n",
        "    Plots evoked EEG/MEG data across multiple subjects for a set of electrodes, organized into subplots.\n",
        "\n",
        "    Parameters:\n",
        "    - electrode_dict: dict\n",
        "        Dictionary where keys are subjects and values are lists of electrodes to plot for each subject.\n",
        "    - data_dict: dict\n",
        "        Dictionary where each key is a subject and each value is the evoked data for that subject.\n",
        "    - std_err_dict: dict\n",
        "        Dictionary where each key is a subject and each value is the standard error data for that subject.\n",
        "    - mat_dict: dict\n",
        "        Dictionary where each key is a subject and each value is the significance matrix for that subject.\n",
        "    - channel_to_index_dict: dict\n",
        "        Dictionary where each key is a subject and each value is a dictionary mapping channel names to their indices for that subject.\n",
        "    - plot_x_dim: int, optional\n",
        "        Number of columns in the grid layout for plotting the channels.\n",
        "    - plot_y_dim: int, optional\n",
        "        Number of rows in the grid layout for plotting the channels.\n",
        "    - sample_rate: float\n",
        "        Sampling rate of the data in Hz.\n",
        "    - dec_factor: int\n",
        "        Decimation factor by which to downsample the sampling rate.\n",
        "    - y_label: str, optional\n",
        "        Label for the y-axis.\n",
        "\n",
        "    Returns:\n",
        "    - fig: matplotlib.figure.Figure object\n",
        "        The figure object containing the grid of plots.\n",
        "    \"\"\"\n",
        "    channels_per_fig = plot_x_dim * plot_y_dim\n",
        "    plot_index = 0\n",
        "    fig_num = 1\n",
        "\n",
        "    fig, axes = plt.subplots(plot_y_dim, plot_x_dim, figsize=(20, 12))\n",
        "    fig.suptitle(\"Channels Across Subjects with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for subject, electrodes in electrode_dict.items():\n",
        "        for electrode in electrodes:\n",
        "            if electrode in channel_to_index_dict[subject]:\n",
        "                if plot_index >= channels_per_fig:\n",
        "                    plt.tight_layout()\n",
        "                    plt.subplots_adjust(top=0.95)\n",
        "                    yield fig, fig_num\n",
        "\n",
        "                    # Start a new figure if the previous one is full\n",
        "                    fig, axes = plt.subplots(plot_y_dim, plot_x_dim, figsize=(20, 12))\n",
        "                    fig.suptitle(\"Channels Across Subjects with Significance Overlay\")\n",
        "                    axes_flat = axes.flatten()\n",
        "                    plot_index = 0\n",
        "                    fig_num += 1\n",
        "\n",
        "                ax = axes_flat[plot_index]\n",
        "                ch_idx = channel_to_index_dict[subject][electrode]\n",
        "                stderr = std_err_dict[subject].data[ch_idx, :]\n",
        "                time_in_seconds = np.arange(0, len(mat_dict[subject][ch_idx])) / (sample_rate / dec_factor)\n",
        "                sig_data_in_seconds = np.array(mat_dict[subject][ch_idx])\n",
        "\n",
        "                ax.plot(data_dict[subject].times, data_dict[subject].data[ch_idx, :])\n",
        "                # Add the standard error shading\n",
        "                ax.fill_between(data_dict[subject].times, data_dict[subject].data[ch_idx, :] - stderr, data_dict[subject].data[ch_idx, :] + stderr, alpha=0.2)\n",
        "\n",
        "                # Find the maximum y-value for the current channel\n",
        "                max_y_value = np.max(data_dict[subject].data[ch_idx, :])\n",
        "\n",
        "                # Overlay significance as a horizontal line at the max y-value\n",
        "                significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "                for point in significant_points:\n",
        "                    ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1)\n",
        "\n",
        "                ax.set_title(f\"{subject}: {electrode}\")\n",
        "                ax.set_ylabel(y_label)\n",
        "\n",
        "                plot_index += 1\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    yield fig, fig_num\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "load in the sig electrodes per subject roi that is made in rsa_using_toolbox.ipynb, so we can plot it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify the file path where the dictionary was saved\n",
        "load_path = 'sig_electrodes_per_subject_roi.json'\n",
        "\n",
        "# Use json to load the dictionary\n",
        "with open(load_path, 'r') as file:\n",
        "    sig_electrodes_per_subject_roi = json.load(file)\n",
        "\n",
        "print(\"Dictionary loaded successfully\")\n",
        "print(sig_electrodes_per_subject_roi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rois = 'occ'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "now actually plot the chosen electrodes (lets do just sig occ elecs for now)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now plot across subjects\n",
        "# Initialize dictionaries to hold data for each subject\n",
        "data_dict = {}\n",
        "std_err_dict = {}\n",
        "mat_dict = {}\n",
        "channel_to_index_dict = {}\n",
        "\n",
        "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "rois = list(sig_electrodes_per_subject_roi.keys())\n",
        "output_name = 'Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8'\n",
        "\n",
        "for roi in rois:\n",
        "    # Assuming 'subjects' is a list of all subject IDs\n",
        "    for sub in subjects:\n",
        "        electrode_dict = sig_electrodes_per_subject_roi[roi]\n",
        "\n",
        "        if sub not in electrode_dict:\n",
        "            continue  # Skip subjects not in the electrode dictionary\n",
        "\n",
        "        electrodes = electrode_dict[sub]\n",
        "        if not electrodes:\n",
        "            print(f\"No electrodes specified for subject {sub}. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        task = 'GlobalLocal'\n",
        "        LAB_root = None\n",
        "        if LAB_root is None:\n",
        "            HOME = os.path.expanduser(\"~\")\n",
        "            if os.name == 'nt':  # windows\n",
        "                LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "            else:  # mac or linux\n",
        "                LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "        layout = get_data(task, root=LAB_root)\n",
        "        filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                               extension='.edf', desc='clean', preload=False)\n",
        "        sample_rate = filt.info['sfreq']  # get sampling rate, should be 2048 Hz\n",
        "        dec_factor = 8  # set this\n",
        "\n",
        "        # Define file paths\n",
        "        HG_ev1_file = os.path.join(save_dir, sub, f'{sub}_{output_name}_HG_ev1-epo.fif')\n",
        "        HG_ev1_rescaled_file = os.path.join(save_dir, sub, f'{sub}_{output_name}_HG_ev1_rescaled-epo.fif')\n",
        "\n",
        "        # Load the epochs and evoked objects\n",
        "        HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
        "        HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "        HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "        mat_save_path = os.path.join(save_dir, sub, f'{output_name}_mat.npy')\n",
        "        mat = np.load(mat_save_path)\n",
        "\n",
        "        channels = []  # load in all channels\n",
        "        channel_to_index = {}\n",
        "        channel_file = os.path.join(save_dir, sub, f'channels_{sub}_GlobalLocal.txt')\n",
        "        with open(channel_file, 'r') as f:\n",
        "            for line in f:\n",
        "                index, channel = line.strip().split(': ')\n",
        "                channels.append(channel)\n",
        "                channel_to_index[channel] = int(index)\n",
        "\n",
        "        # Populate dictionaries for each subject\n",
        "        data_dict[sub] = HG_ev1_evoke  # for raw data\n",
        "        std_err_dict[sub] = HG_ev1_evoke_stderr\n",
        "        mat_dict[sub] = mat\n",
        "        channel_to_index_dict[sub] = channel_to_index\n",
        "\n",
        "    # Plot and save raw data\n",
        "    for fig, fig_num in plot_channels_across_subjects(\n",
        "        electrode_dict,\n",
        "        data_dict,\n",
        "        std_err_dict,\n",
        "        mat_dict,\n",
        "        channel_to_index_dict,\n",
        "        plot_x_dim=4,\n",
        "        plot_y_dim=4,\n",
        "        sample_rate=sample_rate,\n",
        "        dec_factor=dec_factor,\n",
        "        y_label=\"Amplitude\"  # Raw data y-axis label\n",
        "    ):\n",
        "        raw_plot_path = os.path.join(save_dir, f'{roi}_raw_{output_name}_sig_channel_traces_page_{fig_num}.png')\n",
        "        fig.savefig(raw_plot_path)\n",
        "        plt.close(fig)\n",
        "\n",
        "    # Update dictionaries for z-scored data\n",
        "    for sub in subjects:\n",
        "        data_dict[sub] = HG_ev1_evoke_rescaled  # for z-scored data\n",
        "        std_err_dict[sub] = HG_ev1_evoke_rescaled_stderr\n",
        "\n",
        "    # Plot and save z-scored data\n",
        "    for fig, fig_num in plot_channels_across_subjects(\n",
        "        electrode_dict,\n",
        "        data_dict,\n",
        "        std_err_dict,\n",
        "        mat_dict,\n",
        "        channel_to_index_dict,\n",
        "        plot_x_dim=4,\n",
        "        plot_y_dim=4,\n",
        "        sample_rate=sample_rate,\n",
        "        dec_factor=dec_factor,\n",
        "        y_label=\"z-score\"  # Z-scored data y-axis label\n",
        "    ):\n",
        "        zscore_plot_path = os.path.join(save_dir, f'{roi}_zscore_{output_name}_sig_channel_traces_page_{fig_num}.png')\n",
        "        fig.savefig(zscore_plot_path)\n",
        "        plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### z-scored signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for raw traces, just plot HG_ev1_evoke instead of HG_ev1_evoke_rescaled. And for the standard error, use the HG_ev1_evoke_stderr instead of HG_ev1_evoke_rescaled_stderr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### raw traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Assuming all imports and previous definitions are in place\n",
        "\n",
        "# def plot_channels_on_grid_time_perm_cluster_raw(channels_subset):\n",
        "#     fig, axes = plt.subplots(6, 10, figsize=(20, 33))\n",
        "#     fig.suptitle(\"Channels with Significance Overlay\")\n",
        "#     axes_flat = axes.flatten()\n",
        "\n",
        "#     for channel, ax in zip(channels_subset, axes_flat):\n",
        "#         stderr = HG_ev1_evoke_stderr.data[channel_to_index[channel], :]\n",
        "#         time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / sample_rate  # should be 2048 Hz sample rate. Need mat though..should i save this somehow?\n",
        "#         sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "#         ax.plot(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "#          # Add the standard error shading\n",
        "#         ax.fill_between(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :] - stderr, HG_ev1_evoke.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "#         # Find the maximum y-value for the current channel\n",
        "#         max_y_value = np.max(HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "\n",
        "#         # Overlay significance as a horizontal line at the max y-value\n",
        "#         significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "#         for point in significant_points:\n",
        "#             ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "#         ax.set_title(channel)\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.subplots_adjust(top=0.95)\n",
        "#     return fig\n",
        "\n",
        "# # Iterate over all channels in chunks of 60 and plot them\n",
        "# for i in range(0, len(sig_chans), 60):\n",
        "#     channels_subset = channels[i:i+60]\n",
        "#     fig = plot_channels_on_grid_time_perm_cluster_raw(channels_subset)\n",
        "#     combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndTimePermClusterSignificance_Page_{i//36 + 1}.png')\n",
        "#     fig.savefig(combined_plot_path)\n",
        "#     plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ieeg",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
