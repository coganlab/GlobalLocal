{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "from misc_functions import load_sig_chans, channel_names_to_indices\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the outer dictionary.\n",
    "subjects_electrodestoROIs_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make subjects rois to electrodes dict. Don't need to run this more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "\n",
    "# subjects = ['D0103'] #testing cuz d0065 being weird\n",
    "\n",
    "for sub in subjects:\n",
    "    # sub = 'D0059'\n",
    "    task = 'GlobalLocal'\n",
    "    output_name = \"Response_fixationCrossBase_1sec_mirror\"\n",
    "    events = [\"Response\"]\n",
    "    times = (-1,1.5)\n",
    "    base_times = [-1,0]\n",
    "    LAB_root = None\n",
    "    channels = None\n",
    "    full_trial_base = False\n",
    "\n",
    "\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        if os.name == 'nt':  # windows\n",
    "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "        else:  # mac\n",
    "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                    \"CoganLab\")\n",
    "\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
    "                        extension='.edf', desc='clean', preload=False)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    good = crop_empty_data(filt)\n",
    "    # %%\n",
    "\n",
    "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
    "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
    "\n",
    "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
    "    good.drop_channels(good.info['bads'])\n",
    "\n",
    "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
    "\n",
    "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.load_data()\n",
    "\n",
    "    # If channels is None, use all channels\n",
    "    if channels is None:\n",
    "        channels = good.ch_names\n",
    "    else:\n",
    "        # Validate the provided channels\n",
    "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
    "        if invalid_channels:\n",
    "            raise ValueError(\n",
    "                f\"The following channels are not valid: {invalid_channels}\")\n",
    "\n",
    "        # Use only the specified channels\n",
    "        good.pick_channels(channels)\n",
    "\n",
    "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
    "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
    "\n",
    "    default_dict = gen_labels(good.info)\n",
    "    \n",
    "    # Create rawROI_dict for the subject\n",
    "    rawROI_dict = defaultdict(list)\n",
    "    for key, value in default_dict.items():\n",
    "        rawROI_dict[value].append(key)\n",
    "    rawROI_dict = dict(rawROI_dict)\n",
    "\n",
    "    # Filter out keys containing \"White-Matter\"\n",
    "    filtROI_dict = {key: value for key, value in rawROI_dict.items() if \"White-Matter\" not in key}\n",
    "\n",
    "    # Store the dictionaries in the subjects dictionary\n",
    "    subjects_electrodestoROIs_dict[sub] = {\n",
    "        'default_dict': dict(default_dict),\n",
    "        'rawROI_dict': dict(rawROI_dict),\n",
    "        'filtROI_dict': dict(filtROI_dict)\n",
    "    }\n",
    "\n",
    "\n",
    "# # Save to a JSON file. Uncomment when actually running.\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(subjects_electrodestoROIs_dict, file, indent=4)\n",
    "\n",
    "print(f\"Saved subjects_dict to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load subjects electrodes to rois dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from subjects_electrodestoROIs_dict.json\n"
     ]
    }
   ],
   "source": [
    "# Load from a JSON file\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    subjects_electrodestoROIs_dict = json.load(file)\n",
    "\n",
    "print(f\"Loaded data from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load high gamma data so we can do roi analysis on it\n",
    "once we have more subjects, turn this into a function and loop over all subjects.  \n",
    "this code is a crime against humanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c25_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "168 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c25_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c25_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "168 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "56 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "56 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_mne_objects(sub, output_name, task, LAB_root=None):\n",
    "    \"\"\"\n",
    "    Load MNE objects for a given subject and output name.\n",
    "\n",
    "    Parameters:\n",
    "    - sub (str): Subject identifier.\n",
    "    - output_name (str): Output name used in the file naming.\n",
    "    - task (str): Task identifier.\n",
    "    - LAB_root (str, optional): Root directory for the lab. If None, it will be determined based on the OS.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing loaded MNE objects.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine LAB_root based on the operating system\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "    \n",
    "    # Ensure save directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Define file paths\n",
    "    HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
    "    HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
    "    HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
    "\n",
    "    # Load the objects\n",
    "    HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
    "    HG_base = mne.read_epochs(HG_base_file)\n",
    "    HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
    "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
    "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
    "\n",
    "    return {\n",
    "        'HG_ev1': HG_ev1,\n",
    "        'HG_base': HG_base,\n",
    "        'HG_ev1_rescaled': HG_ev1_rescaled,\n",
    "        'HG_ev1_evoke': HG_ev1_evoke,\n",
    "        'HG_ev1_evoke_rescaled': HG_ev1_evoke_rescaled\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# sub = 'D0057'\n",
    "# output_name = \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"\n",
    "# task = 'GlobalLocal'\n",
    "loaded_objects_D0057_i = load_mne_objects('D0057', \"Stimulus_c25_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0057_c = load_mne_objects('D0057', \"Stimulus_c75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "# Access the objects\n",
    "HG_ev1_D0057_i = loaded_objects_D0057_i['HG_ev1']\n",
    "HG_base_D0057_i = loaded_objects_D0057_i['HG_base']\n",
    "HG_ev1_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "HG_ev1_D0057_c = loaded_objects_D0057_c['HG_ev1']\n",
    "HG_base_D0057_c = loaded_objects_D0057_c['HG_base']\n",
    "HG_ev1_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke_rescaled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load accuracy arrays so we can filter by only accurate trials  \n",
    "turn this into a single function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where your .npy files are saved\n",
    "npy_directory = r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\accArrays'  # Replace with your directory path\n",
    "\n",
    "# Dictionary to hold the data\n",
    "acc_array = {}\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for file in os.listdir(npy_directory):\n",
    "    if file.endswith('.npy'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(npy_directory, file)\n",
    "        # Load the numpy array from the file\n",
    "        acc_array[file.split('_')[0]] = np.load(file_path)\n",
    "\n",
    "# Now you have a dictionary where each key is the subject ID\n",
    "# and the value is the numpy array of accuracies for that subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_accuracy_to_epochs(epochs, accuracy_array):\n",
    "    \"\"\"\n",
    "    Adds accuracy data from accuracy_array to the metadata of epochs.\n",
    "    Assumes the order of trials in accuracy_array matches the order in epochs.\n",
    "    \"\"\"\n",
    "    if epochs.metadata is None:\n",
    "        # Create a new DataFrame if no metadata exists\n",
    "        epochs.metadata = pd.DataFrame(index=range(len(epochs)))\n",
    "    \n",
    "    # Ensure the accuracy_array length matches the number of epochs\n",
    "    assert len(accuracy_array) == len(epochs), \"Mismatch in number of trials and accuracy data length.\"\n",
    "    \n",
    "    # Add the accuracy array as a new column in the metadata\n",
    "    epochs.metadata['accuracy'] = accuracy_array\n",
    "\n",
    "    # Reset the index to ensure it's sequential starting from 0\n",
    "    epochs.metadata.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay so we need to grab the event timings from HG_ev1_rescaled.events in samples, and convert to seconds.  \n",
    "Although keep in mind these will be early by however long the event starts before the stimulus onset, when compared to the combinedData.csv.  \n",
    "Then, load in combinedData.csv for this subject and grab the trialCounts that have stimOnsets that match up with the events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load evoked and stuff for all subjects in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for subject: D0057\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "121 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "102 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0059\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0063\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "104 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0065\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0071\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0077\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "116 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "116 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "105 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0090\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "111 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0100\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "109 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "114 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0102\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "106 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "Loading data for subject: D0103\n",
      "  Loading output: Stimulus_cr_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 'r'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cr_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "110 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n",
      "  Loading output: Stimulus_cs_fixationCrossBase_1sec_mirror with conditions: {'congruency': 'c', 'switchType': 's'}\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_cs_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "113 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Adding metadata with 0 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "def create_subjects_mne_objects_dict(subjects, output_names_conditions, task, combined_data, LAB_root=None):\n",
    "    \"\"\"\n",
    "    Adjusted to handle multiple conditions per output name, with multiple condition columns.\n",
    "\n",
    "    Parameters:\n",
    "    - subjects: List of subject IDs.\n",
    "    - output_names_conditions: Dictionary where keys are output names and values are dictionaries\n",
    "        of condition column names and their required values.\n",
    "    - task: Task identifier.\n",
    "    - combined_data: DataFrame with combined behavioral and trial information.\n",
    "    - LAB_root: Root directory for data (optional).\n",
    "    \"\"\"\n",
    "    subjects_mne_objects = {}\n",
    "\n",
    "    for sub in subjects:\n",
    "        print(f\"Loading data for subject: {sub}\")\n",
    "        sub_mne_objects = {}\n",
    "        for output_name, conditions in output_names_conditions.items():\n",
    "            print(f\"  Loading output: {output_name} with conditions: {conditions}\")\n",
    "            \n",
    "            # Build the filtering condition\n",
    "            sub_without_zeroes = \"D\" + sub[1:].lstrip('0') \n",
    "            condition_filter = (combined_data['subject_ID'] == sub_without_zeroes) # this indexes using the subject without zeroes in the name. Confusing. I know.\n",
    "            \n",
    "            for condition_column, condition_value in conditions.items():\n",
    "                if isinstance(condition_value, list):\n",
    "                    # If the condition needs to match any value in a list\n",
    "                    condition_filter &= combined_data[condition_column].isin(condition_value)\n",
    "                else:\n",
    "                    # If the condition is a single value\n",
    "                    condition_filter &= (combined_data[condition_column] == condition_value)\n",
    "            \n",
    "            # Filter combinedData for the specific subject and conditions\n",
    "            subject_condition_data = combined_data[condition_filter]\n",
    "            \n",
    "            # Load MNE objects and update with accuracy data\n",
    "            mne_objects = load_mne_objects(sub, output_name, task, LAB_root)\n",
    "            \n",
    "            if sub in acc_array:\n",
    "                trial_counts = subject_condition_data['trialCount'].values.astype(int)\n",
    "                accuracy_data = [acc_array[sub][i-1] for i in trial_counts if i-1 < len(acc_array[sub])] # Subtract 1 here for zero-based indexing in acc array.\n",
    "                \n",
    "                # Now pass trial_counts along with accuracy_data\n",
    "                mne_objects['HG_ev1_rescaled'] = add_accuracy_to_epochs(mne_objects['HG_ev1_rescaled'], accuracy_data)\n",
    "\n",
    "            sub_mne_objects[output_name] = mne_objects\n",
    "        subjects_mne_objects[sub] = sub_mne_objects\n",
    "\n",
    "    return subjects_mne_objects\n",
    "\n",
    "\n",
    "# # example of how to use this with multiple conditions, even matching any value in a list. Although I only ever have two conditions of a type so not super necessary.\n",
    "# # make sure to use the correct column names and values that match with what combinedData uses.\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": [\"s1\", \"s2\"]  # Example where switchType needs to match any value in the list\n",
    "#     },\n",
    "#     \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0071', 'D0077', 'D0090', 'D0100', 'D0102', 'D0103']\n",
    "# # congruency\n",
    "# output_names = [\"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#     },\n",
    "#     \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # switch\n",
    "# output_names = [\"Stimulus_r25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_r25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"r\",\n",
    "#     },\n",
    "#     \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"s\",\n",
    "#     }\n",
    "# }\n",
    "\n",
    "#  ir vs is\n",
    "output_names = [\"Stimulus_ir_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\"]\n",
    "output_names_conditions = {\n",
    "    \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "#  cr vs cs\n",
    "output_names = [\"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_cs_fixationCrossBase_1sec_mirror\"]\n",
    "output_names_conditions = {\n",
    "    \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "#  is vs cs\n",
    "output_names = [\"Stimulus_cs_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\"]\n",
    "output_names_conditions = {\n",
    "    \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"s\"\n",
    "    },\n",
    "    \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "#  ir vs cr\n",
    "output_names = [\"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_ir_fixationCrossBase_1sec_mirror\"]\n",
    "output_names_conditions = {\n",
    "    \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"r\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# all interaction effects (run this with the anova code. Ugh make everything more modular later.)\n",
    "output_names = [\"Stimulus_ir_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\", \"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_cs_fixationCrossBase_1sec_mirror\"]\n",
    "\n",
    "output_names_conditions = {\n",
    "    \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"s\"\n",
    "    },\n",
    "    \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "task='GlobalLocal'\n",
    "\n",
    "# Assuming 'combined_data' is your DataFrame and 'subjects' is your list of subject IDs\n",
    "subjects_mne_objects = create_subjects_mne_objects_dict(subjects, output_names_conditions, task=\"GlobalLocal\", combined_data=combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old way to create mne objects dict without accuracy indexing. Delete once filtering by accuracy works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import mne\n",
    "# import numpy as np\n",
    "\n",
    "# def create_subjects_mne_objects_dict(subjects, output_names, task, LAB_root=None):\n",
    "#     subjects_mne_objects = {}\n",
    "\n",
    "#     for sub in subjects:\n",
    "#         print(f\"Loading data for subject: {sub}\")  # Debugging print\n",
    "#         sub_mne_objects = {}\n",
    "#         for output_name in output_names:\n",
    "#             print(f\"  Loading output: {output_name}\")  # Debugging print\n",
    "#             mne_objects = load_mne_objects(sub, output_name, task, LAB_root)\n",
    "\n",
    "#             # Debugging prints for data shapes\n",
    "#             print(f\"    HG_ev1 shape: {mne_objects['HG_ev1'].get_data().shape}\")\n",
    "#             print(f\"    HG_base shape: {mne_objects['HG_base'].get_data().shape}\")\n",
    "#             print(f\"    HG_ev1_rescaled shape: {mne_objects['HG_ev1_rescaled'].get_data().shape}\")\n",
    "#             print(f\"    HG_ev1_evoke shape: {mne_objects['HG_ev1_evoke'].data.shape}\")\n",
    "#             print(f\"    HG_ev1_evoke_rescaled shape: {mne_objects['HG_ev1_evoke_rescaled'].data.shape}\")\n",
    "\n",
    "#             # NEW code 2/6 for accuracy metadata\n",
    "#             # Assuming each subject's accuracy array is loaded into acc_array dict\n",
    "#             if sub in acc_array:\n",
    "#                 accuracy_data = acc_array[sub]\n",
    "#                 #update hg ev1 rescaled with accuracy data.\n",
    "#                 mne_objects['HG_ev1_rescaled'] = add_accuracy_to_epochs(mne_objects['HG_ev1_rescaled'], accuracy_data)\n",
    "\n",
    "#             sub_mne_objects[output_name] = mne_objects\n",
    "#         subjects_mne_objects[sub] = sub_mne_objects\n",
    "\n",
    "#     return subjects_mne_objects\n",
    "\n",
    "# # Example usage\n",
    "# subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "# output_names = [\"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"]\n",
    "# task = 'GlobalLocal'\n",
    "\n",
    "# subjects_mne_objects = create_subjects_mne_objects_dict(subjects, output_names, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0059\n",
      "Loaded significant channels for subject D0063\n",
      "Loaded significant channels for subject D0065\n",
      "Loaded significant channels for subject D0071\n",
      "Loaded significant channels for subject D0077\n",
      "Loaded significant channels for subject D0090\n",
      "Loaded significant channels for subject D0100\n",
      "Loaded significant channels for subject D0102\n",
      "Loaded significant channels for subject D0103\n"
     ]
    }
   ],
   "source": [
    "def get_sig_chans(sub, task, LAB_root=None):\n",
    "    # Determine LAB_root based on the operating system\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "\n",
    "    stim_filename = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
    "    stim_sig_chans = load_sig_chans(stim_filename)\n",
    "    return stim_sig_chans\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store significant channels per subject\n",
    "sig_chans_per_subject = {}\n",
    "\n",
    "# Populate the dictionary using get_sig_chans for each subject\n",
    "for sub in subjects:\n",
    "    sig_chans_per_subject[sub] = get_sig_chans(sub, 'GlobalLocal')\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the significant electrodes across subjects for each ROI of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup\n",
    "ACC based on Destrieux et al 2010 definition is G_and_S_cingul-Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject D0103, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LFAM15']\n",
      "For subject D0057, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RAI12', 'RAI13', 'RAI15', 'RAI16', 'RPI14', 'RAMF10', 'RAMF11', 'RAMF12']\n",
      "For subject D0059, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LMMF9', 'LMMF11', 'LMMF12', 'LPSF16']\n",
      "For subject D0063, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LASF10', 'LASF14', 'LASF15', 'LASF16', 'LMSF5', 'LMSF6', 'LMSF12', 'LPSF10', 'LPSF12', 'RAI10', 'RAI11', 'RAI16', 'RAMF11', 'RAMF12', 'RAMF13', 'RMMF13', 'RMMF14', 'RASF15', 'RMSF8', 'RMSF9', 'RMSF10', 'RMSF7', 'RAMF8', 'RAMF9', 'RAMF10', 'RMMF9', 'RMMF10']\n",
      "For subject D0065, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RASF13', 'RASF14', 'RASF15', 'RMSF11', 'RMSF12', 'RMSF13', 'RMSF14']\n",
      "For subject D0069, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0071, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RIA11', 'RIA12', 'RIA14', 'RIA16', 'RIP14', 'RIP15']\n",
      "For subject D0077, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0090, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RIA12', 'RIA14', 'RIA15']\n",
      "For subject D0094, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFAM8', 'LFAM9', 'LFAM10', 'LFAM13', 'LFAM14', 'LFPM10', 'LFPM12', 'LIA11', 'LIA14', 'LIA16']\n",
      "For subject D0100, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0102, G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFAM15']\n",
      "Subject D0103 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14']\n",
      "Subject D0057 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RPI14']\n",
      "Subject D0059 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LMMF9', 'LMMF11', 'LMMF12', 'LPSF16']\n",
      "Subject D0063 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LMSF5', 'LPSF12', 'RAMF12', 'RMMF13', 'RMMF14', 'RMMF10']\n",
      "Subject D0065 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RASF14']\n",
      "Subject D0069 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0071 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RIA11', 'RIA12', 'RIA14', 'RIA16']\n",
      "Subject D0077 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0090 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RIA12']\n",
      "Subject D0094 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0100 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0102 significant G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RFAM15']\n",
      "For subject D0103, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: ['LFAM2', 'LFAM3']\n",
      "For subject D0057, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: ['RAMF1']\n",
      "For subject D0059, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: []\n",
      "For subject D0063, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: ['LASF1', 'LASF3', 'LASF7', 'LASF9', 'LMSF1', 'LMSF2', 'LMSF4', 'RMSF3', 'RMSF4', 'RMSF5', 'RMMF1', 'RAMF1', 'RAMF2', 'RMMF2', 'RMMF3', 'RMMF4']\n",
      "For subject D0065, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: ['RASF1', 'RASF2', 'RASF7', 'RASF8', 'RASF9', 'RMSF4', 'RMSF5']\n",
      "For subject D0069, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: []\n",
      "For subject D0071, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: []\n",
      "For subject D0077, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: []\n",
      "For subject D0090, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: []\n",
      "For subject D0094, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: ['LFPM2']\n",
      "For subject D0100, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: []\n",
      "For subject D0102, G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes are: ['RFAM2', 'RFMM1']\n",
      "Subject D0103 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: ['LFAM3']\n",
      "Subject D0057 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0059 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0063 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: ['LMSF2', 'LMSF4', 'RMSF3', 'RMSF4']\n",
      "Subject D0065 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0069 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0071 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0077 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0090 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0094 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0100 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: []\n",
      "Subject D0102 significant G_and_S_cingul-Ant, G_and_S_cingul-Mid-Ant electrodes: ['RFMM1']\n",
      "For subject D0103, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: []\n",
      "For subject D0057, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: ['RPIP11', 'RPIP12', 'RPIP14']\n",
      "For subject D0059, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: ['LMPF11', 'LMPF12', 'LMPF14', 'LMPF16']\n",
      "For subject D0063, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: []\n",
      "For subject D0065, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: ['RMMP14', 'RPMP14', 'RPMP16', 'RPIP16']\n",
      "For subject D0069, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: []\n",
      "For subject D0071, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: ['RTPS9']\n",
      "For subject D0077, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: ['ROAM5', 'ROAM6', 'ROAS12', 'ROAS13', 'ROAS14', 'ROAS15', 'ROPS10', 'ROPS12', 'RPAS6', 'RPAS7', 'RPAS10', 'ROAS7', 'ROAS11']\n",
      "For subject D0090, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: []\n",
      "For subject D0094, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: []\n",
      "For subject D0100, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: ['LOAS15', 'LPAI18']\n",
      "For subject D0102, G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes are: []\n",
      "Subject D0103 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n",
      "Subject D0057 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: ['RPIP11', 'RPIP12', 'RPIP14']\n",
      "Subject D0059 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: ['LMPF11', 'LMPF12', 'LMPF14']\n",
      "Subject D0063 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n",
      "Subject D0065 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n",
      "Subject D0069 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n",
      "Subject D0071 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: ['RTPS9']\n",
      "Subject D0077 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: ['ROAS14', 'ROPS10', 'ROPS12', 'RPAS7', 'ROAS7', 'ROAS11']\n",
      "Subject D0090 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n",
      "Subject D0094 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n",
      "Subject D0100 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n",
      "Subject D0102 significant G_parietal_sup, S_intrapariet_and_P_trans, G_pariet_inf-Angular, G_pariet_inf-Supramar electrodes: []\n"
     ]
    }
   ],
   "source": [
    "def filter_electrodes_by_roi(subjects_electrodes_dict, sig_chans_per_subject, roi_list):\n",
    "    \"\"\"\n",
    "    Filters electrodes based on specified ROIs and returns significant electrodes for each subject.\n",
    "\n",
    "    Args:\n",
    "    subjects_electrodes_dict (dict): A dictionary with subjects as keys and electrode-to-ROI mappings as values.\n",
    "    sig_chans_per_subject (dict): A dictionary with subjects as keys and lists of significant channels as values.\n",
    "    roi_list (list): A list of ROIs to filter electrodes.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with subjects as keys and lists of significant electrodes in specified ROIs as values.\n",
    "    \"\"\"\n",
    "    filtered_electrodes_per_subject = {}\n",
    "\n",
    "    for sub, electrodes_dict in subjects_electrodes_dict.items():\n",
    "        filtered = {key: value for key, value in electrodes_dict['filtROI_dict'].items() \n",
    "                    if any(roi in key for roi in roi_list)}\n",
    "\n",
    "        # Aggregate electrodes into a list for each subject\n",
    "        filtered_electrodes = []\n",
    "        for electrodes in filtered.values():\n",
    "            filtered_electrodes.extend(electrodes)\n",
    "\n",
    "        filtered_electrodes_per_subject[sub] = filtered_electrodes\n",
    "        print(f'For subject {sub}, {\", \".join(roi_list)} electrodes are: {filtered_electrodes}')\n",
    "\n",
    "    # Now filter for significant electrodes\n",
    "    sig_filtered_electrodes_per_subject = {}\n",
    "\n",
    "    for sub, filtered_electrodes in filtered_electrodes_per_subject.items():\n",
    "        # Retrieve the list of significant channels for the subject\n",
    "        sig_chans = sig_chans_per_subject.get(sub, [])\n",
    "\n",
    "        # Find the intersection of filtered electrodes and significant channels for the subject\n",
    "        sig_filtered_electrodes = [elec for elec in filtered_electrodes if elec in sig_chans]\n",
    "\n",
    "        # Store the significant filtered electrodes for the subject\n",
    "        sig_filtered_electrodes_per_subject[sub] = sig_filtered_electrodes\n",
    "        print(f\"Subject {sub} significant {', '.join(roi_list)} electrodes: {sig_filtered_electrodes}\")\n",
    "\n",
    "    return filtered_electrodes_per_subject, sig_filtered_electrodes_per_subject\n",
    "\n",
    "# Example usage:\n",
    "dlpfc_rois = [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"] #dorsolateral prefrontal cortex\n",
    "acc_rois = [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"] #anterior cingulate cortex\n",
    "parietal_rois = [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"] #superior parietal lobule, intraparietal sulcus, and inferior parietal lobule (split into angular gyrus and supramarginal gyrus)\n",
    "dlpfc_electrodes_per_subject, sig_dlpfc_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, dlpfc_rois)\n",
    "acc_electrodes_per_subject, sig_acc_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, acc_rois)\n",
    "parietal_electrodes_per_subject, sig_parietal_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, parietal_rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get total number of electrodes (make this modular with roi later once everything works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sig dlpfc electrodes across all subjects: 22\n",
      "Total number of sig acc electrodes across all subjects: 6\n",
      "Total number of sig parietal electrodes across all subjects: 13\n"
     ]
    }
   ],
   "source": [
    "total_entries = 0\n",
    "for sub in sig_dlpfc_electrodes_per_subject:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(sig_dlpfc_electrodes_per_subject[sub])\n",
    "\n",
    "print(\"Total number of sig dlpfc electrodes across all subjects:\", total_entries)\n",
    "\n",
    "total_entries = 0\n",
    "for sub in sig_acc_electrodes_per_subject:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(sig_acc_electrodes_per_subject[sub])\n",
    "\n",
    "print(\"Total number of sig acc electrodes across all subjects:\", total_entries)\n",
    "\n",
    "total_entries = 0\n",
    "for sub in sig_parietal_electrodes_per_subject:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(sig_parietal_electrodes_per_subject[sub])\n",
    "\n",
    "print(\"Total number of sig parietal electrodes across all subjects:\", total_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D0103': ['LFAM8', 'LFAM9', 'LAI13', 'LAI14'],\n",
       " 'D0057': ['RPI14'],\n",
       " 'D0059': ['LMMF9', 'LMMF11', 'LMMF12', 'LPSF16'],\n",
       " 'D0063': ['LMSF5', 'LPSF12', 'RAMF12', 'RMMF13', 'RMMF14', 'RMMF10'],\n",
       " 'D0065': ['RASF14'],\n",
       " 'D0069': [],\n",
       " 'D0071': ['RIA11', 'RIA12', 'RIA14', 'RIA16'],\n",
       " 'D0077': [],\n",
       " 'D0090': ['RIA12'],\n",
       " 'D0094': [],\n",
       " 'D0100': [],\n",
       " 'D0102': ['RFAM15']}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_dlpfc_electrodes_per_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D0103': ['LFAM3'],\n",
       " 'D0057': [],\n",
       " 'D0059': [],\n",
       " 'D0063': ['LMSF2', 'LMSF4', 'RMSF3', 'RMSF4'],\n",
       " 'D0065': [],\n",
       " 'D0069': [],\n",
       " 'D0071': [],\n",
       " 'D0077': [],\n",
       " 'D0090': [],\n",
       " 'D0094': [],\n",
       " 'D0100': [],\n",
       " 'D0102': ['RFMM1']}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_acc_electrodes_per_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'D0103': [],\n",
       " 'D0057': ['RPIP11', 'RPIP12', 'RPIP14'],\n",
       " 'D0059': ['LMPF11', 'LMPF12', 'LMPF14'],\n",
       " 'D0063': [],\n",
       " 'D0065': [],\n",
       " 'D0069': [],\n",
       " 'D0071': ['RTPS9'],\n",
       " 'D0077': ['ROAS14', 'ROPS10', 'ROPS12', 'RPAS7', 'ROAS7', 'ROAS11'],\n",
       " 'D0090': [],\n",
       " 'D0094': [],\n",
       " 'D0100': [],\n",
       " 'D0102': []}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_parietal_electrodes_per_subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do stats\n",
    "\n",
    "current approach is to run time_perm_cluster on significant dlpfc electrodes for each subject, comparing congruent and incongruent conditions. Then, average p-values across all subjects. Discuss this with Greg, probably wrong approach.\n",
    "\n",
    "**1/23 new approach is to average across all trials for sig dlpfc electrodes, comparing incongruent and congruent conditions. Then, run stats on this new avg electrode value x time array.\n",
    "\n",
    "Also, I'm using HG_ev1_rescaled instead of HG_ev1 to compare congruent and incongruent, so that they're normalized with a common baseline. I think this is better than comparing the raw HG traces directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is 1/23 new approach of avg across trials first\n",
    "\n",
    "do stats and plotting together. Stats needs trial avg data, plotting just needs congruent_data without trial averaging (initially at least)  \n",
    "this code is so bad right now, turn into a function later  \n",
    "\n",
    "trialAvg is for the time perm cluster stats  \n",
    "timeAvg_firstHalfSecond_firstHalfSecond_firstHalfSecond_firstHalfSecond_firstHalfSecond is for the window stats (not sure if this is even right)  \n",
    "\n",
    "here, also only average across the accurate trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_and_average_epochs(epochs, start_idx, end_idx, accuracy_column='accuracy'):\n",
    "    \"\"\"\n",
    "    Calculates trial averages for accurate trials and time averages with inaccurate trials marked as NaNs.\n",
    "\n",
    "    Parameters:\n",
    "    - epochs: MNE Epochs object with accuracy metadata.\n",
    "    - start_idx: Start index for time averaging.\n",
    "    - end_idx: End index for time averaging.\n",
    "    - accuracy_column: Name of the column in the metadata that contains accuracy data.\n",
    "\n",
    "    Returns:\n",
    "    - trial_avg_data: Trial-averaged data across accurate trials.\n",
    "    - time_avg_data: Time-averaged data with inaccurate trials marked as NaNs.\n",
    "    \"\"\"\n",
    "    # Separate accurate and all trials data\n",
    "    accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
    "    all_epochs_data = epochs.get_data().copy()\n",
    "\n",
    "    # Mark inaccurate trials as NaNs in the all_epochs_data\n",
    "    inaccurate_indices = epochs.metadata[accuracy_column] != 1.0\n",
    "    all_epochs_data[inaccurate_indices, :, :] = np.nan\n",
    "\n",
    "    # Calculate trial average for accurate trials\n",
    "    trial_avg_data = np.nanmean(accurate_epochs_data, axis=0)\n",
    "\n",
    "    # Calculate time average within the specified window\n",
    "    time_avg_data = np.nanmean(all_epochs_data[:, :, start_idx:end_idx], axis=2)\n",
    "\n",
    "    return trial_avg_data, time_avg_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn these into dictionaries instead of a bunch of variables later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_0_data_timeAvg_firstHalfSecond_list['dlpfc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:27: RuntimeWarning: Mean of empty slice\n",
      "  time_avg_data = np.nanmean(all_epochs_data[:, :, start_idx:end_idx], axis=2)\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2707541680.py:53: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2707541680.py:54: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2707541680.py:53: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2707541680.py:54: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:16: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_16716\\2439027647.py:17: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
      "  all_epochs_data = epochs.get_data().copy()\n"
     ]
    }
   ],
   "source": [
    "# Initialize a dictionary to hold mappings\n",
    "overall_electrode_mapping = []\n",
    "\n",
    "# Initialize a dictionary to hold mappings for each ROI\n",
    "electrode_mapping_per_roi = {\n",
    "    'dlpfc': [],\n",
    "    'acc': [],\n",
    "    'parietal': []\n",
    "}\n",
    "\n",
    "# Initialize lists for storing data\n",
    "output_0_data_trialAvg_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "output_1_data_trialAvg_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "output_0_data_timeAvg_firstHalfSecond_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "output_1_data_timeAvg_firstHalfSecond_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "output_0_data_timeAvg_secondHalfSecond_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "output_1_data_timeAvg_secondHalfSecond_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "output_0_data_timeAvg_fullSecond_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "output_1_data_timeAvg_fullSecond_list = {'dlpfc': [], 'acc': [], 'parietal': []}\n",
    "\n",
    "# Time windows\n",
    "start_idx_firstHalfSecond, end_idx_firstHalfSecond = 2048, 3072\n",
    "start_idx_secondHalfSecond, end_idx_secondHalfSecond = 3072, 4096\n",
    "start_idx_fullSecond, end_idx_fullSecond = 2048, 4096\n",
    "\n",
    "\n",
    "for sub in subjects:\n",
    "    for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "        # Determine the significant electrodes for the current roi\n",
    "        if roi == 'dlpfc':\n",
    "            sig_electrodes = sig_dlpfc_electrodes_per_subject.get(sub, [])\n",
    "        elif roi == 'acc':\n",
    "            sig_electrodes = sig_acc_electrodes_per_subject.get(sub, [])\n",
    "        else:  # parietal\n",
    "            sig_electrodes = sig_parietal_electrodes_per_subject.get(sub, [])\n",
    "        \n",
    "        # Skip this roi for the current subject if no significant electrodes are present\n",
    "        if not sig_electrodes:\n",
    "            continue\n",
    "        for electrode in sig_electrodes:\n",
    "            # For each significant electrode, append a tuple to the mapping list\n",
    "            # Tuple format: (Subject ID, ROI, Electrode Name, Index in List)\n",
    "            # The index can be the current length of the list before appending\n",
    "            index = len(overall_electrode_mapping)\n",
    "            overall_electrode_mapping.append((sub, roi, electrode, index))  \n",
    "\n",
    "            # For each significant electrode, append a tuple to the mapping list of the corresponding ROI\n",
    "            # Tuple format: (Subject ID, Electrode Name, Index in List for this ROI)\n",
    "            index = len(electrode_mapping_per_roi[roi])  # Get the current length of the list for this ROI\n",
    "            electrode_mapping_per_roi[roi].append((sub, electrode, index))\n",
    "            \n",
    "        # Load trial-level data for the current condition and pick significant electrodes\n",
    "        output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "        output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "\n",
    "        # Calculate averages for each time window\n",
    "        trial_avg_0, time_avg_0_firstHalfSecond = filter_and_average_epochs(output_0_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "        trial_avg_1, time_avg_1_firstHalfSecond = filter_and_average_epochs(output_1_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "        _, time_avg_0_secondHalfSecond = filter_and_average_epochs(output_0_epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "        _, time_avg_1_secondHalfSecond = filter_and_average_epochs(output_1_epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "        _, time_avg_0_fullSecond = filter_and_average_epochs(output_0_epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "        _, time_avg_1_fullSecond = filter_and_average_epochs(output_1_epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "\n",
    "        # Append the results to their respective lists\n",
    "        output_0_data_trialAvg_list[roi].append(trial_avg_0)\n",
    "        output_1_data_trialAvg_list[roi].append(trial_avg_1)\n",
    "        output_0_data_timeAvg_firstHalfSecond_list[roi].append(time_avg_0_firstHalfSecond)\n",
    "        output_1_data_timeAvg_firstHalfSecond_list[roi].append(time_avg_1_firstHalfSecond)\n",
    "        output_0_data_timeAvg_secondHalfSecond_list[roi].append(time_avg_0_secondHalfSecond)\n",
    "        output_1_data_timeAvg_secondHalfSecond_list[roi].append(time_avg_1_secondHalfSecond)\n",
    "        output_0_data_timeAvg_fullSecond_list[roi].append(time_avg_0_fullSecond)\n",
    "        output_1_data_timeAvg_fullSecond_list[roi].append(time_avg_1_fullSecond)\n",
    "\n",
    "# After collecting all data, concatenate across subjects for each roi and condition\n",
    "concatenated_trialAvg_data = {}\n",
    "concatenated_timeAvg_firstHalfSecond_data = {}\n",
    "concatenated_timeAvg_secondHalfSecond_data = {}\n",
    "concatenated_timeAvg_fullSecond_data = {}\n",
    "\n",
    "for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "    concatenated_trialAvg_data[roi] = {\n",
    "        'output_0': np.concatenate(output_0_data_trialAvg_list[roi], axis=0),\n",
    "        'output_1': np.concatenate(output_1_data_trialAvg_list[roi], axis=0)\n",
    "    }\n",
    "    # concatenated_timeAvg_firstHalfSecond_data[roi] = {\n",
    "    #     'output_0': np.concatenate(output_0_data_timeAvg_firstHalfSecond_list[roi], axis=1),\n",
    "    #     'output_1': np.concatenate(output_1_data_timeAvg_firstHalfSecond_list[roi], axis=1)\n",
    "    # }\n",
    "    # concatenated_timeAvg_secondHalfSecond_data[roi] = {\n",
    "    #     'output_0': np.concatenate(output_0_data_timeAvg_secondHalfSecond_list[roi], axis=1),\n",
    "    #     'output_1': np.concatenate(output_1_data_timeAvg_secondHalfSecond_list[roi], axis=1)\n",
    "    # }\n",
    "    # concatenated_timeAvg_fullSecond_data[roi] = {\n",
    "    #     'output_0': np.concatenate(output_0_data_timeAvg_fullSecond_list[roi], axis=1),\n",
    "    #     'output_1': np.concatenate(output_1_data_timeAvg_fullSecond_list[roi], axis=1)\n",
    "    # }\n",
    "\n",
    "\n",
    "# Calculate mean and SEM across electrodes for all time windows and rois\n",
    "overall_averages = {}\n",
    "overall_sems = {}\n",
    "for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "    overall_averages[roi] = {}\n",
    "    overall_sems[roi] = {}\n",
    "    for output in ['output_0', 'output_1']:\n",
    "        trialAvg_data = concatenated_trialAvg_data[roi][output]\n",
    "        overall_averages[roi][output] = np.nanmean(trialAvg_data, axis=0)\n",
    "        overall_sems[roi][output] = np.std(trialAvg_data, axis=0, ddof=1) / np.sqrt(trialAvg_data.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "time_perm_cluster_results = {}\n",
    "for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "    time_perm_cluster_results[roi] = time_perm_cluster(\n",
    "        concatenated_trialAvg_data[roi]['output_0'],\n",
    "        concatenated_trialAvg_data[roi]['output_1'], 0.05, n_jobs=6\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Initialize lists to store data\n",
    "# output_0_data_trialAvg_list_dlpfc = []\n",
    "# output_1_data_trialAvg_list_dlpfc = []\n",
    "# output_0_data_trialAvg_list_acc = []\n",
    "# output_1_data_trialAvg_list_acc = []\n",
    "# output_0_data_trialAvg_list_parietal = []\n",
    "# output_1_data_trialAvg_list_parietal = []\n",
    "\n",
    "# # Initialize lists to store time-averaged data\n",
    "# output_0_data_timeAvg_firstHalfSecond_list_dlpfc = []\n",
    "# output_1_data_timeAvg_firstHalfSecond_list_dlpfc = []\n",
    "# output_0_data_timeAvg_firstHalfSecond_list_acc = []\n",
    "# output_1_data_timeAvg_firstHalfSecond_list_acc = []\n",
    "# output_0_data_timeAvg_firstHalfSecond_list_parietal = []\n",
    "# output_1_data_timeAvg_firstHalfSecond_list_parietal = []\n",
    "\n",
    "# # Initialize additional lists for the second half-second time-averaged data\n",
    "# output_0_data_timeAvg_secondHalfSecond_list_dlpfc = []\n",
    "# output_1_data_timeAvg_secondHalfSecond_list_dlpfc = []\n",
    "# output_0_data_timeAvg_secondHalfSecond_list_acc = []\n",
    "# output_1_data_timeAvg_secondHalfSecond_list_acc = []\n",
    "# output_0_data_timeAvg_secondHalfSecond_list_parietal = []\n",
    "# output_1_data_timeAvg_secondHalfSecond_list_parietal = []\n",
    "\n",
    "# start_idx_firstHalfSecond, end_idx_firstHalfSecond = 2048, 3072  # Time window from 0 to 0.5 seconds\n",
    "# start_idx_secondHalfSecond, end_idx_secondHalfSecond = 3072, 4096 # time window from 0.5 to 1 seconds\n",
    "# start_idx_fullSecond, end_idx_fullSecond = 2048, 4096\n",
    "\n",
    "# # subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "\n",
    "# for sub in subjects:\n",
    "#     # Skip this subject if no dlpfc electrodes\n",
    "#     if not sig_dlpfc_electrodes_per_subject[sub]:\n",
    "#         continue\n",
    "\n",
    "#     # Load trial-level data for each condition and pick significant DLPFC electrodes\n",
    "#     output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].copy().pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n",
    "#     output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].copy().pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n",
    "\n",
    "#     # Use the new function to filter based on accuracy and calculate averages\n",
    "#     trial_avg_0_dlpfc, time_avg_0_firstHalfSecond_dlpfc = filter_and_average_epochs(output_0_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "#     trial_avg_1_dlpfc, time_avg_1_firstHalfSecond_dlpfc = filter_and_average_epochs(output_1_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "\n",
    "#     # Append the results to the respective lists\n",
    "#     output_0_data_trialAvg_list_dlpfc.append(trial_avg_0_dlpfc)\n",
    "#     output_1_data_trialAvg_list_dlpfc.append(trial_avg_1_dlpfc)\n",
    "#     output_0_data_timeAvg_firstHalfSecond_list_dlpfc.append(time_avg_0_firstHalfSecond_dlpfc)\n",
    "#     output_1_data_timeAvg_firstHalfSecond_list_dlpfc.append(time_avg_1_firstHalfSecond_dlpfc)\n",
    "\n",
    "# # do for acc\n",
    "# for sub in subjects:\n",
    "#     # Skip this subject if no acc electrodes\n",
    "#     if not sig_acc_electrodes_per_subject[sub]:\n",
    "#         continue\n",
    "\n",
    "#     # Load trial-level data for each condition and pick significant DLPFC electrodes\n",
    "#     output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].copy().pick_channels(sig_acc_electrodes_per_subject[sub])\n",
    "#     output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].copy().pick_channels(sig_acc_electrodes_per_subject[sub])\n",
    "\n",
    "#     # Use the new function to filter based on accuracy and calculate averages\n",
    "#     trial_avg_0_acc, time_avg_0_firstHalfSecond_acc = filter_and_average_epochs(output_0_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "#     trial_avg_1_acc, time_avg_1_firstHalfSecond_acc = filter_and_average_epochs(output_1_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "\n",
    "#     # Append the results to the respective lists\n",
    "#     output_0_data_trialAvg_list_acc.append(trial_avg_0_acc)\n",
    "#     output_1_data_trialAvg_list_acc.append(trial_avg_1_acc)\n",
    "#     output_0_data_timeAvg_firstHalfSecond_list_acc.append(time_avg_0_firstHalfSecond_acc)\n",
    "#     output_1_data_timeAvg_firstHalfSecond_list_acc.append(time_avg_1_firstHalfSecond_acc)\n",
    "    \n",
    "# # #do for parietal\n",
    "# # for sub in subjects:\n",
    "# #     # Skip this subject if no dlpfc electrodes\n",
    "# #     if not sig_parietal_electrodes_per_subject[sub]:\n",
    "# #         continue\n",
    "\n",
    "# #     # Load trial-level data for each condition and pick significant DLPFC electrodes\n",
    "# #     output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].copy().pick_channels(sig_parietal_electrodes_per_subject[sub])\n",
    "# #     output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].copy().pick_channels(sig_parietal_electrodes_per_subject[sub])\n",
    "\n",
    "# #     # Use the new function to filter based on accuracy and calculate averages\n",
    "# #     trial_avg_0_parietal, time_avg_0_parietal = filter_and_average_epochs(output_0_epochs, start_idx, end_idx)\n",
    "# #     trial_avg_1_parietal, time_avg_1_parietal = filter_and_average_epochs(output_1_epochs, start_idx, end_idx)\n",
    "\n",
    "# #     # Append the results to the respective lists\n",
    "# #     output_0_data_trialAvg_list_parietal.append(trial_avg_0_parietal)\n",
    "# #     output_1_data_trialAvg_list_parietal.append(trial_avg_1_parietal)\n",
    "# #     output_0_data_timeAvg_list_parietal.append(time_avg_0_parietal)\n",
    "# #     output_1_data_timeAvg_list_parietal.append(time_avg_1_parietal)\n",
    "\n",
    "\n",
    "# # # below functions only go this far, keep this code\n",
    "# # # Concatenate data across all electrodes\n",
    "# # output_0_data_trialAvg_dlpfc = np.concatenate(output_0_data_trialAvg_list_dlpfc, axis=0)\n",
    "# # output_1_data_trialAvg_dlpfc = np.concatenate(output_1_data_trialAvg_list_dlpfc, axis=0)\n",
    "\n",
    "# # output_0_data_trialAvg_acc = np.concatenate(output_0_data_trialAvg_list_acc, axis=0)\n",
    "# # output_1_data_trialAvg_acc = np.concatenate(output_1_data_trialAvg_list_acc, axis=0)\n",
    "\n",
    "# # output_0_data_trialAvg_parietal = np.concatenate(output_0_data_trialAvg_list_parietal, axis=0)\n",
    "# # output_1_data_trialAvg_parietal = np.concatenate(output_1_data_trialAvg_list_parietal, axis=0)\n",
    "\n",
    "\n",
    "# # # Concatenate time-averaged data across all subjects for each brain roi and condition\n",
    "# # output_0_data_timeAvg_dlpfc = np.concatenate(output_0_data_timeAvg_list_dlpfc, axis=1)\n",
    "# # output_1_data_timeAvg_dlpfc = np.concatenate(output_1_data_timeAvg_list_dlpfc, axis=1)\n",
    "\n",
    "# # output_0_data_timeAvg_acc = np.concatenate(output_0_data_timeAvg_list_acc, axis=1)\n",
    "# # output_1_data_timeAvg_acc = np.concatenate(output_1_data_timeAvg_list_acc, axis=1)\n",
    "\n",
    "# # output_0_data_timeAvg_parietal = np.concatenate(output_0_data_timeAvg_list_parietal, axis=1)\n",
    "# # output_1_data_timeAvg_parietal = np.concatenate(output_1_data_timeAvg_list_parietal, axis=1)\n",
    "\n",
    "\n",
    "# # # Calculate mean and SEM across electrodes\n",
    "# # overall_average_dlpfc_output_0 = np.nanmean(output_0_data_trialAvg_dlpfc, axis=0)\n",
    "# # overall_sem_dlpfc_output_0 = np.std(output_0_data_trialAvg_dlpfc, axis=0, ddof=1) / np.sqrt(output_0_data_trialAvg_dlpfc.shape[0])\n",
    "# # overall_average_dlpfc_output_1 = np.nanmean(output_1_data_trialAvg_dlpfc, axis=0)\n",
    "# # overall_sem_dlpfc_output_1 = np.std(output_1_data_trialAvg_dlpfc, axis=0, ddof=1) / np.sqrt(output_1_data_trialAvg_dlpfc.shape[0])\n",
    "\n",
    "# # overall_average_acc_output_0 = np.nanmean(output_0_data_trialAvg_acc, axis=0)\n",
    "# # overall_sem_acc_output_0 = np.std(output_0_data_trialAvg_acc, axis=0, ddof=1) / np.sqrt(output_0_data_trialAvg_acc.shape[0])\n",
    "# # overall_average_acc_output_1 = np.nanmean(output_1_data_trialAvg_acc, axis=0)\n",
    "# # overall_sem_acc_output_1 = np.std(output_1_data_trialAvg_acc, axis=0, ddof=1) / np.sqrt(output_1_data_trialAvg_acc.shape[0])\n",
    "\n",
    "# # overall_average_parietal_output_0 = np.nanmean(output_0_data_trialAvg_parietal, axis=0)\n",
    "# # overall_sem_parietal_output_0 = np.std(output_0_data_trialAvg_parietal, axis=0, ddof=1) / np.sqrt(output_0_data_trialAvg_parietal.shape[0])\n",
    "# # overall_average_parietal_output_1 = np.nanmean(output_1_data_trialAvg_parietal, axis=0)\n",
    "# # overall_sem_parietal_output_1 = np.std(output_1_data_trialAvg_parietal, axis=0, ddof=1) / np.sqrt(output_1_data_trialAvg_parietal.shape[0])\n",
    "\n",
    "\n",
    "# # # Run the time perm cluster test\n",
    "# # mat_dlpfc = time_perm_cluster(output_0_data_trialAvg_dlpfc, output_1_data_trialAvg_dlpfc, 0.05, n_jobs=6)\n",
    "# # mat_acc = time_perm_cluster(output_0_data_trialAvg_acc, output_1_data_trialAvg_acc, 0.05, n_jobs=6)\n",
    "# # mat_parietal = time_perm_cluster(output_0_data_trialAvg_parietal, output_1_data_trialAvg_parietal, 0.05, n_jobs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do window stats  \n",
    "use the time avg outputs from previous cell  \n",
    "use fdr correction after comparing output 0 and output 1 for each electrode to get a p-values list  \n",
    "\n",
    "DO A SHUFFLE INSTEAD OF PAIRED T-TEST AS OF 2/7/24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle test (perm test). This basically time perm cluster but avg across time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def permutation_test(data_timeavg_output_0, data_timeavg_output_1, n_permutations=10000):\n",
    "    \"\"\"\n",
    "    Perform a permutation test to compare two conditions.\n",
    "\n",
    "    Parameters:\n",
    "    - data_timeavg_output_0: Numpy array for condition 0.\n",
    "    - data_timeavg_output_1: Numpy array for condition 1.\n",
    "    - n_permutations: Number of permutations to perform.\n",
    "\n",
    "    Returns:\n",
    "    - p_value: P-value assessing the significance of the observed difference.\n",
    "    \"\"\"\n",
    "    # Calculate the observed difference in means between the two conditions\n",
    "    observed_diff = np.nanmean(data_timeavg_output_0) - np.nanmean(data_timeavg_output_1)\n",
    "    \n",
    "    # Combine the data from both conditions\n",
    "    combined_data = np.hstack([data_timeavg_output_0, data_timeavg_output_1])\n",
    "    \n",
    "    # Initialize a variable to count how many times the permuted difference exceeds the observed difference\n",
    "    count_extreme_values = 0\n",
    "    \n",
    "    for _ in range(n_permutations):\n",
    "        # Shuffle the combined data\n",
    "        np.random.shuffle(combined_data)\n",
    "        \n",
    "        # Split the shuffled data back into two new groups\n",
    "        permuted_0 = combined_data[:len(data_timeavg_output_0)]\n",
    "        permuted_1 = combined_data[len(data_timeavg_output_0):]\n",
    "        \n",
    "        # Calculate the mean difference for this permutation\n",
    "        permuted_diff = np.nanmean(permuted_0) - np.nanmean(permuted_1)\n",
    "        \n",
    "        # Check if the permuted difference is as extreme as the observed difference\n",
    "        if abs(permuted_diff) >= abs(observed_diff):\n",
    "            count_extreme_values += 1\n",
    "    \n",
    "    # Calculate the p-value\n",
    "    p_value = count_extreme_values / n_permutations\n",
    "    \n",
    "    return p_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_permutation_test_within_electrodes(data_0_list, data_1_list, n_permutations=10000):\n",
    "    \"\"\"\n",
    "    Perform a permutation test for each electrode comparing two conditions across subjects.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_0_list: List of subject arrays from condition 0, each array is trials x electrodes.\n",
    "    - data_1_list: List of subject arrays from condition 1, each array is trials x electrodes.\n",
    "    - n_permutations: Number of permutations for the test.\n",
    "    \n",
    "    Returns:\n",
    "    - p_values: A list of p-values for each electrode, across all subjects.\n",
    "    \"\"\"\n",
    "    p_values = []\n",
    "\n",
    "    # Ensure there is a corresponding condition 1 array for each condition 0 array\n",
    "    if len(data_0_list) != len(data_1_list):\n",
    "        raise ValueError(\"Mismatch in number of subjects between conditions\")\n",
    "\n",
    "    # Iterate through each subject's data arrays\n",
    "    for idx, (data_0, data_1) in enumerate(zip(data_0_list, data_1_list)):\n",
    "        print(f\"Subject {idx} - Condition 0 shape: {data_0.shape}, Condition 1 shape: {data_1.shape}\")\n",
    "\n",
    "        # Check for matching electrode counts between conditions within a subject\n",
    "        if data_0.shape[1] != data_1.shape[1]:\n",
    "            raise ValueError(f\"Electrode count mismatch in subject {idx}\")\n",
    "\n",
    "        n_electrodes_this_sub = data_0.shape[1]  # Number of electrodes for this subject\n",
    "\n",
    "        # Perform the permutation test for each electrode in this subject\n",
    "        for electrode_idx in range(n_electrodes_this_sub):  # Fix: use range(n_electrodes) to iterate correctly\n",
    "            p_value = permutation_test(data_0[:, electrode_idx], data_1[:, electrode_idx], n_permutations)\n",
    "            p_values.append(p_value)\n",
    "\n",
    "    return p_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_permutation_test_across_electrodes(data_0_list, data_1_list, n_permutations=10000):\n",
    "    \"\"\"\n",
    "    Perform a permutation test across electrodes comparing two conditions.\n",
    "    \n",
    "    Parameters:\n",
    "    - data_0_list: List of arrays from condition 0, each array is trials x electrodes.\n",
    "    - data_1_list: List of arrays from condition 1, each array is trials x electrodes.\n",
    "    - n_permutations: Number of permutations for the test.\n",
    "    \n",
    "    Returns:\n",
    "    - p_value: P-value from the permutation test.\n",
    "    \"\"\"\n",
    "    # Aggregate data across electrodes\n",
    "    data_0_aggregated = np.concatenate([np.nanmean(data, axis=0) for data in data_0_list])  # Average across trials to get a single value per electrode\n",
    "    data_1_aggregated = np.concatenate([np.nanmean(data, axis=0) for data in data_1_list])  # though should I do avg across electrodes instead..?? Uhhhh. No, I think.\n",
    "    \n",
    "    # Perform the permutation test\n",
    "    p_value = permutation_test(data_0_aggregated, data_1_aggregated, n_permutations)\n",
    "    \n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do perm testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject 0 - Condition 0 shape: (121, 1), Condition 1 shape: (102, 1)\n",
      "Subject 1 - Condition 0 shape: (110, 4), Condition 1 shape: (113, 4)\n",
      "Subject 2 - Condition 0 shape: (118, 6), Condition 1 shape: (104, 6)\n",
      "Subject 3 - Condition 0 shape: (105, 1), Condition 1 shape: (117, 1)\n",
      "Subject 4 - Condition 0 shape: (109, 4), Condition 1 shape: (111, 4)\n",
      "Subject 5 - Condition 0 shape: (111, 1), Condition 1 shape: (111, 1)\n",
      "Subject 6 - Condition 0 shape: (117, 1), Condition 1 shape: (106, 1)\n",
      "Subject 7 - Condition 0 shape: (110, 4), Condition 1 shape: (113, 4)\n",
      "Subject 0 - Condition 0 shape: (118, 4), Condition 1 shape: (104, 4)\n",
      "Subject 1 - Condition 0 shape: (117, 1), Condition 1 shape: (106, 1)\n",
      "Subject 2 - Condition 0 shape: (110, 1), Condition 1 shape: (113, 1)\n",
      "Subject 0 - Condition 0 shape: (121, 3), Condition 1 shape: (102, 3)\n",
      "Subject 1 - Condition 0 shape: (110, 3), Condition 1 shape: (113, 3)\n",
      "Subject 2 - Condition 0 shape: (109, 1), Condition 1 shape: (111, 1)\n",
      "Subject 3 - Condition 0 shape: (116, 6), Condition 1 shape: (105, 6)\n"
     ]
    }
   ],
   "source": [
    "# Assuming the functions perform_permutation_test_within_electrodes and perform_permutation_test_across_electrodes return lists of p-values\n",
    "p_values = {}\n",
    "rois = ['dlpfc', 'acc', 'parietal']\n",
    "for roi in rois:\n",
    "    # Initialize p_values[roi] as a dictionary\n",
    "    p_values[roi] = {}\n",
    "\n",
    "    # Perform the tests and store results\n",
    "    p_values[roi]['within'] = perform_permutation_test_within_electrodes(output_0_data_timeAvg_firstHalfSecond_list[roi], output_1_data_timeAvg_firstHalfSecond_list[roi], n_permutations=10000)\n",
    "    p_values[roi]['across'] = perform_permutation_test_across_electrodes(output_0_data_timeAvg_firstHalfSecond_list[roi], output_1_data_timeAvg_firstHalfSecond_list[roi], n_permutations=10000)\n",
    "\n",
    "all_p_values = []\n",
    "for roi in p_values:\n",
    "    for test_type in p_values[roi]:\n",
    "        p = p_values[roi][test_type]\n",
    "        if isinstance(p, list):\n",
    "            all_p_values.extend(p)\n",
    "        else:  # Assume it's a single float value\n",
    "            all_p_values.append(p)\n",
    "\n",
    "# Apply FDR correction\n",
    "_, adjusted_p_values = multipletests(all_p_values, alpha=0.05, method='fdr_bh')[:2]\n",
    "\n",
    "# Incorporating adjusted p-values back into the structure is a bit more complex and depends on how you want to use them next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dlpfc': {'within': [0.2972,\n",
       "   0.2641,\n",
       "   0.9632,\n",
       "   0.5992,\n",
       "   0.2678,\n",
       "   0.0882,\n",
       "   0.246,\n",
       "   0.3544,\n",
       "   0.8306,\n",
       "   0.312,\n",
       "   0.9271,\n",
       "   0.7132,\n",
       "   0.8788,\n",
       "   0.2037,\n",
       "   0.9557,\n",
       "   0.3454,\n",
       "   0.6933,\n",
       "   0.5169,\n",
       "   0.369,\n",
       "   0.6368,\n",
       "   0.6565,\n",
       "   0.2463],\n",
       "  'across': 0.9368},\n",
       " 'acc': {'within': [0.407, 0.8218, 0.6427, 0.7348, 0.3698, 0.5994],\n",
       "  'across': 0.6079},\n",
       " 'parietal': {'within': [0.0769,\n",
       "   0.306,\n",
       "   0.9659,\n",
       "   0.6881,\n",
       "   0.138,\n",
       "   0.0064,\n",
       "   0.1829,\n",
       "   0.579,\n",
       "   0.8397,\n",
       "   0.9703,\n",
       "   0.9993,\n",
       "   0.9642,\n",
       "   0.9975],\n",
       "  'across': 0.8878}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dlpfc': [('D0057', 'RPI14', 0),\n",
       "  ('D0059', 'LMMF9', 1),\n",
       "  ('D0059', 'LMMF11', 2),\n",
       "  ('D0059', 'LMMF12', 3),\n",
       "  ('D0059', 'LPSF16', 4),\n",
       "  ('D0063', 'LMSF5', 5),\n",
       "  ('D0063', 'LPSF12', 6),\n",
       "  ('D0063', 'RAMF12', 7),\n",
       "  ('D0063', 'RMMF13', 8),\n",
       "  ('D0063', 'RMMF14', 9),\n",
       "  ('D0063', 'RMMF10', 10),\n",
       "  ('D0065', 'RASF14', 11),\n",
       "  ('D0071', 'RIA11', 12),\n",
       "  ('D0071', 'RIA12', 13),\n",
       "  ('D0071', 'RIA14', 14),\n",
       "  ('D0071', 'RIA16', 15),\n",
       "  ('D0090', 'RIA12', 16),\n",
       "  ('D0102', 'RFAM15', 17),\n",
       "  ('D0103', 'LFAM8', 18),\n",
       "  ('D0103', 'LFAM9', 19),\n",
       "  ('D0103', 'LAI13', 20),\n",
       "  ('D0103', 'LAI14', 21)],\n",
       " 'acc': [('D0063', 'LMSF2', 0),\n",
       "  ('D0063', 'LMSF4', 1),\n",
       "  ('D0063', 'RMSF3', 2),\n",
       "  ('D0063', 'RMSF4', 3),\n",
       "  ('D0102', 'RFMM1', 4),\n",
       "  ('D0103', 'LFAM3', 5)],\n",
       " 'parietal': [('D0057', 'RPIP11', 0),\n",
       "  ('D0057', 'RPIP12', 1),\n",
       "  ('D0057', 'RPIP14', 2),\n",
       "  ('D0059', 'LMPF11', 3),\n",
       "  ('D0059', 'LMPF12', 4),\n",
       "  ('D0059', 'LMPF14', 5),\n",
       "  ('D0071', 'RTPS9', 6),\n",
       "  ('D0077', 'ROAS14', 7),\n",
       "  ('D0077', 'ROPS10', 8),\n",
       "  ('D0077', 'ROPS12', 9),\n",
       "  ('D0077', 'RPAS7', 10),\n",
       "  ('D0077', 'ROAS7', 11),\n",
       "  ('D0077', 'ROAS11', 12)]}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "electrode_mapping_per_roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95712941, 0.95712941, 0.9993    , 0.9993    , 0.95712941,\n",
       "       0.95712941, 0.95712941, 0.95712941, 0.9993    , 0.95712941,\n",
       "       0.9993    , 0.9993    , 0.9993    , 0.95712941, 0.9993    ,\n",
       "       0.95712941, 0.9993    , 0.9993    , 0.95712941, 0.9993    ,\n",
       "       0.9993    , 0.95712941, 0.9993    , 0.99488889, 0.9993    ,\n",
       "       0.9993    , 0.9993    , 0.95712941, 0.9993    , 0.9993    ,\n",
       "       0.95712941, 0.95712941, 0.9993    , 0.9993    , 0.95712941,\n",
       "       0.2816    , 0.95712941, 0.9993    , 0.9993    , 0.9993    ,\n",
       "       0.9993    , 0.9993    , 0.9993    , 0.9993    ])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjusted_pvals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do anova  \n",
    "this requires reloading in all four conditions (four this time cuz interaction contrasts).  \n",
    "ONLY RUN THIS WHEN LOADING IN THE FOUR INTERACTION CONTRASTS RIGHT NOW.  \n",
    "Integrate with other stats and plotting and stuff later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "untested 2/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming output_names contains all four conditions\n",
    "output_data_trialAvg_lists = {output_name: {'dlpfc': [], 'acc': [], 'parietal': []} for output_name in output_names}\n",
    "output_data_timeAvg_firstHalfSecond_lists = {output_name: {'dlpfc': [], 'acc': [], 'parietal': []} for output_name in output_names}\n",
    "output_data_timeAvg_secondHalfSecond_lists = {output_name: {'dlpfc': [], 'acc': [], 'parietal': []} for output_name in output_names}\n",
    "output_data_timeAvg_fullSecond_lists = {output_name: {'dlpfc': [], 'acc': [], 'parietal': []} for output_name in output_names}\n",
    "\n",
    "for sub in subjects:\n",
    "    for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "        for output_name in output_names:\n",
    "            # Determine significant electrodes for the current ROI and subject\n",
    "            sig_electrodes = sig_dlpfc_electrodes_per_subject.get(sub, []) if roi == 'dlpfc' else sig_acc_electrodes_per_subject.get(sub, []) if roi == 'acc' else sig_parietal_electrodes_per_subject.get(sub, [])\n",
    "            \n",
    "            if not sig_electrodes:  # Skip if no significant electrodes\n",
    "                continue\n",
    "            \n",
    "            # Load trial-level data for the current condition and pick significant electrodes\n",
    "            epochs = subjects_mne_objects[sub][output_name]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "            \n",
    "            # Calculate averages for each time window\n",
    "            trial_avg, time_avg_firstHalfSecond = filter_and_average_epochs(epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "            _, time_avg_secondHalfSecond = filter_and_average_epochs(epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "            _, time_avg_fullSecond = filter_and_average_epochs(epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "            \n",
    "            # Append the results to their respective lists\n",
    "            output_data_trialAvg_lists[output_name][roi].append(trial_avg)\n",
    "            output_data_timeAvg_firstHalfSecond_lists[output_name][roi].append(time_avg_firstHalfSecond)\n",
    "            output_data_timeAvg_secondHalfSecond_lists[output_name][roi].append(time_avg_secondHalfSecond)\n",
    "            output_data_timeAvg_fullSecond_lists[output_name][roi].append(time_avg_fullSecond)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example structure for organizing data\n",
    "data_for_anova = []\n",
    "\n",
    "# Assuming output_0_data_trialAvg_list and output_1_data_trialAvg_list are filled as per the conditions\n",
    "for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "    for condition, trial_avg_data in [('Condition1', output_0_data_trialAvg_list[roi]), ('Condition2', output_1_data_trialAvg_list[roi])]:\n",
    "        # Assume trial_avg_data is a list of arrays, each array corresponding to a subject\n",
    "        for subject_index, subject_data in enumerate(trial_avg_data):\n",
    "            subject_id = subjects[subject_index]  # Map back to subject ID\n",
    "            for electrode_index, electrode_data in enumerate(subject_data):\n",
    "                # Map electrode index back to electrode name if necessary\n",
    "                # Here, electrode_data is the mean activity for this electrode under the current condition\n",
    "                data_for_anova.append({\n",
    "                    'SubjectID': subject_id,\n",
    "                    'Electrode': electrode_mapping_per_roi[roi][electrode_index][1],  # Assuming mapping provides electrode names\n",
    "                    'ROI': roi,\n",
    "                    'Condition': condition,\n",
    "                    'MeanActivity': np.mean(electrode_data)  # or directly use electrode_data if it's already a mean value\n",
    "                })\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_for_anova = pd.DataFrame(data_for_anova)\n",
    "\n",
    "# Now df_for_anova is ready for further analysis, including ANOVA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# def perform_analysis_and_fdr_correction(data_timeavg_output_0, data_timeavg_output_1):\n",
    "#     \"\"\"\n",
    "#     Perform paired t-test for each electrode between two conditions and apply FDR correction,\n",
    "#     ignoring NaN values and reporting the number of NaN pairs. Returns both adjusted and unadjusted p-values.\n",
    "\n",
    "#     Parameters:\n",
    "#     - data_timeavg_output_0: Numpy array for condition 0.\n",
    "#     - data_timeavg_output_1: Numpy array for condition 1.\n",
    "\n",
    "#     Returns:\n",
    "#     - p_vals_adj: Adjusted p-values after FDR correction.\n",
    "#     - unadj_p_vals: Original, unadjusted p-values from the t-tests.\n",
    "#     - t_stats: T-statistics from the t-tests.\n",
    "#     - nan_counts: Number of NaN pairs for each electrode, indicating missing data.\n",
    "#     \"\"\"\n",
    "#     p_values = []\n",
    "#     t_stats = []\n",
    "#     nan_counts = []  # To store the count of NaN pairs for each electrode\n",
    "\n",
    "#     # Ensure input data dimensions match\n",
    "#     assert data_timeavg_output_0.shape == data_timeavg_output_1.shape, \"Data arrays must have the same shape\"\n",
    "\n",
    "#     # Perform paired t-test for each electrode, ignoring NaNs\n",
    "#     for i in range(data_timeavg_output_0.shape[1]):  # Iterate over electrodes\n",
    "#         # Identify NaN pairs\n",
    "#         nan_pairs = np.isnan(data_timeavg_output_0[:, i]) | np.isnan(data_timeavg_output_1[:, i])\n",
    "#         nan_count = np.sum(nan_pairs)\n",
    "#         nan_counts.append(nan_count)\n",
    "        \n",
    "#         # Remove NaN pairs for valid comparison\n",
    "#         valid_indices = ~nan_pairs\n",
    "#         if np.sum(valid_indices) > 1:  # Ensure there are at least two valid pairs for comparison\n",
    "#             t_stat, p_value = stats.ttest_rel(data_timeavg_output_0[valid_indices, i],\n",
    "#                                               data_timeavg_output_1[valid_indices, i])\n",
    "#             t_stats.append(t_stat)\n",
    "#             p_values.append(p_value)\n",
    "#         else:\n",
    "#             # Append NaNs if not enough data points for a valid test\n",
    "#             t_stats.append(np.nan)\n",
    "#             p_values.append(np.nan)\n",
    "\n",
    "#     # Apply FDR correction\n",
    "#     _, p_vals_adj, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "#     # Print out the number of NaN pairs for each electrode\n",
    "#     for i, count in enumerate(nan_counts):\n",
    "#         print(f\"Electrode {i+1} had {count} NaN pairs excluded from analysis.\")\n",
    "\n",
    "#     return p_vals_adj, np.array(p_values), np.array(t_stats), np.array(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "# import numpy as np\n",
    "# from scipy import stats\n",
    "# from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# def perform_analysis_and_fdr_correction(data_timeavg_output_0, data_timeavg_output_1):\n",
    "#     \"\"\"\n",
    "#     Perform paired t-test for each electrode between two conditions and apply FDR correction,\n",
    "#     ignoring NaN values and reporting the number of NaN pairs. Returns both adjusted and unadjusted p-values.\n",
    "\n",
    "#     Parameters:\n",
    "#     - data_timeavg_output_0: Numpy array for condition 0.\n",
    "#     - data_timeavg_output_1: Numpy array for condition 1.\n",
    "\n",
    "#     Returns:\n",
    "#     - p_vals_adj: Adjusted p-values after FDR correction.\n",
    "#     - unadj_p_vals: Original, unadjusted p-values from the t-tests.\n",
    "#     - t_stats: T-statistics from the t-tests.\n",
    "#     - nan_counts: Number of NaN pairs for each electrode, indicating missing data.\n",
    "#     \"\"\"\n",
    "#     p_values = []\n",
    "#     t_stats = []\n",
    "#     nan_counts = []  # To store the count of NaN pairs for each electrode\n",
    "\n",
    "#     # Ensure input data dimensions match\n",
    "#     assert data_timeavg_output_0.shape == data_timeavg_output_1.shape, \"Data arrays must have the same shape\"\n",
    "\n",
    "#     # Perform paired t-test for each electrode, ignoring NaNs\n",
    "#     for i in range(data_timeavg_output_0.shape[1]):  # Iterate over electrodes\n",
    "#         # Identify NaN pairs\n",
    "#         nan_pairs = np.isnan(data_timeavg_output_0[:, i]) | np.isnan(data_timeavg_output_1[:, i])\n",
    "#         nan_count = np.sum(nan_pairs)\n",
    "#         nan_counts.append(nan_count)\n",
    "        \n",
    "#         # Remove NaN pairs for valid comparison\n",
    "#         valid_indices = ~nan_pairs\n",
    "#         if np.sum(valid_indices) > 1:  # Ensure there are at least two valid pairs for comparison\n",
    "#             t_stat, p_value = stats.ttest_rel(data_timeavg_output_0[valid_indices, i],\n",
    "#                                               data_timeavg_output_1[valid_indices, i])\n",
    "#             t_stats.append(t_stat)\n",
    "#             p_values.append(p_value)\n",
    "#         else:\n",
    "#             # Append NaNs if not enough data points for a valid test\n",
    "#             t_stats.append(np.nan)\n",
    "#             p_values.append(np.nan)\n",
    "\n",
    "#     # Apply FDR correction\n",
    "#     _, p_vals_adj, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "#     # Print out the number of NaN pairs for each electrode\n",
    "#     for i, count in enumerate(nan_counts):\n",
    "#         print(f\"Electrode {i+1} had {count} NaN pairs excluded from analysis.\")\n",
    "\n",
    "#     return p_vals_adj, np.array(p_values), np.array(t_stats), np.array(nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Electrode 1 had 42 NaN pairs excluded from analysis.\n",
      "Electrode 2 had 28 NaN pairs excluded from analysis.\n",
      "Electrode 3 had 20 NaN pairs excluded from analysis.\n",
      "Electrode 4 had 24 NaN pairs excluded from analysis.\n",
      "Electrode 5 had 22 NaN pairs excluded from analysis.\n",
      "Electrode 6 had 64 NaN pairs excluded from analysis.\n",
      "Electrode 7 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 8 had 64 NaN pairs excluded from analysis.\n",
      "Electrode 9 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 10 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 11 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 12 had 121 NaN pairs excluded from analysis.\n",
      "Electrode 13 had 20 NaN pairs excluded from analysis.\n",
      "Electrode 14 had 21 NaN pairs excluded from analysis.\n",
      "Electrode 15 had 55 NaN pairs excluded from analysis.\n",
      "Electrode 16 had 21 NaN pairs excluded from analysis.\n",
      "Electrode 17 had 23 NaN pairs excluded from analysis.\n",
      "Electrode 18 had 132 NaN pairs excluded from analysis.\n",
      "Electrode 19 had 79 NaN pairs excluded from analysis.\n",
      "Electrode 20 had 79 NaN pairs excluded from analysis.\n",
      "Electrode 21 had 79 NaN pairs excluded from analysis.\n",
      "Electrode 22 had 79 NaN pairs excluded from analysis.\n",
      "Electrode 1 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 2 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 3 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 4 had 63 NaN pairs excluded from analysis.\n",
      "Electrode 5 had 133 NaN pairs excluded from analysis.\n",
      "Electrode 6 had 79 NaN pairs excluded from analysis.\n",
      "Electrode 1 had 38 NaN pairs excluded from analysis.\n",
      "Electrode 2 had 39 NaN pairs excluded from analysis.\n",
      "Electrode 3 had 39 NaN pairs excluded from analysis.\n",
      "Electrode 4 had 20 NaN pairs excluded from analysis.\n",
      "Electrode 5 had 20 NaN pairs excluded from analysis.\n",
      "Electrode 6 had 24 NaN pairs excluded from analysis.\n",
      "Electrode 7 had 29 NaN pairs excluded from analysis.\n",
      "Electrode 8 had 91 NaN pairs excluded from analysis.\n",
      "Electrode 9 had 93 NaN pairs excluded from analysis.\n",
      "Electrode 10 had 89 NaN pairs excluded from analysis.\n",
      "Electrode 11 had 89 NaN pairs excluded from analysis.\n",
      "Electrode 12 had 90 NaN pairs excluded from analysis.\n",
      "Electrode 13 had 89 NaN pairs excluded from analysis.\n"
     ]
    }
   ],
   "source": [
    "# old code as of 2/6\n",
    "# # Perform the analysis for DLPFC\n",
    "# p_vals_adj_dlpfc, p_vals_dlpfc, t_stats_dlpfc, nan_pairs = perform_analysis_and_fdr_correction(output_0_data_timeAvg_dlpfc, output_1_data_timeAvg_dlpfc)\n",
    "\n",
    "# # Perform the analysis for ACC\n",
    "# p_vals_adj_acc, p_vals_acc, t_stats_acc, nan_pairs = perform_analysis_and_fdr_correction(output_0_data_timeAvg_acc, output_1_data_timeAvg_acc)\n",
    "\n",
    "# # Perform the analysis for parietal\n",
    "# p_vals_adj_parietal, p_vals_parietal, t_stats_parietal, nan_pairs = perform_analysis_and_fdr_correction(output_0_data_timeAvg_parietal, output_1_data_timeAvg_parietal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Data arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m output_1_data \u001b[38;5;241m=\u001b[39m concatenated_data[roi][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Perform the analysis\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m p_vals_adj, unadj_p_vals, t_stats, nan_counts \u001b[38;5;241m=\u001b[39m \u001b[43mperform_analysis_and_fdr_correction\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_0_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_1_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Store the results in the dictionary\u001b[39;00m\n\u001b[0;32m     20\u001b[0m result_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_window\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m, in \u001b[0;36mperform_analysis_and_fdr_correction\u001b[1;34m(data_timeavg_output_0, data_timeavg_output_1)\u001b[0m\n\u001b[0;32m     25\u001b[0m nan_counts \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# To store the count of NaN pairs for each electrode\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Ensure input data dimensions match\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data_timeavg_output_0\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m data_timeavg_output_1\u001b[38;5;241m.\u001b[39mshape, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData arrays must have the same shape\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Perform paired t-test for each electrode, ignoring NaNs\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(data_timeavg_output_0\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):  \u001b[38;5;66;03m# Iterate over electrodes\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Identify NaN pairs\u001b[39;00m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Data arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "# # Define a dictionary to store the analysis results for easy access\n",
    "# analysis_results = {}\n",
    "\n",
    "# # Iterate over each roi and time window to perform the analysis\n",
    "# for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "#     for time_window, concatenated_data in [\n",
    "#         ('firstHalfSecond', concatenated_timeAvg_firstHalfSecond_data),\n",
    "#         ('secondHalfSecond', concatenated_timeAvg_secondHalfSecond_data),\n",
    "#         ('fullSecond', concatenated_timeAvg_fullSecond_data)\n",
    "#     ]:\n",
    "#         # Check if the roi has data for the current time window\n",
    "#         if roi in concatenated_data:\n",
    "#             output_0_data = concatenated_data[roi]['output_0']\n",
    "#             output_1_data = concatenated_data[roi]['output_1']\n",
    "            \n",
    "#             # Perform the analysis\n",
    "#             p_vals_adj, unadj_p_vals, t_stats, nan_counts = perform_analysis_and_fdr_correction(output_0_data, output_1_data)\n",
    "            \n",
    "#             # Store the results in the dictionary\n",
    "#             result_key = f\"{roi}_{time_window}\"\n",
    "#             analysis_results[result_key] = {\n",
    "#                 'p_vals_adj': p_vals_adj,\n",
    "#                 'unadj_p_vals': unadj_p_vals,\n",
    "#                 't_stats': t_stats,\n",
    "#                 'nan_counts': nan_counts\n",
    "#             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for ROI: dlpfc\n",
      "----------------------\n",
      "Time Window: firstHalfSecond\n",
      "Electrode Names: LFAM8, LFAM9, LAI13, LAI14\n",
      "Adjusted p-values: [0.53085508 0.53085508 0.92322281 0.53085508 0.57536847 0.92322281\n",
      " 0.57334206 0.98331877 0.53085508 0.92322281 0.53085508 0.63325222\n",
      " 0.92322281 0.91270669 0.92322281 0.92322281 0.30677918 0.92322281\n",
      " 0.94758699 0.57334206 0.92322281 0.53085508]\n",
      "Unadjusted p-values: [0.16890843 0.15802348 0.78193704 0.07506122 0.26153112 0.60183525\n",
      " 0.22189781 0.98331877 0.08868245 0.79391668 0.13339533 0.31662611\n",
      " 0.8351666  0.49784001 0.76187148 0.83929346 0.01394451 0.73185498\n",
      " 0.90451485 0.23454902 0.72857267 0.09995098]\n",
      "T-statistics: [-1.38123857  1.41718879  0.27716292 -1.78946139 -1.12594555 -0.52280853\n",
      "  1.22627248 -0.02094126 -1.71282162  0.26166446 -1.50851319  1.00635527\n",
      "  0.20834742  0.67911875 -0.30351696 -0.20305881 -2.48052403 -0.34371307\n",
      " -0.12017143 -1.19372342 -0.34770072 -1.65574567]\n",
      "NaN counts: [ 42  28  20  24  22  64  63  64  63  63  63 121  20  21  55  21  23 132\n",
      "  79  79  79  79]\n",
      "\n",
      "Time Window: secondHalfSecond\n",
      "Electrode Names: LFAM8, LFAM9, LAI13, LAI14\n",
      "Adjusted p-values: [5.63823785e-02 7.77079358e-01 7.91093783e-01 4.61684834e-02\n",
      " 2.28640447e-04 6.25676554e-01 5.63823785e-02 3.60929565e-01\n",
      " 3.37534251e-01 3.42806041e-01 1.19154051e-01 3.42806041e-01\n",
      " 7.77079358e-01 8.23431765e-01 6.44196595e-01 8.23431765e-01\n",
      " 5.63823785e-02 7.77079358e-01 9.18813503e-01 4.32401354e-01\n",
      " 4.80264344e-04 2.28640447e-04]\n",
      "Unadjusted p-values: [1.56083642e-02 6.08883589e-01 6.83217358e-01 8.39426971e-03\n",
      " 1.44143674e-05 3.98157807e-01 1.79398477e-02 1.96870672e-01\n",
      " 1.38082193e-01 1.62970936e-01 4.33287460e-02 1.71403021e-01\n",
      " 6.07212109e-01 7.86003048e-01 4.39224951e-01 7.69251944e-01\n",
      " 1.32232133e-02 6.35792202e-01 9.18813503e-01 2.55509891e-01\n",
      " 6.54905924e-05 2.07854952e-05]\n",
      "T-statistics: [-2.44101889 -0.51249649 -0.40866355 -2.66235009 -4.44670032 -0.84719866\n",
      "  2.39151513 -1.29595025 -1.49042149 -1.40160216 -2.03669841  1.37740192\n",
      "  0.5148584  -0.27186557 -0.77534649 -0.29374816 -2.49999887 -0.47518709\n",
      "  0.10210736 -1.14161268 -4.11261034 -4.40176298]\n",
      "NaN counts: [ 42  28  20  24  22  64  63  64  63  63  63 121  20  21  55  21  23 132\n",
      "  79  79  79  79]\n",
      "\n",
      "Time Window: fullSecond\n",
      "Electrode Names: LFAM8, LFAM9, LAI13, LAI14\n",
      "Adjusted p-values: [0.03760347 0.80101551 0.93406334 0.02477688 0.00346324 0.68944826\n",
      " 0.08740786 0.68944826 0.11351532 0.70678716 0.08740786 0.3005803\n",
      " 0.80101551 0.85570836 0.70678716 0.85570836 0.03110976 0.80101551\n",
      " 0.99850805 0.32456739 0.03040338 0.00105655]\n",
      "Unadjusted p-values: [1.02554915e-02 6.55376330e-01 8.91605913e-01 3.37866549e-03\n",
      " 3.14840173e-04 3.86651764e-01 3.17846762e-02 4.07401245e-01\n",
      " 4.64380862e-02 4.75290710e-01 2.84552370e-02 1.36627410e-01\n",
      " 6.30565950e-01 7.76000037e-01 4.81900335e-01 7.77916691e-01\n",
      " 7.07039941e-03 6.43545957e-01 9.98508048e-01 1.62283693e-01\n",
      " 5.52788679e-03 4.80252242e-05]\n",
      "T-statistics: [-2.59427323e+00  4.46992791e-01 -1.36443489e-01 -2.96671678e+00\n",
      " -3.66640819e+00 -8.68093003e-01  2.16609004e+00 -8.30677841e-01\n",
      " -2.00695850e+00 -7.15584840e-01 -2.21098387e+00  1.50029377e+00\n",
      "  4.81660538e-01  2.84916465e-01 -7.04816614e-01 -2.82412104e-01\n",
      " -2.72157390e+00 -4.64294041e-01  1.87313421e-03 -1.40463341e+00\n",
      " -2.81703896e+00 -4.19211419e+00]\n",
      "NaN counts: [ 42  28  20  24  22  64  63  64  63  63  63 121  20  21  55  21  23 132\n",
      "  79  79  79  79]\n",
      "\n",
      "Results for ROI: acc\n",
      "----------------------\n",
      "Time Window: firstHalfSecond\n",
      "Electrode Names: LFAM3\n",
      "Adjusted p-values: [0.7985672  0.81575738 0.7985672  0.7985672  0.92978811 0.7985672 ]\n",
      "Unadjusted p-values: [0.44852362 0.67979781 0.36729756 0.22800652 0.92978811 0.53237813]\n",
      "T-statistics: [-0.7597473  -0.41349479  0.9041077  -1.21014898  0.08835843 -0.6258896 ]\n",
      "NaN counts: [ 63  63  63  63 133  79]\n",
      "\n",
      "Time Window: secondHalfSecond\n",
      "Electrode Names: LFAM3\n",
      "Adjusted p-values: [0.36876173 0.36876173 0.95924228 0.36876173 0.36876173 0.37050686]\n",
      "Unadjusted p-values: [0.08108894 0.20283444 0.95924228 0.23785575 0.24584116 0.30875572]\n",
      "T-statistics: [-1.75549187 -1.2787566  -0.05118458  1.18479407 -1.16812573 -1.02144692]\n",
      "NaN counts: [ 63  63  63  63 133  79]\n",
      "\n",
      "Time Window: fullSecond\n",
      "Electrode Names: LFAM3\n",
      "Adjusted p-values: [0.47681127 0.51519959 0.69989413 0.98442289 0.61320089 0.51519959]\n",
      "Unadjusted p-values: [0.07946855 0.2575998  0.58324511 0.98442289 0.40880059 0.233259  ]\n",
      "T-statistics: [-1.76501806 -1.13613293  0.54976797  0.0195548  -0.82988338 -1.19703713]\n",
      "NaN counts: [ 63  63  63  63 133  79]\n",
      "\n",
      "Results for ROI: parietal\n",
      "----------------------\n",
      "Time Window: firstHalfSecond\n",
      "Electrode Names: \n",
      "Adjusted p-values: [0.98706162 0.13279348 0.33915204 0.71292417 0.53764409 0.33915204\n",
      " 0.71292417 0.89894007 0.99348158 0.95827193 0.76398701 0.99348158\n",
      " 0.98706162]\n",
      "Unadjusted p-values: [0.79400677 0.01021488 0.05296993 0.32326353 0.16542895 0.07826586\n",
      " 0.32904192 0.55319389 0.98537053 0.66341903 0.41137762 0.99348158\n",
      " 0.83520599]\n",
      "T-statistics: [ 0.26148841  2.59524062  1.9477213  -0.99018283 -1.39205492 -1.7699555\n",
      "  0.97850769  0.59450221 -0.01837166 -0.43616485 -0.82404621 -0.00818509\n",
      " -0.20843479]\n",
      "NaN counts: [38 39 39 20 20 24 29 91 93 89 89 90 89]\n",
      "\n",
      "Time Window: secondHalfSecond\n",
      "Electrode Names: \n",
      "Adjusted p-values: [0.16522037 0.07400902 0.19707915 0.90352792 0.7776014  0.54119039\n",
      " 0.77289866 0.16522037 0.77289866 0.90352792 0.65298662 0.16522037\n",
      " 0.16522037]\n",
      "Unadjusted p-values: [0.05813917 0.005693   0.09095961 0.90352792 0.65797041 0.29141021\n",
      " 0.59453743 0.05240458 0.55425583 0.89584585 0.40183792 0.03991988\n",
      " 0.0635463 ]\n",
      "T-statistics: [ 1.90647055  2.79779383  1.69926312 -0.1213575  -0.44336983 -1.05784128\n",
      "  0.53315369 -1.95744952  0.59293335 -0.1311595  -0.84101478  2.07493607\n",
      "  1.87085381]\n",
      "NaN counts: [38 39 39 20 20 24 29 91 93 89 89 90 89]\n",
      "\n",
      "Time Window: fullSecond\n",
      "Electrode Names: \n",
      "Adjusted p-values: [0.32762129 0.00294243 0.10967528 0.65059437 0.4456649  0.32762129\n",
      " 0.56163745 0.4456649  0.73025007 0.73025007 0.4456649  0.32762129\n",
      " 0.4456649 ]\n",
      "Unadjusted p-values: [1.26008189e-01 2.26340938e-04 1.68731201e-02 5.50502928e-01\n",
      " 3.08537237e-01 9.76068599e-02 4.32028809e-01 2.38906567e-01\n",
      " 6.74500889e-01 7.30250070e-01 3.05178566e-01 1.11989982e-01\n",
      " 2.74917835e-01]\n",
      "T-statistics: [ 1.53697412  3.76210501  2.41143416 -0.59800536 -1.02085701 -1.66439706\n",
      "  0.78736551 -1.18307318  0.42093052 -0.34551363 -1.02933093  1.5999162\n",
      "  1.09629086]\n",
      "NaN counts: [38 39 39 20 20 24 29 91 93 89 89 90 89]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# electrode_names_per_roi = {\n",
    "#     'dlpfc': sig_dlpfc_electrodes_per_subject[sub],\n",
    "#     'acc': sig_acc_electrodes_per_subject[sub],\n",
    "#     'parietal': sig_parietal_electrodes_per_subject[sub]\n",
    "# }\n",
    "\n",
    "# # Adjust the script to print electrode names along with the results\n",
    "# for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "#     print(f\"Results for ROI: {roi}\\n----------------------\")\n",
    "#     # Retrieve electrode names for the current ROI\n",
    "#     electrode_names = electrode_names_per_roi.get(roi, [])\n",
    "#     for time_window in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']:\n",
    "#         key = f\"{roi}_{time_window}\"\n",
    "#         if key in analysis_results:\n",
    "#             results = analysis_results[key]\n",
    "#             print(f\"Time Window: {time_window}\")\n",
    "#             print(f\"Electrode Names: {', '.join(electrode_names)}\")\n",
    "#             print(f\"Adjusted p-values: {results['p_vals_adj']}\")\n",
    "#             print(f\"Unadjusted p-values: {results['unadj_p_vals']}\")\n",
    "#             print(f\"T-statistics: {results['t_stats']}\")\n",
    "#             print(f\"NaN counts: {results['nan_counts']}\\n\")\n",
    "#         else:\n",
    "#             print(f\"Time Window: {time_window} - No data\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot and QC stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if no significant differences.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSignificance (0 or 1)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPermutation Test Significance Over Time\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3448\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3446\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3448\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:593\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    591\u001b[0m qapp \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m--> 593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_maybe_allow_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqt_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:230\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    228\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_perm_cluster_results['dlpfc'])\n",
    "plt.xlabel('Timepoints')\n",
    "plt.ylabel('Significance (0 or 1)')\n",
    "plt.title('Permutation Test Significance Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot dlpfc inc vs. con, avg across all subjects (or whatever conditions you wanna compare, just use the proper output names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlpfc  \n",
    "use blue and orange for congruent and incongruent  \n",
    "red and green for repeat and switch\n",
    "# ONLY RUN EITHER SWITCHINESS OR CONGRUENCY!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### switchiness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is vs ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim([min_val, max_val])\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(save_path)  \u001b[38;5;66;03m# Modify save_dir as necessary\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3448\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3446\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3448\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:593\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    591\u001b[0m qapp \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m--> 593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_maybe_allow_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqt_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:230\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    228\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlpfc_ISvsIR_zscore_test.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0057_c = subjects_mne_objects['D0057'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "output_0_avg = overall_averages['dlpfc']['output_0']\n",
    "output_1_avg = overall_averages['dlpfc']['output_1']\n",
    "output_0_sem = overall_sems['dlpfc']['output_0']\n",
    "output_1_sem = overall_sems['dlpfc']['output_1']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the range of your data including SEM for better y-axis limits\n",
    "min_val = min(output_0_avg.min() - output_0_sem.max(),\n",
    "              output_1_avg.min() - output_1_sem.max())\n",
    "\n",
    "max_val = max(output_0_avg.max() + output_0_sem.max(),\n",
    "              output_1_avg.max() + output_1_sem.max())\n",
    "\n",
    "# Optionally, add a small margin to the range\n",
    "margin = (max_val - min_val) * 0.05  # 5% of the range as margin\n",
    "min_val -= margin\n",
    "max_val += margin\n",
    "\n",
    "# Your existing plotting code\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, output_0_avg, label='Average dlpfc inc repeat ', color='red')\n",
    "plt.fill_between(times, output_0_avg - output_0_sem, \n",
    "                 output_0_avg + output_0_sem, alpha=0.3, color='red')\n",
    "plt.plot(times, output_1_avg, label='Average dlpfc inc switch', color='green')\n",
    "plt.fill_between(times, output_1_avg - output_1_sem, \n",
    "                 output_1_avg + output_1_sem, alpha=0.3, color='green')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlpfc Signal with Standard Error (inc switch vs inc repeat)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the y-axis limits\n",
    "plt.ylim([min_val, max_val])\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cs vs cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim([min_val, max_val])\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(save_path)  \u001b[38;5;66;03m# Modify save_dir as necessary\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3448\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3446\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3448\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:593\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    591\u001b[0m qapp \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m--> 593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_maybe_allow_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqt_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:230\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    228\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlpfc_CSvsCR_zscore_test.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0057_c = subjects_mne_objects['D0057'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "output_0_avg = overall_averages['dlpfc']['output_0']\n",
    "output_1_avg = overall_averages['dlpfc']['output_1']\n",
    "output_0_sem = overall_sems['dlpfc']['output_0']\n",
    "output_1_sem = overall_sems['dlpfc']['output_1']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the range of your data including SEM for better y-axis limits\n",
    "min_val = min(output_0_avg.min() - output_0_sem.max(),\n",
    "              output_1_avg.min() - output_1_sem.max())\n",
    "\n",
    "max_val = max(output_0_avg.max() + output_0_sem.max(),\n",
    "              output_1_avg.max() + output_1_sem.max())\n",
    "\n",
    "# Optionally, add a small margin to the range\n",
    "margin = (max_val - min_val) * 0.05  # 5% of the range as margin\n",
    "min_val -= margin\n",
    "max_val += margin\n",
    "\n",
    "# Your existing plotting code\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, output_0_avg, label='Average dlpfc con repeat ', color='red')\n",
    "plt.fill_between(times, output_0_avg - output_0_sem, \n",
    "                 output_0_avg + output_0_sem, alpha=0.3, color='red')\n",
    "plt.plot(times, output_1_avg, label='Average dlpfc con switch', color='green')\n",
    "plt.fill_between(times, output_1_avg - output_1_sem, \n",
    "                 output_1_avg + output_1_sem, alpha=0.3, color='green')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlpfc Signal with Standard Error (con switch vs con repeat)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the y-axis limits\n",
    "plt.ylim([min_val, max_val])\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "s vs r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim([min_val, max_val])\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(save_path)  \u001b[38;5;66;03m# Modify save_dir as necessary\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3448\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3446\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3448\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:593\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    591\u001b[0m qapp \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m--> 593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_maybe_allow_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqt_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:230\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    228\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlpfc_switchiness_zscore_test.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0057_c = subjects_mne_objects['D0057'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "output_0_avg = overall_averages['dlpfc']['output_0']\n",
    "output_1_avg = overall_averages['dlpfc']['output_1']\n",
    "output_0_sem = overall_sems['dlpfc']['output_0']\n",
    "output_1_sem = overall_sems['dlpfc']['output_1']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the range of your data including SEM for better y-axis limits\n",
    "min_val = min(output_0_avg.min() - output_0_sem.max(),\n",
    "              output_1_avg.min() - output_1_sem.max())\n",
    "\n",
    "max_val = max(output_0_avg.max() + output_0_sem.max(),\n",
    "              output_1_avg.max() + output_1_sem.max())\n",
    "\n",
    "# Optionally, add a small margin to the range\n",
    "margin = (max_val - min_val) * 0.05  # 5% of the range as margin\n",
    "min_val -= margin\n",
    "max_val += margin\n",
    "\n",
    "# Your existing plotting code\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, output_0_avg, label='Average dlpfc repeat', color='red')\n",
    "plt.fill_between(times, output_0_avg - output_0_sem, \n",
    "                 output_0_avg + output_0_sem, alpha=0.3, color='red')\n",
    "plt.plot(times, output_1_avg, label='Average dlpfc switch', color='green')\n",
    "plt.fill_between(times, output_1_avg - output_1_sem, \n",
    "                 output_1_avg + output_1_sem, alpha=0.3, color='green')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlpfc Signal with Standard Error (switch vs repeat)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the y-axis limits\n",
    "plt.ylim([min_val, max_val])\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### congruency  \n",
    "add y lim to make the sem centered around the mean, can do this for other plots too if they look weird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inc-repeat vs con-repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim([min_val, max_val])\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(save_path)  \u001b[38;5;66;03m# Modify save_dir as necessary\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3448\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3446\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3448\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:593\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    591\u001b[0m qapp \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m--> 593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_maybe_allow_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqt_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:230\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    228\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlpfc_IRvsCR_zscore_test.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "output_0_avg = overall_averages['dlpfc']['output_0']\n",
    "output_1_avg = overall_averages['dlpfc']['output_1']\n",
    "output_0_sem = overall_sems['dlpfc']['output_0']\n",
    "output_1_sem = overall_sems['dlpfc']['output_1']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the range of your data including SEM for better y-axis limits\n",
    "min_val = min(output_0_avg.min() - output_0_sem.max(),\n",
    "              output_1_avg.min() - output_1_sem.max())\n",
    "\n",
    "max_val = max(output_0_avg.max() + output_0_sem.max(),\n",
    "              output_1_avg.max() + output_1_sem.max())\n",
    "\n",
    "# Optionally, add a small margin to the range\n",
    "margin = (max_val - min_val) * 0.05  # 5% of the range as margin\n",
    "min_val -= margin\n",
    "max_val += margin\n",
    "\n",
    "# Your existing plotting code\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, output_0_avg, label='Average dlpfc con repeat', color='blue')\n",
    "plt.fill_between(times, output_0_avg - output_0_sem, \n",
    "                 output_0_avg + output_0_sem, alpha=0.3, color='blue')\n",
    "plt.plot(times, output_1_avg, label='Average dlpfc inc repeat', color='orange')\n",
    "plt.fill_between(times, output_1_avg - output_1_sem, \n",
    "                 output_1_avg + output_1_sem, alpha=0.3, color='orange')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlpfc Signal with Standard Error (inc repeat vs con repeat)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the y-axis limits\n",
    "plt.ylim([min_val, max_val])\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inc-switch vs con-switch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim([min_val, max_val])\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(save_path)  \u001b[38;5;66;03m# Modify save_dir as necessary\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3448\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3446\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3448\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:593\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    591\u001b[0m qapp \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m--> 593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_maybe_allow_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqt_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:230\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    228\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlpfc_ISvsCS_zscore_test.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "output_0_avg = overall_averages['dlpfc']['output_0']\n",
    "output_1_avg = overall_averages['dlpfc']['output_1']\n",
    "output_0_sem = overall_sems['dlpfc']['output_0']\n",
    "output_1_sem = overall_sems['dlpfc']['output_1']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the range of your data including SEM for better y-axis limits\n",
    "min_val = min(output_0_avg.min() - output_0_sem.max(),\n",
    "              output_1_avg.min() - output_1_sem.max())\n",
    "\n",
    "max_val = max(output_0_avg.max() + output_0_sem.max(),\n",
    "              output_1_avg.max() + output_1_sem.max())\n",
    "\n",
    "# Optionally, add a small margin to the range\n",
    "margin = (max_val - min_val) * 0.05  # 5% of the range as margin\n",
    "min_val -= margin\n",
    "max_val += margin\n",
    "\n",
    "# Your existing plotting code\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, output_0_avg, label='Average dlpfc con switch', color='blue')\n",
    "plt.fill_between(times, output_0_avg - output_0_sem, \n",
    "                 output_0_avg + output_0_sem, alpha=0.3, color='blue')\n",
    "plt.plot(times, output_1_avg, label='Average dlpfc inc switch', color='orange')\n",
    "plt.fill_between(times, output_1_avg - output_1_sem, \n",
    "                 output_1_avg + output_1_sem, alpha=0.3, color='orange')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlpfc Signal with Standard Error (inc switch vs con switch)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the y-axis limits\n",
    "plt.ylim([min_val, max_val])\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inc vs con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[180], line 52\u001b[0m\n\u001b[0;32m     50\u001b[0m plt\u001b[38;5;241m.\u001b[39mylim([min_val, max_val])\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(save_path)  \u001b[38;5;66;03m# Modify save_dir as necessary\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3448\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3446\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m-> 3448\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:593\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    591\u001b[0m qapp \u001b[38;5;241m=\u001b[39m QtWidgets\u001b[38;5;241m.\u001b[39mQApplication\u001b[38;5;241m.\u001b[39minstance()\n\u001b[0;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m--> 593\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_maybe_allow_interrupt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mqt_compat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqapp\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:230\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    228\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlpfc_congruency_zscore_test.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "output_0_avg = overall_averages['dlpfc']['output_0']\n",
    "output_1_avg = overall_averages['dlpfc']['output_1']\n",
    "output_0_sem = overall_sems['dlpfc']['output_0']\n",
    "output_1_sem = overall_sems['dlpfc']['output_1']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Determine the range of your data including SEM for better y-axis limits\n",
    "min_val = min(output_0_avg.min() - output_0_sem.max(),\n",
    "              output_1_avg.min() - output_1_sem.max())\n",
    "\n",
    "max_val = max(output_0_avg.max() + output_0_sem.max(),\n",
    "              output_1_avg.max() + output_1_sem.max())\n",
    "\n",
    "# Optionally, add a small margin to the range\n",
    "margin = (max_val - min_val) * 0.05  # 5% of the range as margin\n",
    "min_val -= margin\n",
    "max_val += margin\n",
    "\n",
    "# Your existing plotting code\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(times, output_0_avg, label='Average dlpfc congruent', color='blue')\n",
    "plt.fill_between(times, output_0_avg - output_0_sem, \n",
    "                 output_0_avg + output_0_sem, alpha=0.3, color='blue')\n",
    "plt.plot(times, output_1_avg, label='Average dlpfc incongruent', color='orange')\n",
    "plt.fill_between(times, output_1_avg - output_1_sem, \n",
    "                 output_1_avg + output_1_sem, alpha=0.3, color='orange')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlpfc Signal with Standard Error (inc vs con)')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust the y-axis limits\n",
    "plt.ylim([min_val, max_val])\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switchiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_acc_switchRepeat_zscore.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "\n",
    "# Plot overall_average_acc of the 0th output with SEM shading\n",
    "plt.plot(times, overall_average_acc_output_0, label='Average acc repeat', color='red')\n",
    "plt.fill_between(times, overall_average_acc_output_0 - overall_sem_acc_output_0, \n",
    "                 overall_average_acc_output_0 + overall_sem_acc_output_0, alpha=0.3, color='red')\n",
    "\n",
    "# Plot overall_average_dlpfc of the 1st output with SEM shading\n",
    "plt.plot(times, overall_average_acc_output_1, label='Average acc switch', color='green')\n",
    "plt.fill_between(times, overall_average_acc_output_1 - overall_sem_acc_output_1, \n",
    "                 overall_average_acc_output_1 + overall_sem_acc_output_1, alpha=0.3, color='green')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average acc Signal with Standard Error (switch vs repeat)')\n",
    "plt.legend()\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_acc_congruency_zscore.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "\n",
    "# Plot overall_average_acc of the 0th output with SEM shading\n",
    "plt.plot(times, overall_average_acc_output_0, label='Average acc congruent', color='blue')\n",
    "plt.fill_between(times, overall_average_acc_output_0 - overall_sem_acc_output_0, \n",
    "                 overall_average_acc_output_0 + overall_sem_acc_output_0, alpha=0.3, color='blue')\n",
    "\n",
    "# Plot overall_average_dlpfc of the 1st output with SEM shading\n",
    "plt.plot(times, overall_average_acc_output_1, label='Average acc incongruent', color='orange')\n",
    "plt.fill_between(times, overall_average_acc_output_1 - overall_sem_acc_output_1, \n",
    "                 overall_average_acc_output_1 + overall_sem_acc_output_1, alpha=0.3, color='orange')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average acc Signal with Standard Error (inc vs con)')\n",
    "plt.legend()\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parietal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switchiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_parietal_switchRepeat_zscore.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "\n",
    "# Plot overall_average_acc of the 0th output with SEM shading\n",
    "plt.plot(times, overall_average_parietal_output_0, label='Average parietal repeat', color='red')\n",
    "plt.fill_between(times, overall_average_parietal_output_0 - overall_sem_parietal_output_0, \n",
    "                 overall_average_parietal_output_0 + overall_sem_parietal_output_0, alpha=0.3, color='red')\n",
    "\n",
    "# Plot overall_average_dlpfc of the 1st output with SEM shading\n",
    "plt.plot(times, overall_average_parietal_output_1, label='Average parietal switch', color='green')\n",
    "plt.fill_between(times, overall_average_parietal_output_1 - overall_sem_parietal_output_1, \n",
    "                 overall_average_parietal_output_1 + overall_sem_parietal_output_1, alpha=0.3, color='green')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average parietal Signal with Standard Error (switch vs repeat)')\n",
    "plt.legend()\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_parietal_congruency_zscore.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "\n",
    "# Plot overall_average_acc of the 0th output with SEM shading\n",
    "plt.plot(times, overall_average_parietal_output_0, label='Average parietal congruent', color='blue')\n",
    "plt.fill_between(times, overall_average_parietal_output_0 - overall_sem_parietal_output_0, \n",
    "                 overall_average_parietal_output_0 + overall_sem_parietal_output_0, alpha=0.3, color='blue')\n",
    "\n",
    "# Plot overall_average_dlpfc of the 1st output with SEM shading\n",
    "plt.plot(times, overall_average_parietal_output_1, label='Average parietal incongruent', color='orange')\n",
    "plt.fill_between(times, overall_average_parietal_output_1 - overall_sem_parietal_output_1, \n",
    "                 overall_average_parietal_output_1 + overall_sem_parietal_output_1, alpha=0.3, color='orange')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average parietal Signal with Standard Error (inc vs con)')\n",
    "plt.legend()\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot individual electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "LAB_root = None\n",
    "channels = None\n",
    "full_trial_base = False\n",
    "\n",
    "\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    if os.name == 'nt':  # windows\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "    else:  # mac\n",
    "        LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                \"CoganLab\")\n",
    "\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "\n",
    "firstColor, secondColor= 'red', 'green' #switchiness\n",
    "# firstColor, secondColor= 'blue', 'orange' #congruency\n",
    "\n",
    "def plot_electrodes_grid(electrodes_data, grid_num, save_dir, roi, output_names, times, firstColor, secondColor):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        ax.plot(times, data['output_0'], label=f'{roi} {output_names[0]}', color=firstColor)\n",
    "        ax.fill_between(times, \n",
    "                        data['output_0'] - np.std(data['output_0'], ddof=1) / np.sqrt(len(data['output_0'])),\n",
    "                        data['output_0'] + np.std(data['output_0'], ddof=1) / np.sqrt(len(data['output_0'])), alpha=0.3)\n",
    "        ax.plot(times, data['output_1'], label=f'{roi} {output_names[1]}', color=secondColor)\n",
    "        ax.fill_between(times, \n",
    "                        data['output_1'] - np.std(data['output_1'], ddof=1) / np.sqrt(len(data['output_1'])),\n",
    "                        data['output_1'] + np.std(data['output_1'], ddof=1) / np.sqrt(len(data['output_1'])), alpha=0.3)\n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Z-score')\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{output_names[0]}_{output_names[1]}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Example Usage\n",
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'dlpfc'\n",
    "\n",
    "# DUDE MAKE THE SIG ELECTRODES PER SUBJECT INTO A DICTIONARY. Bad code is bad.\n",
    "for sub in subjects:\n",
    "    if sub in sig_dlpfc_electrodes_per_subject:\n",
    "        for electrode in sig_dlpfc_electrodes_per_subject[sub]:\n",
    "            electrode_data = {\n",
    "                'output_0': concatenated_trialAvg_data[roi]['output_0'][electrode_counter],\n",
    "                'output_1': concatenated_trialAvg_data[roi]['output_1'][electrode_counter]\n",
    "            }\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid(electrodes_data, grid_num, save_dir, roi, output_names, times, firstColor, secondColor)\n",
    "                \n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid(electrodes_data, grid_num, save_dir, 'dlPFC', output_names, times, firstColor, secondColor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "\n",
    "for sub in subjects:\n",
    "    if sub in sig_acc_electrodes_per_subject:\n",
    "        for electrode in sig_acc_electrodes_per_subject[sub]:\n",
    "            electrode_data = {\n",
    "                'output_0': output_0_data_trialAvg_acc[electrode_counter],\n",
    "                'output_1': output_1_data_trialAvg_acc[electrode_counter]\n",
    "            }\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid(electrodes_data, grid_num, save_dir, 'acc', output_names, times, firstColor, secondColor)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid(electrodes_data, grid_num, save_dir, 'acc', output_names, times, firstColor, secondColor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parietal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "\n",
    "for sub in subjects:\n",
    "    if sub in sig_parietal_electrodes_per_subject:\n",
    "        for electrode in sig_parietal_electrodes_per_subject[sub]:\n",
    "            electrode_data = {\n",
    "                'output_0': output_0_data_trialAvg_parietal[electrode_counter],\n",
    "                'output_1': output_1_data_trialAvg_parietal[electrode_counter]\n",
    "            }\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid(electrodes_data, grid_num, save_dir, 'parietal', output_names, times, firstColor, secondColor)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid(electrodes_data, grid_num, save_dir, 'parietal', output_names, times, firstColor, secondColor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
