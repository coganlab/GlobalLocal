{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### working version 12/1/23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try gregs suggestion of using make_data_same to destroy the fixation cross"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use window stats with perm testing (0 to 0.5, 0.5 to 1, 0 to 1 sec relative to stim onset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans, channel_names_to_indices, \\\n",
        "    filter_and_average_epochs, permutation_test, perform_permutation_test_across_electrodes, \\\n",
        "    perform_permutation_test_within_electrodes, add_accuracy_to_epochs, save_sig_chans_with_reject\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Directory where your .npy files are saved\n",
        "npy_directory = r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\accArrays'  # Replace with your directory path\n",
        "\n",
        "# Dictionary to hold the data\n",
        "acc_array = {}\n",
        "\n",
        "# Iterate over each file in the directory\n",
        "for file in os.listdir(npy_directory):\n",
        "    if file.endswith('.npy'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(npy_directory, file)\n",
        "        # Load the numpy array from the file\n",
        "        acc_array[file.split('_')[0]] = np.load(file_path)\n",
        "\n",
        "# Now you have a dictionary where each key is the subject ID\n",
        "# and the value is the numpy array of accuracies for that subject.\n",
        "        \n",
        "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')\n",
        "\n",
        "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "### after loading in HG_ev1_rescaled, then grab only the correct trials. Think I need to load in combined_data here too?\n",
        "### then load in the perm testing functions (put these into misc functions now that they work, and just load them into roi analysis and this too)\n",
        "###\n",
        "\n",
        "\n",
        "time_windows = {\n",
        "    \"Stimulus_fixationCrossBase_0.2sec_window_0to0.5\": (2048,3072), #do these based on the sample rate, so need to load in filt before looping over windows. Kind of annoying honestly.\n",
        "    \"Stimulus_fixationCrossBase_0.2sec_window_0.5to1\": (3072,4096),\n",
        "    \"Stimulus_fixationCrossBase_0.2sec_window_0to1\": (2048,4096)\n",
        "}\n",
        "\n",
        "for window in time_windows:\n",
        "    for sub in subjects:\n",
        "        start_idx, end_idx = int(time_windows[window][0]), int(time_windows[window][1]) # i think these need to be ints 2/27\n",
        "        task = 'GlobalLocal'\n",
        "        output_name = window #prob turn this into a function where i can set the window length as an input and it'll get added to the output name\n",
        "        events = [\"Stimulus\"]\n",
        "        times = (-1,1.5)\n",
        "        base_times = [-0.2,0]\n",
        "        LAB_root = None\n",
        "        channels = None\n",
        "        full_trial_base = False\n",
        "\n",
        "        if LAB_root is None:\n",
        "            HOME = os.path.expanduser(\"~\")\n",
        "            if os.name == 'nt':  # windows\n",
        "                LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "            else:  # mac\n",
        "                LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                        \"CoganLab\")\n",
        "\n",
        "        layout = get_data(task, root=LAB_root)\n",
        "        filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                            extension='.edf', desc='clean', preload=False)\n",
        "        # Access the sampling frequency\n",
        "        sampling_frequency = filt.info['sfreq']\n",
        "    \n",
        "        # Print the sampling frequency\n",
        "        print(f\"Subject {sub} has a sampling frequency of {sampling_frequency} Hz.\")\n",
        "        \n",
        "        save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "        if not os.path.exists(save_dir):\n",
        "            os.makedirs(save_dir)\n",
        "\n",
        "        good = crop_empty_data(filt)\n",
        "        # %%\n",
        "\n",
        "        print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "        print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "        good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "        print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "        filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "        good.drop_channels(good.info['bads'])\n",
        "\n",
        "        print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "        print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "        print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "        good.load_data()\n",
        "\n",
        "        # If channels is None, use all channels\n",
        "        if channels is None:\n",
        "            channels = good.ch_names\n",
        "        else:\n",
        "            # Validate the provided channels\n",
        "            invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "            if invalid_channels:\n",
        "                raise ValueError(\n",
        "                    f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "            # Use only the specified channels\n",
        "            good.pick_channels(channels)\n",
        "\n",
        "        ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "        good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "        # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "        adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "        outliers_to_nan(trials, outliers=10)\n",
        "        HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "        crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "        all_epochs_list = []\n",
        "\n",
        "        for event in events:\n",
        "        # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "            times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "            trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                                reject_by_annotation=False)\n",
        "            all_epochs_list.append(trials)\n",
        "\n",
        "        # Concatenate all trials\n",
        "        all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "        outliers_to_nan(all_trials, outliers=10)\n",
        "        HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "        print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "        crop_pad(HG_ev1, \"0.5s\")\n",
        "        print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "        ###\n",
        "        print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "        print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "        # sig1 = HG_ev1._data\n",
        "        # sig2 = HG_base._data\n",
        "        # sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "        # sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "        # sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "        # print(f\"Shape of sig1: {sig1.shape}\")\n",
        "        # print(f\"Shape of sig2: {sig2.shape}\")\n",
        "        # print(f\"Shape of sig3: {sig3.shape}\")\n",
        "        # print(f\"Shape of sig4: {sig4.shape}\")\n",
        "        # print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "        # sig2 = sig5\n",
        "        # # Directly reassign the modified signal data to the HG_base._data attribute (THIS MAY BREAK THINGS BUT ITS CORRECT 2/13)\n",
        "        # HG_base._data = sig2\n",
        "\n",
        "        ### filter for accurate trials in HG ev1 \n",
        "        # Build the filtering condition\n",
        "        sub_without_zeroes = \"D\" + sub[1:].lstrip('0') \n",
        "        sub_behavioral_rows = (combined_data['subject_ID'] == sub_without_zeroes) # this indexes using the subject without zeroes in the name. Confusing. I know.\n",
        "\n",
        "        # Filter combinedData for the specific subject and conditions\n",
        "        sub_behavioral_data = combined_data[sub_behavioral_rows]\n",
        "\n",
        "        if sub in acc_array:\n",
        "            trial_counts = sub_behavioral_data['trialCount'].values.astype(int)\n",
        "            accuracy_data = [acc_array[sub][i-1] for i in trial_counts if i-1 < len(acc_array[sub])] # Subtract 1 here for zero-based indexing in acc array.\n",
        "            \n",
        "            # Now pass trial_counts along with accuracy_data to raw HG_ev1\n",
        "            HG_ev1 = add_accuracy_to_epochs(HG_ev1, accuracy_data)\n",
        "            \n",
        "        # Separate accurate and all trials data\n",
        "        accurate_HG_ev1_data = HG_ev1[HG_ev1.metadata['accuracy'] == 1.0].get_data()\n",
        "        all_HG_ev1_data = HG_ev1.get_data().copy()\n",
        "\n",
        "        # Mark inaccurate trials as NaNs in the all_epochs_data\n",
        "        inaccurate_indices = HG_ev1.metadata['accuracy'] != 1.0\n",
        "        all_HG_ev1_data[inaccurate_indices, :, :] = np.nan\n",
        "        \n",
        "        # do stats stuff here. 2/22 I think we need to do this before we decimate.\n",
        "        # Calculate time average within the specified window\n",
        "        time_avg_signal = np.nanmean(all_HG_ev1_data[:, :, start_idx:end_idx], axis=2) #average across specified time window for data\n",
        "        time_avg_base = np.nanmean(HG_base.get_data().copy()[:,:,:], axis=2) #average across all time for baseline. Use a copy of the baseline so we don't mess it up.\n",
        "        p_values = perform_permutation_test_within_electrodes([time_avg_signal], [time_avg_base], one_tailed=True) #update these functions to not need list inputs later.\n",
        "        reject, p_values_adjusted = multipletests(p_values, alpha=0.05, method='fdr_bh')[:2] # reject is a boolean array of whether each channel passed significance threshold after adjusting for multiple comparisons. Adjusted_p_values are the actual adjusted p values.\n",
        "        # check p_values_adjusted after lab meeting! 2/13\n",
        "\n",
        "        HG_base.decimate(2)\n",
        "        HG_ev1.decimate(2)\n",
        "\n",
        "        HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "        HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "        HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "        HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "        HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        " \n",
        "        # Determine which channels are significant based on the reject array\n",
        "        channels = good.ch_names\n",
        "        save_sig_chans_with_reject(output_name, reject, channels, sub, save_dir)\n",
        "\n",
        "        #save all channels with their indices \n",
        "        save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "        # Save HG_ev1\n",
        "        HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_base\n",
        "        HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_rescaled\n",
        "        HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_evoke\n",
        "        HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "        # Save HG_ev1_evoke_rescaled\n",
        "        HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use time point cluster stats for determining stimulus significance (old method as of 2/13/24)\n",
        "\n",
        "updated this one 2/29, once it's tested and works, then turn into a function and delete other cells below"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "uncomment things and delete the subjects variable once we get the mat shape 3/10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "good channels before dropping bads: 178\n",
            "filt channels before dropping bads: 178\n",
            "outlier round 1 channels: ['RAMT8']\n",
            "outlier round 2 channels: ['RAMT8', 'RPI16']\n",
            "Bad channels in 'good': ['RAMT8', 'RPI16']\n",
            "Bad channels in 'good' after dropping once: []\n",
            "good channels after dropping bads: 176\n",
            "filt channels after dropping bads: 176\n",
            "Reading 0 ... 3219820  =      0.000 ...  1572.178 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n25', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n25', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 4097 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [04:09<00:00,  1.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n25', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n25', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 4097 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_13644\\1049140133.py:126: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  all_trials = mne.concatenate_epochs(all_epochs_list)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [04:04<00:00,  1.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HG_ev1 before crop_pad:  -0.5 1.5\n",
            "HG_ev1 after crop_pad:  0.0 1.0\n",
            "Applying baseline correction (mode: zscore)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_13644\\1049140133.py:136: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_13644\\1049140133.py:137: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_ev1.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_13644\\1049140133.py:139: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_13644\\1049140133.py:139: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_13644\\1049140133.py:140: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_13644\\1049140133.py:140: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of HG_ev1._data: (448, 176, 1025)\n",
            "Shape of HG_base._data: (448, 176, 1025)\n",
            "Shape of sig1: (448, 176, 1025)\n",
            "Shape of sig2: (448, 176, 1025)\n",
            "Shape of sig3: (448, 176, 1026)\n",
            "Shape of sig4: (448, 176, 1025)\n",
            "Shape of sig5: (448, 176, 1025)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   16.2s\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:   16.3s\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:   16.3s\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   16.3s\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   16.4s\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   16.5s\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:   28.8s\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:   28.9s\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:   28.9s\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:   29.0s\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:   29.0s\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:   29.0s\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   41.2s\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:   41.3s\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:   41.4s\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:   41.5s\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:   41.5s\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:   41.7s\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:   54.2s\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:   54.4s\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:   54.5s\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:   54.6s\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:   54.6s\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:   54.7s\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  1.5min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed:  2.4min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed:  2.8min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed:  3.1min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed:  3.7min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed:  4.1min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done 120 tasks      | elapsed:  4.4min\n",
            "[Parallel(n_jobs=6)]: Done 121 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=6)]: Done 122 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=6)]: Done 123 tasks      | elapsed:  4.5min\n",
            "[Parallel(n_jobs=6)]: Done 124 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=6)]: Done 125 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=6)]: Done 126 tasks      | elapsed:  4.6min\n",
            "[Parallel(n_jobs=6)]: Done 127 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done 128 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done 129 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done 130 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done 131 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done 132 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done 134 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done 135 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done 136 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=6)]: Done 137 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=6)]: Done 138 tasks      | elapsed:  5.0min\n",
            "[Parallel(n_jobs=6)]: Done 139 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done 140 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done 141 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done 142 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done 143 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done 144 tasks      | elapsed:  5.2min\n",
            "[Parallel(n_jobs=6)]: Done 145 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=6)]: Done 146 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=6)]: Done 147 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=6)]: Done 148 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=6)]: Done 149 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed:  5.4min\n",
            "[Parallel(n_jobs=6)]: Done 151 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done 152 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done 153 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done 154 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done 155 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done 156 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done 157 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done 158 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done 159 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done 160 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done 161 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done 162 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done 163 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done 164 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done 165 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done 170 out of 176 | elapsed:  6.2min remaining:   13.0s\n",
            "[Parallel(n_jobs=6)]: Done 176 out of 176 | elapsed:  6.3min finished\n"
          ]
        }
      ],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_fixationCrossBase_1sec_mirror_0to1Test\"\n",
        "    events = [\"Stimulus\"]\n",
        "    times = (0,1)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "\n",
        "    sig_chans_filename = os.path.join(save_dir, f'sig_chans_{sub}_{output_name}.json')\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "    # Assuming `mat` is your array and `save_dir` is the directory where you want to save it\n",
        "    mat_save_path = os.path.join(save_dir, f'{output_name}_mat.npy')\n",
        "\n",
        "    # Save the mat array\n",
        "    np.save(mat_save_path, mat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loop through everyone and do congruency "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/s25\", \"Stimulus/c75/s25\", \"Stimulus/i25/s25\", \"Stimulus/c25/s25\", \"Stimulus/i75/s75\", \"Stimulus/c75/s75\", \"Stimulus/i25/s75\", \"Stimulus/c25/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_r25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/r25\", \"Stimulus/c75/r25\", \"Stimulus/i25/r25\", \"Stimulus/c25/r25\", \"Stimulus/i75/r75\", \"Stimulus/c75/r75\", \"Stimulus/i25/r75\", \"Stimulus/c25/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_c75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_i75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### do interaction effects (is, ir, cs, cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_is_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/s25\", \"Stimulus/i25/s75\", \"Stimulus/i75/s25\", \"Stimulus/i75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_ir_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/r25\", \"Stimulus/i25/r75\", \"Stimulus/i75/r25\", \"Stimulus/i75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cs_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/s25\", \"Stimulus/c25/s75\", \"Stimulus/c75/s25\", \"Stimulus/c75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cr_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/r25\", \"Stimulus/c25/r75\", \"Stimulus/c75/r25\", \"Stimulus/c75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "do switch type proportions by block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_s75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/s75\", \"Stimulus/i75/s75\", \"Stimulus/c25/s75\", \"Stimulus/c75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_r75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/r75\", \"Stimulus/i75/r75\", \"Stimulus/c25/r75\", \"Stimulus/c75/r75\"]    \n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot each significant channel with its trace and timepoints of significance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "first, load in previously generated hg ev1 and hg base for stimulus significance from baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "turn this into a loop over all three time windows and all 12 subjects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageChops\n",
        "\n",
        "def trim_whitespace(image):\n",
        "    \"\"\"\n",
        "    Trims the whitespace from an image.\n",
        "    \"\"\"\n",
        "    bg = Image.new(image.mode, image.size, image.getpixel((0, 0)))\n",
        "    diff = ImageChops.difference(image, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return image.crop(bbox)\n",
        "    return image  # If no change\n",
        "\n",
        "def plot_channels_on_grid_windows(evoke_data, std_err_data, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim=6, plot_y_dim=6):\n",
        "    \"\"\"\n",
        "    Plots evoked EEG/MEG data for a subset of channels on a grid, overlaying significance markers for specified time windows.\n",
        "\n",
        "    Parameters:\n",
        "    - evoke_data: mne.Evoked object\n",
        "        The evoked data to be plotted. This object contains the averaged EEG/MEG data over epochs.\n",
        "    - std_err_data: \n",
        "        The standard error of the evoked data to be plotted\n",
        "    - channels_subset: list of str\n",
        "        A list of channel names to be plotted. Each channel name must correspond to a channel in `evoke_data`.\n",
        "    - time_windows: dict\n",
        "        A dictionary where keys are strings representing the names of the time windows of interest, and values are tuples\n",
        "        indicating the start and end indices (in samples) of these windows.\n",
        "    - sig_chans: dict\n",
        "        A dictionary where keys are the names of the time windows (matching those in `time_windows`) and values are lists\n",
        "        of channel names (str) that are significant within those windows.\n",
        "    - sample_rate: float\n",
        "        The sampling rate of the data, in Hz. Used to convert sample indices in `time_windows` to time in seconds.\n",
        "    - plot_x_dim: int, optional (default=6)\n",
        "        The number of columns in the grid layout for plotting the channels.\n",
        "    - plot_y_dim: int, optional (default=6)\n",
        "        The number of rows in the grid layout for plotting the channels.\n",
        "\n",
        "    Returns:\n",
        "    - fig: matplotlib.figure.Figure object\n",
        "        The figure object containing the grid of plots. Each plot shows the evoked data for a channel, with significance\n",
        "        markers overlaid for the specified time windows.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(plot_y_dim, plot_x_dim, figsize=(20, 12))  # Adjusted to match your desired layout\n",
        "    fig.suptitle(\"Channels with Significance Overlay for Different Time Windows\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    # Define colors for each time window\n",
        "    colors = ['red', 'green', 'blue']\n",
        "    window_names = list(time_windows.keys())\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = stderr_data.data[channel_to_index[channel], :]\n",
        "        # Plot the channel data with times in seconds\n",
        "        ax.plot(evoke_data.times, evoke_data.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(evoke_data.times, evoke_data.data[channel_to_index[channel], :] - stderr, evoke_data.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        max_y_value = np.max(evoke_data.data[channel_to_index[channel], :])  # Find max y-value for significance lines\n",
        "        # Assuming the epochs start 1 second before the stimulus/event\n",
        "        epoch_start_time = -1  # Start time of epochs in seconds\n",
        "\n",
        "        for window_index, window_name in enumerate(window_names):\n",
        "            if channel in sig_chans[window_name]:\n",
        "                start_idx, end_idx = time_windows[window_name]\n",
        "                # Convert sample indices to times in seconds\n",
        "                start_time = (start_idx / sample_rate) + epoch_start_time\n",
        "                end_time = (end_idx / sample_rate) + epoch_start_time\n",
        "                # Determine y-position for the significance line, adjusting to avoid overlap\n",
        "                y_position = max_y_value - (window_index * 0.02 * max_y_value)  # Adjust overlap offset here\n",
        "\n",
        "                # Cycle through colors for each time window\n",
        "                color = colors[window_index % len(colors)]\n",
        "                ax.hlines(y=y_position, xmin=start_time, xmax=end_time, color=color, linewidth=2, label=f\"{window_name}: {color}\")\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    # Create a legend for the first subplot (if desired) to explain the colors\n",
        "    if len(axes_flat) > 0 and len(window_names) > 0:\n",
        "        handles, labels = axes_flat[0].get_legend_handles_labels()\n",
        "        fig.legend(handles, labels, loc='upper right', title=\"Time Windows & Colors\")\n",
        "\n",
        "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to make space for the legend\n",
        "    return fig\n",
        "\n",
        "sig_chans = {}\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    LAB_root = None\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    sample_rate = filt.info['sfreq'] # get sampling rate, should be 2048 Hz\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    time_windows = {\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0to0.5\": (sample_rate,1.5*sample_rate), #actually grab from 1 to 1.5 because the epochs start at -1 second before stim onset\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0.5to1\": (1.5*sample_rate,2*sample_rate),\n",
        "        \"Stimulus_fixationCrossBase_0.2sec_window_0to1\": (sample_rate,2*sample_rate)\n",
        "    }\n",
        "\n",
        "    for window in time_windows:\n",
        "        output_name = window\n",
        "\n",
        "        # Define file paths\n",
        "        HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
        "        HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
        "        HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
        "\n",
        "        # Load the epochs and evoked objects\n",
        "        HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
        "        HG_base = mne.read_epochs(HG_base_file)\n",
        "        HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
        "        HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "        HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "        HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "        channels = [] # load in all channels\n",
        "        channel_to_index = {}\n",
        "        channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') \n",
        "        with open(channel_file, 'r') as f:\n",
        "            for line in f:\n",
        "                index, channel = line.strip().split(': ')\n",
        "                channels.append(channel)\n",
        "                channel_to_index[channel] = int(index)\n",
        "\n",
        "        sig_chans_filename = os.path.join(save_dir, f'sig_chans_{sub}_{output_name}.json') # load in sig channels\n",
        "        sig_chans[window] = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "    # now plot 6x6 grid of 36 channels on one plot, for the z-scored signal\n",
        "    plot_x_dim = 6\n",
        "    plot_y_dim = 6\n",
        "    channels_per_fig = plot_x_dim * plot_y_dim\n",
        "\n",
        "    # Iterate over all channels in chunks and plot them with z-scored signal\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_windows(HG_ev1_evoke_rescaled, HG_ev1_evoke_rescaled_stderr, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim, plot_y_dim)\n",
        "        combined_plot_path_rescaled = os.path.join(save_dir, f'{sub}_zscore_{output_name}_combinedChannelTracesAndWindowsSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path_rescaled)\n",
        "        plt.close(fig)\n",
        "\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_windows(HG_ev1_evoke, HG_ev1_evoke_stderr, channels_subset, time_windows, sig_chans, sample_rate, plot_x_dim, plot_y_dim)\n",
        "        combined_plot_path_rescaled = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndWindowsSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path_rescaled)\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "this below code is for when using the time perm cluster stats to determine significance timepoint by timepoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# UNTESTED 2/29, NEED TO RERUN STATS TO SAVE MAT FIRST.\n",
        "def plot_channels_on_grid_time_perm_cluster(evoke_data, std_err_data, channels_subset, mat, sample_rate=2048, plot_x_dim=6, plot_y_dim=6):\n",
        "    \"\"\"\n",
        "    Plots evoked EEG/MEG data for a subset of channels on a grid, overlaying significance markers for specified time windows.\n",
        "\n",
        "    Parameters:\n",
        "    - evoke_data: mne.Evoked object\n",
        "        The evoked data to be plotted. This object contains the averaged EEG/MEG data over epochs.\n",
        "    - std_err_data: \n",
        "        The standard error of the evoked data to be plotted\n",
        "    - channels_subset: list of str\n",
        "        A list of channel names to be plotted. Each channel name must correspond to a channel in `evoke_data`.\n",
        "    - mat: numpy.array\n",
        "        A binary matrix (same shape as evoke_data) indicating significant data points (1 for significant, 0 for non-significant).\n",
        "    - sample_rate: float\n",
        "    - sample_rate: float\n",
        "        The sampling rate of the data, in Hz. Used to convert sample indices in `time_windows` to time in seconds.\n",
        "    - plot_x_dim: int, optional (default=6)\n",
        "        The number of columns in the grid layout for plotting the channels.\n",
        "    - plot_y_dim: int, optional (default=6)\n",
        "        The number of rows in the grid layout for plotting the channels.\n",
        "\n",
        "    Returns:\n",
        "    - fig: matplotlib.figure.Figure object\n",
        "        The figure object containing the grid of plots. Each plot shows the evoked data for a channel, with significance\n",
        "        markers overlaid for the specified time windows.\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(plot_x_dim, plot_y_dim, figsize=(20, 12))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = std_err_data.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / sample_rate  # Should be 2048 Hz sample rate\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(evoke_data.times, evoke_data.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(evoke_data.times, evoke_data.data[channel_to_index[channel], :] - stderr, evoke_data.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(evoke_data.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "plot_x_dim = 6\n",
        "plot_y_dim = 6\n",
        "channels_per_fig = plot_x_dim * plot_y_dim\n",
        "\n",
        "sig_chans = {}\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    LAB_root = None\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    sample_rate = filt.info['sfreq'] # get sampling rate, should be 2048 Hz\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    output_name = 'Stimulus_fixationCrossBase_1sec_mirror_0to1test'\n",
        "\n",
        "    # Define file paths\n",
        "    HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
        "    HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
        "    HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
        "\n",
        "    # Load the epochs and evoked objects\n",
        "    HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
        "    HG_base = mne.read_epochs(HG_base_file)\n",
        "    HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    mat_save_path = os.path.join(save_dir, f'{output_name}_mat.npy')\n",
        "    mat = np.load(mat_save_path)\n",
        "\n",
        "    channels = [] # load in all channels\n",
        "    channel_to_index = {}\n",
        "    channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') \n",
        "    with open(channel_file, 'r') as f:\n",
        "        for line in f:\n",
        "            index, channel = line.strip().split(': ')\n",
        "            channels.append(channel)\n",
        "            channel_to_index[channel] = int(index)\n",
        "    \n",
        "    # Iterate over all channels in chunks of channels_per_fig (plot_x_dim * plot_y_dim) and plot them\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_time_perm_cluster(HG_ev1_evoke_rescaled, HG_ev1_evoke_rescaled_stderr, channels_subset, mat, plot_x_dim, plot_y_dim, sample_rate=sample_rate)\n",
        "        combined_plot_path = os.path.join(save_dir, f'{sub}_zscore_{output_name}_combinedChannelTracesAndTimePermClusterSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path)\n",
        "        plt.close(fig)\n",
        "\n",
        "        # Iterate over all channels in chunks of channels_per_fig (plot_x_dim * plot_y_dim) and plot them\n",
        "    for i in range(0, len(channels), channels_per_fig):\n",
        "        channels_subset = channels[i:i+channels_per_fig]\n",
        "        fig = plot_channels_on_grid_time_perm_cluster(HG_ev1_evoke, HG_ev1_evoke_stderr, channels_subset, mat, plot_x_dim, plot_y_dim, sample_rate=sample_rate)\n",
        "        combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndTimePermClusterSignificance_Page_{i//channels_per_fig + 1}.png')\n",
        "        fig.savefig(combined_plot_path)\n",
        "        plt.close(fig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### z-scored signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for raw traces, just plot HG_ev1_evoke instead of HG_ev1_evoke_rescaled. And for the standard error, use the HG_ev1_evoke_stderr instead of HG_ev1_evoke_rescaled_stderr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### raw traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming all imports and previous definitions are in place\n",
        "\n",
        "def plot_channels_on_grid_time_perm_cluster_raw(channels_subset):\n",
        "    fig, axes = plt.subplots(6, 10, figsize=(20, 33))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = HG_ev1_evoke_stderr.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / sample_rate  # should be 2048 Hz sample rate. Need mat though..should i save this somehow?\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :] - stderr, HG_ev1_evoke.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "# Iterate over all channels in chunks of 60 and plot them\n",
        "for i in range(0, len(sig_chans), 60):\n",
        "    channels_subset = channels[i:i+60]\n",
        "    fig = plot_channels_on_grid_time_perm_cluster_raw(channels_subset)\n",
        "    combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndTimePermClusterSignificance_Page_{i//36 + 1}.png')\n",
        "    fig.savefig(combined_plot_path)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
