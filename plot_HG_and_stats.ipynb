{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ieeg.viz.utils\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.calc import stats, scaling\n",
        "from ieeg.process import parallelize\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "from misc_functions import calculate_RTs\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from bids import BIDSLayout\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relabel_axes(old_min, old_max, new_min, new_max):\n",
        "    scale = (new_max - new_min) / (old_max - old_min)\n",
        "\n",
        "    def format_func(value, tick_number):\n",
        "        return new_min + value * scale\n",
        "\n",
        "    plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(format_func))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### grab the data and set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "for sub in subjects:\n",
        "\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                            extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "    # do filtering now\n",
        "    ## Crop raw data to minimize processing time\n",
        "    good = crop_empty_data(filt)\n",
        "\n",
        "    ## remove bad channels\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    good.drop_channels(good.info['bads'])\n",
        "    good.load_data()\n",
        "\n",
        "    # CAR\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "    # make baseline \n",
        "    # make stimulus baseline EpochsTFR\n",
        "    times=[-1, 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10) #this removes trial outliers BUT breaks the shape because different stimulus epochs will then have different trial numbers\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    data_dict = {}  # make something to store all the outputs\n",
        "\n",
        "    for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "        times = [None, None]\n",
        "        times[0] = t[0] - 0.5\n",
        "        times[1] = t[1] + 0.5\n",
        "        trials = trial_ieeg(good, event, times, preload=True)\n",
        "        outliers_to_nan(trials, outliers=10)\n",
        "        HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "        crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "        HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "        # HG_ev1.resample(100)\n",
        "        # HG_ev1.filenames = good.filenames\n",
        "\n",
        "        # Store the variable in the dictionary with the desired name\n",
        "        data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "        data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "        \n",
        "    resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    RTs, skipped = calculate_RTs(good)\n",
        "    avg_RT = np.median(RTs)\n",
        "\n",
        "    # Plot the evoked data\n",
        "    fig = resp_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "    fig.savefig(save_dir + '_HG_ev1_Response_zscore_rt.png')\n",
        "\n",
        "    fig = stim_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "    # Add a vertical line indicating the average reaction time to the plot\n",
        "    for ax in fig.axes:\n",
        "        ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "        \n",
        "    fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore_rt.png')\n",
        "\n",
        "    # # decimate for stats\n",
        "    # resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "    # stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "    # HG_base.decimate(2)\n",
        "    # resp.decimate(2)\n",
        "    # stim.decimate(2)\n",
        "\n",
        "    # # do permutation cluster\n",
        "    # resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "    #                             n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    # stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "    #                             n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    \n",
        "    # # plot stats\n",
        "    # plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "    # plt.imshow(stim_mask, aspect='auto')  # hold on from matlab\n",
        "    # relabel_axes(0, 2500, -1000, 1500)\n",
        "    # plt.savefig(save_dir + '_stimulus_stats_big.png', dpi=300)\n",
        "\n",
        "    # plt.figure(figsize=(16, 8))\n",
        "    # plt.imshow(resp_mask, aspect='auto')\n",
        "    # relabel_axes(0, 2500, -1000, 1500)\n",
        "    # plt.savefig(save_dir + '_response_stats_big.png', dpi=300)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### for testing with a single subject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24}\n",
            "KeysView({'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24})\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outlier round 1 channels: ['LAIP9']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15', 'LMMT1']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15', 'LMMT1', 'LMMT3']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15', 'LMMT1', 'LMMT3', 'LMMT11']\n",
            "Reading 0 ... 3242460  =      0.000 ...  1583.232 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
              "    <tr>\n",
              "        <th>Measurement date</th>\n",
              "        \n",
              "        <td>July 03, 2023  12:45:11 GMT</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Experimenter</th>\n",
              "        \n",
              "        <td>mne_anonymize</td>\n",
              "        \n",
              "    </tr>\n",
              "        <th>Participant</th>\n",
              "        \n",
              "            \n",
              "            <td>sub-D0059</td>\n",
              "            \n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Digitized points</th>\n",
              "        \n",
              "        <td>184 points</td>\n",
              "        \n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Good channels</th>\n",
              "        <td>174 sEEG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>Bad channels</th>\n",
              "        <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>EOG channels</th>\n",
              "        <td>Not available</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "        <th>ECG channels</th>\n",
              "        <td>Not available</td>\n",
              "    \n",
              "    <tr>\n",
              "        <th>Sampling frequency</th>\n",
              "        <td>2048.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Highpass</th>\n",
              "        <td>0.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Lowpass</th>\n",
              "        <td>1024.00 Hz</td>\n",
              "    </tr>\n",
              "    \n",
              "    \n",
              "    \n",
              "    <tr>\n",
              "        <th>Filenames</th>\n",
              "        <td>sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf&lt;br&gt;sub-D0059_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf&lt;br&gt;sub-D0059_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf&lt;br&gt;sub-D0059_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf</td>\n",
              "    </tr>\n",
              "    \n",
              "    <tr>\n",
              "        <th>Duration</th>\n",
              "        <td>00:26:24 (HH:MM:SS)</td>\n",
              "    </tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<RawEDF | sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf, 174 x 3242461 (1583.2 s), ~4.20 GB, data loaded>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "sub = 'D0059'\n",
        "\n",
        "filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "# do filtering now\n",
        "## Crop raw data to minimize processing time\n",
        "good = crop_empty_data(filt)\n",
        "\n",
        "## remove bad channels\n",
        "good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "good.drop_channels(good.info['bads'])\n",
        "good.load_data()\n",
        "\n",
        "# CAR\n",
        "ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "# make baseline \n",
        "# make stimulus baseline EpochsTFR\n",
        "times=[-1, 0.5]\n",
        "\n",
        "trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "outliers_to_nan(trials, outliers=10)\n",
        "HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "data_dict = {}  # Create an empty dictionary\n",
        "\n",
        "for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "    times = [None, None]\n",
        "    times[0] = t[0] - 0.5\n",
        "    times[1] = t[1] + 0.5\n",
        "    trials = trial_ieeg(good, event, times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore') #removed .average() part. Check with Aaron if this is okay.\n",
        "    # HG_ev1.resample(100)\n",
        "    # HG_ev1.filenames = good.filenames\n",
        "\n",
        "    # Store the variable in the dictionary with the desired name\n",
        "    data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "    data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "\n",
        "resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "RTs, skipped = calculate_RTs(good)\n",
        "avg_RT = np.median(RTs)\n",
        "\n",
        "# Plot the evoked data\n",
        "fig = resp_evoke_rescaled.plot()\n",
        "\n",
        "\n",
        "# fig.savefig(save_dir + '_HG_ev1_Response_rescaled_zscore_test.png')\n",
        "\n",
        "fig = stim_evoke_rescaled.plot()\n",
        "# Add a vertical line indicating the average reaction time to the plot\n",
        "for ax in fig.axes:\n",
        "    ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Stimulus_test.png')\n",
        "\n",
        "# # decimate for stats\n",
        "# resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "# stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "# HG_base.decimate(2)\n",
        "# resp.decimate(2)\n",
        "# stim.decimate(2)\n",
        "\n",
        "# # import scipy\n",
        "# resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "#                             n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "# stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "#                             n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "\n",
        "# # plot stats\n",
        "# plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "# plt.imshow(stim_mask, aspect='auto')\n",
        "# # hold on from matlab\n",
        "# # plt.imshow(x) #plot multiple things like this\n",
        "\n",
        "# relabel_axes(0, 2500, -1000, 1500)\n",
        "# plt.savefig(save_dir + '_stimulus_stats_big.png', dpi=300)\n",
        "\n",
        "# plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "# plt.imshow(resp_mask, aspect='auto')\n",
        "# relabel_axes(0, 2500, -1000, 1500)\n",
        "# plt.savefig(save_dir + '_response_stats_big.png', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### testing with averaged across all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24}\n",
            "KeysView({'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24})\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0059\\ieeg\\sub-D0059_acq-01_space-ACPC_electrodes.tsv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (185) does not match the number of channels in the raw data file (184). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outlier round 1 channels: ['LAIP9']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10']\n",
            "outlier round 1 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15', 'LMMT1']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15', 'LMMT1', 'LMMT3']\n",
            "outlier round 2 channels: ['LAIP9', 'LAIP14', 'LMMT2', 'LMMT12', 'LMPT10', 'LMPT11', 'LMPF15', 'LMMT1', 'LMMT3', 'LMMT11']\n",
            "Reading 0 ... 3242460  =      0.000 ...  1583.232 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/n25', 'Response/i25/n75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n25', 'Stimulus/i25/n75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "event_ids: {'c25/r25': 21, 'c25/r75': 22, 'c25/s25': 23, 'c25/s75': 24, 'c75/n25': 25, 'c75/r25': 26, 'c75/r75': 27, 'c75/s25': 28, 'c75/s75': 29, 'i25/n25': 30, 'i25/n75': 31, 'i25/r25': 32, 'i25/r75': 33, 'i25/s25': 34, 'i25/s75': 35, 'i75/n75': 36, 'i75/r25': 37, 'i75/r75': 38, 'i75/s25': 39, 'i75/s75': 40}\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 3073 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [04:23<00:00,  1.70it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/n25', 'Response/i25/n75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n25', 'Stimulus/i25/n75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "event_ids: {'c25/r25': 21, 'c25/r75': 22, 'c25/s25': 23, 'c25/s75': 24, 'c75/n25': 25, 'c75/r25': 26, 'c75/r75': 27, 'c75/s25': 28, 'c75/s75': 29, 'i25/n25': 30, 'i25/n75': 31, 'i25/r25': 32, 'i25/r75': 33, 'i25/s25': 34, 'i25/s75': 35, 'i75/n75': 36, 'i75/r25': 37, 'i75/r75': 38, 'i75/s25': 39, 'i75/s75': 40}\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [08:49<00:00,  1.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/n25', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/n25', 'Response/i25/n75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/n25', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n25', 'Stimulus/i25/n75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "event_ids: {'c25/r25': 1, 'c25/r75': 2, 'c25/s25': 3, 'c25/s75': 4, 'c75/n25': 5, 'c75/r25': 6, 'c75/r75': 7, 'c75/s25': 8, 'c75/s75': 9, 'i25/n25': 10, 'i25/n75': 11, 'i25/r25': 12, 'i25/r75': 13, 'i25/s25': 14, 'i25/s75': 15, 'i75/n75': 16, 'i75/r25': 17, 'i75/r75': 18, 'i75/s25': 19, 'i75/s75': 20}\n",
            "Not setting metadata\n",
            "447 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 447 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 447/447 [08:44<00:00,  1.17s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
          ]
        }
      ],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "sub = 'D0059'\n",
        "\n",
        "filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "# do filtering now\n",
        "## Crop raw data to minimize processing time\n",
        "good = crop_empty_data(filt)\n",
        "\n",
        "## remove bad channels\n",
        "good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "good.drop_channels(good.info['bads'])\n",
        "good.load_data()\n",
        "\n",
        "# CAR\n",
        "ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "# make baseline as average of all data\n",
        "good_avg = good._data.mean()\n",
        "\n",
        "\n",
        "# make stimulus baseline EpochsTFR\n",
        "times=[-1, 0.5]\n",
        "\n",
        "trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "outliers_to_nan(trials, outliers=10)\n",
        "HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "data_dict = {}  # Create an empty dictionary\n",
        "\n",
        "for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "    times = [None, None]\n",
        "    times[0] = t[0] - 0.5\n",
        "    times[1] = t[1] + 0.5\n",
        "    trials = trial_ieeg(good, event, times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    HG_ev1_rescaled = HG_ev1 #redundant perhaps.\n",
        "    HG_ev1_rescaled._data = HG_ev1_rescaled._data / good_avg\n",
        "\n",
        "    # Store the variable in the dictionary with the desired name\n",
        "    data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "    data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "\n",
        "resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "RTs, skipped = calculate_RTs(good)\n",
        "avg_RT = np.median(RTs)\n",
        "\n",
        "# Plot the evoked data\n",
        "fig = resp_evoke_rescaled.plot()\n",
        "\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Response_allDataBaseline.png')\n",
        "\n",
        "fig = stim_evoke_rescaled.plot()\n",
        "# Add a vertical line indicating the average reaction time to the plot\n",
        "for ax in fig.axes:\n",
        "    ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Stimulus_allDataBaseline.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_2144\\117201705.py:4: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 512.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_2144\\117201705.py:5: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 512.0 Hz, which can cause aliasing artifacts.\n",
            "  resp.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_2144\\117201705.py:6: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 512.0 Hz, which can cause aliasing artifacts.\n",
            "  stim.decimate(2)\n",
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 463, in _process_worker\n    r = call_item()\n        ^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py\", line 291, in __call__\n    return self.fn(*self.args, **self.kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py\", line 580, in __call__\n    return [func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py\", line 580, in <listcomp>\n    return [func(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\calc\\stats.py\", line 297, in time_perm_cluster\n    pad_shape = [(0, 0) if eq[i] else\n                ^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\calc\\stats.py\", line 298, in <listcomp>\n    (0, sig1.shape[i] - sig2.shape[i])\n                        ~~~~~~~~~~^^^\nIndexError: tuple index out of range\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[70], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m stim\u001b[39m.\u001b[39mdecimate(\u001b[39m2\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# import scipy\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m resp_mask \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39;49mtime_perm_cluster(resp\u001b[39m.\u001b[39;49m_data, good\u001b[39m.\u001b[39;49m_data, \u001b[39m0.05\u001b[39;49m, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     10\u001b[0m                             n_perm\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, n_jobs\u001b[39m=\u001b[39;49m\u001b[39m6\u001b[39;49m, ignore_adjacency\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m stim_mask \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39mtime_perm_cluster(stim\u001b[39m.\u001b[39m_data, good\u001b[39m.\u001b[39m_data, \u001b[39m0.05\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[0;32m     12\u001b[0m                             n_perm\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, n_jobs\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m, ignore_adjacency\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[39m# plot stats\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\calc\\stats.py:289\u001b[0m, in \u001b[0;36mtime_perm_cluster\u001b[1;34m(sig1, sig2, p_thresh, p_cluster, n_perm, tails, axis, stat_func, ignore_adjacency, n_jobs)\u001b[0m\n\u001b[0;32m    283\u001b[0m ins \u001b[39m=\u001b[39m ((np\u001b[39m.\u001b[39msqueeze(sig1[:, i]), np\u001b[39m.\u001b[39msqueeze(sig2[:, i])) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m\n\u001b[0;32m    284\u001b[0m        np\u001b[39m.\u001b[39mndindex(\u001b[39mtuple\u001b[39m(sig1\u001b[39m.\u001b[39mshape[j] \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m ignore_adjacency)))\n\u001b[0;32m    285\u001b[0m proc \u001b[39m=\u001b[39m Parallel(n_jobs, return_generator\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, verbose\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m)(\n\u001b[0;32m    286\u001b[0m     delayed(time_perm_cluster)(\n\u001b[0;32m    287\u001b[0m         \u001b[39m*\u001b[39mi, p_thresh\u001b[39m=\u001b[39mp_thresh, p_cluster\u001b[39m=\u001b[39mp_cluster, n_perm\u001b[39m=\u001b[39mn_perm,\n\u001b[0;32m    288\u001b[0m         tails\u001b[39m=\u001b[39mtails, axis\u001b[39m=\u001b[39maxis, stat_func\u001b[39m=\u001b[39mstat_func) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m ins)\n\u001b[1;32m--> 289\u001b[0m \u001b[39mfor\u001b[39;00m i, iout \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(proc):\n\u001b[0;32m    290\u001b[0m     out[i] \u001b[39m=\u001b[39m iout\n\u001b[0;32m    291\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:1568\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1565\u001b[0m     \u001b[39myield\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1568\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retrieve()\n\u001b[0;32m   1570\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1571\u001b[0m     \u001b[39m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1572\u001b[0m     \u001b[39m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1573\u001b[0m     \u001b[39m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1574\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:1672\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1665\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1666\u001b[0m \n\u001b[0;32m   1667\u001b[0m     \u001b[39m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1668\u001b[0m     \u001b[39m# triggerd an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1669\u001b[0m     \u001b[39m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1670\u001b[0m     \u001b[39m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1671\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aborting:\n\u001b[1;32m-> 1672\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raise_error_fast()\n\u001b[0;32m   1673\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m   1675\u001b[0m     \u001b[39m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1676\u001b[0m     \u001b[39m# async callbacks to progress.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[39m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[39m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m \u001b[39m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1706\u001b[0m \u001b[39mif\u001b[39;00m error_job \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1707\u001b[0m     error_job\u001b[39m.\u001b[39;49mget_result(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout)\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:727\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    721\u001b[0m backend \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparallel\u001b[39m.\u001b[39m_backend\n\u001b[0;32m    723\u001b[0m \u001b[39mif\u001b[39;00m backend\u001b[39m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    724\u001b[0m     \u001b[39m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    725\u001b[0m     \u001b[39m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     \u001b[39m# be returned.\u001b[39;00m\n\u001b[1;32m--> 727\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_return_or_raise()\n\u001b[0;32m    729\u001b[0m \u001b[39m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    730\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:745\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    744\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 745\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[0;32m    746\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_result\n\u001b[0;32m    747\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
            "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "# decimate for stats\n",
        "resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "HG_base.decimate(2)\n",
        "resp.decimate(2)\n",
        "stim.decimate(2)\n",
        "\n",
        "# import scipy\n",
        "resp_mask = stats.time_perm_cluster(resp._data, good._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "stim_mask = stats.time_perm_cluster(stim._data, good._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "\n",
        "# plot stats\n",
        "plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "plt.imshow(stim_mask, aspect='auto')\n",
        "# hold on from matlab\n",
        "# plt.imshow(x) #plot multiple things like this\n",
        "\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_stimulus_stats_allBase.png', dpi=300)\n",
        "\n",
        "plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "plt.imshow(resp_mask, aspect='auto')\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_response_stats_allBase.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "desired_total_size_last_two_dims: 222894\n",
            "num_samples: 2532\n",
            "current_size: 564188214\n",
            "size_diff: 179394\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Get the shape of stim._data\n",
        "stim_shape = stim._data.shape\n",
        "\n",
        "# Calculate desired total size for the last two dimensions\n",
        "desired_total_size_last_two_dims = stim_shape[1] * stim_shape[2]\n",
        "\n",
        "# Calculate the number of samples for the first dimension\n",
        "num_samples = current_size // desired_total_size_last_two_dims\n",
        "\n",
        "# If current_size is not an exact multiple of desired_total_size_last_two_dims, add 1 to num_samples\n",
        "if current_size % desired_total_size_last_two_dims != 0:\n",
        "    num_samples += 1\n",
        "\n",
        "# Correct the desired size\n",
        "desired_size = (num_samples, stim_shape[1], stim_shape[2])\n",
        "\n",
        "# Calculate current size and the difference\n",
        "current_size = good._data.size\n",
        "size_diff = desired_total_size_last_two_dims * num_samples - current_size\n",
        "\n",
        "print(f\"desired_total_size_last_two_dims: {desired_total_size_last_two_dims}\")\n",
        "print(f\"num_samples: {num_samples}\")\n",
        "print(f\"current_size: {current_size}\")\n",
        "print(f\"size_diff: {size_diff}\")\n",
        "\n",
        "\n",
        "# Flatten the array first\n",
        "flat_data = good._data.flatten()\n",
        "\n",
        "if size_diff > 0:\n",
        "    # If the current size is smaller than the desired size, pad with zeros\n",
        "    padded = np.pad(flat_data, (0, size_diff))\n",
        "elif size_diff < 0:\n",
        "    # If the current size is larger than the desired size, truncate the array\n",
        "    padded = flat_data[:desired_total_size_last_two_dims * num_samples]\n",
        "else:\n",
        "    # If the sizes match, no padding or truncating is necessary\n",
        "    padded = flat_data\n",
        "\n",
        "# Now reshape\n",
        "good_reshaped = padded.reshape(desired_size)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:  3.3min\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  6.3min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed: 12.6min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed: 12.6min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed: 12.7min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed: 12.7min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed: 12.7min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed: 12.7min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed: 15.1min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed: 15.1min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed: 15.1min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed: 15.1min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed: 16.3min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed: 16.3min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed: 16.4min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed: 16.4min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed: 16.4min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed: 16.4min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed: 17.5min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed: 17.5min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed: 17.6min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed: 17.6min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed: 17.6min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed: 17.6min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed: 18.7min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed: 18.7min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed: 18.8min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed: 18.8min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed: 18.8min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed: 18.9min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed: 20.0min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed: 20.0min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed: 20.1min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed: 21.2min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed: 21.2min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed: 21.3min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed: 21.3min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed: 21.3min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed: 21.3min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed: 22.4min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed: 22.4min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed: 22.5min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed: 22.6min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed: 22.6min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed: 23.7min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed: 23.7min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed: 23.8min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed: 24.9min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed: 24.9min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed: 25.0min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed: 25.0min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed: 25.0min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed: 25.0min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed: 26.1min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed: 26.1min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed: 26.2min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed: 26.2min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed: 26.3min\n",
            "[Parallel(n_jobs=6)]: Done 120 tasks      | elapsed: 26.3min\n",
            "[Parallel(n_jobs=6)]: Done 121 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=6)]: Done 122 tasks      | elapsed: 27.4min\n",
            "[Parallel(n_jobs=6)]: Done 123 tasks      | elapsed: 27.5min\n",
            "[Parallel(n_jobs=6)]: Done 124 tasks      | elapsed: 27.5min\n",
            "[Parallel(n_jobs=6)]: Done 125 tasks      | elapsed: 27.5min\n",
            "[Parallel(n_jobs=6)]: Done 126 tasks      | elapsed: 27.5min\n",
            "[Parallel(n_jobs=6)]: Done 127 tasks      | elapsed: 28.6min\n",
            "[Parallel(n_jobs=6)]: Done 128 tasks      | elapsed: 28.6min\n",
            "[Parallel(n_jobs=6)]: Done 129 tasks      | elapsed: 28.7min\n",
            "[Parallel(n_jobs=6)]: Done 130 tasks      | elapsed: 28.7min\n",
            "[Parallel(n_jobs=6)]: Done 131 tasks      | elapsed: 28.7min\n",
            "[Parallel(n_jobs=6)]: Done 132 tasks      | elapsed: 28.7min\n",
            "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed: 29.8min\n",
            "[Parallel(n_jobs=6)]: Done 134 tasks      | elapsed: 29.8min\n",
            "[Parallel(n_jobs=6)]: Done 135 tasks      | elapsed: 29.9min\n",
            "[Parallel(n_jobs=6)]: Done 136 tasks      | elapsed: 29.9min\n",
            "[Parallel(n_jobs=6)]: Done 137 tasks      | elapsed: 30.0min\n",
            "[Parallel(n_jobs=6)]: Done 138 tasks      | elapsed: 30.0min\n",
            "[Parallel(n_jobs=6)]: Done 139 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=6)]: Done 140 tasks      | elapsed: 31.0min\n",
            "[Parallel(n_jobs=6)]: Done 141 tasks      | elapsed: 31.1min\n",
            "[Parallel(n_jobs=6)]: Done 142 tasks      | elapsed: 31.2min\n",
            "[Parallel(n_jobs=6)]: Done 143 tasks      | elapsed: 31.2min\n",
            "[Parallel(n_jobs=6)]: Done 144 tasks      | elapsed: 31.2min\n",
            "[Parallel(n_jobs=6)]: Done 145 tasks      | elapsed: 32.2min\n",
            "[Parallel(n_jobs=6)]: Done 146 tasks      | elapsed: 32.3min\n",
            "[Parallel(n_jobs=6)]: Done 147 tasks      | elapsed: 32.3min\n",
            "[Parallel(n_jobs=6)]: Done 148 tasks      | elapsed: 32.4min\n",
            "[Parallel(n_jobs=6)]: Done 149 tasks      | elapsed: 32.4min\n",
            "[Parallel(n_jobs=6)]: Done 150 tasks      | elapsed: 32.5min\n",
            "[Parallel(n_jobs=6)]: Done 151 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=6)]: Done 152 tasks      | elapsed: 33.5min\n",
            "[Parallel(n_jobs=6)]: Done 153 tasks      | elapsed: 33.6min\n",
            "[Parallel(n_jobs=6)]: Done 154 tasks      | elapsed: 33.7min\n",
            "[Parallel(n_jobs=6)]: Done 155 tasks      | elapsed: 33.7min\n",
            "[Parallel(n_jobs=6)]: Done 156 tasks      | elapsed: 33.7min\n",
            "[Parallel(n_jobs=6)]: Done 157 tasks      | elapsed: 34.7min\n",
            "[Parallel(n_jobs=6)]: Done 158 tasks      | elapsed: 34.7min\n",
            "[Parallel(n_jobs=6)]: Done 159 tasks      | elapsed: 34.8min\n",
            "[Parallel(n_jobs=6)]: Done 160 tasks      | elapsed: 34.9min\n",
            "[Parallel(n_jobs=6)]: Done 161 tasks      | elapsed: 34.9min\n",
            "[Parallel(n_jobs=6)]: Done 162 tasks      | elapsed: 34.9min\n",
            "[Parallel(n_jobs=6)]: Done 163 tasks      | elapsed: 35.9min\n",
            "[Parallel(n_jobs=6)]: Done 168 out of 174 | elapsed: 36.1min remaining:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done 174 out of 174 | elapsed: 37.3min finished\n"
          ]
        }
      ],
      "source": [
        "test = stats.time_perm_cluster(stim._data, good_reshaped, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
