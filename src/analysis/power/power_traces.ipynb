{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c30e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "# Get the absolute path to the directory containing the current script\n",
    "# For GlobalLocal/src/analysis/preproc/make_epoched_data.py, this is GlobalLocal/src/analysis/preproc\n",
    "try:\n",
    "    # This will work if running as a .py script\n",
    "    current_file_path = os.path.abspath(__file__)\n",
    "    current_script_dir = os.path.dirname(current_file_path)\n",
    "except NameError:\n",
    "    # This will be executed if __file__ is not defined (e.g., in a Jupyter Notebook)\n",
    "    # os.getcwd() often gives the directory of the notebook,\n",
    "    # or the directory from which the Jupyter server was started.\n",
    "    current_script_dir = os.getcwd()\n",
    "\n",
    "# Navigate up three levels to get to the 'GlobalLocal' directory\n",
    "project_root = os.path.abspath(os.path.join(current_script_dir, '..', '..', '..'))\n",
    "\n",
    "# Add the 'GlobalLocal' directory to sys.path if it's not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root) # insert at the beginning to prioritize it\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import numpy as np\n",
    "from ieeg.calc.stats import time_perm_cluster, window_averaged_shuffle\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "# from utils import make_or_load_subjects_electrodes_to_ROIs_dict, load_acc_arrays, calculate_RTs, save_channels_to_file, save_sig_chans, \\\n",
    "#       load_sig_chans, channel_names_to_indices, filter_and_average_epochs, permutation_test, perform_permutation_test_across_electrodes, perform_permutation_test_within_electrodes, \\\n",
    "#       add_accuracy_to_epochs, load_mne_objects, create_subjects_mne_objects_dict, extract_significant_effects, convert_dataframe_to_serializable_format, \\\n",
    "#       perform_modular_anova, make_plotting_parameters, plot_significance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "# still need to test if the permutation test functions load in properly.\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# from src.analysis.power.roi_analysis import blah_blah\n",
    "from src.analysis.config import experiment_conditions\n",
    "from src.analysis.config import plotting_parameters\n",
    "import src.analysis.utils.general_utils as utils # import utils functions one by one by name\n",
    "from src.analysis.power.power_traces import make_multi_channel_evokeds_for_all_conditions_and_rois, plot_power_traces_for_all_rois"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50e954",
   "metadata": {},
   "source": [
    "get lab root for save dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "task='GlobalLocal'\n",
    "# Determine LAB_root based on the operating system\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir_root = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17ace1",
   "metadata": {},
   "source": [
    "choose which subjects you wanna run (has to be a list, even if just one subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ee848",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103', 'D0107A', 'D0110', 'D0116', 'D0117', 'D0121']\n",
    "# subjects = ['D0057']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6debcaf",
   "metadata": {},
   "source": [
    "### make or load subjects electrodes to rois dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e4bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in subjects electrodes to rois dict. If it doesn't already exist, make it and then load it.\n",
    "config_dir = os.path.join(project_root, 'src', 'analysis', 'config')\n",
    "\n",
    "subjects_electrodestoROIs_dict = utils.make_or_load_subjects_electrodes_to_ROIs_dict(subjects, task='GlobalLocal', LAB_root=None, save_dir=config_dir, \n",
    "                                        filename='subjects_electrodestoROIs_dict.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acd51b",
   "metadata": {},
   "source": [
    "check number of elecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81604e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total number of electrodes in the 'default_dict' across subjects\n",
    "total_electrodes = utils.count_electrodes_across_subjects(subjects_electrodestoROIs_dict, subjects)\n",
    "print('total elecs:', total_electrodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de999e5",
   "metadata": {},
   "source": [
    "load behavioral data (combinedData.csv) and map blockType to congruency and switch proportions in the behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a6406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(os.path.join(LAB_root, 'D_Data', 'GlobalLocal', 'combinedData.csv'))\n",
    "combined_data[['switchProportion', 'congruencyProportion']] = combined_data.apply(utils.map_block_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a16de4",
   "metadata": {},
   "source": [
    "### load epochs objects for chosen conditions for all subjects in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78174b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='GlobalLocal'\n",
    "conditions = experiment_conditions.stimulus_err_corr_conditions # set this to whichever conditions you're running\n",
    "stimulus_locked = True  #toggle\n",
    "response_locked = not stimulus_locked\n",
    "\n",
    "if stimulus_locked:\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10\"\n",
    "    epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_0.0-30.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    # epochs_root_file = \"Stimulus_100sec_within1-101sec_experimentStartBase_decFactor_8_outliers_10_passband_70-150_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "\n",
    "elif response_locked:\n",
    "    # epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind\"\n",
    "    epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind\"\n",
    "\n",
    "condition_names = [condition for condition in conditions.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18795727",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conditions == experiment_conditions.stimulus_conditions:\n",
    "    conditions_save_name = 'stimulus_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_experiment_conditions:\n",
    "    conditions_save_name = 'stimulus_experiment_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_main_effect_conditions:\n",
    "    conditions_save_name = 'stimulus_main_effect_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_lwpc_conditions:\n",
    "    conditions_save_name = 'stimulus_lwpc_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_lwps_conditions:\n",
    "    conditions_save_name = 'stimulus_lwps_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_big_letter_conditions:\n",
    "    conditions_save_name = 'stimulus_big_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_small_letter_conditions:\n",
    "    conditions_save_name = 'stimulus_small_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_task_conditions:\n",
    "    conditions_save_name = 'stimulus_task_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_congruency_conditions:\n",
    "    conditions_save_name = 'stimulus_congruency_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_switch_type_conditions:\n",
    "    conditions_save_name = 'stimulus_switch_type_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_err_corr_conditions:\n",
    "    conditions_save_name = 'stimulus_err_corr_conditions_sem_green' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "\n",
    "elif conditions == experiment_conditions.response_conditions:\n",
    "    conditions_save_name = 'response_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_experiment_conditions:\n",
    "    conditions_save_name = 'response_experiment_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_big_letter_conditions:\n",
    "    conditions_save_name = 'response_big_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_small_letter_conditions:\n",
    "    conditions_save_name = 'response_small_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_task_conditions:\n",
    "    conditions_save_name = 'response_task_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_congruency_conditions:\n",
    "    conditions_save_name = 'response_congruency_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_switch_type_conditions:\n",
    "    conditions_save_name = 'response_switch_type_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_err_corr_conditions:\n",
    "    conditions_save_name = 'response_err_corr_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "    \n",
    "# Assuming 'combined_data' is your DataFrame and 'subjects' is your list of subject IDs\n",
    "#subjects_mne_objects = utils.create_subjects_mne_objects_dict(subjects=subjects, epochs_root_file=epochs_root_file, conditions=conditions, task=\"GlobalLocal\", just_HG_ev1_rescaled=True, acc_trials_only=True, error_trials_only=False)\n",
    "#one without selecting only correct trials\n",
    "subjects_mne_objects = utils.create_subjects_mne_objects_dict(subjects=subjects, epochs_root_file=epochs_root_file, conditions=conditions, task=\"GlobalLocal\", just_HG_ev1_rescaled=True, acc_trials_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b8444",
   "metadata": {},
   "source": [
    "### load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38778777",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_chans_per_subject = utils.get_sig_chans_per_subject(subjects, epochs_root_file, task='GlobalLocal', LAB_root=None)\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959842a",
   "metadata": {},
   "source": [
    "### get the significant electrodes across subjects for each ROI of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e56bd",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup\n",
    "ACC based on Destrieux et al 2010 definition is G_and_S_cingul-Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25517fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rois_dict = {\n",
    "#     # 'dlpfc': [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "#     # 'acc': [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"],\n",
    "#     # 'parietal': [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"],\n",
    "#     'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "#     'v1': [\"G_oc-temp_med-Lingual\", \"S_calcarine\", \"G_cuneus\"],\n",
    "#     'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"]\n",
    "# }\n",
    "\n",
    "# the cns 24/sfn 24 poster plots need just one roi. Fix all this code later. 10/1.\n",
    "# rois_dict = {\n",
    "#     'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"]\n",
    "# }\n",
    "\n",
    "rois_dict = {\n",
    "    'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"],\n",
    "    'dlpfc': [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    'acc': [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"],\n",
    "    'parietal': [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"],\n",
    "}\n",
    "\n",
    "rois = list(rois_dict.keys())\n",
    "                                                \n",
    "all_electrodes_per_subject_roi, sig_electrodes_per_subject_roi = make_sig_electrodes_per_subject_and_roi_dict(rois_dict, subjects_electrodestoROIs_dict, sig_chans_per_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b075f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('total sig elecs:', sum(len(sig_chans_per_subject[sub]) for sub in sig_chans_per_subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aeadde",
   "metadata": {},
   "source": [
    "get number of sig and all electrodes per subject and across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d6d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for roi in rois:\n",
    "    for sub in subjects:\n",
    "        sig_elecs = sig_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "        all_elecs = all_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "        print(f\"Subject {sub}, ROI {roi}, Num of Sig Electrodes: {len(sig_elecs)}, Num of All Electrodes: {len(all_elecs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "total_electrodes_info = utils.calculate_total_electrodes(sig_electrodes_per_subject_roi, all_electrodes_per_subject_roi)\n",
    "for roi, counts in total_electrodes_info.items():\n",
    "    print(f\"Total number of significant {roi} electrodes across all subjects:\", counts['total_significant_electrodes'])\n",
    "    print(f\"Total number of {roi} electrodes across all subjects:\", counts['total_electrodes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e82d9",
   "metadata": {},
   "source": [
    "check sampling rates to make sure they're all the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689a09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'subjects_mne_objects' is your dictionary containing MNE objects for each subject\n",
    "sampling_rate = 256\n",
    "subject_rates = utils.check_sampling_rates(subjects_mne_objects, expected_sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff1018",
   "metadata": {},
   "source": [
    "TODO: stats next (maybe do time perm cluster with t-test as follow-up test for ANOVA significance, let's try using MNE functions for ANOVA and perm test)   \n",
    "TODO: add in code for selecting electrodes of a specific ROI  \n",
    "TODO: plotting average traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f8636",
   "metadata": {},
   "source": [
    "now let's actually try plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(save_dir_root, epochs_root_file)\n",
    "\n",
    "evks_dict_sig_elecs = make_multi_channel_evokeds_for_all_conditions_and_rois(\n",
    "    subjects_mne_objects, subjects, rois, condition_names, \n",
    "    sig_electrodes_per_subject_roi\n",
    ") \n",
    "\n",
    "evks_dict_all_elecs = make_multi_channel_evokeds_for_all_conditions_and_rois(\n",
    "    subjects_mne_objects, subjects, rois, condition_names, \n",
    "    all_electrodes_per_subject_roi\n",
    ")\n",
    "\n",
    "plot_power_traces_for_all_rois(\n",
    "    evks_dict_all_elecs, rois, condition_names, conditions_save_name, plotting_parameters,\n",
    "    save_dir=save_dir,\n",
    "    error_type='sem', figsize=(12, 8), \n",
    "    x_label='Time from Stimulus Onset (s)', \n",
    "    y_label='Power (z)',\n",
    "    font_size=35, title_font_size=40, save_name_suffix='all_elecs'\n",
    ")\n",
    "\n",
    "plot_power_traces_for_all_rois(\n",
    "    evks_dict_sig_elecs, rois, condition_names, conditions_save_name, plotting_parameters,\n",
    "    save_dir=save_dir,\n",
    "    error_type='sem', figsize=(12, 8), \n",
    "    x_label='Time from Stimulus Onset (s)', \n",
    "    y_label='Power (z)',\n",
    "    font_size=35, title_font_size=40, save_name_suffix='sig_elecs'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca8027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.analysis.config.plotting_parameters as plotting_parameters\n",
    "\n",
    "# This will print the exact path of the file Python is loading\n",
    "print(plotting_parameters.__file__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c7847",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
