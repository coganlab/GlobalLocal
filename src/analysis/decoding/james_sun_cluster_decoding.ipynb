{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a4ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: Keras package is not installed. You will be unable to useall neural net decoders\n",
      "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n",
      "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "# Get the absolute path to the directory containing the current script\n",
    "# For GlobalLocal/src/analysis/preproc/make_epoched_data.py, this is GlobalLocal/src/analysis/preproc\n",
    "try:\n",
    "    # This will work if running as a .py script\n",
    "    current_file_path = os.path.abspath(__file__)\n",
    "    current_script_dir = os.path.dirname(current_file_path)\n",
    "except NameError:\n",
    "    # This will be executed if __file__ is not defined (e.g., in a Jupyter Notebook)\n",
    "    # os.getcwd() often gives the directory of the notebook,\n",
    "    # or the directory from which the Jupyter server was started.\n",
    "    current_script_dir = os.getcwd()\n",
    "\n",
    "# Navigate up three levels to get to the 'GlobalLocal' directory\n",
    "project_root = os.path.abspath(os.path.join(current_script_dir, '..', '..', '..'))\n",
    "\n",
    "# Add the 'GlobalLocal' directory to sys.path if it's not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root) # insert at the beginning to prioritize it\n",
    "    \n",
    "from functools import partial\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "from ieeg.calc.mat import LabeledArray, combine\n",
    "from ieeg.viz.parula import parula_map\n",
    "\n",
    "# TODO: hmm fix these utils imports, import the funcs individually. 6/1/25.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# rsa toolbox imports\n",
    "from rsatoolbox.io.mne import read_epochs\n",
    "from rsatoolbox.data.ops import merge_datasets\n",
    "from rsatoolbox.rdm import calc_rdm_movie\n",
    "from rsatoolbox.rdm.calc import _parse_input\n",
    "from rsatoolbox.util.build_rdm import _build_rdms\n",
    "from rsatoolbox.rdm import compare\n",
    "from rsatoolbox.vis import show_rdm\n",
    "from rsatoolbox.vis.timecourse import plot_timecourse\n",
    "\n",
    "from os.path import join, expanduser, basename\n",
    "import glob, json\n",
    "import numpy, tqdm, mne, pandas\n",
    "import rsatoolbox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from ieeg.decoding.decoders import PcaLdaClassification\n",
    "from ieeg.calc.oversample import MinimumNaNSplit\n",
    "from ieeg.calc.fast import mixup\n",
    "\n",
    "from src.analysis.config import experiment_conditions\n",
    "\n",
    "from src.analysis.utils.labeled_array_utils import (\n",
    "    put_data_in_labeled_array_per_roi_subject,\n",
    "    remove_nans_from_labeled_array,\n",
    "    remove_nans_from_all_roi_labeled_arrays,\n",
    "    concatenate_conditions_by_string,\n",
    "    get_data_in_time_range\n",
    ")\n",
    "\n",
    "from src.analysis.decoding.decoding import (\n",
    "    concatenate_and_balance_data_for_decoding, \n",
    "    get_and_plot_confusion_matrix_for_rois_jim,\n",
    "    Decoder, \n",
    "    windower,\n",
    "    get_confusion_matrices_for_rois_time_window_decoding_jim,\n",
    "    compute_accuracies,\n",
    "    perform_time_perm_cluster_test_for_accuracies,\n",
    "    plot_accuracies,\n",
    "    mixup2\n",
    ")\n",
    "\n",
    "from src.analysis.spec.wavelet_functions import get_uncorrected_wavelets, get_uncorrected_multitaper, get_sig_tfr_differences, plot_mask_pages\n",
    "from src.analysis.spec.subjects_tfr_objects_functions import load_or_make_subjects_tfr_objects, get_sig_tfr_differences_per_subject, get_sig_tfr_differences_per_roi\n",
    "\n",
    "from src.analysis.utils.general_utils import (\n",
    "    make_or_load_subjects_electrodes_to_ROIs_dict,\n",
    "    get_good_data,\n",
    "    get_sig_chans_per_subject,\n",
    "    make_sig_electrodes_per_subject_and_roi_dict,\n",
    "    calculate_total_electrodes,\n",
    "    check_sampling_rates\n",
    ")\n",
    "\n",
    "import mne.time_frequency\n",
    "from ieeg.calc.scaling import rescale\n",
    "from ieeg.timefreq.utils import wavelet_scaleogram, crop_pad\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from typing import Union, List, Sequence, Dict\n",
    "import doctest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d07116",
   "metadata": {},
   "source": [
    "#### 0. Load data.   \n",
    "Need a way to load in the frequency information too, not just trials x channels x timepoints. Because I'm going to use frequency as a decoding feature too. For each electrode, for each training set, I think I can just mask the multitaper with the significant clusters and use that as the decoding feature, and then concatenate across electrodes to build the full training matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c04940ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the subjects' electrodes-to-ROIs dictionary...\n",
      "Loaded data from C:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\config\\subjects_electrodestoROIs_dict.json\n",
      "Dictionary loaded successfully. Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103', 'D0107A', 'D0110', 'D0116', 'D0117', 'D0121']\n",
    "\n",
    "# params - these will become input variables once i functionalize this stuff\n",
    "subjects = ['D0103']\n",
    "signal_times = [-1.0, 1.5]\n",
    "acc_trials_only = False\n",
    "error_trials_only = False\n",
    "stat_func = partial(ttest_ind, equal_var=False, nan_policy='omit')\n",
    "p_thresh = 0.2\n",
    "ignore_adjacency = 1 # ignore the channels dimension for clusters, just find clusters over frequency and time\n",
    "n_perm = 10\n",
    "n_jobs = 1\n",
    "freqs = np.arange(2, 200., 4.)\n",
    "n_cycles = freqs / 2\n",
    "return_itc = False\n",
    "time_bandwidth=10 \n",
    "spec_method = 'multitaper'\n",
    "average=False\n",
    "seed=None\n",
    "tails=2\n",
    "n_splits=2\n",
    "n_repeats=1\n",
    "random_state=42\n",
    "\n",
    "# load in subjects electrodes to rois dict. If it doesn't already exist, make it and then load it.\n",
    "config_dir = r'C:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\config'\n",
    "subjects_electrodestoROIs_dict = make_or_load_subjects_electrodes_to_ROIs_dict(subjects, task='GlobalLocal', LAB_root=None, save_dir=config_dir, \n",
    "                                                filename='subjects_electrodestoROIs_dict.json')\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "\n",
    "USER = os.path.basename(HOME)\n",
    "\n",
    "if os.name == 'nt':  # Windows\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "elif sys.platform == 'darwin':  # macOS\n",
    "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "else:  # Linux (cluster)\n",
    "    # Check if we're on the cluster by looking for /cwork directory\n",
    "    if os.path.exists(f\"/cwork/{USER}\"):\n",
    "        LAB_root = f\"/cwork/{USER}\"\n",
    "    else:\n",
    "        # Fallback for other Linux systems\n",
    "        LAB_root = os.path.join(HOME, \"CoganLab\")\n",
    "\n",
    "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
    "\n",
    "task='GlobalLocal'\n",
    "conditions = experiment_conditions.stimulus_big_letter_conditions # set this to whichever conditions you're running\n",
    "\n",
    "stimulus_locked = True  #toggle\n",
    "response_locked = not stimulus_locked\n",
    "\n",
    "if stimulus_locked:\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_0.0-30.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "\n",
    "elif response_locked:\n",
    "    # epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind\"\n",
    "    epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind\"\n",
    "\n",
    "condition_names = list(conditions.keys()) # get the condition names as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "531435b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if conditions == experiment_conditions.stimulus_conditions:\n",
    "    conditions_save_name = 'stimulus_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_experiment_conditions:\n",
    "    conditions_save_name = 'stimulus_experiment_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_main_effect_conditions:\n",
    "    conditions_save_name = 'stimulus_main_effect_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_lwpc_conditions:\n",
    "    conditions_save_name = 'stimulus_lwpc_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_lwps_conditions:\n",
    "    conditions_save_name = 'stimulus_lwps_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_big_letter_conditions:\n",
    "    conditions_save_name = 'stimulus_big_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_small_letter_conditions:\n",
    "    conditions_save_name = 'stimulus_small_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_task_conditions:\n",
    "    conditions_save_name = 'stimulus_task_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_congruency_conditions:\n",
    "    conditions_save_name = 'stimulus_congruency_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_switch_type_conditions:\n",
    "    conditions_save_name = 'stimulus_switch_type_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "\n",
    "elif conditions == experiment_conditions.response_conditions:\n",
    "    conditions_save_name = 'response_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_experiment_conditions:\n",
    "    conditions_save_name = 'response_experiment_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_big_letter_conditions:\n",
    "    conditions_save_name = 'response_big_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_small_letter_conditions:\n",
    "    conditions_save_name = 'response_small_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_task_conditions:\n",
    "    conditions_save_name = 'response_task_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_congruency_conditions:\n",
    "    conditions_save_name = 'response_congruency_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_switch_type_conditions:\n",
    "    conditions_save_name = 'response_switch_type_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54dfc3",
   "metadata": {},
   "source": [
    "load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce4b49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0103\n"
     ]
    }
   ],
   "source": [
    "sig_chans_per_subject = get_sig_chans_per_subject(subjects, epochs_root_file, task='GlobalLocal', LAB_root=None)\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c70bea6",
   "metadata": {},
   "source": [
    "get the significant electrodes across subjects for each ROI of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43db4297",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup\n",
    "ACC based on Destrieux et al 2010 definition is G_and_S_cingul-Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48af7055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject D0057, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RAI6', 'RAI12', 'RAI13', 'RAI14', 'RAI15', 'RAI16', 'RPI15', 'RPI14', 'RAMF10', 'RAMF11', 'RAMF12', 'RAMF13', 'RAMF14', 'RAIF11', 'RAIF12', 'RAIF13', 'RAIF14']\n",
      "For subject D0059, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LMMF9', 'LMMF11', 'LMMF10', 'LMMF12', 'LPSF16']\n",
      "For subject D0063, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LASF10', 'LASF11', 'LASF14', 'LASF15', 'LASF16', 'LMSF5', 'LMSF6', 'LMSF12', 'LPSF10', 'LPSF12', 'ROF16', 'RAI16', 'RAMF11', 'RAMF12', 'RAMF13', 'RAMF14', 'RMMF13', 'RMMF14', 'RAI4', 'RAI6', 'RAI5', 'RAI10', 'RAI11', 'RASF15', 'RASF16', 'RMSF8', 'RMSF9', 'RMSF10', 'RMSF11', 'RMSF12', 'RMSF7', 'RAMF8', 'RAMF9', 'RAMF10', 'RMMF9', 'RMMF10']\n",
      "For subject D0065, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RASF13', 'RASF14', 'RASF15', 'RASF16', 'RMSF11', 'RMSF12', 'RMSF13', 'RMSF14', 'RI7']\n",
      "For subject D0069, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LOF8']\n",
      "For subject D0071, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO14', 'RFO16', 'RIA4', 'RIP6', 'RIA5', 'RIA11', 'RIA12', 'RIA13', 'RIA14', 'RIA16', 'RIP14', 'RIP15', 'RIP16']\n",
      "For subject D0077, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0090, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO15', 'RIA6', 'RIA11', 'RIA12', 'RIA14', 'RIA15', 'RIA16', 'RIP7']\n",
      "For subject D0094, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFO12', 'LFO13', 'LFO15', 'LFO16', 'LFAM8', 'LFAM9', 'LFAM10', 'LFAM13', 'LFAM14', 'LFPM10', 'LFPM11', 'LFPM12', 'LPAS1', 'LIA16', 'LFAI3', 'LFAI4', 'LFAI5', 'LFPI10', 'LPAI9', 'LPAI10', 'LIA4', 'LIA5', 'LFAI9', 'LFAI10', 'LIA11', 'LIA12', 'LIA13', 'LIA14']\n",
      "For subject D0100, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0102, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO13', 'RFO14', 'RFAM15', 'RFAI2', 'RFAI3']\n",
      "For subject D0103, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LFAM15', 'LAI4', 'LAI7', 'LAI8', 'LAI18', 'LFO15', 'LFAI4']\n",
      "For subject D0107A, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFOA16', 'RFOA17', 'RFOA18', 'RFAI3', 'RIA5', 'RIA6', 'RFAM7', 'RFAM9', 'RFAM10', 'RFAM11', 'RFAM12', 'RFMM9', 'RFMM11', 'RFMM12', 'RFMM13', 'RFMM14', 'RFMM15', 'RFMM8', 'RIA12', 'RIA13', 'RIA14', 'RIA15', 'RIA16', 'RIA17', 'RIA18']\n",
      "For subject D0110, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LASF10', 'LOF13', 'LOF15', 'LINS4', 'LINS5']\n",
      "For subject D0116, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFOA14', 'LFOA17', 'LFOA18', 'LFOP15', 'LFAM10', 'LFAM11', 'LFMM14', 'LAI12', 'LAI16', 'LFAM12', 'LAI7', 'LAI8', 'LFMI3', 'LFMI5', 'LFMI6', 'RFOA14', 'RFOA15', 'RFOA16', 'RFOP15', 'RFMM10', 'RFMM11', 'RFMM12', 'RAI7', 'RAI11', 'RAI12', 'RAI14', 'RAI15', 'RAI16', 'RAI17', 'RFMI4']\n",
      "For subject D0117, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RMOF15', 'RINSA15', 'RINSA16', 'RLOF10', 'RLOF11', 'RLOF16', 'RINSA3', 'RINSA11', 'RINSA12', 'RINSA13', 'RINSA14']\n",
      "For subject D0121, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFOA15', 'LFOP12', 'LFO5', 'LFO6', 'LFO8', 'LFO9', 'LFO12', 'LFO13', 'LFO14', 'LFO15', 'LFO16', 'LFO17', 'LFO18', 'LFA1', 'LFA2', 'LFP16', 'LFP17', 'LFPS1', 'LFPS2', 'LFPP1', 'LFOP13', 'LFOP15', 'LFOP16', 'LFOP18', 'LFA7', 'LFA8', 'LFAS6', 'LFAM8', 'LFAM9', 'LFA9', 'LFA10', 'LFA11', 'LFA12', 'LFAM10', 'LFAM11', 'LFAM12', 'LFMM8', 'LFMM9', 'LFMM10', 'LFMM11', 'LFMM12', 'LFAS7', 'LFAS8', 'LFAS9', 'LFAS10', 'LFMS7', 'LFMS9', 'LFMS10', 'LFMS11', 'LFMS12', 'LFPS6', 'LFPS7', 'LFPS9', 'LFPS10', 'LFPP7', 'LFPP9', 'LFPP10', 'LFMI4', 'LFMI5', 'LFMI8', 'LFMI9']\n",
      "Subject D0057 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0059 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0063 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0065 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0069 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0071 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0077 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0090 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0094 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0100 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0102 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0103 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LAI4', 'LAI7', 'LAI8', 'LFAI4']\n",
      "Subject D0107A significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0110 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0116 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0117 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0121 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "For subject D0057, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RPIT1']\n",
      "For subject D0059, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['LPT13']\n",
      "For subject D0063, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RMMT1', 'RMMT2']\n",
      "For subject D0065, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RPMT1', 'RPIT1', 'RPIT2']\n",
      "For subject D0069, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "For subject D0071, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPI1', 'RO1', 'RO2', 'RO10']\n",
      "For subject D0077, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPI2', 'ROPI5', 'ROPI6', 'ROPI8', 'ROPM9', 'ROPM11', 'ROPM12', 'ROPM1', 'ROPM8']\n",
      "For subject D0090, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPO1', 'RTPI1', 'RTPI2']\n",
      "For subject D0094, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "For subject D0100, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['LTOJ1', 'LTPI1', 'LOAI1', 'LOPI1', 'LOPI4', 'LOPM1', 'LTOJ3', 'LTOJ4', 'LOMM3', 'LOMM4', 'LOMM5', 'LOPM2', 'LTOJ13', 'LOAI12', 'LOAI13', 'LOAI14', 'LOAI15', 'LOMI8', 'LOMI9', 'LOMI11', 'LOMI12', 'LOPI9', 'LOPI10', 'LOAM15', 'LOMM15', 'LOPM10', 'LOMS13', 'LOMS14', 'LOMS15', 'LOPS9', 'LOPS11', 'LOPS12', 'LPPI14', 'LPPI15', 'LOMM13', 'LOMM14', 'LOMS11', 'LOMS12', 'LOPM8', 'LOPM9', 'LPPI7', 'LPPI8', 'LPPI9']\n",
      "For subject D0102, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTAI6', 'RTPI1']\n",
      "For subject D0103, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['LTLI3', 'LTPI2', 'LTPI3', 'LTPI4']\n",
      "For subject D0107A, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPI3']\n",
      "For subject D0110, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "For subject D0116, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "For subject D0117, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "For subject D0121, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "Subject D0057 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0059 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0063 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0065 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0069 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0071 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0077 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0090 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0094 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0100 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0102 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0103 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['LTPI2', 'LTPI3', 'LTPI4']\n",
      "Subject D0107A significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0110 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0116 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0117 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0121 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n"
     ]
    }
   ],
   "source": [
    "# rois_dict = {\n",
    "#     'dlpfc': [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "#     'acc': [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"],\n",
    "#     'parietal': [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"],\n",
    "#     'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "#     'v1': [\"G_oc-temp_med-Lingual\", \"S_calcarine\", \"G_cuneus\"],\n",
    "#     'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"]\n",
    "# }\n",
    "\n",
    "# rois_dict = {\n",
    "#     'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"]\n",
    "# }\n",
    "\n",
    "rois_dict = {\n",
    "    'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"]\n",
    "}\n",
    "\n",
    "rois = list(rois_dict.keys())\n",
    "all_electrodes_per_subject_roi, sig_electrodes_per_subject_roi = make_sig_electrodes_per_subject_and_roi_dict(rois_dict, subjects_electrodestoROIs_dict, sig_chans_per_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "280f6688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sig elecs: 82\n"
     ]
    }
   ],
   "source": [
    "print('total sig elecs:', sum(len(sig_chans_per_subject[sub]) for sub in sig_chans_per_subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e40e3c2",
   "metadata": {},
   "source": [
    "get number of sig and all electrodes per subject and across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3fd540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject D0103, ROI lpfc, Num of Sig Electrodes: 8, Num of All Electrodes: 11\n",
      "Subject D0103, ROI occ, Num of Sig Electrodes: 3, Num of All Electrodes: 4\n"
     ]
    }
   ],
   "source": [
    "for roi in rois:\n",
    "    for sub in subjects:\n",
    "        sig_elecs = sig_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "        all_elecs = all_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "        print(f\"Subject {sub}, ROI {roi}, Num of Sig Electrodes: {len(sig_elecs)}, Num of All Electrodes: {len(all_elecs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb5ec907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of significant lpfc electrodes across all subjects: 8\n",
      "Total number of lpfc electrodes across all subjects: 265\n",
      "Total number of significant occ electrodes across all subjects: 3\n",
      "Total number of occ electrodes across all subjects: 73\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "total_electrodes_info = calculate_total_electrodes(sig_electrodes_per_subject_roi, all_electrodes_per_subject_roi)\n",
    "for roi, counts in total_electrodes_info.items():\n",
    "    print(f\"Total number of significant {roi} electrodes across all subjects:\", counts['total_significant_electrodes'])\n",
    "    print(f\"Total number of {roi} electrodes across all subjects:\", counts['total_electrodes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a911b",
   "metadata": {},
   "source": [
    "#### 1. For each electrode, make multitaper using all training trials, for both conditions to be compared (this can only do two conditions, can't do more rn)\n",
    "\n",
    "TODO: Need to loop over the trials and use some as training set, and have some held out as a test set that isn't used to find clusters. Maybe do this in the stats step though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e60e7a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing TFR data. Loading from: C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\spec\\multitaper\\subjects_tfr_objects\\stimulus_big_letter_conditions_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False_1_subjects_multitaper\n"
     ]
    }
   ],
   "source": [
    "subjects_tfr_objects = load_or_make_subjects_tfr_objects(\n",
    "    layout=layout,\n",
    "    spec_method=spec_method,\n",
    "    conditions_save_name=conditions_save_name,\n",
    "    subjects=subjects,\n",
    "    conditions=conditions,\n",
    "    signal_times=signal_times,\n",
    "    freqs=freqs,\n",
    "    n_cycles=n_cycles,\n",
    "    time_bandwidth=time_bandwidth,\n",
    "    return_itc=return_itc,\n",
    "    n_jobs=n_jobs,\n",
    "    average=average,\n",
    "    acc_trials_only=acc_trials_only,\n",
    "    error_trials_only=error_trials_only \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f756323",
   "metadata": {},
   "source": [
    "#### 2. Find clusters that are significantly different between the two conditions, in the multitaper spectrogram  \n",
    "do this for all channels per subject, and then also for all channels in an roi across subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84da78fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # THIS TAKES FOREVER DON'T RUN IT, JUST FOR DEBUGGING SO I CAN PLOT THE SIG CLUSTERS\n",
    "\n",
    "# # For per-subject analysis (no electrode filtering needed)\n",
    "# sig_elec_masks_per_subject, sig_elec_pvals_per_subject = get_sig_tfr_differences_per_subject(subjects_tfr_objects=subjects_tfr_objects, condition_names=condition_names, stat_func=stat_func, p_thresh=p_thresh, n_perm=n_perm, ignore_adjacency=ignore_adjacency, n_jobs=n_jobs, seed=seed, tails=tails)\n",
    "\n",
    "# all_elec_masks_per_subject, all_elec_pvals_per_subject = get_sig_tfr_differences_per_subject(subjects_tfr_objects=subjects_tfr_objects, condition_names=condition_names, stat_func=stat_func, p_thresh=p_thresh, n_perm=n_perm, ignore_adjacency=ignore_adjacency, n_jobs=n_jobs, seed=seed, tails=tails)\n",
    "\n",
    "# # For per-ROI analysis (with electrode filtering)\n",
    "# sig_elec_masks_per_roi, sig_elec_pvals_per_roi = get_sig_tfr_differences_per_roi(subjects_tfr_objects=subjects_tfr_objects, electrodes_per_subject_roi=sig_electrodes_per_subject_roi, condition_names=condition_names, stat_func=stat_func, p_thresh=p_thresh, n_perm=n_perm, ignore_adjacency=ignore_adjacency, n_jobs=n_jobs, seed=seed, tails=tails)\n",
    "\n",
    "# all_elec_masks_per_roi, all_elec_pvals_per_roi = get_sig_tfr_differences_per_roi(subjects_tfr_objects=subjects_tfr_objects, electrodes_per_subject_roi=all_electrodes_per_subject_roi, condition_names=condition_names, stat_func=stat_func, p_thresh=p_thresh, n_perm=n_perm, ignore_adjacency=ignore_adjacency, n_jobs=n_jobs, seed=seed, tails=tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa06aa",
   "metadata": {},
   "source": [
    "plot these clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a83c8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TODO: Update the mean differences to be per subject and per roi, currently copied over from wavelet_differences.\n",
    "# first_sub = subjects[0]\n",
    "# first_condition = list(subjects_tfr_objects[first_sub].keys())[0]\n",
    "# ch_names = subjects_tfr_objects[first_sub][first_condition].ch_names\n",
    "# times = subjects_tfr_objects[first_sub][first_condition].times\n",
    "# freqs = subjects_tfr_objects[first_sub][first_condition].freqs\n",
    "\n",
    "# subjects_tfr_objects_save_dir = os.path.join(layout.root, 'derivatives', 'spec', spec_method, 'subjects_tfr_objects')\n",
    "\n",
    "# # Now plot the mask pages:\n",
    "# for sub in subjects:\n",
    "#     sig_elecs_mask = sig_elec_masks_per_subject[sub]\n",
    "#     sig_elecs_mask_pages = plot_mask_pages(sig_elecs_mask,\n",
    "#                     ch_names,\n",
    "#                     times=times,\n",
    "#                     freqs=freqs,\n",
    "#                     channels_per_page=60,\n",
    "#                     grid_shape=(6, 10),\n",
    "#                     cmap=parula_map,\n",
    "#                     title_prefix=f\"{sub} \",\n",
    "#                     log_freq=True,\n",
    "#                     show=False)\n",
    "\n",
    "#     # Save each page as a separate figure file:\n",
    "#     for i, fig in enumerate(sig_elecs_mask_pages):\n",
    "#         fig_name = f\"{sub}_sig_elecs_sig_{spec_method}_clusters_{conditions_save_name}_page_{i+1}.png\"\n",
    "#         fig_pathname = os.path.join(subjects_tfr_objects_save_dir, fig_name)\n",
    "#         fig.savefig(fig_pathname, bbox_inches='tight')\n",
    "#         print(\"Saved figure:\", fig_name)\n",
    "\n",
    "#     all_elecs_mask = all_elec_masks_per_subject[sub]\n",
    "#     all_elecs_mask_pages = plot_mask_pages(all_elecs_mask,\n",
    "#                         ch_names,\n",
    "#                         times=times,\n",
    "#                         freqs=freqs,\n",
    "#                         channels_per_page=60,\n",
    "#                         grid_shape=(6, 10),\n",
    "#                         cmap=parula_map,\n",
    "#                         title_prefix=f\"{sub} \",\n",
    "#                         log_freq=True,\n",
    "#                         show=False)\n",
    "\n",
    "#     # Save each page as a separate figure file:\n",
    "#     for i, fig in enumerate(all_elecs_mask_pages):\n",
    "#         fig_name = f\"{sub}_all_elecs_sig_{spec_method}_clusters_{conditions_save_name}_page_{i+1}.png\"\n",
    "#         fig_pathname = os.path.join(subjects_tfr_objects_save_dir, fig_name)\n",
    "#         fig.savefig(fig_pathname, bbox_inches='tight')\n",
    "#         print(\"Saved figure:\", fig_name)\n",
    "\n",
    "# for roi in rois:\n",
    "#     sig_elecs_roi_mask = sig_elec_masks_per_roi[roi]\n",
    "#     sig_elecs_roi_mask_pages = plot_mask_pages(sig_elecs_roi_mask,\n",
    "#                     ch_names,\n",
    "#                     times=times,\n",
    "#                     freqs=freqs,\n",
    "#                     channels_per_page=60,\n",
    "#                     grid_shape=(6, 10),\n",
    "#                     cmap=parula_map,\n",
    "#                     title_prefix=f\"{sub} {roi} \",\n",
    "#                     log_freq=True,\n",
    "#                     show=False)\n",
    "\n",
    "#     # Save each page as a separate figure file:\n",
    "#     for i, fig in enumerate(sig_elecs_roi_mask_pages):\n",
    "#         fig_name = f\"{sub}_{roi}_sig_elecs_sig_{spec_method}_clusters_{conditions_save_name}_page_{i+1}.png\"\n",
    "#         fig_pathname = os.path.join(subjects_tfr_objects_save_dir, fig_name)\n",
    "#         fig.savefig(fig_pathname, bbox_inches='tight')\n",
    "#         print(\"Saved figure:\", fig_name)\n",
    "\n",
    "#     all_elecs_roi_mask = all_elec_masks_per_roi[roi]\n",
    "#     all_elecs_roi_mask_pages = plot_mask_pages(all_elecs_roi_mask,\n",
    "#                     ch_names,\n",
    "#                     times=times,\n",
    "#                     freqs=freqs,\n",
    "#                     channels_per_page=60,\n",
    "#                     grid_shape=(6, 10),\n",
    "#                     cmap=parula_map,\n",
    "#                     title_prefix=f\"{sub} {roi} \",\n",
    "#                     log_freq=True,\n",
    "#                     show=False)\n",
    "\n",
    "#     # Save each page as a separate figure file:\n",
    "#     for i, fig in enumerate(all_elecs_roi_mask_pages):\n",
    "#         fig_name = f\"{sub}_{roi}_all_elecs_sig_{spec_method}_clusters_{conditions_save_name}_page_{i+1}.png\"\n",
    "#         fig_pathname = os.path.join(subjects_tfr_objects_save_dir, fig_name)\n",
    "#         fig.savefig(fig_pathname, bbox_inches='tight')\n",
    "#         print(\"Saved figure:\", fig_name)\n",
    "            \n",
    "# # # get the mean differences themselves and plot them\n",
    "# # mean_diff_inc_vs_con = mean_diff(incongruent_spec._data, congruent_spec._data, axis=0)\n",
    "# # mean_diff_switch_vs_repeat = mean_diff(switch_spec._data, repeat_spec._data, axis=0)\n",
    "\n",
    "# # # Now, plot the mean differences directly:\n",
    "# # congruency_mean_diff_pages = plot_mask_pages(\n",
    "# #     mean_diff_inc_vs_con,\n",
    "# #     incongruent_spec.ch_names,\n",
    "# #     times=incongruent_spec.times,\n",
    "# #     freqs=incongruent_spec.freqs,\n",
    "# #     grid_shape=(6, 10),\n",
    "# #     cmap=parula_map,  # play with color maps\n",
    "# #     title_prefix=f\"{sub} Mean Inc-Con Diff: \",\n",
    "# #     log_freq=True,\n",
    "# #     show=False\n",
    "# # )\n",
    "\n",
    "# # # Save each page as a separate figure file:\n",
    "# # for i, fig in enumerate(congruency_mean_diff_pages):\n",
    "# #     if rescaled:\n",
    "# #         fig_name = f\"{sub}_inc-con_mean_diff_multitaper_{conditions_and_output_names_and_events['incongruent']['output_name']}-{conditions_and_output_names_and_events['congruent']['output_name']}_rescaled_page_{i+1}.jpg\"\n",
    "# #     else:\n",
    "# #         fig_name = f\"{sub}_inc-con_mean_diff_multitaper_{conditions_and_output_names_and_events['incongruent']['output_name']}-{conditions_and_output_names_and_events['congruent']['output_name']}_uncorrected_page_{i+1}.jpg\"\n",
    "# #     fig_pathname = os.path.join(save_dir, fig_name)\n",
    "# #     fig.savefig(fig_pathname, bbox_inches='tight')\n",
    "# #     print(\"Saved figure:\", fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c66f9d5",
   "metadata": {},
   "source": [
    "let's try creating roi labeled arrays and then masking these and decoding using them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4c8d35",
   "metadata": {},
   "source": [
    "make roi_labeled_arrays, a dict where the keys are rois and the values are LabeledArrays. Index the same way as a nested dict. Use .labels to get labels from current level.\n",
    "\n",
    "\n",
    "#### roi_labeled_arrays structure\n",
    "- **roi1**: ROI name, string\n",
    "  - **conditions**: condition name\n",
    "    - **trials**: This is the maximal number of trials across subjects for any condition, filled with nans for subjects who don't have this many trials\n",
    "      - **channels**: This is the number of channels in the roi, each channel is labeled as subject-channel name. Concatenated across subjects.\n",
    "        - **freqs**: This is the number of frequencies in the roi, each frequency is labeled as frequency name.\n",
    "          - **samples**: 1 sample as a float. This is the time for this sample.\n",
    "\n",
    "- **roi2**: ROI name, string\n",
    "  - **conditions**: condition name\n",
    "    - **trials**: This is the maximal number of trials across subjects for any condition, filled with nans for subjects who don't have this many trials\n",
    "      - **channels**: This is the number of channels in the roi, each channel is labeled as subject-channel name. Concatenated across subjects.\n",
    "        - **freqs**: This is the number of frequencies in the roi, each frequency is labeled as frequency name.\n",
    "          - **samples**: 1 sample as a float. This is the time for this sample.\n",
    "\n",
    "- **roiX**: ROI name, string\n",
    "  - **conditions**: condition name\n",
    "    - **trials**: This is the maximal number of trials across subjects for any condition, filled with nans for subjects who don't have this many trials\n",
    "      - **channels**: This is the number of channels in the roi, each channel is labeled as subject-channel name. Concatenated across subjects.\n",
    "        - **freqs**: This is the number of frequencies in the roi, each frequency is labeled as frequency name.\n",
    "          - **samples**: 1 sample as a float. This is the time for this sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08b236c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI 'lpfc': Maximum trials per condition:\n",
      "  Condition 'Stimulus_bigS': 176 trials from subjects ['D0103']\n",
      "  Condition 'Stimulus_bigH': 183 trials from subjects ['D0103']\n",
      "in roi lpfc, subject D0103 has 176 trials for condition Stimulus_bigS\n",
      "in roi lpfc, subject D0103 has 183 trials for condition Stimulus_bigH\n",
      "Subject D0103, ROI lpfc, LabeledArray shape: (2, 183, 11, 3, 142)\n",
      "ROI 'occ': Maximum trials per condition:\n",
      "  Condition 'Stimulus_bigS': 176 trials from subjects ['D0103']\n",
      "  Condition 'Stimulus_bigH': 183 trials from subjects ['D0103']\n",
      "in roi occ, subject D0103 has 176 trials for condition Stimulus_bigS\n",
      "in roi occ, subject D0103 has 183 trials for condition Stimulus_bigH\n",
      "Subject D0103, ROI occ, LabeledArray shape: (2, 183, 4, 3, 142)\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "\n",
    "# choose whether to use sig elecs or all elecs\n",
    "electrodes = all_electrodes_per_subject_roi # toggle this to sig_electrodes_per_subject_roi if just using sig elecs, or electrodes_per_subject_roi if using all elecs\n",
    "\n",
    "if electrodes == all_electrodes_per_subject_roi:\n",
    "    elec_string_to_add_to_filename = 'all_elecs'\n",
    "elif electrodes == sig_electrodes_per_subject_roi:\n",
    "    elec_string_to_add_to_filename = 'sig_elecs'\n",
    "else:\n",
    "    elec_string_to_add_to_filename = None\n",
    "\n",
    "roi_labeled_arrays = put_data_in_labeled_array_per_roi_subject(\n",
    "    subjects_tfr_objects,\n",
    "    condition_names,\n",
    "    rois,\n",
    "    subjects,\n",
    "    electrodes, \n",
    "    obs_axs=0,  # Trials dimension (ignoring the conditions dimension for now cuz we iterate over it)\n",
    "    chans_axs=1,  # Channels dimension\n",
    "    freq_axs=2,\n",
    "    time_axs=3,   # Time dimension\n",
    "    random_state=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e04536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move all this into decoding.py once i get it working\n",
    "\n",
    "def decode_on_sig_tfr_clusters(\n",
    "    X_train_raw, y_train, X_test_raw,\n",
    "    train_indices, \n",
    "    roi_labeled_array, condition_names, obs_axs, chans_axs,\n",
    "    stat_func, p_thresh, n_perm,\n",
    "    Decoder, cats, explained_variance, oversample,\n",
    "    ignore_adjacency=1, seed=42, tails=2, alpha=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Balance data and decode with TFR cluster masking.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_train_raw : np.ndarray\n",
    "        Raw training data (trials, channels, freqs, times)\n",
    "    y_train : np.ndarray\n",
    "        Training labels\n",
    "    X_test_raw : np.ndarray\n",
    "        Raw test data\n",
    "    train_indices : np.ndarray\n",
    "        Indices of training trials in the original roi_labeled_array\n",
    "    roi_labeled_array : LabeledArray\n",
    "        The full roi labeled array for extracting channel info\n",
    "    condition_names : list\n",
    "        List of condition names to compare\n",
    "    obs_axs : int\n",
    "        Axis of the roi_labeled_array that contains trial labels\n",
    "    chans_axs : int\n",
    "        Axis of the roi_labeled_array that contains channel labels\n",
    "    stat_func : function\n",
    "        Statistical function for cluster computation\n",
    "    p_thresh : float\n",
    "        P-value threshold for significance\n",
    "    n_perm : int\n",
    "        Number of permutations\n",
    "    Decoder : class\n",
    "        Decoder class to use for decoding\n",
    "    cats : list\n",
    "        List of category names\n",
    "    explained_variance : float\n",
    "        Proportion of variance to explain with PCA\n",
    "    oversample : bool\n",
    "        Whether to oversample the training data\n",
    "    ignore_adjacency : int\n",
    "        Whether to ignore adjacency in clustering\n",
    "    seed : int\n",
    "        Random seed\n",
    "    tails : int\n",
    "        Number of tails for statistical test\n",
    "    alpha : float\n",
    "        Alpha parameter for mixup augmentation\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Get channel labels from the labeled array as a list\n",
    "    channel_labels = roi_labeled_array.labels[chans_axs+1] # add 1 to the chans axs because of the conditions axis that got addd\n",
    "    \n",
    "    # Step 1: Create training-only TFR masks\n",
    "    channel_masks = compute_sig_tfr_masks_from_roi_labeled_array(\n",
    "        roi_labeled_array, train_indices, condition_names, \n",
    "        obs_axs, chans_axs,\n",
    "        stat_func, p_thresh, n_perm, \n",
    "        ignore_adjacency, seed, tails\n",
    "    )\n",
    "    \n",
    "    # Step 2: Apply masks and flatten (now passing channel_labels)\n",
    "    X_train_masked = apply_tfr_masks_and_flatten_to_make_decoding_matrix(X_train_raw, obs_axs, chans_axs, channel_masks, channel_labels)\n",
    "    X_test_masked = apply_tfr_masks_and_flatten_to_make_decoding_matrix(X_test_raw, obs_axs, chans_axs, channel_masks, channel_labels)\n",
    "    \n",
    "    # Step 3: Decode\n",
    "    decoder = Decoder(cats, explained_variance=explained_variance, n_splits=1, n_repeats=1, oversample=oversample)\n",
    "    \n",
    "    # Handle NaN filling using existing mixup2 function\n",
    "    mixup2(arr=X_train_masked, labels=y_train, obs_axs=obs_axs, alpha=alpha, seed=seed)\n",
    "    \n",
    "    # Fill test NaNs with noise (as done in sample_fold)\n",
    "    is_nan = np.isnan(X_test_masked)\n",
    "    X_test_masked[is_nan] = np.random.normal(0,1,np.sum(is_nan))\n",
    "\n",
    "    # Fit and predict\n",
    "    decoder.fit(X_train_masked, y_train)\n",
    "    preds = decoder.predict(X_test_masked)\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def compute_sig_tfr_masks_from_roi_labeled_array(\n",
    "    roi_labeled_array, train_indices, condition_names,\n",
    "    obs_axs, chans_axs, stat_func, p_thresh, n_perm, \n",
    "    ignore_adjacency=1, seed=42, tails=2\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute significant TFR clusters using only training trials from roi_labeled_array.\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    channel_masks : dict\n",
    "        {channel_label: mask_array} where mask is (n_freqs, n_times)\n",
    "    \"\"\"\n",
    "    channel_masks = {}\n",
    "    \n",
    "    # Get channel labels from the labeled array\n",
    "    channel_labels = roi_labeled_array.labels[chans_axs+1]\n",
    "\n",
    "    # Validate we have exactly 2 conditions for now\n",
    "    if len(condition_names) != 2:\n",
    "        raise ValueError(\n",
    "            f\"For now, just doing perm test instead of ANOVA, \"\n",
    "            f\"so this will only work for two conditions. Got {len(condition_names)} conditions.\"\n",
    "        )\n",
    "\n",
    "    # Split training data by condition\n",
    "    train_data_by_condition = {}\n",
    "    for cond in condition_names:  # hmm the stats only work for two conditions, so just do two conditions for now. Can expand to >2 conditions in the future, would just need to do ANOVA i think instead of time perm cluster.\n",
    "        # Extract training trials for this condition\n",
    "        cond_data = roi_labeled_array[cond]  # Shape: (trials, channels, freqs, times). Test this!\n",
    "        cond_train_data = np.take(cond_data, train_indices, axis=obs_axs) # TODO: keep going through this code 4:45 on 8/1 - huh? this is a 4d array, check what train_indices is. Should grab along the trials axis. Maybe do np.take(train_indices, axis=obs_axs) to be safe.\n",
    "        train_data_by_condition[cond] = cond_train_data\n",
    "    \n",
    "    # For each channel, compute significant clusters\n",
    "    n_channels = len(channel_labels)\n",
    "    for ch_idx in range(n_channels):\n",
    "        ch_label = channel_labels[ch_idx]\n",
    "        \n",
    "        # Get data for this channel across conditions\n",
    "        cond_data_this_chan = {}\n",
    "        for cond in condition_names:\n",
    "            cond_data_this_chan[cond] = np.take(train_data_by_condition[cond], ch_idx, axis=chans_axs)\n",
    "        \n",
    "        # TODO: Once I implement ANOVA, don't hard code cond1 and cond2 data, just use the cond_data_this_chan dict and feed it into some get_sig_tfr_differences function that implements ANOVA instead of time perm cluster. \n",
    "        cond0_data = cond_data_this_chan[condition_names[0]]\n",
    "        cond1_data = cond_data_this_chan[condition_names[1]]\n",
    "\n",
    "        # Run time perm cluster (TODO: implement ANOVA too as another option for when i'm decoding more than two conditions)\n",
    "        if len(cond0_data) > 0 and len(cond1_data) > 0:\n",
    "            mask, _ = get_sig_tfr_differences(\n",
    "                cond0_data, cond1_data,\n",
    "                stat_func=stat_func,\n",
    "                p_thresh=p_thresh,\n",
    "                n_perm=n_perm,\n",
    "                axis=obs_axs,  # trials axis\n",
    "                ignore_adjacency=ignore_adjacency,\n",
    "                seed=seed,\n",
    "                tails=tails\n",
    "            )\n",
    "            channel_masks[ch_label] = mask\n",
    "        else:\n",
    "            # No data for comparison\n",
    "            channel_masks[ch_label] = np.zeros(\n",
    "                (cond1_data.shape[1], cond1_data.shape[2]), dtype=bool\n",
    "            )\n",
    "            raise ValueError(f\"cond 0 has {len(cond0_data)} trials and cond 1 has {len(cond1_data)} trials. Can't decode! \")\n",
    "    \n",
    "    return channel_masks\n",
    "\n",
    "def apply_tfr_masks_and_flatten_to_make_decoding_matrix(data, obs_axs, chans_axs, channel_masks, channel_labels):\n",
    "    \"\"\"\n",
    "    Apply channel-specific TFR masks and flatten feature matrices into vectors for each trial, ultimately resulting in a trials x features matrix\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : np.ndarray\n",
    "        Shape: (n_trials, n_channels, n_freqs, n_times)\n",
    "    obs_axs : int\n",
    "        Axis of the data that contains trial labels\n",
    "    chans_axs : int\n",
    "        Axis of the data that contains channel labels\n",
    "    channel_masks : dict\n",
    "        {channel_label: mask_array} where channel_label is like \"D0103-LPFC1\"\n",
    "    channel_labels : list\n",
    "        List of channel labels in the same order as data's channel dimension\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    decoding_matrix : np.ndarray\n",
    "        Shape: (n_trials, n_features)\n",
    "    \"\"\"\n",
    "    n_trials, n_channels = data.shape[obs_axs], data.shape[chans_axs]\n",
    "    feature_vectors = []\n",
    "    \n",
    "    # Move trials to first axis if needed - TODO: check if this is necessary..?\n",
    "    if obs_axs != 0:\n",
    "        data = np.moveaxis(data, obs_axs, 0)\n",
    "        chans_axs = chans_axs - 1 if chans_axs > obs_axs else chans_axs\n",
    "\n",
    "    # Iterate through each channel\n",
    "    for ch_idx in range(n_channels):\n",
    "        # Extract this channel's data for all trials\n",
    "        # Shape changes from (n_trials, n_channels, n_freqs, n_times) \n",
    "        # to (n_trials, n_freqs, n_times)\n",
    "        channel_data = np.take(data, ch_idx, chans_axs)\n",
    "        \n",
    "        # Get the label for this channel index\n",
    "        ch_label = channel_labels[ch_idx]  # e.g., \"D0103-LPFC1\"\n",
    "        \n",
    "        # Check if we have a mask for this channel\n",
    "        if ch_label in channel_masks:\n",
    "            # Get the boolean mask (n_freqs, n_times)\n",
    "            mask = channel_masks[ch_label]\n",
    "            \n",
    "            # Apply mask to each trial's data\n",
    "            # channel_data[:, mask] selects only the True positions in mask, because mask is n freqs x n times\n",
    "            # This reduces (n_trials, n_freqs, n_times) to (n_trials, n_significant_features)\n",
    "            masked_features = channel_data[:, mask]\n",
    "            \n",
    "            # Note: reshape(n_trials, -1) is redundant here since it's already 2D\n",
    "            # masked_features is already (n_trials, n_features)\n",
    "        else:\n",
    "            # No mask for this channel - use all time-frequency points\n",
    "            # Flatten from (n_trials, n_freqs, n_times) to (n_trials, n_freqs*n_times)\n",
    "            masked_features = channel_data.reshape(n_trials, -1)\n",
    "        \n",
    "        # Add this channel's features to our list\n",
    "        feature_vectors.append(masked_features)\n",
    "    \n",
    "    # Concatenate all channels' features horizontally\n",
    "    # If channel 1 has 50 features and channel 2 has 30 features,\n",
    "    # result will have 80 features total\n",
    "    decoding_matrix = np.concatenate(feature_vectors, axis=chans_axs)\n",
    "    return decoding_matrix\n",
    "\n",
    "def get_confusion_matrix_for_rois_tfr_cluster(\n",
    "    roi_labeled_arrays, rois, strings_to_find, stat_func, \n",
    "    Decoder, explained_variance=0.95,\n",
    "    p_thresh=0.05, n_perm=100, \n",
    "    n_splits=5, n_repeats=5, obs_axs=0, chans_axs=1,\n",
    "    balance_method='subsample', oversample=False,\n",
    "    random_state=42, alpha=0.2\n",
    "):\n",
    "    \"\"\"\n",
    "    Modified version that uses TFR cluster masking.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    roi_labeled_arrays : dict\n",
    "        Dictionary of labeled arrays by ROI\n",
    "    rois : list\n",
    "        List of ROIs to process\n",
    "    strings_to_find : list\n",
    "        List of condition strings to find\n",
    "    stat_func : function\n",
    "        Statistical function for cluster computation\n",
    "    Decoder : class\n",
    "        Decoder class to use. Not sure if this will work with other decoders besides PCA-LDA.\n",
    "    explained_variance : float\n",
    "        Variance to explain in PCA\n",
    "    p_thresh : float\n",
    "        P-value threshold\n",
    "    n_perm : int\n",
    "        Number of permutations\n",
    "    n_splits : int\n",
    "        Number of CV splits\n",
    "    n_repeats : int\n",
    "        Number of CV repeats\n",
    "    obs_axs : int\n",
    "        Observation axis\n",
    "    chans_axs : int\n",
    "        Channel axis\n",
    "    balance_method : str\n",
    "        Method for balancing ('subsample' or 'oversample')\n",
    "    oversample : bool\n",
    "        Whether to oversample in decoder\n",
    "    random_state : int\n",
    "        Random seed\n",
    "    alpha : float\n",
    "        Mixup alpha parameter\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    confusion_matrices : dict\n",
    "        Dictionary of confusion matrices by ROI\n",
    "    \"\"\"\n",
    "    confusion_matrices = {}\n",
    "    \n",
    "    for roi in rois:\n",
    "        print(f\"Processing ROI: {roi}\")\n",
    "        \n",
    "        # Get data and labels\n",
    "        concatenated_data, labels, cats = concatenate_and_balance_data_for_decoding(\n",
    "            roi_labeled_arrays, roi, strings_to_find, obs_axs, balance_method, random_state\n",
    "        )\n",
    "        \n",
    "        # Set up cross-validation\n",
    "        all_cms = []\n",
    "        \n",
    "        for repeat in range(n_repeats):\n",
    "            repeat_seed = random_state + repeat * 1000\n",
    "            skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=repeat_seed)\n",
    "            \n",
    "            fold_cms = []\n",
    "            \n",
    "            for fold_idx, (train_indices, test_indices) in enumerate(skf.split(concatenated_data, labels)):\n",
    "                print(f\"  Repeat {repeat+1}/{n_repeats}, Fold {fold_idx+1}/{n_splits}\")\n",
    "                \n",
    "                # Get train/test data\n",
    "                X_train_raw = concatenated_data[train_indices]\n",
    "                X_test_raw = concatenated_data[test_indices]\n",
    "                y_train = labels[train_indices]\n",
    "                y_test = labels[test_indices]\n",
    "                \n",
    "                # Balance and decode with TFR masking\n",
    "                preds = decode_on_sig_tfr_clusters(\n",
    "                    X_train_raw, y_train, X_test_raw, y_test,\n",
    "                    train_indices,\n",
    "                    roi_labeled_arrays[roi], condition_names, obs_axs, chans_axs,\n",
    "                    stat_func, p_thresh, n_perm,\n",
    "                    Decoder, cats, explained_variance, oversample,\n",
    "                    ignore_adjacency=1, seed=repeat_seed + fold_idx, tails=2, alpha=alpha\n",
    "                )\n",
    "                \n",
    "                cm = confusion_matrix(y_test, preds)\n",
    "                fold_cms.append(cm)\n",
    "            \n",
    "            # Sum across folds\n",
    "            repeat_cm = np.sum(fold_cms, axis=0)\n",
    "            all_cms.append(repeat_cm)\n",
    "        \n",
    "        # Average across repeats\n",
    "        final_cm = np.mean(all_cms, axis=0)\n",
    "        confusion_matrices[roi] = final_cm\n",
    "    \n",
    "    return confusion_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ff3c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f041336f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    import mne\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    import numpy as np\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    from typing import Dict, List\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    ch_names = ['CH1', 'CH2', 'CH3', 'CH4', 'CH5']\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    sfreq = 200.0\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    info = mne.create_info(ch_names=ch_names, sfreq=sfreq, ch_types='seeg')\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    n_epochs, n_freqs, n_times = 2, 10, 50\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    data = np.random.randn(n_epochs, len(ch_names), n_freqs, n_times)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    freqs = np.arange(10., 20., 1.)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    times = np.linspace(-0.5, 1.0, n_times)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    tfr_mock = mne.time_frequency.EpochsTFR(info, data, times, freqs)\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    subjects_tfr_objects_mock = {'sub_1': {'condition_1': tfr_mock, 'condition_2': tfr_mock.copy()}}\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    electrodes_per_subject_roi_mock = {\n",
      "        'roi_1': {'sub_1': ['CH1', 'CH2', 'CH3']},\n",
      "        'roi_2': {'sub_1': ['CH4', 'CH5']}\n",
      "    }\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    subjects_tfr_objects_for_roi_1 = get_subjects_tfr_objects_for_specific_roi(\n",
      "        subjects_tfr_objects=subjects_tfr_objects_mock,\n",
      "        electrodes_per_subject_roi=electrodes_per_subject_roi_mock,\n",
      "        roi='roi_1',\n",
      "        subjects=['sub_1'],\n",
      "        condition_names=['condition_1', 'condition_2']\n",
      "    )\n",
      "Expecting nothing\n",
      "**********************************************************************\n",
      "File \"__main__\", line 40, in __main__.get_subjects_tfr_objects_for_specific_roi\n",
      "Failed example:\n",
      "    subjects_tfr_objects_for_roi_1 = get_subjects_tfr_objects_for_specific_roi(\n",
      "        subjects_tfr_objects=subjects_tfr_objects_mock,\n",
      "        electrodes_per_subject_roi=electrodes_per_subject_roi_mock,\n",
      "        roi='roi_1',\n",
      "        subjects=['sub_1'],\n",
      "        condition_names=['condition_1', 'condition_2']\n",
      "    )\n",
      "Expected nothing\n",
      "Got:\n",
      "    Subject sub_1, Condition condition_1: Selected 3/5 channels for ROI roi_1\n",
      "    Subject sub_1, Condition condition_2: Selected 3/5 channels for ROI roi_1\n",
      "Trying:\n",
      "    print(\"Original channels:\", subjects_tfr_objects_mock['sub_1']['condition_1'].ch_names)\n",
      "Expecting:\n",
      "    Original channels: ['CH1', 'CH2', 'CH3', 'CH4', 'CH5']\n",
      "ok\n",
      "Trying:\n",
      "    print(\"Filtered channels for roi_1:\", subjects_tfr_objects_for_roi_1['sub_1']['condition_1'].ch_names)\n",
      "Expecting:\n",
      "    Filtered channels for roi_1: ['CH1', 'CH2', 'CH3']\n",
      "ok\n",
      "1 items had no tests:\n",
      "    __main__\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of  16 in __main__.get_subjects_tfr_objects_for_specific_roi\n",
      "16 tests in 2 items.\n",
      "15 passed and 1 failed.\n",
      "***Test Failed*** 1 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=1, attempted=16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
