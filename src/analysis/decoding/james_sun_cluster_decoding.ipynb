{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3a4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "# Get the absolute path to the directory containing the current script\n",
    "# For GlobalLocal/src/analysis/preproc/make_epoched_data.py, this is GlobalLocal/src/analysis/preproc\n",
    "try:\n",
    "    # This will work if running as a .py script\n",
    "    current_file_path = os.path.abspath(__file__)\n",
    "    current_script_dir = os.path.dirname(current_file_path)\n",
    "except NameError:\n",
    "    # This will be executed if __file__ is not defined (e.g., in a Jupyter Notebook)\n",
    "    # os.getcwd() often gives the directory of the notebook,\n",
    "    # or the directory from which the Jupyter server was started.\n",
    "    current_script_dir = os.getcwd()\n",
    "\n",
    "# Navigate up three levels to get to the 'GlobalLocal' directory\n",
    "project_root = os.path.abspath(os.path.join(current_script_dir, '..', '..', '..'))\n",
    "\n",
    "# Add the 'GlobalLocal' directory to sys.path if it's not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root) # insert at the beginning to prioritize it\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "from ieeg.calc.mat import LabeledArray, combine\n",
    "\n",
    "# TODO: hmm fix these utils imports, import the funcs individually. 6/1/25.\n",
    "from src.analysis.utils.general_utils import *\n",
    "from src.analysis.utils.general_utils import make_or_load_subjects_electrodes_to_ROIs_dict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import norm\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# rsa toolbox imports\n",
    "from rsatoolbox.io.mne import read_epochs\n",
    "from rsatoolbox.data.ops import merge_datasets\n",
    "from rsatoolbox.rdm import calc_rdm_movie\n",
    "from rsatoolbox.rdm.calc import _parse_input\n",
    "from rsatoolbox.util.build_rdm import _build_rdms\n",
    "from rsatoolbox.rdm import compare\n",
    "from rsatoolbox.vis import show_rdm\n",
    "from rsatoolbox.vis.timecourse import plot_timecourse\n",
    "\n",
    "from os.path import join, expanduser, basename\n",
    "import glob, json\n",
    "import numpy, tqdm, mne, pandas\n",
    "import rsatoolbox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from ieeg.decoding.decoders import PcaLdaClassification\n",
    "from ieeg.calc.oversample import MinimumNaNSplit\n",
    "from ieeg.calc.fast import mixup\n",
    "\n",
    "from src.analysis.config import experiment_conditions\n",
    "\n",
    "from src.analysis.utils.labeled_array_utils import (\n",
    "    put_data_in_labeled_array_per_roi_subject,\n",
    "    remove_nans_from_labeled_array,\n",
    "    remove_nans_from_all_roi_labeled_arrays,\n",
    "    concatenate_conditions_by_string,\n",
    "    get_data_in_time_range\n",
    ")\n",
    "\n",
    "from src.analysis.decoding.decoding import (\n",
    "    process_and_balance_data_for_decoding, \n",
    "    get_and_plot_confusion_matrix_for_rois_jim,\n",
    "    Decoder, \n",
    "    windower,\n",
    "    get_confusion_matrices_for_rois_time_window_decoding_jim,\n",
    "    compute_accuracies,\n",
    "    perform_time_perm_cluster_test_for_accuracies,\n",
    "    plot_accuracies\n",
    ")\n",
    "\n",
    "import mne.time_frequency\n",
    "from ieeg.calc.scaling import rescale\n",
    "from ieeg.timefreq.utils import wavelet_scaleogram, crop_pad\n",
    "import numpy as np\n",
    "from src.analysis.spec.wavelet_functions import get_uncorrected_wavelets, get_uncorrected_multitaper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d07116",
   "metadata": {},
   "source": [
    "#### 0. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04940ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in subjects electrodes to rois dict. If it doesn't already exist, make it and then load it.\n",
    "config_dir = r'C:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\config'\n",
    "subjects_electrodestoROIs_dict = make_or_load_subjects_electrodes_to_ROIs_dict(subjects, task='GlobalLocal', LAB_root=None, save_dir=config_dir, \n",
    "                                                filename='subjects_electrodestoROIs_dict.json')\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "\n",
    "# get box directory depending on OS\n",
    "if os.name == 'nt': # windows\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "else: # mac\n",
    "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
    "\n",
    "# let's make a dictionary where the keys are output names and the values are lists of corresponding events\n",
    "output_names_and_events_dict = {}\n",
    "# output_names_and_events_dict['Stimulus_c25and75_fixationCrossBase_0.5sec'] = [\"Stimulus/c75.0\", \"Stimulus/c25.0\"]\n",
    "# output_names_and_events_dict['Stimulus_i25and75_fixationCrossBase_0.5sec'] = [\"Stimulus/i75.0\", \"Stimulus/i25.0\"]\n",
    "# output_names_and_events_dict['Stimulus_s25and75_fixationCrossBase_0.5sec'] = ['Stimulus/i75.0/s25.0', 'Stimulus/i25.0/s75.0', 'Stimulus/c75.0/s25.0', 'Stimulus/c25.0/s75.0']\n",
    "# output_names_and_events_dict['Stimulus_r25and75_fixationCrossBase_0.5sec'] = ['Stimulus/i75.0/r25.0', 'Stimulus/i25.0/r75.0', 'Stimulus/c75.0/r25.0', 'Stimulus/c25.0/r75.0']\n",
    "output_names_and_events_dict['Stimulus_fixationCrossBase_0.5sec'] = [\"Stimulus\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a911b",
   "metadata": {},
   "source": [
    "#### 1. For each electrode, make multitaper using all training trials, for both conditions to be compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a9b08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Turn this cell into a function\n",
    "\n",
    "baseline_times = [-0.5, 0]\n",
    "signal_times = [-0.5, 1.5]\n",
    "\n",
    "# subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103', 'D0107A', 'D0110', 'D0116', 'D0117', 'D0121']\n",
    "\n",
    "subjects = ['D0057']\n",
    "\n",
    "subjects_tfr_objects = {}\n",
    "\n",
    "# TODO: Kind of make a subjects_mne_objects thing but for wavelets/multitaper i think. Need to store data across subjects.\n",
    "for sub in subjects:\n",
    "    subjects_tfr_objects[sub] = {}\n",
    "    \n",
    "    # load in good data so we can use it for gettin bad channels and getting filenames\n",
    "    good = get_good_data(sub, layout)\n",
    "\n",
    "    # make stimulus baseline EpochsTFR\n",
    "    base = get_uncorrected_multitaper(sub, layout, events=[\"Stimulus\"], times=baseline_times)\n",
    "\n",
    "    # make signal wavelets\n",
    "    for output_name, events in output_names_and_events_dict.items():\n",
    "        spec = get_uncorrected_multitaper(sub, layout, events, signal_times)\n",
    "        spec_rescaled = rescale(spec, base, copy=True, mode='ratio').average(\n",
    "            lambda x: np.nanmean(x, axis=0), copy=True)\n",
    "        spec_rescaled._data = np.log10(spec_rescaled._data) * 20 # convert to dB\n",
    "        fnames = [os.path.relpath(f, layout.root) for f in good.filenames]\n",
    "        spec_rescaled.info['subject_info']['files'] = tuple(fnames)\n",
    "        spec_rescaled.info['bads'] = good.info['bads']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f756323",
   "metadata": {},
   "source": [
    "#### 2. Find clusters that are significantly different between the two conditions, in the multitaper spectrogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798bdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_perm_cluster(spec_rescaled_condition_1, spec_rescaled_condition_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f83ddec",
   "metadata": {},
   "source": [
    "#### 3. Train a decoder on just the significant time-frequency clusters, test on the test trials\n",
    "\n",
    "#### 4. Repeat but with new test trials (cross-validate)\n",
    "\n",
    "#### 5. Figure out a way of plotting this. This is univariate approach, make things modular so I can do multivariate later once I figure that out."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
