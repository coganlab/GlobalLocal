{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### working version 12/1/23"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try gregs suggestion of using make_data_same to destroy the fixation cross"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use window stats with perm testing (0 to 0.5, 0.5 to 1, 0 to 1 sec relative to stim onset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DELETE ME AT END OF DAY 2/13\n",
        "import mne\n",
        "import json\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def calculate_RTs(raw):\n",
        "    annotations = raw.annotations\n",
        "    reaction_times = []\n",
        "    skipped = []\n",
        "\n",
        "    for i in range(len(annotations) - 1):\n",
        "        current_annotation = annotations[i]\n",
        "        next_annotation = annotations[i + 1]\n",
        "        if 'Stimulus' in current_annotation['description']:\n",
        "            if 'Response' in next_annotation['description']:\n",
        "                reaction_time = next_annotation['onset'] - current_annotation['onset']\n",
        "                reaction_times.append(reaction_time)\n",
        "            else:\n",
        "                skipped.append(i)\n",
        "\n",
        "    return reaction_times, skipped\n",
        "\n",
        "\n",
        "def save_sig_chans(mask_name, mask, channels, subject, save_path):\n",
        "    # Get the indices of the channels that are significant at any time point\n",
        "    significant_indices = np.any(mask, axis=1)\n",
        "    \n",
        "    # Convert indices to channel names (optional)\n",
        "    sig_chans = [channels[i] for i in np.where(significant_indices)[0]]\n",
        "    \n",
        "    # Create a dictionary to store the data\n",
        "    data = {\n",
        "        \"subject\": subject,\n",
        "        \"sig_chans\": sig_chans\n",
        "    }\n",
        "    \n",
        "    # Define the filename\n",
        "    filename = os.path.join(save_path, f'sig_chans_{subject}_{mask_name}.json')\n",
        "    \n",
        "    # Save the dictionary as a JSON file\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(data, file)\n",
        "    \n",
        "    print(f'Saved significant channels for subject {subject} and mask {mask_name} to {filename}')\n",
        "\n",
        "\n",
        "def load_sig_chans(filename):\n",
        "    with open(filename, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    \n",
        "    # You can access the subject and significant channels directly from the dictionary\n",
        "    subject = data['subject']\n",
        "    sig_chans = data['sig_chans']\n",
        "\n",
        "    print(f'Loaded significant channels for subject {subject}')\n",
        "    return sig_chans\n",
        "\n",
        "\n",
        "def channel_names_to_indices(sig_chans, channels):\n",
        "    indices = [channels.index(chan_name) for chan_name in sig_chans if chan_name in channels]\n",
        "    return indices\n",
        "\n",
        "# untested code 8/21/23\n",
        "def save_channels_to_file(channels, subject, task, save_dir):\n",
        "    \"\"\"\n",
        "    Save each channel name and its corresponding index to a text file.\n",
        "    \n",
        "    Parameters:\n",
        "    - channels (list): The list of channel names.\n",
        "    - subject (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - save_dir (str): The directory where the text file should be saved.\n",
        "    \"\"\"\n",
        "    channel_text_filename = os.path.join(save_dir, f'channels_{subject}_{task}.txt')\n",
        "    with open(channel_text_filename, 'w') as channel_file:\n",
        "        for i, channel_name in enumerate(channels):\n",
        "            channel_file.write(f\"{i}: {channel_name}\\n\")\n",
        "    \n",
        "    print(f'Saved channel names and indices to {channel_text_filename}')\n",
        "\n",
        "\n",
        "\n",
        "def filter_and_average_epochs(epochs, start_idx, end_idx, accuracy_column='accuracy'):\n",
        "    \"\"\"\n",
        "    Calculates trial averages for accurate trials and time averages with inaccurate trials marked as NaNs.\n",
        "\n",
        "    Parameters:\n",
        "    - epochs: MNE Epochs object with accuracy metadata.\n",
        "    - start_idx: Start index for time averaging.\n",
        "    - end_idx: End index for time averaging.\n",
        "    - accuracy_column: Name of the column in the metadata that contains accuracy data.\n",
        "\n",
        "    Returns:\n",
        "    - trial_avg_data: Trial-averaged data across accurate trials.\n",
        "    - time_avg_data: Time-averaged data with inaccurate trials marked as NaNs.\n",
        "    \"\"\"\n",
        "    # Separate accurate and all trials data\n",
        "    accurate_epochs_data = epochs[epochs.metadata[accuracy_column] == 1.0].get_data()\n",
        "    all_epochs_data = epochs.get_data().copy()\n",
        "\n",
        "    # Mark inaccurate trials as NaNs in the all_epochs_data\n",
        "    inaccurate_indices = epochs.metadata[accuracy_column] != 1.0\n",
        "    all_epochs_data[inaccurate_indices, :, :] = np.nan\n",
        "\n",
        "    # Calculate trial average for accurate trials\n",
        "    trial_avg_data = np.nanmean(accurate_epochs_data, axis=0)\n",
        "\n",
        "    # Calculate time average within the specified window\n",
        "    time_avg_data = np.nanmean(all_epochs_data[:, :, start_idx:end_idx], axis=2)\n",
        "\n",
        "    return trial_avg_data, time_avg_data\n",
        "\n",
        "\n",
        "\n",
        "def permutation_test(data_timeavg_output_0, data_timeavg_output_1, n_permutations=10000, one_tailed=False):\n",
        "    \"\"\"\n",
        "    Perform a permutation test to compare two conditions.\n",
        "\n",
        "    Parameters:\n",
        "    - data_timeavg_output_0: Numpy array for condition 0.\n",
        "    - data_timeavg_output_1: Numpy array for condition 1.\n",
        "    - n_permutations: Number of permutations to perform.\n",
        "    - one_tailed: Boolean indicating if the test should be one-tailed. False by default.\n",
        "\n",
        "    Returns:\n",
        "    - p_value: P-value assessing the significance of the observed difference.\n",
        "    \"\"\"\n",
        "    # Calculate the observed difference in means between the two conditions\n",
        "    observed_diff = np.nanmean(data_timeavg_output_0) - np.nanmean(data_timeavg_output_1)\n",
        "    \n",
        "    # Combine the data from both conditions\n",
        "    combined_data = np.hstack([data_timeavg_output_0, data_timeavg_output_1])\n",
        "    \n",
        "    # Initialize a variable to count how many times the permuted difference exceeds the observed difference\n",
        "    count_extreme_values = 0\n",
        "    \n",
        "    for _ in range(n_permutations):\n",
        "        # Shuffle the combined data\n",
        "        np.random.shuffle(combined_data)\n",
        "        \n",
        "        # Split the shuffled data back into two new groups\n",
        "        permuted_0 = combined_data[:len(data_timeavg_output_0)]\n",
        "        permuted_1 = combined_data[len(data_timeavg_output_0):]\n",
        "        \n",
        "        # Calculate the mean difference for this permutation\n",
        "        permuted_diff = np.nanmean(permuted_0) - np.nanmean(permuted_1)\n",
        "        \n",
        "        # Check if the permuted difference is as extreme as the observed difference\n",
        "        # For a one-tailed test, only count when permuted_diff is greater than observed_diff\n",
        "        if one_tailed:\n",
        "            if permuted_diff > observed_diff:\n",
        "                count_extreme_values += 1\n",
        "        else:\n",
        "            if abs(permuted_diff) >= abs(observed_diff):\n",
        "                count_extreme_values += 1\n",
        "    \n",
        "    # Calculate the p-value\n",
        "    p_value = count_extreme_values / n_permutations\n",
        "    \n",
        "    return p_value\n",
        "\n",
        "\n",
        "\n",
        "def perform_permutation_test_within_electrodes(data_0_list, data_1_list, n_permutations=10000, one_tailed=False):\n",
        "    \"\"\"\n",
        "    Perform a permutation test for each electrode comparing two conditions across subjects.\n",
        "    \n",
        "    Parameters:\n",
        "    - data_0_list: List of subject arrays from condition 0, each array is trials x electrodes.\n",
        "    - data_1_list: List of subject arrays from condition 1, each array is trials x electrodes.\n",
        "    - n_permutations: Number of permutations for the test.\n",
        "    \n",
        "    Returns:\n",
        "    - p_values: A list of p-values for each electrode, across all subjects.\n",
        "    \"\"\"\n",
        "    p_values = []\n",
        "\n",
        "    # Ensure there is a corresponding condition 1 array for each condition 0 array\n",
        "    if len(data_0_list) != len(data_1_list):\n",
        "        raise ValueError(\"Mismatch in number of subjects between conditions\")\n",
        "\n",
        "    # Iterate through each subject's data arrays\n",
        "    for idx, (data_0, data_1) in enumerate(zip(data_0_list, data_1_list)):\n",
        "        print(f\"Subject {idx} - Condition 0 shape: {data_0.shape}, Condition 1 shape: {data_1.shape}\")\n",
        "\n",
        "        # Check for matching electrode counts between conditions within a subject\n",
        "        if data_0.shape[1] != data_1.shape[1]:\n",
        "            raise ValueError(f\"Electrode count mismatch in subject {idx}\")\n",
        "\n",
        "        n_electrodes_this_sub = data_0.shape[1]  # Number of electrodes for this subject\n",
        "\n",
        "        # Perform the permutation test for each electrode in this subject\n",
        "        for electrode_idx in range(n_electrodes_this_sub):  # Fix: use range(n_electrodes) to iterate correctly\n",
        "            p_value = permutation_test(data_0[:, electrode_idx], data_1[:, electrode_idx], n_permutations, one_tailed)\n",
        "            p_values.append(p_value)\n",
        "\n",
        "    return p_values\n",
        "\n",
        "def perform_permutation_test_across_electrodes(data_0_list, data_1_list, n_permutations=10000, one_tailed=False):\n",
        "    \"\"\"\n",
        "    Perform a permutation test across electrodes comparing two conditions.\n",
        "    \n",
        "    Parameters:\n",
        "    - data_0_list: List of arrays from condition 0, each array is trials x electrodes.\n",
        "    - data_1_list: List of arrays from condition 1, each array is trials x electrodes.\n",
        "    - n_permutations: Number of permutations for the test.\n",
        "    \n",
        "    Returns:\n",
        "    - p_value: P-value from the permutation test.\n",
        "    \"\"\"\n",
        "    # Aggregate data across electrodes\n",
        "    data_0_aggregated = np.concatenate([np.nanmean(data, axis=0) for data in data_0_list])  # Average across trials to get a single value per electrode\n",
        "    data_1_aggregated = np.concatenate([np.nanmean(data, axis=0) for data in data_1_list])  # though should I do avg across electrodes instead..?? Uhhhh. No, I think.\n",
        "    \n",
        "    # Perform the permutation test\n",
        "    p_value = permutation_test(data_0_aggregated, data_1_aggregated, n_permutations, one_tailed)\n",
        "    \n",
        "    return p_value\n",
        "\n",
        "def add_accuracy_to_epochs(epochs, accuracy_array):\n",
        "    \"\"\"\n",
        "    Adds accuracy data from accuracy_array to the metadata of epochs.\n",
        "    Assumes the order of trials in accuracy_array matches the order in epochs.\n",
        "    \"\"\"\n",
        "    if epochs.metadata is None:\n",
        "        # Create a new DataFrame if no metadata exists\n",
        "        epochs.metadata = pd.DataFrame(index=range(len(epochs)))\n",
        "    \n",
        "    # Ensure the accuracy_array length matches the number of epochs\n",
        "    assert len(accuracy_array) == len(epochs), \"Mismatch in number of trials and accuracy data length.\"\n",
        "    \n",
        "    # Add the accuracy array as a new column in the metadata\n",
        "    epochs.metadata['accuracy'] = accuracy_array\n",
        "\n",
        "    # Reset the index to ensure it's sequential starting from 0\n",
        "    epochs.metadata.reset_index(drop=True, inplace=True)\n",
        "    \n",
        "    return epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans, channel_names_to_indices, \\\n",
        "    filter_and_average_epochs, permutation_test, perform_permutation_test_across_electrodes, perform_permutation_test_within_electrodes, add_accuracy_to_epochs\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "\n",
        "# Directory where your .npy files are saved\n",
        "npy_directory = r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\accArrays'  # Replace with your directory path\n",
        "\n",
        "# Dictionary to hold the data\n",
        "acc_array = {}\n",
        "\n",
        "# Iterate over each file in the directory\n",
        "for file in os.listdir(npy_directory):\n",
        "    if file.endswith('.npy'):\n",
        "        # Construct the full file path\n",
        "        file_path = os.path.join(npy_directory, file)\n",
        "        # Load the numpy array from the file\n",
        "        acc_array[file.split('_')[0]] = np.load(file_path)\n",
        "\n",
        "# Now you have a dictionary where each key is the subject ID\n",
        "# and the value is the numpy array of accuracies for that subject.\n",
        "        \n",
        "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 228 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0057\\ieeg\\sub-D0057_acq-01_space-ACPC_electrodes.tsv.\n",
            "Not fully anonymizing info - keeping his_id, sex, and hand info\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Omitted 226 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: The number of channels in the channels.tsv sidecar file (179) does not match the number of channels in the raw data file (178). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "good channels before dropping bads: 178\n",
            "filt channels before dropping bads: 178\n",
            "outlier round 1 channels: ['RAMT8']\n",
            "outlier round 2 channels: ['RAMT8', 'RPI16']\n",
            "Bad channels in 'good': ['RAMT8', 'RPI16']\n",
            "Bad channels in 'good' after dropping once: []\n",
            "good channels after dropping bads: 176\n",
            "filt channels after dropping bads: 176\n",
            "Reading 0 ... 3219820  =      0.000 ...  1572.178 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n25', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n25', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 4097 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [04:00<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/n25', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n25', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n25', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n75', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n25', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\570391859.py:86: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
            "  all_trials = mne.concatenate_epochs(all_epochs_list)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [06:10<00:00,  1.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HG_ev1 before crop_pad:  -1.5 2.0\n",
            "HG_ev1 after crop_pad:  -1.0 1.5\n",
            "Shape of HG_ev1._data: (448, 176, 5121)\n",
            "Shape of HG_base._data: (448, 176, 2049)\n",
            "Shape of sig1: (448, 176, 5121)\n",
            "Shape of sig2: (448, 176, 2049)\n",
            "Shape of sig3: (448, 176, 2050)\n",
            "Shape of sig4: (448, 176, 2049)\n",
            "Shape of sig5: (448, 176, 5121)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\570391859.py:113: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\570391859.py:114: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_ev1.decimate(2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying baseline correction (mode: zscore)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\570391859.py:118: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\570391859.py:118: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\570391859.py:119: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\570391859.py:119: RuntimeWarning: Mean of empty slice\n",
            "  HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n"
          ]
        }
      ],
      "source": [
        "### after loading in HG_ev1_rescaled, then grab only the correct trials. Think I need to load in combined_data here too?\n",
        "### then load in the perm testing functions (put these into misc functions now that they work, and just load them into roi analysis and this too)\n",
        "###\n",
        "\n",
        "subjects = ['D0057']\n",
        "\n",
        "for sub in subjects:\n",
        "\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_fixationCrossBase_1sec_mirror_window_0to0.5\" #prob turn this into a function where i can set the window length as an input and it'll get added to the output name\n",
        "    events = [\"Stimulus\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "    # Directly reassign the modified signal data to the HG_base._data attribute (THIS MAY BREAK THINGS BUT ITS CORRECT 2/13)\n",
        "    HG_base._data = sig2\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# move this to misc functions once everythings working 2/13\n",
        "\n",
        "def save_sig_chans_with_reject(output_name, reject, channels, subject, save_dir):\n",
        "    # Determine which channels are significant based on the reject array\n",
        "    significant_indices = np.where(reject)[0]\n",
        "    \n",
        "    # Convert significant indices to channel names\n",
        "    sig_chans = [channels[i] for i in significant_indices]\n",
        "    \n",
        "    # Create a dictionary to store the data\n",
        "    data = {\n",
        "        \"subject\": subject,\n",
        "        \"sig_chans\": sig_chans\n",
        "    }\n",
        "    \n",
        "    # Define the filename\n",
        "    filename = os.path.join(save_dir, f'sig_chans_{subject}_{output_name}.json')\n",
        "    \n",
        "    # Save the dictionary as a JSON file\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(data, file)\n",
        "    \n",
        "    print(f'Saved significant channels for subject {subject} and {output_name} to {filename}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\1690555050.py:18: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  accurate_HG_ev1_data = HG_ev1[HG_ev1.metadata['accuracy'] == 1.0].get_data()\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\1690555050.py:19: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  all_HG_ev1_data = HG_ev1.get_data().copy()\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\1690555050.py:29: RuntimeWarning: Mean of empty slice\n",
            "  time_avg_signal = np.nanmean(all_HG_ev1_data[:, :, start_idx:end_idx], axis=2) #average across specified time window for data\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\1690555050.py:30: FutureWarning: The current default of copy=False will change to copy=True in 1.7. Set the value of copy explicitly to avoid this warning\n",
            "  time_avg_base = np.nanmean(HG_base.get_data().copy()[:,:,:], axis=2) #average across all time for baseline. Use a copy of the baseline so we don't mess it up.\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_19616\\1690555050.py:30: RuntimeWarning: Mean of empty slice\n",
            "  time_avg_base = np.nanmean(HG_base.get_data().copy()[:,:,:], axis=2) #average across all time for baseline. Use a copy of the baseline so we don't mess it up.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subject 0 - Condition 0 shape: (448, 176), Condition 1 shape: (448, 176)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "### filter for accurate trials in HG ev1 \n",
        "# Build the filtering condition\n",
        "sub_without_zeroes = \"D\" + sub[1:].lstrip('0') \n",
        "sub_behavioral_rows = (combined_data['subject_ID'] == sub_without_zeroes) # this indexes using the subject without zeroes in the name. Confusing. I know.\n",
        "\n",
        "# Filter combinedData for the specific subject and conditions\n",
        "sub_behavioral_data = combined_data[sub_behavioral_rows]\n",
        "\n",
        "if sub in acc_array:\n",
        "    trial_counts = sub_behavioral_data['trialCount'].values.astype(int)\n",
        "    accuracy_data = [acc_array[sub][i-1] for i in trial_counts if i-1 < len(acc_array[sub])] # Subtract 1 here for zero-based indexing in acc array.\n",
        "    \n",
        "    # Now pass trial_counts along with accuracy_data to raw HG_ev1\n",
        "    HG_ev1 = add_accuracy_to_epochs(HG_ev1, accuracy_data)\n",
        "    \n",
        "# Separate accurate and all trials data\n",
        "accurate_HG_ev1_data = HG_ev1[HG_ev1.metadata['accuracy'] == 1.0].get_data()\n",
        "all_HG_ev1_data = HG_ev1.get_data().copy()\n",
        "\n",
        "# Mark inaccurate trials as NaNs in the all_epochs_data\n",
        "inaccurate_indices = HG_ev1.metadata['accuracy'] != 1.0\n",
        "all_HG_ev1_data[inaccurate_indices, :, :] = np.nan\n",
        "\n",
        "\n",
        "# do stats stuff here\n",
        "# Calculate time average within the specified window\n",
        "start_idx, end_idx = 2048, 3072 #should be 2048 to 3072 for 0 to 0.5. Make this modular, based on the times variable later. And also based on the input to this function.\n",
        "time_avg_signal = np.nanmean(all_HG_ev1_data[:, :, start_idx:end_idx], axis=2) #average across specified time window for data\n",
        "time_avg_base = np.nanmean(HG_base.get_data().copy()[:,:,:], axis=2) #average across all time for baseline. Use a copy of the baseline so we don't mess it up.\n",
        "p_values = perform_permutation_test_within_electrodes([time_avg_signal], [time_avg_base], one_tailed=True) #update these functions to not need list inputs later.\n",
        "reject, p_values_adjusted = multipletests(p_values, alpha=0.05, method='fdr_bh')[:2] # reject is a boolean array of whether each channel passed significance threshold after adjusting for multiple comparisons. Adjusted_p_values are the actual adjusted p values.\n",
        "\n",
        "# Determine which channels are significant based on the reject array\n",
        "channels = good.ch_names\n",
        "save_sig_chans_with_reject(output_name, reject, channels, sub, save_dir)\n",
        "\n",
        "#save all channels with their indices \n",
        "save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "\n",
        "# # save significant channels to a json\n",
        "# save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "# # Save HG_ev1\n",
        "# HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "# # Save HG_base\n",
        "# HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "# # Save HG_ev1_rescaled\n",
        "# HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "# # Save HG_ev1_evoke\n",
        "# HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "# # Save HG_ev1_evoke_rescaled\n",
        "# HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "use time point cluster stats for determining stimulus significance (old method as of 2/13/24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "    # fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1), picks=sig_chans) #this line is not finishing...\n",
        "\n",
        "    # fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore_sigChans.png')\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### loop through everyone and do congruency "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/s25\", \"Stimulus/c75/s25\", \"Stimulus/i25/s25\", \"Stimulus/c25/s25\", \"Stimulus/i75/s75\", \"Stimulus/c75/s75\", \"Stimulus/i25/s75\", \"Stimulus/c25/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_r25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i75/r25\", \"Stimulus/c75/r25\", \"Stimulus/i25/r25\", \"Stimulus/c25/r25\", \"Stimulus/i75/r75\", \"Stimulus/c75/r75\", \"Stimulus/i25/r75\", \"Stimulus/c25/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25\", \"Stimulus/c75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25\", \"Stimulus/i75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### do interaction effects (is, ir, cs, cr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_is_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/s25\", \"Stimulus/i25/s75\", \"Stimulus/i75/s25\", \"Stimulus/i75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_ir_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/i25/r25\", \"Stimulus/i25/r75\", \"Stimulus/i75/r25\", \"Stimulus/i75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###\n",
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "    outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "from ieeg.calc.reshape import make_data_same\n",
        "from ieeg.calc.stats import time_perm_cluster\n",
        "from ieeg.viz.mri import gen_labels\n",
        "\n",
        "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def plot_HG_and_stats(sub, task, output_name, event=None, times=(-1, 1.5),\n",
        "                      base_times=(-0.5, 0), LAB_root=None, channels=None,\n",
        "                      full_trial_base=False):\n",
        "    \"\"\"\n",
        "    Plot high gamma (HG) and statistics for a given subject and task using specified event.\n",
        "\n",
        "    Parameters:\n",
        "    - sub (str): The subject identifier.\n",
        "    - task (str): The task identifier.\n",
        "    - output_name (str): The name for the output files.\n",
        "    - event (str, optional): Event name to process. Defaults to None.\n",
        "    - times (tuple, optional): A tuple indicating the start and end times for processing. Defaults to (-1, 1.5).\n",
        "    - base_times (tuple, optional): A tuple indicating the start and end base times for processing. Defaults to (-0.5, 0).\n",
        "    - LAB_root (str, optional): The root directory for the lab. Will be determined based on OS if not provided. Defaults to None.\n",
        "    - channels (list of strings, optional): The channels to plot and get stats for. Default is all channels.\n",
        "    - full_trial_base (boolean): Whether to use the full trial as the baseline period. Default is False.\n",
        "    This function will process the provided event for a given subject and task.\n",
        "    High gamma (HG) will be computed, and statistics will be calculated and plotted.\n",
        "    The results will be saved to output files.\n",
        "    \"\"\"\n",
        "    pass\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cs_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/s25\", \"Stimulus/c25/s75\", \"Stimulus/c75/s25\", \"Stimulus/c75/s75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "\n",
        "subjects = ['D0100', 'D0102', 'D0103']\n",
        "\n",
        "for sub in subjects:\n",
        "    task = 'GlobalLocal'\n",
        "    output_name = \"Stimulus_cr_fixationCrossBase_1sec_mirror\"\n",
        "    events = [\"Stimulus/c25/r25\", \"Stimulus/c25/r75\", \"Stimulus/c75/r25\", \"Stimulus/c75/r75\"]\n",
        "    times = (-1,1.5)\n",
        "    base_times = [-1,0]\n",
        "    LAB_root = None\n",
        "    channels = None\n",
        "    full_trial_base = False\n",
        "\n",
        "    if LAB_root is None:\n",
        "        HOME = os.path.expanduser(\"~\")\n",
        "        if os.name == 'nt':  # windows\n",
        "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "        else:  # mac\n",
        "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                                    \"CoganLab\")\n",
        "\n",
        "    layout = get_data(task, root=LAB_root)\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False)\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    good = crop_empty_data(filt)\n",
        "    # %%\n",
        "\n",
        "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "    good.drop_channels(good.info['bads'])\n",
        "\n",
        "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "    good.load_data()\n",
        "\n",
        "    # If channels is None, use all channels\n",
        "    if channels is None:\n",
        "        channels = good.ch_names\n",
        "    else:\n",
        "        # Validate the provided channels\n",
        "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "        if invalid_channels:\n",
        "            raise ValueError(\n",
        "                f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "        # Use only the specified channels\n",
        "        good.pick_channels(channels)\n",
        "\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "    adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    all_epochs_list = []\n",
        "\n",
        "    for event in events:\n",
        "    # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "        times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "        trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "                            reject_by_annotation=False)\n",
        "        all_epochs_list.append(trials)\n",
        "\n",
        "    # Concatenate all trials\n",
        "    all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "    outliers_to_nan(all_trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "    print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "    HG_base.decimate(2)\n",
        "    HG_ev1.decimate(2)\n",
        "\n",
        "    HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "    HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    HG_ev1_evoke_stderr = HG_ev1.standard_error()\n",
        "    HG_ev1_evoke_rescaled_stderr = HG_ev1_rescaled.standard_error()\n",
        "\n",
        "    # if event == \"Stimulus\":\n",
        "    #     print('plotting stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "    #     print('plotted')\n",
        "    #     # for ax in fig.axes:\n",
        "    #     #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    #     print('about to save')\n",
        "    #     fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "    #     print('saved')\n",
        "    # else:\n",
        "    #     print('about to plot if not stimulus')\n",
        "    #     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "    #     print('plotted non stimulus')\n",
        "    #     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "    # Save HG_ev1\n",
        "    HG_ev1.save(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_base\n",
        "    HG_base.save(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_rescaled\n",
        "    HG_ev1_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke\n",
        "    HG_ev1_evoke.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke-epo.fif', overwrite=True)\n",
        "\n",
        "    # Save HG_ev1_evoke_rescaled\n",
        "    HG_ev1_evoke_rescaled.save(f'{save_dir}/{sub}_{output_name}_HG_ev1_evoke_rescaled-epo.fif', overwrite=True)\n",
        "\n",
        "    ###\n",
        "    print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "    print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "    sig1 = HG_ev1._data\n",
        "    sig2 = HG_base._data\n",
        "    sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "    sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "    sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "    print(f\"Shape of sig1: {sig1.shape}\")\n",
        "    print(f\"Shape of sig2: {sig2.shape}\")\n",
        "    print(f\"Shape of sig3: {sig3.shape}\")\n",
        "    print(f\"Shape of sig4: {sig4.shape}\")\n",
        "    print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "    sig2 = sig5\n",
        "\n",
        "    mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "    fig = plt.figure()\n",
        "    plt.imshow(mat, aspect='auto')\n",
        "    fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "    channels = good.ch_names\n",
        "\n",
        "    #save channels with their indices \n",
        "    save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "    # save significant channels to a json\n",
        "    save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "    sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_{output_name}.json'\n",
        "    sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "to load in previously generated hg ev1 and hg base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load HG_ev1\n",
        "loaded_HG_ev1 = mne.read_epochs(f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif')\n",
        "\n",
        "# Load HG_base\n",
        "loaded_HG_base = mne.read_epochs(f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### plot each significant channel with its trace and timepoints of significance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# print(sys.path)\n",
        "# sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "# from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
        "#     outliers_to_nan\n",
        "# from ieeg.io import raw_from_layout, get_data\n",
        "# from ieeg.timefreq.utils import crop_pad\n",
        "# from ieeg.timefreq import gamma\n",
        "# from ieeg.calc.scaling import rescale\n",
        "# import mne\n",
        "# import os\n",
        "# import numpy as np\n",
        "# from ieeg.calc.reshape import make_data_same\n",
        "# from ieeg.calc.stats import time_perm_cluster\n",
        "\n",
        "# from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# subjects = ['D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
        "\n",
        "# for sub in subjects:\n",
        "#     # sub = 'D0057'\n",
        "#     task = 'GlobalLocal'\n",
        "#     output_name = \"Stimulus_fixationCrossBase_1sec_mirror\"\n",
        "#     events = [\"Stimulus\"]\n",
        "#     times = (-1,1.5)\n",
        "#     base_times = [-1,0]\n",
        "#     LAB_root = None\n",
        "#     channels = None\n",
        "#     full_trial_base = False\n",
        "\n",
        "#     if LAB_root is None:\n",
        "#         HOME = os.path.expanduser(\"~\")\n",
        "#         if os.name == 'nt':  # windows\n",
        "#             LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "#         else:  # mac\n",
        "#             LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "#                                     \"CoganLab\")\n",
        "\n",
        "#     layout = get_data(task, root=LAB_root)\n",
        "#     filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "#                         extension='.edf', desc='clean', preload=False)\n",
        "#     save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "#     if not os.path.exists(save_dir):\n",
        "#         os.makedirs(save_dir)\n",
        "\n",
        "#     good = crop_empty_data(filt)\n",
        "#     # %%\n",
        "\n",
        "#     print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
        "#     print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "#     good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "#     print(\"Bad channels in 'good':\", good.info['bads'])\n",
        "\n",
        "#     filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
        "#     good.drop_channels(good.info['bads'])\n",
        "\n",
        "#     print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
        "\n",
        "#     print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
        "#     print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
        "\n",
        "#     good.load_data()\n",
        "\n",
        "#     # If channels is None, use all channels\n",
        "#     if channels is None:\n",
        "#         channels = good.ch_names\n",
        "#     else:\n",
        "#         # Validate the provided channels\n",
        "#         invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
        "#         if invalid_channels:\n",
        "#             raise ValueError(\n",
        "#                 f\"The following channels are not valid: {invalid_channels}\")\n",
        "\n",
        "#         # Use only the specified channels\n",
        "#         good.pick_channels(channels)\n",
        "\n",
        "#     ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "#     good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "#     # Create a baseline EpochsTFR using the stimulus event\n",
        "\n",
        "#     adjusted_base_times = [base_times[0] - 0.5, base_times[1] + 0.5]\n",
        "#     trials = trial_ieeg(good, \"Stimulus\", adjusted_base_times, preload=True)\n",
        "#     outliers_to_nan(trials, outliers=10)\n",
        "#     HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "#     crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "#     all_epochs_list = []\n",
        "\n",
        "#     for event in events:\n",
        "#     # Epoching and HG extraction for each specified event. Then concatenate all trials epochs objects together (do Stimulus/c25 and Stimulus/c75 for example, and combine to get all congruent trials)\n",
        "#         times_adj = [times[0] - 0.5, times[1] + 0.5]\n",
        "#         trials = trial_ieeg(good, event, times_adj, preload=True,\n",
        "#                             reject_by_annotation=False)\n",
        "#         all_epochs_list.append(trials)\n",
        "\n",
        "#     # Concatenate all trials\n",
        "#     all_trials = mne.concatenate_epochs(all_epochs_list)\n",
        "\n",
        "#     outliers_to_nan(all_trials, outliers=10)\n",
        "#     HG_ev1 = gamma.extract(all_trials, copy=True, n_jobs=1)\n",
        "#     print(\"HG_ev1 before crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "#     crop_pad(HG_ev1, \"0.5s\")\n",
        "#     print(\"HG_ev1 after crop_pad: \", HG_ev1.tmin, HG_ev1.tmax)\n",
        "\n",
        "#     HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "\n",
        "#     HG_base.decimate(2)\n",
        "#     HG_ev1.decimate(2)\n",
        "\n",
        "#     HG_ev1_avgOverTime = np.nanmean(HG_ev1.get_data(), axis=2)\n",
        "#     HG_ev1_rescaled_avgOverTime = np.nanmean(HG_ev1_rescaled.get_data(), axis=2)\n",
        "\n",
        "#     HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0)) #axis=0 should be set for actually running this, the axis=2 is just for drift testing.\n",
        "#     HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "#     if event == \"Stimulus\":\n",
        "#         print('plotting stimulus')\n",
        "#         fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1)) #this line is not finishing...\n",
        "#         print('plotted')\n",
        "#         # for ax in fig.axes:\n",
        "#         #     ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "#         print('about to save')\n",
        "#         fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore.png')\n",
        "#         print('saved')\n",
        "#     else:\n",
        "#         print('about to plot if not stimulus')\n",
        "#         fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "#         print('plotted non stimulus')\n",
        "#         fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore.png')\n",
        "\n",
        "#     ###\n",
        "#     print(f\"Shape of HG_ev1._data: {HG_ev1._data.shape}\")\n",
        "#     print(f\"Shape of HG_base._data: {HG_base._data.shape}\")\n",
        "\n",
        "#     sig1 = HG_ev1._data\n",
        "#     sig2 = HG_base._data\n",
        "#     sig3 = make_data_same(sig2, (sig2.shape[0],sig2.shape[1],sig2.shape[2]+1)) # originally we want to make the baseline the same shape as the signal. We still want to do that, but first, we'll make it bigger to reflect it once, then back to normal to randomly offset it and remove fixation cross effects.\n",
        "#     sig4 = make_data_same(sig3, sig2.shape) #here we do the random offset, we know that sig3 is bigger than sig1 by 1 in the time dimension so it will get randomly sliced.\n",
        "#     sig5 = make_data_same(sig4, sig1.shape) #and now sig4 should be sig2 but with a random offset, and we can then set it equal to sig1's shape like the original plan.\n",
        "#     print(f\"Shape of sig1: {sig1.shape}\")\n",
        "#     print(f\"Shape of sig2: {sig2.shape}\")\n",
        "#     print(f\"Shape of sig3: {sig3.shape}\")\n",
        "#     print(f\"Shape of sig4: {sig4.shape}\")\n",
        "#     print(f\"Shape of sig5: {sig5.shape}\")\n",
        "\n",
        "#     sig2 = sig5\n",
        "\n",
        "#     mat = time_perm_cluster(sig1, sig2, 0.05, n_jobs=6, ignore_adjacency=1)\n",
        "#     fig = plt.figure()\n",
        "#     plt.imshow(mat, aspect='auto')\n",
        "#     fig.savefig(save_dir + f'_{output_name}_stats.png', dpi=300)\n",
        "\n",
        "#     channels = good.ch_names\n",
        "\n",
        "#     #save channels with their indices \n",
        "#     save_channels_to_file(channels, sub, task, save_dir)\n",
        "\n",
        "#     # save significant channels to a json\n",
        "#     save_sig_chans(f'{output_name}', mat, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "#     base_path = r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs'\n",
        "#     sig_chans_filename = f'{base_path}\\\\{sub}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
        "#     sig_chans = load_sig_chans(sig_chans_filename)\n",
        "\n",
        "#     fig = HG_ev1_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1), picks=sig_chans) #this line is not finishing...\n",
        "\n",
        "#     fig.savefig(save_dir + f'_HG_ev1_{output_name}_zscore_sigChans.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ok make greg significance and high gamma combined plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image, ImageChops\n",
        "\n",
        "def trim_whitespace(image):\n",
        "    \"\"\"\n",
        "    Trims the whitespace from an image.\n",
        "    \"\"\"\n",
        "    bg = Image.new(image.mode, image.size, image.getpixel((0, 0)))\n",
        "    diff = ImageChops.difference(image, bg)\n",
        "    diff = ImageChops.add(diff, diff, 2.0, -100)\n",
        "    bbox = diff.getbbox()\n",
        "    if bbox:\n",
        "        return image.crop(bbox)\n",
        "    return image  # If no change\n",
        "\n",
        "channel_to_index = {}\n",
        "\n",
        "# maybe make this not so dependent on the previous code...\n",
        "\n",
        "channel_file = os.path.join(save_dir, f'channels_{sub}_GlobalLocal.txt') #maybe make this less dependent on previous code?\n",
        "with open(channel_file, 'r') as f:\n",
        "    for line in f:\n",
        "        index, channel = line.strip().split(': ')\n",
        "        channel_to_index[channel] = int(index)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### new code that tries to plot 6x6 grid of 36 channels on one plot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### z-scored signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming all imports and previous definitions are in place\n",
        "\n",
        "def plot_channels_on_grid(channels_subset):\n",
        "    fig, axes = plt.subplots(6, 10, figsize=(20, 33))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = HG_ev1_evoke_rescaled_stderr.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / 1000  # Assuming 1kHz sample rate\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(HG_ev1_evoke_rescaled.times, HG_ev1_evoke_rescaled.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(HG_ev1_evoke_rescaled.times, HG_ev1_evoke_rescaled.data[channel_to_index[channel], :] - stderr, HG_ev1_evoke_rescaled.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(HG_ev1_evoke_rescaled.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "# Iterate over all channels in chunks of 60 and plot them\n",
        "for i in range(0, len(sig_chans), 60):\n",
        "    channels_subset = channels[i:i+60]\n",
        "    fig = plot_channels_on_grid(channels_subset)\n",
        "    combined_plot_path = os.path.join(save_dir, f'{sub}_zscore_{output_name}_combinedChannelTracesAndSignificance_Page_{i//36 + 1}.png')\n",
        "    fig.savefig(combined_plot_path)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for raw traces, just plot HG_ev1_evoke instead of HG_ev1_evoke_rescaled. And for the standard error, use the HG_ev1_evoke_stderr instead of HG_ev1_evoke_rescaled_stderr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### raw traces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Assuming all imports and previous definitions are in place\n",
        "\n",
        "def plot_channels_on_grid(channels_subset):\n",
        "    fig, axes = plt.subplots(6, 10, figsize=(20, 33))\n",
        "    fig.suptitle(\"Channels with Significance Overlay\")\n",
        "    axes_flat = axes.flatten()\n",
        "\n",
        "    for channel, ax in zip(channels_subset, axes_flat):\n",
        "        stderr = HG_ev1_evoke_stderr.data[channel_to_index[channel], :]\n",
        "        time_in_seconds = np.arange(0, len(mat[channel_to_index[channel]])) / 1000  # Assuming 1kHz sample rate\n",
        "        sig_data_in_seconds = np.array(mat[channel_to_index[channel]])\n",
        "        ax.plot(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "         # Add the standard error shading\n",
        "        ax.fill_between(HG_ev1_evoke.times, HG_ev1_evoke.data[channel_to_index[channel], :] - stderr, HG_ev1_evoke.data[channel_to_index[channel], :] + stderr, alpha=0.2)\n",
        "\n",
        "        # Find the maximum y-value for the current channel\n",
        "        max_y_value = np.max(HG_ev1_evoke.data[channel_to_index[channel], :])\n",
        "\n",
        "        # Overlay significance as a horizontal line at the max y-value\n",
        "        significant_points = np.where(sig_data_in_seconds == 1)[0]\n",
        "        for point in significant_points:\n",
        "            ax.hlines(y=max_y_value, xmin=time_in_seconds[point]-1, xmax=time_in_seconds[point] + 0.005 - 1, color='red', linewidth=1) # subtract 1 cuz the sig time is from 0 to 2.5, while the high gamma time is from -1 to 1.5\n",
        "\n",
        "        ax.set_title(channel)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.subplots_adjust(top=0.95)\n",
        "    return fig\n",
        "\n",
        "# Iterate over all channels in chunks of 60 and plot them\n",
        "for i in range(0, len(sig_chans), 60):\n",
        "    channels_subset = channels[i:i+60]\n",
        "    fig = plot_channels_on_grid(channels_subset)\n",
        "    combined_plot_path = os.path.join(save_dir, f'{sub}_raw_{output_name}_combinedChannelTracesAndSignificance_Page_{i//36 + 1}.png')\n",
        "    fig.savefig(combined_plot_path)\n",
        "    plt.close(fig)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
