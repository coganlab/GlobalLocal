{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ieeg.viz.utils\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.calc import stats, scaling\n",
        "from ieeg.process import parallelize\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "from misc_functions import calculate_RTs\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from bids import BIDSLayout\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "from misc_functions import calculate_RTs, save_sig_chans\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relabel_axes(old_min, old_max, new_min, new_max):\n",
        "    scale = (new_max - new_min) / (old_max - old_min)\n",
        "\n",
        "    def format_func(value, tick_number):\n",
        "        return new_min + value * scale\n",
        "\n",
        "    plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(format_func))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### grab the data and set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "for sub in subjects:\n",
        "\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                            extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "    # do filtering now\n",
        "    ## Crop raw data to minimize processing time\n",
        "    good = crop_empty_data(filt)\n",
        "\n",
        "    ## remove bad channels\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    good.drop_channels(good.info['bads'])\n",
        "    good.load_data()\n",
        "\n",
        "    # CAR\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "    # make baseline \n",
        "    # make stimulus baseline EpochsTFR\n",
        "    times=[-1, 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10) #this removes trial outliers BUT breaks the shape because different stimulus epochs will then have different trial numbers\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    data_dict = {}  # make something to store all the outputs\n",
        "\n",
        "    for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "        times = [None, None]\n",
        "        times[0] = t[0] - 0.5\n",
        "        times[1] = t[1] + 0.5\n",
        "        trials = trial_ieeg(good, event, times, preload=True)\n",
        "        outliers_to_nan(trials, outliers=10)\n",
        "        HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "        crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "        HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "        # HG_ev1.resample(100)\n",
        "        # HG_ev1.filenames = good.filenames\n",
        "\n",
        "        # Store the variable in the dictionary with the desired name\n",
        "        data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "        data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "        \n",
        "    resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    RTs, skipped = calculate_RTs(good)\n",
        "    avg_RT = np.median(RTs)\n",
        "\n",
        "    # Plot the evoked data\n",
        "    fig = resp_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "    fig.savefig(save_dir + '_HG_ev1_Response_zscore_rt.png')\n",
        "\n",
        "    fig = stim_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "    # Add a vertical line indicating the average reaction time to the plot\n",
        "    for ax in fig.axes:\n",
        "        ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "        \n",
        "    fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore_rt.png')\n",
        "\n",
        "    # decimate for stats\n",
        "    resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "    stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "    HG_base.decimate(2)\n",
        "    resp.decimate(2)\n",
        "    stim.decimate(2)\n",
        "\n",
        "    # do permutation cluster\n",
        "    resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "                                n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "                                n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    \n",
        "    #untested code 8/1\n",
        "    # Assuming you have the channel names in a variable called 'channels'\n",
        "    channels = good.ch_names\n",
        "\n",
        "    # Save the significant channels for the response\n",
        "    save_sig_chans(resp_mask, channels, sub, save_dir)\n",
        "\n",
        "    # Save the significant channels for the stimulus\n",
        "    save_sig_chans(stim_mask, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "    # plot stats\n",
        "    plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "    plt.imshow(stim_mask, aspect='auto')  # hold on from matlab\n",
        "    relabel_axes(0, 2500, -1000, 1500)\n",
        "    plt.savefig(save_dir + '_stimulus_stats_big.png', dpi=300)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.imshow(resp_mask, aspect='auto')\n",
        "    relabel_axes(0, 2500, -1000, 1500)\n",
        "    plt.savefig(save_dir + '_response_stats_big.png', dpi=300)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### testing with single subject with prestimulus baseline period"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24}\n",
            "KeysView({'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24})\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-01_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-02_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (133) does not match the number of channels in the raw data file (132). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-02_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-03_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 224 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (133) does not match the number of channels in the raw data file (132). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-03_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_acq-01_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-04_desc-clean_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 224 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (133) does not match the number of channels in the raw data file (132). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-04_desc-clean_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0069\\ieeg\\sub-D0069_acq-01_space-ACPC_electrodes.tsv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Omitted 214 annotation(s) that were outside data range.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: The number of channels in the channels.tsv sidecar file (133) does not match the number of channels in the raw data file (132). Will not try to set channel names.\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n",
            "c:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:100: RuntimeWarning: Cannot set channel type for the following channels, as they are missing in the raw data: Trigger\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "outlier round 1 channels: ['LTMS11']\n",
            "outlier round 2 channels: ['LTMS11', 'LTAS9']\n",
            "Reading 0 ... 3711369  =      0.000 ...  1812.192 secs...\n",
            "Applying average reference.\n",
            "Applying a custom ('sEEG',) reference.\n",
            "Used Annotations descriptions: ['Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/n25', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n25', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n25', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n25', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "event_ids: {'c25/n75': 21, 'c25/r25': 22, 'c25/r75': 23, 'c25/s25': 24, 'c25/s75': 25, 'c75/r25': 26, 'c75/r75': 27, 'c75/s25': 28, 'c75/s75': 29, 'i25/n25': 30, 'i25/r25': 31, 'i25/r75': 32, 'i25/s25': 33, 'i25/s75': 34, 'i75/n25': 35, 'i75/n75': 36, 'i75/r25': 37, 'i75/r75': 38, 'i75/s25': 39, 'i75/s75': 40}\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 3073 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [03:16<00:00,  2.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Used Annotations descriptions: ['Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/n25', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n25', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n25', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n25', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "event_ids: {'c25/n75': 21, 'c25/r25': 22, 'c25/r75': 23, 'c25/s25': 24, 'c25/s75': 25, 'c75/r25': 26, 'c75/r75': 27, 'c75/s25': 28, 'c75/s75': 29, 'i25/n25': 30, 'i25/r25': 31, 'i25/r75': 32, 'i25/s25': 33, 'i25/s75': 34, 'i75/n25': 35, 'i75/n75': 36, 'i75/r25': 37, 'i75/r75': 38, 'i75/s25': 39, 'i75/s75': 40}\n",
            "Not setting metadata\n",
            "448 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 448 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 448/448 [06:32<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying baseline correction (mode: zscore)\n",
            "Used Annotations descriptions: ['Response/c25/n75', 'Response/c25/r25', 'Response/c25/r75', 'Response/c25/s25', 'Response/c25/s75', 'Response/c75/r25', 'Response/c75/r75', 'Response/c75/s25', 'Response/c75/s75', 'Response/i25/n25', 'Response/i25/r25', 'Response/i25/r75', 'Response/i25/s25', 'Response/i25/s75', 'Response/i75/n25', 'Response/i75/n75', 'Response/i75/r25', 'Response/i75/r75', 'Response/i75/s25', 'Response/i75/s75', 'Stimulus/c25/n75', 'Stimulus/c25/r25', 'Stimulus/c25/r75', 'Stimulus/c25/s25', 'Stimulus/c25/s75', 'Stimulus/c75/r25', 'Stimulus/c75/r75', 'Stimulus/c75/s25', 'Stimulus/c75/s75', 'Stimulus/i25/n25', 'Stimulus/i25/r25', 'Stimulus/i25/r75', 'Stimulus/i25/s25', 'Stimulus/i25/s75', 'Stimulus/i75/n25', 'Stimulus/i75/n75', 'Stimulus/i75/r25', 'Stimulus/i75/r75', 'Stimulus/i75/s25', 'Stimulus/i75/s75']\n",
            "event_ids: {'c25/n75': 1, 'c25/r25': 2, 'c25/r75': 3, 'c25/s25': 4, 'c25/s75': 5, 'c75/r25': 6, 'c75/r75': 7, 'c75/s25': 8, 'c75/s75': 9, 'i25/n25': 10, 'i25/r25': 11, 'i25/r75': 12, 'i25/s25': 13, 'i25/s75': 14, 'i75/n25': 15, 'i75/n75': 16, 'i75/r25': 17, 'i75/r75': 18, 'i75/s25': 19, 'i75/s75': 20}\n",
            "Not setting metadata\n",
            "424 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Using data from preloaded Raw for 424 events and 7169 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 424/424 [06:11<00:00,  1.14it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Applying baseline correction (mode: zscore)\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
            "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_8472\\999434550.py:92: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  HG_base.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_8472\\999434550.py:93: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  resp.decimate(2)\n",
            "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_8472\\999434550.py:94: RuntimeWarning: The measurement information indicates a low-pass frequency of 1024.0 Hz. The decim=2 parameter will result in a sampling frequency of 1024.0 Hz, which can cause aliasing artifacts.\n",
            "  stim.decimate(2)\n",
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:  2.0min\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  5.7min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  6.6min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  9.3min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed: 10.2min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed: 10.5min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed: 10.5min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed: 10.5min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed: 11.1min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed: 11.3min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed: 11.3min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed: 12.0min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed: 12.2min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed: 12.2min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed: 12.3min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed: 12.3min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed: 12.3min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed: 12.9min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed: 13.1min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed: 13.1min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed: 13.2min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed: 13.2min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed: 13.2min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed: 13.8min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed: 13.9min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed: 14.0min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed: 14.1min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed: 14.1min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed: 14.1min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed: 14.7min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed: 14.8min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed: 14.9min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed: 15.5min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed: 15.7min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed: 15.8min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed: 16.4min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed: 16.6min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed: 16.7min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed: 16.8min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed: 16.9min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed: 16.9min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed: 17.3min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed: 17.5min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed: 17.6min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed: 17.7min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed: 18.4min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed: 18.4min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed: 18.6min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed: 18.7min\n",
            "[Parallel(n_jobs=6)]: Done 123 out of 130 | elapsed: 19.4min remaining:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done 127 out of 130 | elapsed: 19.9min remaining:   28.1s\n",
            "[Parallel(n_jobs=6)]: Done 130 out of 130 | elapsed: 20.1min finished\n",
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   57.4s\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:   57.5s\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:   57.6s\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   57.7s\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   57.7s\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   57.8s\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  2.9min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  4.8min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  4.9min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  5.8min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  6.7min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  6.8min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  8.7min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  9.5min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed: 10.4min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed: 10.5min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed: 10.6min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed: 11.3min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed: 11.4min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed: 11.5min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed: 11.6min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed: 11.6min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed: 11.6min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed: 12.2min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed: 12.3min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed: 12.5min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed: 12.5min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed: 12.5min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed: 12.5min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed: 13.2min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed: 13.2min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed: 13.4min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed: 13.5min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed: 13.5min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed: 13.5min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed: 14.1min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed: 14.1min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed: 14.4min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed: 14.4min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed: 14.4min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed: 14.4min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed: 15.0min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed: 15.3min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed: 15.4min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed: 15.4min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed: 15.4min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed: 15.9min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed: 16.2min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed: 16.3min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed: 16.3min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed: 16.3min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed: 16.8min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed: 16.8min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed: 17.1min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed: 17.2min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed: 17.7min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed: 17.8min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed: 18.1min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed: 18.2min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed: 18.6min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed: 18.7min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed: 19.0min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed: 19.1min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed: 19.1min\n",
            "[Parallel(n_jobs=6)]: Done 123 out of 130 | elapsed: 19.9min remaining:  1.1min\n",
            "[Parallel(n_jobs=6)]: Done 127 out of 130 | elapsed: 20.4min remaining:   28.8s\n",
            "[Parallel(n_jobs=6)]: Done 130 out of 130 | elapsed: 20.6min finished\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved significant channels for subject D0069 and mask Response to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\sig_chans_D0069_Response.json\n",
            "Saved significant channels for subject D0069 and mask Stimulus to C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\sig_chans_D0069_Stimulus.json\n"
          ]
        }
      ],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "\n",
        "sub='D0071'\n",
        "\n",
        "filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "# do filtering now\n",
        "## Crop raw data to minimize processing time\n",
        "good = crop_empty_data(filt)\n",
        "\n",
        "## remove bad channels\n",
        "good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "good.drop_channels(good.info['bads'])\n",
        "good.load_data()\n",
        "\n",
        "# CAR\n",
        "ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "# make baseline \n",
        "# make stimulus baseline EpochsTFR\n",
        "times=[-1, 0.5]\n",
        "trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "outliers_to_nan(trials, outliers=10) #this removes trial outliers BUT breaks the shape because different stimulus epochs will then have different trial numbers\n",
        "HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "data_dict = {}  # make something to store all the outputs\n",
        "\n",
        "for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "    times = [None, None]\n",
        "    times[0] = t[0] - 0.5\n",
        "    times[1] = t[1] + 0.5\n",
        "    trials = trial_ieeg(good, event, times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "    # HG_ev1.resample(100)\n",
        "    # HG_ev1.filenames = good.filenames\n",
        "\n",
        "    # Store the variable in the dictionary with the desired name\n",
        "    data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "    data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "    \n",
        "resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "RTs, skipped = calculate_RTs(good)\n",
        "avg_RT = np.median(RTs)\n",
        "\n",
        "# Plot the evoked data\n",
        "fig = resp_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "fig.savefig(save_dir + '_HG_ev1_Response_zscore_rt.png')\n",
        "\n",
        "fig = stim_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "# Add a vertical line indicating the average reaction time to the plot\n",
        "for ax in fig.axes:\n",
        "    ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    \n",
        "fig.savefig(save_dir + '_HG_ev1_Stimulus_zscore_rt.png')\n",
        "\n",
        "# decimate for stats\n",
        "resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "HG_base.decimate(2)\n",
        "resp.decimate(2)\n",
        "stim.decimate(2)\n",
        "\n",
        "# do permutation cluster\n",
        "resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "\n",
        "#untested code 8/1\n",
        "# Assuming you have the channel names in a variable called 'channels'\n",
        "channels = good.ch_names\n",
        "\n",
        "# Save the significant channels for the response\n",
        "save_sig_chans('Response', resp_mask, channels, sub, save_dir)\n",
        "\n",
        "# Save the significant channels for the stimulus\n",
        "save_sig_chans('Stimulus', stim_mask, channels, sub, save_dir)\n",
        "\n",
        "\n",
        "# plot stats\n",
        "plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "plt.imshow(stim_mask, aspect='auto')  # hold on from matlab\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_stimulus_stats_big.png', dpi=300)\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "plt.imshow(resp_mask, aspect='auto')\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_response_stats_big.png', dpi=300)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### testing with baseline period of 1 sec before stimulus and 1.3 seconds after avg response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "sub = 'D0059'\n",
        "\n",
        "filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "# do filtering now\n",
        "## Crop raw data to minimize processing time\n",
        "good = crop_empty_data(filt)\n",
        "\n",
        "## remove bad channels\n",
        "good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "good.drop_channels(good.info['bads'])\n",
        "good.load_data()\n",
        "\n",
        "# CAR\n",
        "ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "RTs, skipped = calculate_RTs(good)\n",
        "avg_RT = np.median(RTs)\n",
        "print(avg_RT)\n",
        "# make stimulus baseline EpochsTFR\n",
        "times=[-1.5, avg_RT+1.3+0.5] #this is for 0.5 sec of padding on each side\n",
        "\n",
        "# make baseline \n",
        "# make stimulus baseline EpochsTFR\n",
        "# times=[-1, 0.5]\n",
        "\n",
        "trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "outliers_to_nan(trials, outliers=10)\n",
        "HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "data_dict = {}  # Create an empty dictionary\n",
        "\n",
        "for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "    times = [None, None]\n",
        "    times[0] = t[0] - 0.5\n",
        "    times[1] = t[1] + 0.5\n",
        "    trials = trial_ieeg(good, event, times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore') #removed .average() part. Check with Aaron if this is okay.\n",
        "    # HG_ev1.resample(100)\n",
        "    # HG_ev1.filenames = good.filenames\n",
        "\n",
        "    # Store the variable in the dictionary with the desired name\n",
        "    data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "    data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "\n",
        "resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "RTs, skipped = calculate_RTs(good)\n",
        "avg_RT = np.median(RTs)\n",
        "\n",
        "# Plot the evoked data\n",
        "fig = resp_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Response_fullTrialBaseline_zscore.png')\n",
        "\n",
        "fig = stim_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))\n",
        "# Add a vertical line indicating the average reaction time to the plot\n",
        "for ax in fig.axes:\n",
        "    ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "    ax.axvline(x=-0.5, color='g', linestyle='--')\n",
        "fig.savefig(save_dir + '_HG_ev1_Stimulus_fullTrialBaseline_zscore.png')\n",
        "\n",
        "# # decimate for stats\n",
        "# resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "# stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "# HG_base.decimate(2)\n",
        "# resp.decimate(2)\n",
        "# stim.decimate(2)\n",
        "\n",
        "# # import scipy\n",
        "# resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "#                             n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "# stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "#                             n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "\n",
        "# # plot stats\n",
        "# plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "# plt.imshow(stim_mask, aspect='auto')\n",
        "# # hold on from matlab\n",
        "# # plt.imshow(x) #plot multiple things like this\n",
        "\n",
        "# relabel_axes(0, 2500, -1000, 1500)\n",
        "# plt.savefig(save_dir + '_stimulus_stats_big.png', dpi=300)\n",
        "\n",
        "# plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "# plt.imshow(resp_mask, aspect='auto')\n",
        "# relabel_axes(0, 2500, -1000, 1500) \n",
        "# plt.savefig(save_dir + '_response_stats_big.png', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### testing with baseline as average of all data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "sub = 'D0059'\n",
        "\n",
        "filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "# do filtering now\n",
        "## Crop raw data to minimize processing time\n",
        "good = crop_empty_data(filt)\n",
        "\n",
        "## remove bad channels\n",
        "good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "good.drop_channels(good.info['bads'])\n",
        "good.load_data()\n",
        "\n",
        "# CAR\n",
        "ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "# make baseline as average of all data\n",
        "good_avg = good._data.mean()\n",
        "\n",
        "\n",
        "# make stimulus baseline EpochsTFR\n",
        "times=[-1, 0.5]\n",
        "\n",
        "trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "outliers_to_nan(trials, outliers=10)\n",
        "HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "data_dict = {}  # Create an empty dictionary\n",
        "\n",
        "for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "    times = [None, None]\n",
        "    times[0] = t[0] - 0.5\n",
        "    times[1] = t[1] + 0.5\n",
        "    trials = trial_ieeg(good, event, times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "    HG_ev1_rescaled = HG_ev1 #redundant perhaps.\n",
        "    HG_ev1_rescaled._data = HG_ev1_rescaled._data / good_avg\n",
        "\n",
        "    # Store the variable in the dictionary with the desired name\n",
        "    data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "    data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "\n",
        "resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "RTs, skipped = calculate_RTs(good)\n",
        "avg_RT = np.median(RTs)\n",
        "\n",
        "# Plot the evoked data\n",
        "fig = resp_evoke_rescaled.plot()\n",
        "\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Response_allDataBaseline.png')\n",
        "\n",
        "fig = stim_evoke_rescaled.plot()\n",
        "# Add a vertical line indicating the average reaction time to the plot\n",
        "for ax in fig.axes:\n",
        "    ax.axvline(x=avg_RT, color='r', linestyle='--')\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Stimulus_allDataBaseline.png')\n",
        "\n",
        "\n",
        "# decimate for stats\n",
        "resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "HG_base.decimate(2)\n",
        "resp.decimate(2)\n",
        "stim.decimate(2)\n",
        "\n",
        "# import scipy\n",
        "resp_mask = stats.time_perm_cluster(resp._data, good._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "stim_mask = stats.time_perm_cluster(stim._data, good._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "\n",
        "# plot stats\n",
        "plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "plt.imshow(stim_mask, aspect='auto')\n",
        "# hold on from matlab\n",
        "# plt.imshow(x) #plot multiple things like this\n",
        "\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_stimulus_stats_allBase.png', dpi=300)\n",
        "\n",
        "plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "plt.imshow(resp_mask, aspect='auto')\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_response_stats_allBase.png', dpi=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "desired_total_size_last_two_dims: 222894\n",
            "num_samples: 2532\n",
            "current_size: 564188214\n",
            "size_diff: 179394\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# Get the shape of stim._data\n",
        "stim_shape = stim._data.shape\n",
        "\n",
        "# Calculate desired total size for the last two dimensions\n",
        "desired_total_size_last_two_dims = stim_shape[1] * stim_shape[2]\n",
        "\n",
        "# Calculate the number of samples for the first dimension\n",
        "num_samples = current_size // desired_total_size_last_two_dims\n",
        "\n",
        "# If current_size is not an exact multiple of desired_total_size_last_two_dims, add 1 to num_samples\n",
        "if current_size % desired_total_size_last_two_dims != 0:\n",
        "    num_samples += 1\n",
        "\n",
        "# Correct the desired size\n",
        "desired_size = (num_samples, stim_shape[1], stim_shape[2])\n",
        "\n",
        "# Calculate current size and the difference\n",
        "current_size = good._data.size\n",
        "size_diff = desired_total_size_last_two_dims * num_samples - current_size\n",
        "\n",
        "print(f\"desired_total_size_last_two_dims: {desired_total_size_last_two_dims}\")\n",
        "print(f\"num_samples: {num_samples}\")\n",
        "print(f\"current_size: {current_size}\")\n",
        "print(f\"size_diff: {size_diff}\")\n",
        "\n",
        "\n",
        "# Flatten the array first\n",
        "flat_data = good._data.flatten()\n",
        "\n",
        "if size_diff > 0:\n",
        "    # If the current size is smaller than the desired size, pad with zeros\n",
        "    padded = np.pad(flat_data, (0, size_diff))\n",
        "elif size_diff < 0:\n",
        "    # If the current size is larger than the desired size, truncate the array\n",
        "    padded = flat_data[:desired_total_size_last_two_dims * num_samples]\n",
        "else:\n",
        "    # If the sizes match, no padding or truncating is necessary\n",
        "    padded = flat_data\n",
        "\n",
        "# Now reshape\n",
        "good_reshaped = padded.reshape(desired_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = stats.time_perm_cluster(stim._data, good_reshaped, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
