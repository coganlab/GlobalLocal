{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6c30e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "# Get the absolute path to the directory containing the current script\n",
    "# For GlobalLocal/src/analysis/preproc/make_epoched_data.py, this is GlobalLocal/src/analysis/preproc\n",
    "try:\n",
    "    # This will work if running as a .py script\n",
    "    current_file_path = os.path.abspath(__file__)\n",
    "    current_script_dir = os.path.dirname(current_file_path)\n",
    "except NameError:\n",
    "    # This will be executed if __file__ is not defined (e.g., in a Jupyter Notebook)\n",
    "    # os.getcwd() often gives the directory of the notebook,\n",
    "    # or the directory from which the Jupyter server was started.\n",
    "    current_script_dir = os.getcwd()\n",
    "\n",
    "# Navigate up three levels to get to the 'GlobalLocal' directory\n",
    "project_root = os.path.abspath(os.path.join(current_script_dir, '..', '..', '..'))\n",
    "\n",
    "# Add the 'GlobalLocal' directory to sys.path if it's not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root) # insert at the beginning to prioritize it\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import numpy as np\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster, window_averaged_shuffle\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "# from utils import make_or_load_subjects_electrodes_to_ROIs_dict, load_acc_arrays, calculate_RTs, save_channels_to_file, save_sig_chans, \\\n",
    "#       load_sig_chans, channel_names_to_indices, filter_and_average_epochs, permutation_test, perform_permutation_test_across_electrodes, perform_permutation_test_within_electrodes, \\\n",
    "#       add_accuracy_to_epochs, load_mne_objects, create_subjects_mne_objects_dict, extract_significant_effects, convert_dataframe_to_serializable_format, \\\n",
    "#       perform_modular_anova, make_plotting_parameters, plot_significance\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "# still need to test if the permutation test functions load in properly.\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# from src.analysis.power.roi_analysis import blah_blah\n",
    "from src.analysis.config import experiment_conditions, plotting_parameters\n",
    "import src.analysis.utils.general_utils as utils # import utils functions one by one by name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc50e954",
   "metadata": {},
   "source": [
    "get lab root for save dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dbf165",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "# Determine LAB_root based on the operating system\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir_root = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea17ace1",
   "metadata": {},
   "source": [
    "choose which subjects you wanna run (has to be a list, even if just one subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ee848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103', 'D0107A', 'D0110', 'D0116', 'D0117', 'D0121']\n",
    "subjects = ['D0057']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6debcaf",
   "metadata": {},
   "source": [
    "### make or load subjects electrodes to rois dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43e4bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the subjects' electrodes-to-ROIs dictionary...\n",
      "Loaded data from C:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\config\\subjects_electrodestoROIs_dict.json\n",
      "Dictionary loaded successfully. Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# load in subjects electrodes to rois dict. If it doesn't already exist, make it and then load it.\n",
    "config_dir = r'C:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\config'\n",
    "subjects_electrodestoROIs_dict = utils.make_or_load_subjects_electrodes_to_ROIs_dict(subjects, task='GlobalLocal', LAB_root=None, save_dir=config_dir, \n",
    "                                                filename='subjects_electrodestoROIs_dict.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5acd51b",
   "metadata": {},
   "source": [
    "check number of elecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81604e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total elecs: 175\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of electrodes in the 'default_dict' across subjects\n",
    "total_electrodes = utils.count_electrodes_across_subjects(subjects_electrodestoROIs_dict, subjects)\n",
    "print('total elecs:', total_electrodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de999e5",
   "metadata": {},
   "source": [
    "load behavioral data (combinedData.csv) and map blockType to congruency and switch proportions in the behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "56a6406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')\n",
    "combined_data[['congruencyProportion', 'switchProportion']] = combined_data.apply(utils.map_block_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a16de4",
   "metadata": {},
   "source": [
    "### load epochs objects for chosen conditions for all subjects in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78174b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='GlobalLocal'\n",
    "conditions = experiment_conditions.stimulus_switch_type_conditions # set this to whichever conditions you're running\n",
    "stimulus_locked = True  #toggle\n",
    "response_locked = not stimulus_locked\n",
    "\n",
    "if stimulus_locked:\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10\"\n",
    "    epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    # epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_0.0-30.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "    # epochs_root_file = \"Stimulus_100sec_within1-101sec_experimentStartBase_decFactor_8_outliers_10_passband_70-150_padLength_0.5s_stat_func_ttest_ind_equal_var_False\"\n",
    "\n",
    "elif response_locked:\n",
    "    # epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_4.0-8.0_padLength_0.5s_stat_func_ttest_ind\"\n",
    "    epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind\"\n",
    "\n",
    "condition_names = [condition for condition in conditions.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "18795727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for subject: D0057\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "449 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_passband_70.0-150.0_padLength_0.5s_stat_func_ttest_ind_equal_var_False_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "449 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus_r with parameters: {'BIDS_events': ['Stimulus/r25.0', 'Stimulus/r75.0'], 'switchType': 'r'}\n",
      "Not setting metadata\n",
      "212 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\utils\\general_utils.py:403: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  event_epochs = mne.concatenate_epochs(combined_epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Original shape: (212, 175, 641)\n",
      "    Trials with all NaN values: 0\n",
      "    Average NaN count per trial: 111.9\n",
      "    Max NaN count in a trial: 1282\n",
      "    Stimulus_r: 212 valid trials out of 212\n",
      "  Loading condition: Stimulus_s with parameters: {'BIDS_events': ['Stimulus/s25.0', 'Stimulus/s75.0'], 'switchType': 's'}\n",
      "Not setting metadata\n",
      "189 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\utils\\general_utils.py:403: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  event_epochs = mne.concatenate_epochs(combined_epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Original shape: (189, 175, 641)\n",
      "    Trials with all NaN values: 0\n",
      "    Average NaN count per trial: 135.7\n",
      "    Max NaN count in a trial: 1923\n",
      "    Stimulus_s: 189 valid trials out of 189\n",
      "  Loading condition: Stimulus_r with parameters: {'BIDS_events': ['Stimulus/r25.0', 'Stimulus/r75.0'], 'switchType': 'r'}\n",
      "Not setting metadata\n",
      "212 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\utils\\general_utils.py:403: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  event_epochs = mne.concatenate_epochs(combined_epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Original shape: (212, 175, 641)\n",
      "    Trials with all NaN values: 0\n",
      "    Average NaN count per trial: 111.9\n",
      "    Max NaN count in a trial: 1282\n",
      "    Stimulus_r: 212 valid trials out of 212\n",
      "  Loading condition: Stimulus_s with parameters: {'BIDS_events': ['Stimulus/s25.0', 'Stimulus/s75.0'], 'switchType': 's'}\n",
      "Not setting metadata\n",
      "189 matching events found\n",
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jz421\\Desktop\\GlobalLocal\\src\\analysis\\utils\\general_utils.py:403: RuntimeWarning: Concatenation of Annotations within Epochs is not supported yet. All annotations will be dropped.\n",
      "  event_epochs = mne.concatenate_epochs(combined_epochs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Original shape: (189, 175, 641)\n",
      "    Trials with all NaN values: 0\n",
      "    Average NaN count per trial: 135.7\n",
      "    Max NaN count in a trial: 1923\n",
      "    Stimulus_s: 189 valid trials out of 189\n"
     ]
    }
   ],
   "source": [
    "if conditions == experiment_conditions.stimulus_conditions:\n",
    "    conditions_save_name = 'stimulus_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_experiment_conditions:\n",
    "    conditions_save_name = 'stimulus_experiment_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_main_effect_conditions:\n",
    "    conditions_save_name = 'stimulus_main_effect_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_lwpc_conditions:\n",
    "    conditions_save_name = 'stimulus_lwpc_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_lwps_conditions:\n",
    "    conditions_save_name = 'stimulus_lwps_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_big_letter_conditions:\n",
    "    conditions_save_name = 'stimulus_big_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_small_letter_conditions:\n",
    "    conditions_save_name = 'stimulus_small_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_task_conditions:\n",
    "    conditions_save_name = 'stimulus_task_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_congruency_conditions:\n",
    "    conditions_save_name = 'stimulus_congruency_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.stimulus_switch_type_conditions:\n",
    "    conditions_save_name = 'stimulus_switch_type_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "\n",
    "elif conditions == experiment_conditions.response_conditions:\n",
    "    conditions_save_name = 'response_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_experiment_conditions:\n",
    "    conditions_save_name = 'response_experiment_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_big_letter_conditions:\n",
    "    conditions_save_name = 'response_big_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_small_letter_conditions:\n",
    "    conditions_save_name = 'response_small_letter_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_task_conditions:\n",
    "    conditions_save_name = 'response_task_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_congruency_conditions:\n",
    "    conditions_save_name = 'response_congruency_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "elif conditions == experiment_conditions.response_switch_type_conditions:\n",
    "    conditions_save_name = 'response_switch_type_conditions' + '_' + epochs_root_file + '_' + str(len(subjects)) + '_' + 'subjects'\n",
    "    \n",
    "# Assuming 'combined_data' is your DataFrame and 'subjects' is your list of subject IDs\n",
    "subjects_mne_objects = utils.create_subjects_mne_objects_dict(subjects=subjects, epochs_root_file=epochs_root_file, conditions=conditions, task=\"GlobalLocal\", just_HG_ev1_rescaled=True, acc_trials_only=True, error_trials_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318b8444",
   "metadata": {},
   "source": [
    "### load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38778777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0057\n"
     ]
    }
   ],
   "source": [
    "sig_chans_per_subject = utils.get_sig_chans_per_subject(subjects, epochs_root_file, task='GlobalLocal', LAB_root=None)\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7959842a",
   "metadata": {},
   "source": [
    "### get the significant electrodes across subjects for each ROI of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e56bd",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup\n",
    "ACC based on Destrieux et al 2010 definition is G_and_S_cingul-Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b25517fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject D0057, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RAI6', 'RAI12', 'RAI13', 'RAI14', 'RAI15', 'RAI16', 'RPI15', 'RPI14', 'RAMF10', 'RAMF11', 'RAMF12', 'RAMF13', 'RAMF14', 'RAIF11', 'RAIF12', 'RAIF13', 'RAIF14']\n",
      "Subject D0057 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RAI6', 'RAMF14']\n",
      "For subject D0057, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RPIT1']\n",
      "Subject D0057 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['RPIT1']\n"
     ]
    }
   ],
   "source": [
    "# rois_dict = {\n",
    "#     # 'dlpfc': [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "#     # 'acc': [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"],\n",
    "#     # 'parietal': [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"],\n",
    "#     'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "#     'v1': [\"G_oc-temp_med-Lingual\", \"S_calcarine\", \"G_cuneus\"],\n",
    "#     'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"]\n",
    "# }\n",
    "\n",
    "# the cns 24/sfn 24 poster plots need just one roi. Fix all this code later. 10/1.\n",
    "# rois_dict = {\n",
    "#     'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"]\n",
    "# }\n",
    "\n",
    "rois_dict = {\n",
    "    'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"]\n",
    "}\n",
    "\n",
    "rois = list(rois_dict.keys())\n",
    "all_electrodes_per_subject_roi, sig_electrodes_per_subject_roi = utils.make_sig_electrodes_per_subject_and_roi_dict(rois_dict, subjects_electrodestoROIs_dict, sig_chans_per_subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d5b075f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total sig elecs: 74\n"
     ]
    }
   ],
   "source": [
    "print('total sig elecs:', sum(len(sig_chans_per_subject[sub]) for sub in sig_chans_per_subject))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aeadde",
   "metadata": {},
   "source": [
    "get number of sig and all electrodes per subject and across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "823d6d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject D0057, ROI lpfc, Num of Sig Electrodes: 2, Num of All Electrodes: 17\n",
      "Subject D0057, ROI occ, Num of Sig Electrodes: 1, Num of All Electrodes: 1\n"
     ]
    }
   ],
   "source": [
    "for roi in rois:\n",
    "    for sub in subjects:\n",
    "        sig_elecs = sig_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "        all_elecs = all_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "        print(f\"Subject {sub}, ROI {roi}, Num of Sig Electrodes: {len(sig_elecs)}, Num of All Electrodes: {len(all_elecs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3955df57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of significant lpfc electrodes across all subjects: 2\n",
      "Total number of lpfc electrodes across all subjects: 17\n",
      "Total number of significant occ electrodes across all subjects: 1\n",
      "Total number of occ electrodes across all subjects: 1\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "total_electrodes_info = utils.calculate_total_electrodes(sig_electrodes_per_subject_roi, all_electrodes_per_subject_roi)\n",
    "for roi, counts in total_electrodes_info.items():\n",
    "    print(f\"Total number of significant {roi} electrodes across all subjects:\", counts['total_significant_electrodes'])\n",
    "    print(f\"Total number of {roi} electrodes across all subjects:\", counts['total_electrodes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e82d9",
   "metadata": {},
   "source": [
    "check sampling rates to make sure they're all the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "689a09a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject D0057 has the expected sampling rate: 256.0 Hz.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'subjects_mne_objects' is your dictionary containing MNE objects for each subject\n",
    "sampling_rate = 256\n",
    "subject_rates = utils.check_sampling_rates(subjects_mne_objects, expected_sampling_rate=sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff1018",
   "metadata": {},
   "source": [
    "TODO: stats next (maybe do time perm cluster with t-test as follow-up test for ANOVA significance, let's try using MNE functions for ANOVA and perm test)   \n",
    "TODO: add in code for selecting electrodes of a specific ROI  \n",
    "TODO: plotting average traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e5c3cc9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'condition_parameter': 'repeat', 'color': 'blue', 'line_style': '-'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plotting_parameters.plotting_parameters['Stimulus_r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e5e34b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 641)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just do something like this to get the elecs in an roi for a subject. Then, add this to a list of evokeds i think. \n",
    "subjects_mne_objects['D0057']['Stimulus_s']['HG_ev1_power_rescaled_avg'].pick(sig_electrodes_per_subject_roi['lpfc'].get('D0057', [])).get_data().shape\n",
    "\n",
    "# Hmm, how to combine evokeds across subjects here?\n",
    "\n",
    "# then i can do plot_compare_evokeds for the various conditions against each other. But the number of channels and timepoints must be the same across conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d19eb6",
   "metadata": {},
   "source": [
    "these functions are for manipulating evoked objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d41857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_single_channel_evokeds(single_channel_evokeds, ch_type='seeg'):\n",
    "    \"\"\"\n",
    "    Combine a list of single-channel evoked objects into one multi-channel evoked object.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    single_channel_evokeds : list of mne.Evoked\n",
    "        List of single-channel evoked objects to combine\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    combined_evoked : mne.Evoked\n",
    "        Multi-channel evoked object\n",
    "    \"\"\"\n",
    "    if not single_channel_evokeds:\n",
    "        return None\n",
    "    \n",
    "    # Get the first evoked as a template\n",
    "    template = single_channel_evokeds[0].copy()\n",
    "    \n",
    "    # Stack all the data from single channels\n",
    "    all_data = []\n",
    "    all_ch_names = []\n",
    "    \n",
    "    for evk in single_channel_evokeds:\n",
    "        all_data.append(evk.data)\n",
    "        all_ch_names.extend(evk.ch_names)\n",
    "    \n",
    "    # Create new data array with shape (n_channels, n_times)\n",
    "    combined_data = np.vstack(all_data)\n",
    "    \n",
    "    # Create new info with all channels\n",
    "    info = mne.create_info(\n",
    "        ch_names=all_ch_names,\n",
    "        sfreq=template.info['sfreq'],\n",
    "        ch_types=ch_type  # probably all are sEEG\n",
    "    )\n",
    "    \n",
    "    # Create the combined evoked object\n",
    "    combined_evoked = mne.EvokedArray(\n",
    "        data=combined_data,\n",
    "        info=info,\n",
    "        tmin=template.tmin,\n",
    "        nave=template.nave,\n",
    "        comment=template.comment\n",
    "    )\n",
    "    \n",
    "    return combined_evoked\n",
    "\n",
    "def get_subject_electrodes_for_roi(subject, roi, electrodes_per_subject_roi):\n",
    "    \"\"\"\n",
    "    Get electrodes for a specific subject and ROI.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subject : str\n",
    "        Subject ID\n",
    "    roi : str\n",
    "        ROI name\n",
    "    electrodes_per_subject_roi : dict\n",
    "        Dictionary mapping ROIs to subjects and their electrodes. Example is sig_electrodes_per_subject_roi[roi][subject]\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of electrode names, empty if none found\n",
    "    \"\"\"\n",
    "    return electrodes_per_subject_roi.get(roi, {}).get(subject, [])\n",
    "\n",
    "def get_evoked_for_specific_subject_and_condition(subjects_mne_objects, subject, condition_name, \n",
    "                      mne_object_type='HG_ev1_power_rescaled'):\n",
    "    \"\"\"\n",
    "    Get the trial-averaged evoked object for a specific subject and condition.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subjects_mne_objects : dict\n",
    "        Nested dictionary with MNE objects\n",
    "    subject : str\n",
    "        Subject ID\n",
    "    condition_name : str\n",
    "        Condition name\n",
    "    mne_object_type : str\n",
    "        Which MNE object to use\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    mne.Evoked\n",
    "        Evoked object for the subject and condition\n",
    "    \"\"\"\n",
    "    return subjects_mne_objects[subject][condition_name][mne_object_type + \"_avg\"].copy()\n",
    "    \n",
    "def extract_single_electrode_evokeds(evoked, electrode_names):\n",
    "    \"\"\"\n",
    "    Extract individual evoked objects for each electrode.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    evoked : mne.Evoked\n",
    "        Multi-channel evoked object\n",
    "    electrode_names : list\n",
    "        List of electrode names to extract\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of single-electrode evoked objects\n",
    "    \"\"\"\n",
    "    single_electrode_evokeds = []\n",
    "    \n",
    "    # First pick only the specified electrodes\n",
    "    evoked_subset = evoked.copy().pick_channels(electrode_names)\n",
    "    \n",
    "    # Then create individual evoked objects for each electrode\n",
    "    for ch_name in evoked_subset.ch_names:\n",
    "        evoked_single = evoked_subset.copy().pick_channels([ch_name])\n",
    "        single_electrode_evokeds.append(evoked_single)\n",
    "    \n",
    "    return single_electrode_evokeds\n",
    "\n",
    "def create_list_of_single_channel_evokeds_across_subjects_for_roi_and_condition(subjects_mne_objects, subjects, roi, electrodes_per_subject_roi, \n",
    "                           condition_name, mne_object_type='HG_ev1_power_rescaled'):\n",
    "    \"\"\"\n",
    "    Create lists of single-electrode evoked objects for each condition across all electrodes in an ROI.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subjects_mne_objects : dict\n",
    "        Nested dictionary with MNE objects\n",
    "    subjects : list\n",
    "        List of subject IDs\n",
    "    roi : str\n",
    "        ROI name (e.g., 'lpfc', 'occ')\n",
    "    electrodes_per_subject_roi : dict\n",
    "        Dictionary mapping ROIs to subjects and their electrodes\n",
    "    condition_name : str\n",
    "        Condition name to process\n",
    "    mne_object_type : str\n",
    "        Which MNE object to use (default: 'HG_ev1_power_rescaled')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    List\n",
    "        A list of evokeds where each entry is a trial-averaged evoked object for a significant electrode, and a similar list for all electrodes.\n",
    "    \"\"\"\n",
    "\n",
    "    all_evokeds_electrodes = []\n",
    "    \n",
    "    for sub in subjects:\n",
    "        # Get the trial-averaged evoked for this subject and condition\n",
    "        evoked = get_evoked_for_specific_subject_and_condition(subjects_mne_objects, sub, condition_name, mne_object_type)\n",
    "        \n",
    "        # Get electrode lists for this subject and ROI\n",
    "        electrodes = get_subject_electrodes_for_roi(sub, roi, electrodes_per_subject_roi)\n",
    "        \n",
    "        if not electrodes:\n",
    "            continue\n",
    "            \n",
    "        # Extract single-electrode evokeds for significant electrodes\n",
    "        evoked_electrodes_for_this_subject = extract_single_electrode_evokeds(evoked, electrodes)\n",
    "        all_evokeds_electrodes.extend(evoked_electrodes_for_this_subject)\n",
    "            \n",
    "    return all_evokeds_electrodes\n",
    "\n",
    "def make_evoked_electrode_lists_for_rois(subjects_mne_objects, subjects, rois, \n",
    "                                       electrodes_per_subject_roi, \n",
    "                                       condition_name, mne_object_type='HG_ev1_power_rescaled'):\n",
    "    \"\"\"\n",
    "    Create evoked electrode lists for all ROIs for a specific condition.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subjects_mne_objects : dict\n",
    "        Nested dictionary with MNE objects\n",
    "    subjects : list\n",
    "        List of subject IDs\n",
    "    rois : list\n",
    "        List of ROI names\n",
    "    electrodes_per_subject_roi : dict\n",
    "        Dictionary mapping ROIs to subjects and their all electrodes\n",
    "    condition_name : str\n",
    "        Condition name to process\n",
    "    mne_object_type : str\n",
    "        Which MNE object to use\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with ROI names as keys and evokeds as values\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for roi in rois:\n",
    "        evokeds = create_list_of_single_channel_evokeds_across_subjects_for_roi_and_condition(\n",
    "            subjects_mne_objects, subjects, roi, electrodes_per_subject_roi, \n",
    "            condition_name, mne_object_type\n",
    "        )\n",
    "        out[roi] = evokeds\n",
    "    return out\n",
    "\n",
    "def make_evoked_electrode_lists_for_all_conditions_and_rois(subjects_mne_objects, subjects, rois, \n",
    "                                                   condition_names, electrodes_per_subject_roi, \n",
    "                                                   mne_object_type='HG_ev1_power_rescaled'):\n",
    "    \"\"\"\n",
    "    Create evoked electrode lists for all conditions and ROIs.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subjects_mne_objects : dict\n",
    "        Nested dictionary with MNE objects\n",
    "    subjects : list\n",
    "        List of subject IDs\n",
    "    rois : list\n",
    "        List of ROI names\n",
    "    condition_names : list\n",
    "        List of condition names\n",
    "    electrodes_per_subject_roi : dict\n",
    "        Dictionary mapping ROIs to subjects and their electrodes\n",
    "    mne_object_type : str\n",
    "        Which MNE object to use\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Nested dictionary: condition_name -> roi -> evokeds\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "    for condition_name in condition_names:\n",
    "        out[condition_name] = make_evoked_electrode_lists_for_rois(\n",
    "            subjects_mne_objects, subjects, rois,\n",
    "            electrodes_per_subject_roi, condition_name, mne_object_type\n",
    "        )\n",
    "    return out\n",
    "\n",
    "def make_multi_channel_evokeds_for_all_conditions_and_rois(subjects_mne_objects, subjects, rois, \n",
    "                                                           condition_names, electrodes_per_subject_roi,\n",
    "                                                           mne_object_type='HG_ev1_power_rescaled'):\n",
    "    \"\"\"\n",
    "    Create multi-channel evoked objects for all conditions and ROIs by combining single-channel evokeds.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subjects_mne_objects : dict\n",
    "        Nested dictionary with MNE objects\n",
    "    subjects : list\n",
    "        List of subject IDs\n",
    "    rois : list\n",
    "        List of ROI names\n",
    "    condition_names : list\n",
    "        List of condition names\n",
    "    electrodes_per_subject_roi : dict\n",
    "        Dictionary mapping ROIs to subjects and their electrodes\n",
    "    mne_object_type : str\n",
    "        Which MNE object to use (default: 'HG_ev1_power_rescaled')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Nested dictionary: condition_name -> roi -> multi-channel evoked object\n",
    "    \"\"\"\n",
    "    # First get all single-channel evokeds\n",
    "    evks_dict_single_elecs = make_evoked_electrode_lists_for_all_conditions_and_rois(\n",
    "        subjects_mne_objects, subjects, rois, condition_names, \n",
    "        electrodes_per_subject_roi, mne_object_type\n",
    "    )\n",
    "    \n",
    "    # Now combine them into multi-channel evokeds\n",
    "    evks_dict_multi_elecs = {}\n",
    "    \n",
    "    for condition_name in condition_names:\n",
    "        evks_dict_multi_elecs[condition_name] = {}\n",
    "        \n",
    "        for roi in rois:\n",
    "            single_channel_evks = evks_dict_single_elecs[condition_name][roi]\n",
    "            combined_evk = combine_single_channel_evokeds(single_channel_evks)\n",
    "            evks_dict_multi_elecs[condition_name][roi] = combined_evk\n",
    "            \n",
    "    return evks_dict_multi_elecs\n",
    "    \n",
    "def create_roi_grand_average(subjects_mne_objects, subjects, roi, electrodes_per_subject_roi,\n",
    "                           condition_names, mne_object_type='HG_ev1_power_rescaled'):\n",
    "    \"\"\"\n",
    "    Create grand average evoked objects for each condition across all electrodes in an ROI.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    subjects_mne_objects : dict\n",
    "        Nested dictionary with MNE objects\n",
    "    subjects : list\n",
    "        List of subject IDs\n",
    "    roi : str\n",
    "        ROI name (e.g., 'lpfc', 'occ')\n",
    "    electrodes_per_subject_roi : dict\n",
    "        Dictionary mapping ROIs to subjects and their electrodes\n",
    "    condition_names : list\n",
    "        List of condition names to process\n",
    "    mne_object_type : str\n",
    "        Which MNE object to use (default: 'HG_ev1_power_rescaled')\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with condition names as keys and grand average evoked objects across all or sig electrodes in this ROI as values. AKA first trial average within each electrode, then average across electrodes. Also return SEM across electrodes.\n",
    "    \"\"\"\n",
    "    grand_averages_electrodes = {}\n",
    "    \n",
    "    for condition_name in condition_names:\n",
    "        all_evokeds_electrodes = create_list_of_single_channel_evokeds_across_subjects_for_roi_and_condition(subjects_mne_objects, subjects, roi, electrodes_per_subject_roi, condition_name, mne_object_type)\n",
    "        grand_avg = mne.grand_average(all_evokeds_electrodes)\n",
    "        grand_averages_electrodes[condition_name] = grand_avg\n",
    "\n",
    "    return grand_averages_electrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7f8636",
   "metadata": {},
   "source": [
    "now let's actually try plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_power_trace_for_roi(evks_dict, roi, condition_names, conditions_save_name, plotting_parameters,\n",
    "                            save_dir=None, show_std=True, show_sem=False, show_ci=False, ci=0.95, figsize=(12, 8), x_label='Time (s)', ylim=None, y_label='Power (z)', font_size=12, title_font_size=14):\n",
    "    \"\"\"\n",
    "    Custom plot with standard deviation or standard error shading.\n",
    "    \n",
    "    Since MNE's plot_compare_evokeds only supports confidence intervals,\n",
    "    this function manually creates plots with SD or SEM shading.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    evks_dict : dict\n",
    "        Dictionary with condition names as keys and evoked dictionaries as values\n",
    "    roi : str\n",
    "        ROI name\n",
    "    condition_names : list\n",
    "        List of condition names to plot\n",
    "    conditions_save_name : str\n",
    "        Name to use for saving the plot\n",
    "    plotting_parameters : dict\n",
    "        Dictionary with plotting parameters\n",
    "    save_dir : str\n",
    "        Directory to save the plot\n",
    "    show_std : bool\n",
    "        Whether to show standard deviation shading\n",
    "    show_sem : bool\n",
    "        Whether to show standard error of mean shading\n",
    "    figsize : tuple\n",
    "        Figure size\n",
    "    ylim : tuple\n",
    "        Y-axis limits\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    fig : matplotlib figure\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    for condition_name in condition_names:\n",
    "        evoked = evks_dict[condition_name][roi]\n",
    "        if evoked is None or evoked.data.shape[0] == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get plotting parameters\n",
    "        param_key = None\n",
    "        for key in plotting_parameters.keys():\n",
    "            if condition_name in key or key in condition_name:\n",
    "                param_key = key\n",
    "                break\n",
    "        \n",
    "        if param_key and param_key in plotting_parameters:\n",
    "            params = plotting_parameters[param_key]\n",
    "            color = params.get('color', 'black')\n",
    "            linestyle = params.get('line_style', '-')\n",
    "            label = params.get('condition_parameter', condition_name)\n",
    "        else:\n",
    "            color = 'black'\n",
    "            linestyle = '-'\n",
    "            label = condition_name\n",
    "        \n",
    "        # Get data\n",
    "        times = evoked.times\n",
    "        data = evoked.data\n",
    "        n_channels = data.shape[0]\n",
    "        \n",
    "        # Calculate mean across channels\n",
    "        mean_data = np.mean(data, axis=0)\n",
    "        \n",
    "        # Plot mean\n",
    "        ax.plot(times, mean_data, color=color, linestyle=linestyle,\n",
    "                linewidth=2.5, label=label)\n",
    "        \n",
    "        # Add shading\n",
    "        if show_std:\n",
    "            std_data = np.std(data, axis=0)\n",
    "            ax.fill_between(times, mean_data - std_data, mean_data + std_data,\n",
    "                           alpha=0.3, color=color, linewidth=0)\n",
    "        elif show_sem:\n",
    "            sem_data = np.std(data, axis=0) / np.sqrt(n_channels)\n",
    "            ax.fill_between(times, mean_data - sem_data, mean_data + sem_data,\n",
    "                           alpha=0.3, color=color, linewidth=0)\n",
    "        elif show_ci:\n",
    "            ci_data = np.percentile(data, [100 * (1 - ci), 100 * ci], axis=0)\n",
    "            ax.fill_between(times, ci_data[0], ci_data[1],\n",
    "                           alpha=0.3, color=color, linewidth=0)\n",
    "\n",
    "    # Customize plot\n",
    "\n",
    "    ax.set_xlabel(x_label, fontsize=font_size)\n",
    "    ax.set_ylabel(y_label, fontsize=font_size)\n",
    "    ax.axhline(y=0, color='black', linestyle=':', alpha=0.5)\n",
    "    ax.axvline(x=0, color='black', linestyle=':', alpha=0.5)\n",
    "    \n",
    "    # Set title\n",
    "    title = f'{roi.upper()}'\n",
    "\n",
    "    if show_std:\n",
    "        title += ' (±1 SD)'\n",
    "    elif show_sem:\n",
    "        title += ' (±1 SEM)'\n",
    "    elif show_ci:\n",
    "        title += f' ({ci*100}% CI)'\n",
    "\n",
    "    ax.set_title(title, fontsize=title_font_size, fontweight='bold')\n",
    "    \n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "    \n",
    "    ax.legend(loc='best', framealpha=0.95)\n",
    "    ax.grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save if directory provided\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        error_type = 'std' if show_std else 'sem' if show_sem else 'ci' if show_ci else 'no_error'\n",
    "        filename = f'{roi}_{conditions_save_name}_{error_type}_shading.png'\n",
    "        filepath = os.path.join(save_dir, filename)\n",
    "        plt.savefig(filepath, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Saved plot to: {filepath}\")\n",
    "    \n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "def plot_power_traces_for_all_rois(evks_dict_elecs, rois, \n",
    "                                  condition_names, plotting_parameters, save_dir=None,\n",
    "                                  error_type='std', figsize=(12, 8), x_label='Time (s)', y_label='Power (z)',\n",
    "                                  font_size=12, title_font_size=14):\n",
    "    \"\"\"\n",
    "    Plot power traces for each ROI comparing the specified conditions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    evks_dict_elecs : dict\n",
    "        Evoked objects for electrodes\n",
    "    rois : list\n",
    "        List of ROI names\n",
    "    condition_names : list\n",
    "        List of condition names\n",
    "    plotting_parameters : dict\n",
    "        Plotting parameters dictionary\n",
    "    save_dir : str\n",
    "        Directory to save plots\n",
    "    error_type : str\n",
    "        Type of error to show: 'std', 'sem', 'ci', or 'none'\n",
    "    x_label : str\n",
    "        X-axis label\n",
    "    y_label : str\n",
    "        Y-axis label\n",
    "    font_size : int\n",
    "        Font size for labels and title\n",
    "    title_font_size : int\n",
    "        Font size for title\n",
    "    figsize : tuple\n",
    "        Figure size for each plot\n",
    "    \"\"\"\n",
    "    if save_dir:\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    for roi in rois:\n",
    "        # Plot all electrodes\n",
    "        if error_type == 'std':\n",
    "            # Use custom function for standard deviation\n",
    "            plot_power_trace_for_roi(\n",
    "                evks_dict_elecs, roi, condition_names, plotting_parameters,\n",
    "                save_dir=save_dir,\n",
    "                show_std=True, show_sem=False, font_size=font_size, \n",
    "                x_label=x_label, y_label=y_label,\n",
    "                title_font_size=title_font_size, figsize=figsize\n",
    "            )\n",
    "        elif error_type == 'sem':\n",
    "            # Use custom function for standard error\n",
    "            plot_power_trace_for_roi(\n",
    "                evks_dict_elecs, roi, condition_names, plotting_parameters,\n",
    "                save_dir=save_dir,\n",
    "                show_std=False, show_sem=True, font_size=font_size, \n",
    "                x_label=x_label, y_label=y_label,\n",
    "                title_font_size=title_font_size, figsize=figsize\n",
    "            )\n",
    "        elif error_type == 'ci':\n",
    "            # Use MNE function with 95% CI\n",
    "            plot_power_trace_for_roi(\n",
    "                evks_dict_elecs, roi, condition_names, plotting_parameters,\n",
    "                save_dir=save_dir,\n",
    "                show_std=False, show_sem=False, show_ci=True, ci=0.95, font_size=font_size, \n",
    "                x_label=x_label, y_label=y_label,\n",
    "                title_font_size=title_font_size, figsize=figsize\n",
    "            )\n",
    "        else:\n",
    "            # No error bars\n",
    "            plot_power_trace_for_roi(\n",
    "                evks_dict_elecs, roi, condition_names, plotting_parameters,\n",
    "                save_dir=save_dir,\n",
    "                show_std=False, show_sem=False, show_ci=False, ci=None, font_size=font_size, \n",
    "                x_label=x_label, y_label=y_label,\n",
    "                title_font_size=title_font_size, figsize=figsize\n",
    "            )\n",
    "    \n",
    "    if save_dir:\n",
    "        print(f\"\\nAll plots saved to: {save_dir}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2656fd56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"median\"\n",
      "combining channels using \"median\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n",
      "combining channels using \"mean\"\n",
      "combining channels using \"mean\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_18252\\3879614566.py:16: RuntimeWarning: Only 1 channel in \"picks\"; cannot combine by method \"mean\".\n",
      "  mne.viz.plot_compare_evokeds(evks_for_plotting, title=roi, combine=combine, ci=0.95)\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_18252\\3879614566.py:16: RuntimeWarning: Cannot find channel coordinates in the supplied Evokeds. Not showing channel locations.\n",
      "  mne.viz.plot_compare_evokeds(evks_for_plotting, title=roi, combine=combine, ci=0.95)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"median\"\n",
      "combining channels using \"median\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_18252\\3879614566.py:16: RuntimeWarning: Only 1 channel in \"picks\"; cannot combine by method \"median\".\n",
      "  mne.viz.plot_compare_evokeds(evks_for_plotting, title=roi, combine=combine, ci=0.95)\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_18252\\3879614566.py:16: RuntimeWarning: Cannot find channel coordinates in the supplied Evokeds. Not showing channel locations.\n",
      "  mne.viz.plot_compare_evokeds(evks_for_plotting, title=roi, combine=combine, ci=0.95)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using \"gfp\"\n",
      "combining channels using \"gfp\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_18252\\3879614566.py:16: RuntimeWarning: Only 1 channel in \"picks\"; cannot combine by method \"gfp\".\n",
      "  mne.viz.plot_compare_evokeds(evks_for_plotting, title=roi, combine=combine, ci=0.95)\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_18252\\3879614566.py:16: RuntimeWarning: Cannot find channel coordinates in the supplied Evokeds. Not showing channel locations.\n",
      "  mne.viz.plot_compare_evokeds(evks_for_plotting, title=roi, combine=combine, ci=0.95)\n"
     ]
    }
   ],
   "source": [
    "save_dir = os.path.join(save_dir_root, epochs_root_file)\n",
    "\n",
    "evks_dict_sig_elecs = make_multi_channel_evokeds_for_all_conditions_and_rois(\n",
    "    subjects_mne_objects, subjects, rois, condition_names, \n",
    "    sig_electrodes_per_subject_roi\n",
    ") \n",
    "\n",
    "evks_dict_all_elecs = make_multi_channel_evokeds_for_all_conditions_and_rois(\n",
    "    subjects_mne_objects, subjects, rois, condition_names, \n",
    "    all_electrodes_per_subject_roi\n",
    ")\n",
    "\n",
    "plot_power_traces_for_all_rois(\n",
    "    evks_dict_all_elecs, rois, condition_names, plotting_parameters,\n",
    "    save_dir=save_dir,\n",
    "    error_type='std', figsize=(12, 8), x_label='Time (s)', y_label='Power (z)',\n",
    "    font_size=12, title_font_size=14\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
