{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ieeg.viz.utils\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.calc import stats, scaling\n",
        "from ieeg.process import parallelize\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from bids import BIDSLayout\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relabel_axes(old_min, old_max, new_min, new_max):\n",
        "    scale = (new_max - new_min) / (old_max - old_min)\n",
        "\n",
        "    def format_func(value, tick_number):\n",
        "        return new_min + value * scale\n",
        "\n",
        "    plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(format_func))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### grab the data and set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24}\n",
            "KeysView({'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24})\n",
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077']\n",
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077']\n",
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077']\n",
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077']\n",
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077']\n",
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077']\n",
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077']\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "No files match your search terms",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[76], line 22\u001b[0m\n\u001b[0;32m     18\u001b[0m subjects \u001b[39m=\u001b[39m layout\u001b[39m.\u001b[39mget(return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m, target\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msubject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m \u001b[39mfor\u001b[39;00m sub \u001b[39min\u001b[39;00m subjects:\u001b[39mprint\u001b[39m(subjects)\n\u001b[1;32m---> 22\u001b[0m filt \u001b[39m=\u001b[39m raw_from_layout(layout\u001b[39m.\u001b[39;49mderivatives[\u001b[39m'\u001b[39;49m\u001b[39mderivatives/clean\u001b[39;49m\u001b[39m'\u001b[39;49m], subject\u001b[39m=\u001b[39;49msub,\n\u001b[0;32m     23\u001b[0m                            extension\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.edf\u001b[39;49m\u001b[39m'\u001b[39;49m, desc\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mclean\u001b[39;49m\u001b[39m'\u001b[39;49m, preload\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m) \u001b[39m#get line-noise filtered data\u001b[39;00m\n\u001b[0;32m     27\u001b[0m save_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(layout\u001b[39m.\u001b[39mroot, \u001b[39m'\u001b[39m\u001b[39mderivatives\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfreqFilt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfigs\u001b[39m\u001b[39m'\u001b[39m, sub)\n\u001b[0;32m     28\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(save_dir):\n",
            "File \u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:104\u001b[0m, in \u001b[0;36mraw_from_layout\u001b[1;34m(layout, preload, run, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m     whole_raw: mne\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mRaw \u001b[39m=\u001b[39m mne\u001b[39m.\u001b[39mconcatenate_raws(raw)\n\u001b[0;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 104\u001b[0m     BIDS_path \u001b[39m=\u001b[39m bidspath_from_layout(layout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    105\u001b[0m     whole_raw \u001b[39m=\u001b[39m read_raw_bids(bids_path\u001b[39m=\u001b[39mBIDS_path)\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m preload:\n",
            "File \u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\ieeg\\io.py:64\u001b[0m, in \u001b[0;36mbidspath_from_layout\u001b[1;34m(layout, **kwargs)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSearch terms matched more than one file: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     61\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m try adding more search terms\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(my_search))\n\u001b[0;32m     63\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39m(my_search) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 64\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo files match your search terms\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m found \u001b[39m=\u001b[39m my_search[\u001b[39m0\u001b[39m]\n\u001b[0;32m     66\u001b[0m entities \u001b[39m=\u001b[39m found\u001b[39m.\u001b[39mget_entities()\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: No files match your search terms"
          ]
        }
      ],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "for sub in subjects:\n",
        "\n",
        "    if sub == 'D0057':\n",
        "        continue\n",
        "\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                            extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "    # do filtering now\n",
        "    ## Crop raw data to minimize processing time\n",
        "    new = crop_empty_data(filt, )\n",
        "\n",
        "    # Mark channel outliers as bad\n",
        "    # new.info['bads'] = channel_outlier_marker(new, 4)\n",
        "    # Exclude bad channels\n",
        "    good = new.copy().drop_channels(filt.info['bads'])\n",
        "    good.load_data()\n",
        "\n",
        "    # CAR\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "    # Remove intermediates from mem\n",
        "    del new\n",
        "\n",
        "    # make baseline \n",
        "    # make stimulus baseline EpochsTFR\n",
        "    times=[-1, 0.5]\n",
        "\n",
        "    trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "    # outliers_to_nan(trials, outliers=10)\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    data_dict = {}  # Create an empty dictionary\n",
        "\n",
        "    for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "        times = [None, None]\n",
        "        times[0] = t[0] - 0.5\n",
        "        times[1] = t[1] + 0.5\n",
        "        trials = trial_ieeg(good, event, times, preload=True)\n",
        "        # outliers_to_nan(trials, outliers=10)\n",
        "        HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "        crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "        HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='ratio') #removed .average() part. Check with Aaron if this is okay.\n",
        "        # HG_ev1.resample(100)\n",
        "        # HG_ev1.filenames = good.filenames\n",
        "\n",
        "        # Store the variable in the dictionary with the desired name\n",
        "        data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "        data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "        \n",
        "\n",
        "\n",
        "    resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    # # # Manually interpolate NaN values\n",
        "    # resp_evoke.data = np.where(np.isnan(resp_evoke.data), np.interp(resp_evoke.times, resp_evoke.times[~np.isnan(resp_evoke.data[0])], resp_evoke.data[0, ~np.isnan(resp_evoke.data[0])]), resp_evoke.data)\n",
        "\n",
        "    # # Exclude time points with NaN values\n",
        "    # valid_time_points = ~np.isnan(resp_evoke.data[0])  # Filter time points without NaNs\n",
        "    # resp_evoke = resp_evoke.crop(tmin=resp_evoke.times[valid_time_points][0], tmax=resp_evoke.times[valid_time_points][-1])\n",
        "\n",
        "    # Plot the evoked data\n",
        "    fig = resp_evoke_rescaled.plot()\n",
        "    fig.savefig(save_dir + '_HG_ev1_Response_rescaled.png')\n",
        "\n",
        "    fig = stim_evoke_rescaled.plot()\n",
        "    fig.savefig(save_dir + '_HG_ev1_Stimulus_rescaled.png')\n",
        "\n",
        "\n",
        "    # decimate for stats\n",
        "    resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "    stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "    HG_base.decimate(2)\n",
        "    resp.decimate(2)\n",
        "    stim.decimate(2)\n",
        "\n",
        "    # import scipy\n",
        "    resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "                                n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "                                n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "    # plot stats\n",
        "    plt.figure(figsize=(16, 12))  # Adjust the width and height as needed\n",
        "    plt.imshow(stim_mask)\n",
        "    relabel_axes(0, 2500, -1000, 1500)\n",
        "    plt.savefig(save_dir + '_stimulus_stats.png', dpi=300)\n",
        "\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    plt.imshow(resp_mask)\n",
        "    relabel_axes(0, 2500, -1000, 1500)\n",
        "    plt.savefig(save_dir + '_response_stats.png', dpi=300)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
