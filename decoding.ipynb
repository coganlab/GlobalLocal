{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin']\n",
      "\n",
      "WARNING: Xgboost package is not installed. You will be unable touse the xgboost decoder\n",
      "\n",
      "WARNING: Keras package is not installed. You will be unable to useall neural net decoders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "from ieeg.calc.mat import LabeledArray, combine\n",
    "\n",
    "from utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas import read_csv\n",
    "import scipy.stats as stats\n",
    "import joblib\n",
    "\n",
    "from scipy.ndimage import label\n",
    "from scipy.stats import norm\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# rsa toolbox imports\n",
    "from rsatoolbox.io.mne import read_epochs\n",
    "from rsatoolbox.data.ops import merge_datasets\n",
    "from rsatoolbox.rdm import calc_rdm_movie\n",
    "from rsatoolbox.rdm.calc import _parse_input\n",
    "from rsatoolbox.util.build_rdm import _build_rdms\n",
    "from rsatoolbox.rdm import compare\n",
    "from rsatoolbox.vis import show_rdm\n",
    "from rsatoolbox.vis.timecourse import plot_timecourse\n",
    "\n",
    "from os.path import join, expanduser, basename\n",
    "import glob, json\n",
    "import numpy, tqdm, mne, pandas\n",
    "import rsatoolbox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from ieeg.decoding.decoders import PcaLdaClassification\n",
    "from ieeg.calc.oversample import MinimumNaNSplit\n",
    "from ieeg.calc.fast import mixup\n",
    "from jim_decoding_functions import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load the subjects' electrodes-to-ROIs dictionary...\n",
      "Loaded data from subjects_electrodestoROIs_dict.json\n",
      "Dictionary loaded successfully. Ready to proceed!\n"
     ]
    }
   ],
   "source": [
    "# subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103', 'D0107A', 'D0110']\n",
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "# load in subjects electrodes to rois dict. If it doesn't already exist, make it and then load it.\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "subjects_electrodestoROIs_dict = make_or_load_subjects_electrodes_to_rois_dict(filename, subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_experiment_conditions = {\n",
    "    \"Stimulus/i25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/i25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i25.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/i75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/i75.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c25.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Stimulus/c75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Stimulus/c75.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# congruency_conditions = {\n",
    "#     \"Stimulus_c\": {\n",
    "#         \"BIDS_events\": [\"Stimulus/c25/s25\", \"Stimulus/c25/s75\", \"Stimulus/c75/s25\", \"Stimulus/c75/s75\", \"Stimulus/c25/r25\", \"Stimulus/c25/r75\", \"Stimulus/c75/r25\", \"Stimulus/c75/r75\"],\n",
    "#         \"congruency\": \"c\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "stimulus_conditions = {\n",
    "    \"Stimulus/BigLetters/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetters/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Stimulus/BigLetters/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetters/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetters/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Stimulus/BigLetterh/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Stimulus/BigLetterh/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response_experiment_conditions = {\n",
    "    \"Response/i25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/i75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/s25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/s75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/i25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/i25.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/i75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/r25.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/i75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/i75.0/r75.0\",\n",
    "        \"congruency\": \"i\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c25.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c25.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c75.0/s25.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/s25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c75.0/s75.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/s75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"s\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c25.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c25.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/c25.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"75%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    },\n",
    "    \"Response/c75.0/r25.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/r25.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"25%\"\n",
    "    },\n",
    "    \"Response/c75.0/r75.0\": {\n",
    "        \"BIDS_events\": \"Response/c75.0/r75.0\",\n",
    "        \"congruency\": \"c\",\n",
    "        \"congruencyProportion\": \"25%\",\n",
    "        \"switchType\": \"r\",\n",
    "        \"switchProportion\": \"75%\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response_conditions = {\n",
    "    \"Response/BigLetters/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetters/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Response/BigLetters/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetters/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetters/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"s\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetterh/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetterh/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetterh/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetterh/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"h\",\n",
    "        \"task\": \"l\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetters/Taskg\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetters/Taskg\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"g\"\n",
    "    },\n",
    "    \"Response/BigLetterh/SmallLetters/Taskl\": {\n",
    "        \"BIDS_events\": \"Response/BigLetterh/SmallLetters/Taskl\",\n",
    "        \"bigLetter\": \"h\",\n",
    "        \"smallLetter\": \"s\",\n",
    "        \"task\": \"l\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for subject: D0057\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "449 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "449 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0059\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0063\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "452 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "452 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0065\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0069\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0071\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0071\\D0071_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0077\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0077\\D0077_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0090\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "450 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0090\\D0090_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "450 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0094\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0094\\D0094_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0100\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "451 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0100\\D0100_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "451 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0102\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0102\\D0102_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "Loading data for subject: D0103\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0103\\D0103_Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10_HG_ev1_power_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskg', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetterh/Taskl', 'bigLetter': 's', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskg', 'bigLetter': 's', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetters/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetters/SmallLetters/Taskl', 'bigLetter': 's', 'smallLetter': 's', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetterh/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'bigLetter': 'h', 'smallLetter': 'h', 'task': 'l'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskg with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskg', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'g'}\n",
      "  Loading condition: Stimulus/BigLetterh/SmallLetters/Taskl with parameters: {'BIDS_events': 'Stimulus/BigLetterh/SmallLetters/Taskl', 'bigLetter': 'h', 'smallLetter': 's', 'task': 'l'}\n"
     ]
    }
   ],
   "source": [
    "task='GlobalLocal'\n",
    "\n",
    "conditions = stimulus_conditions # toggle\n",
    "\n",
    "if conditions == stimulus_conditions or stimulus_experiment_conditions:\n",
    "    epochs_root_file = \"Stimulus_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10\"\n",
    "elif conditions == response_conditions or response_experiment_conditions:\n",
    "    epochs_root_file = \"Response_0.5sec_within1sec_randoffset_preStimulusBase_decFactor_8_outliers_10\"\n",
    "else:\n",
    "    raise ValueError(\"Unknown condition type.\")\n",
    "\n",
    "condition_names = list(conditions.keys()) # get the condition names as a list\n",
    "\n",
    "# This breaks if just_HG_ev1_rescaled is set to False currently. Fix this! 8/11\n",
    "subjects_mne_objects = create_subjects_mne_objects_dict(subjects=subjects, epochs_root_file=epochs_root_file, conditions=conditions, task=\"GlobalLocal\", just_HG_ev1_rescaled=True, acc_trials_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Stimulus/BigLetters/SmallLetterh/Taskg',\n",
       " 'Stimulus/BigLetters/SmallLetterh/Taskl',\n",
       " 'Stimulus/BigLetters/SmallLetters/Taskg',\n",
       " 'Stimulus/BigLetters/SmallLetters/Taskl',\n",
       " 'Stimulus/BigLetterh/SmallLetterh/Taskg',\n",
       " 'Stimulus/BigLetterh/SmallLetterh/Taskl',\n",
       " 'Stimulus/BigLetterh/SmallLetters/Taskg',\n",
       " 'Stimulus/BigLetterh/SmallLetters/Taskl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "condition_names = list(conditions.keys()) # get the condition names as a list\n",
    "condition_names_bids = [condition['BIDS_events'] for condition in conditions.values()] # get the condition names in bids format\n",
    "condition_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get significant channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0059\n",
      "Loaded significant channels for subject D0063\n",
      "Loaded significant channels for subject D0065\n",
      "Loaded significant channels for subject D0069\n",
      "Loaded significant channels for subject D0071\n",
      "Loaded significant channels for subject D0077\n",
      "Loaded significant channels for subject D0090\n",
      "Loaded significant channels for subject D0094\n",
      "Loaded significant channels for subject D0100\n",
      "Loaded significant channels for subject D0102\n",
      "Loaded significant channels for subject D0103\n"
     ]
    }
   ],
   "source": [
    "sig_chans_per_subject = get_sig_chans_per_subject(subjects, epochs_root_file, task='GlobalLocal', LAB_root=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of subjects\n",
    "root_dir = rf\"C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For subject D0057, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RAI6', 'RAI12', 'RAI13', 'RAI14', 'RAI15', 'RAI16', 'RPI15', 'RPI14', 'RAMF10', 'RAMF11', 'RAMF12', 'RAMF13', 'RAMF14', 'RAIF11', 'RAIF12', 'RAIF13', 'RAIF14']\n",
      "For subject D0059, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LMMF9', 'LMMF11', 'LMMF10', 'LMMF12', 'LPSF16']\n",
      "For subject D0063, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LOF16', 'LASF10', 'LASF11', 'LASF14', 'LASF15', 'LASF16', 'LMSF5', 'LMSF6', 'LMSF12', 'LPSF10', 'LPSF12', 'ROF16', 'RAI16', 'RAMF11', 'RAMF12', 'RAMF13', 'RAMF14', 'RMMF13', 'RMMF14', 'RAI4', 'RAI6', 'RAI5', 'RAI10', 'RAI11', 'RASF15', 'RASF16', 'RMSF8', 'RMSF9', 'RMSF10', 'RMSF11', 'RMSF12', 'RMSF7', 'RAMF8', 'RAMF9', 'RAMF10', 'RMMF9', 'RMMF10']\n",
      "For subject D0065, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RASF13', 'RASF14', 'RASF15', 'RASF16', 'RMSF11', 'RMSF12', 'RMSF13', 'RMSF14', 'RI7']\n",
      "For subject D0069, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LOF8']\n",
      "For subject D0071, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO14', 'RFO16', 'RIA4', 'RIP6', 'RIA5', 'RIA11', 'RIA12', 'RIA13', 'RIA14', 'RIA16', 'RIP14', 'RIP15', 'RIP16']\n",
      "For subject D0077, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0090, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO15', 'RIA6', 'RIA11', 'RIA12', 'RIA14', 'RIA15', 'RIA16', 'RIP7']\n",
      "For subject D0094, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFO12', 'LFO13', 'LFO15', 'LFO16', 'LFAM8', 'LFAM9', 'LFAM10', 'LFAM13', 'LFAM14', 'LFPM10', 'LFPM11', 'LFPM12', 'LPAS1', 'LIA16', 'LFAI3', 'LFAI4', 'LFAI5', 'LFPI10', 'LPAI9', 'LPAI10', 'LIA4', 'LIA5', 'LFAI9', 'LFAI10', 'LIA11', 'LIA12', 'LIA13', 'LIA14']\n",
      "For subject D0100, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: []\n",
      "For subject D0102, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFO13', 'RFO14', 'RFAM15', 'RFAI2', 'RFAI3']\n",
      "For subject D0103, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LFAM15', 'LAI4', 'LAI7', 'LAI8', 'LAI18', 'LFO15', 'LFAI4']\n",
      "For subject D0107A, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['RFOA16', 'RFOA17', 'RFOA18', 'RFAI3', 'RIA5', 'RIA6', 'RFAM7', 'RFAM9', 'RFAM10', 'RFAM11', 'RFAM12', 'RFMM9', 'RFMM11', 'RFMM12', 'RFMM13', 'RFMM14', 'RFMM15', 'RFMM8', 'RIA12', 'RIA13', 'RIA14', 'RIA15', 'RIA16', 'RIA17', 'RIA18']\n",
      "For subject D0110, G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes are: ['LASF10', 'LOF13', 'LOF15', 'LINS4', 'LINS5']\n",
      "Subject D0057 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RAI6', 'RPI15', 'RPI14', 'RAMF13', 'RAMF14']\n",
      "Subject D0059 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LMMF9', 'LMMF11', 'LMMF10', 'LMMF12', 'LPSF16']\n",
      "Subject D0063 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LMSF5', 'RAMF12', 'RAMF13', 'RMMF13', 'RMMF14', 'RAI4', 'RAI6', 'RAI11', 'RMMF10']\n",
      "Subject D0065 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RASF14', 'RASF15', 'RI7']\n",
      "Subject D0069 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0071 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RFO14', 'RFO16', 'RIA4', 'RIP6', 'RIA5', 'RIA11', 'RIA12', 'RIA13', 'RIA14', 'RIA16', 'RIP16']\n",
      "Subject D0077 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0090 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RIA6', 'RIA11', 'RIA12']\n",
      "Subject D0094 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LFAM8', 'LFAM9', 'LFAM10', 'LFPM10', 'LFPM11', 'LFPM12', 'LFPI10', 'LPAI10', 'LFAI9', 'LFAI10', 'LIA11']\n",
      "Subject D0100 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0102 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['RFO13', 'RFO14', 'RFAM15', 'RFAI3']\n",
      "Subject D0103 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: ['LFAM8', 'LFAM9', 'LAI13', 'LAI14', 'LAI4', 'LAI7', 'LAI8', 'LFAI4']\n",
      "Subject D0107A significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "Subject D0110 significant G_front_inf-Opercular, G_front_inf-Orbital, G_front_inf-Triangul, G_front_middle, G_front_sup, Lat_Fis-ant-Horizont, Lat_Fis-ant-Vertical, S_circular_insula_ant, S_circular_insula_sup, S_front_inf, S_front_middle, S_front_sup electrodes: []\n",
      "For subject D0057, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: ['RPIT1']\n",
      "For subject D0059, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0063, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0065, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: ['RPMT1']\n",
      "For subject D0069, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0071, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: ['RTPI1', 'RO1', 'RO2']\n",
      "For subject D0077, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: ['ROPM1']\n",
      "For subject D0090, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0094, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0100, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: ['LTOJ1', 'LTPI1', 'LOAI1', 'LOPI1', 'LOPI2', 'LOPI4', 'LOPM1', 'LTOJ3', 'LTOJ4', 'LOMM3', 'LOMM4', 'LOMM5', 'LOPM2']\n",
      "For subject D0102, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0103, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0107A, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "For subject D0110, G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes are: []\n",
      "Subject D0057 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0059 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0063 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0065 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0069 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0071 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: ['RO1', 'RO2']\n",
      "Subject D0077 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: ['ROPM1']\n",
      "Subject D0090 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0094 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0100 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: ['LTOJ1', 'LTPI1', 'LOPI2', 'LOPM1', 'LTOJ4', 'LOMM3', 'LOMM4', 'LOMM5']\n",
      "Subject D0102 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0103 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0107A significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "Subject D0110 significant G_oc-temp_med-Lingual, S_calcarine, G_cuneus electrodes: []\n",
      "For subject D0057, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RPIT1']\n",
      "For subject D0059, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['LPT13', 'LPT16']\n",
      "For subject D0063, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RMMT1', 'RMMT2']\n",
      "For subject D0065, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RPMT1', 'RPIT1', 'RPIT2']\n",
      "For subject D0069, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "For subject D0071, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPI1', 'RO1', 'RO2', 'RO10']\n",
      "For subject D0077, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPI2', 'ROPI5', 'ROPI6', 'ROPI8', 'ROPM9', 'ROPM11', 'ROPM12', 'ROPM1', 'ROPM8']\n",
      "For subject D0090, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPO1', 'RTPI1', 'RTPI2']\n",
      "For subject D0094, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "For subject D0100, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['LTOJ1', 'LTPI1', 'LOAI1', 'LOPI1', 'LOPI2', 'LOPI4', 'LOPM1', 'LTOJ3', 'LTOJ4', 'LOMM3', 'LOMM4', 'LOMM5', 'LOPM2', 'LTOJ13', 'LOAI12', 'LOAI13', 'LOAI14', 'LOAI15', 'LOMI8', 'LOMI9', 'LOMI11', 'LOMI12', 'LOPI8', 'LOPI9', 'LOPI10', 'LOAM15', 'LOMM15', 'LOPM10', 'LOMS13', 'LOMS14', 'LOMS15', 'LOPS9', 'LOPS11', 'LOPS12', 'LPPI14', 'LPPI15', 'LOMM13', 'LOMM14', 'LOMS11', 'LOMS12', 'LOPM8', 'LOPM9', 'LPPI7', 'LPPI8', 'LPPI9']\n",
      "For subject D0102, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTAI6', 'RTPI1']\n",
      "For subject D0103, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['LTLI3', 'LTPI2', 'LTPI3', 'LTPI4']\n",
      "For subject D0107A, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: ['RTPI3']\n",
      "For subject D0110, G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes are: []\n",
      "Subject D0057 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0059 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0063 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0065 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['RPIT1', 'RPIT2']\n",
      "Subject D0069 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0071 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['RO1', 'RO2', 'RO10']\n",
      "Subject D0077 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['ROPI5', 'ROPI6', 'ROPI8', 'ROPM9', 'ROPM1', 'ROPM8']\n",
      "Subject D0090 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['RTPO1', 'RTPI1', 'RTPI2']\n",
      "Subject D0094 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0100 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['LTOJ1', 'LTPI1', 'LOPI2', 'LOPM1', 'LTOJ4', 'LOMM3', 'LOMM4', 'LOMM5', 'LTOJ13', 'LOAI12', 'LOAI13', 'LOAI14', 'LOAI15', 'LOMI8', 'LOMI9', 'LOMI11', 'LOMI12', 'LOPI8', 'LOPI9', 'LOPI10', 'LOAM15', 'LOPM10', 'LOMS13', 'LOPS11', 'LOPS12', 'LOMM13', 'LOMM14', 'LOPM8', 'LOPM9', 'LPPI7', 'LPPI8', 'LPPI9']\n",
      "Subject D0102 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['RTPI1']\n",
      "Subject D0103 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: ['LTLI3', 'LTPI2', 'LTPI3', 'LTPI4']\n",
      "Subject D0107A significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "Subject D0110 significant G_cuneus, G_and_S_occipital_inf, G_occipital_middle, G_occipital_sup, G_oc-temp_lat-fusifor, G_oc-temp_med-Lingual, Pole_occipital, S_calcarine, S_oc_middle_and_Lunatus, S_oc_sup_and_transversal, S_occipital_ant electrodes: []\n",
      "For subject D0057,  electrodes are: []\n",
      "For subject D0059,  electrodes are: []\n",
      "For subject D0063,  electrodes are: []\n",
      "For subject D0065,  electrodes are: []\n",
      "For subject D0069,  electrodes are: []\n",
      "For subject D0071,  electrodes are: []\n",
      "For subject D0077,  electrodes are: []\n",
      "For subject D0090,  electrodes are: []\n",
      "For subject D0094,  electrodes are: []\n",
      "For subject D0100,  electrodes are: []\n",
      "For subject D0102,  electrodes are: []\n",
      "For subject D0103,  electrodes are: []\n",
      "For subject D0107A,  electrodes are: []\n",
      "For subject D0110,  electrodes are: []\n",
      "Subject D0057 significant  electrodes: []\n",
      "Subject D0059 significant  electrodes: []\n",
      "Subject D0063 significant  electrodes: []\n",
      "Subject D0065 significant  electrodes: []\n",
      "Subject D0069 significant  electrodes: []\n",
      "Subject D0071 significant  electrodes: []\n",
      "Subject D0077 significant  electrodes: []\n",
      "Subject D0090 significant  electrodes: []\n",
      "Subject D0094 significant  electrodes: []\n",
      "Subject D0100 significant  electrodes: []\n",
      "Subject D0102 significant  electrodes: []\n",
      "Subject D0103 significant  electrodes: []\n",
      "Subject D0107A significant  electrodes: []\n",
      "Subject D0110 significant  electrodes: []\n",
      "For subject D0057,  electrodes are: []\n",
      "For subject D0059,  electrodes are: []\n",
      "For subject D0063,  electrodes are: []\n",
      "For subject D0065,  electrodes are: []\n",
      "For subject D0069,  electrodes are: []\n",
      "For subject D0071,  electrodes are: []\n",
      "For subject D0077,  electrodes are: []\n",
      "For subject D0090,  electrodes are: []\n",
      "For subject D0094,  electrodes are: []\n",
      "For subject D0100,  electrodes are: []\n",
      "For subject D0102,  electrodes are: []\n",
      "For subject D0103,  electrodes are: []\n",
      "For subject D0107A,  electrodes are: []\n",
      "For subject D0110,  electrodes are: []\n",
      "Subject D0057 significant  electrodes: []\n",
      "Subject D0059 significant  electrodes: []\n",
      "Subject D0063 significant  electrodes: []\n",
      "Subject D0065 significant  electrodes: []\n",
      "Subject D0069 significant  electrodes: []\n",
      "Subject D0071 significant  electrodes: []\n",
      "Subject D0077 significant  electrodes: []\n",
      "Subject D0090 significant  electrodes: []\n",
      "Subject D0094 significant  electrodes: []\n",
      "Subject D0100 significant  electrodes: []\n",
      "Subject D0102 significant  electrodes: []\n",
      "Subject D0103 significant  electrodes: []\n",
      "Subject D0107A significant  electrodes: []\n",
      "Subject D0110 significant  electrodes: []\n"
     ]
    }
   ],
   "source": [
    "# Define your ROIs dictionary and other parameters\n",
    "rois_dict = {\n",
    "    'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    'v1': [\"G_oc-temp_med-Lingual\", \"S_calcarine\", \"G_cuneus\"],\n",
    "    'occ': [\"G_cuneus\", \"G_and_S_occipital_inf\", \"G_occipital_middle\", \"G_occipital_sup\", \"G_oc-temp_lat-fusifor\", \"G_oc-temp_med-Lingual\", \"Pole_occipital\", \"S_calcarine\", \"S_oc_middle_and_Lunatus\", \"S_oc_sup_and_transversal\", \"S_occipital_ant\"],\n",
    "    'occ_filtered': [],\n",
    "    'occ_best_filtered': []\n",
    "}\n",
    "\n",
    "rois = list(rois_dict.keys())\n",
    "# Assuming you have subjects_electrodestoROIs_dict and sig_chans_per_subject dictionaries\n",
    "electrodes_per_subject_roi, sig_electrodes_per_subject_roi, = make_sig_electrodes_per_subject_and_roi_dict(\n",
    "    rois_dict, subjects_electrodestoROIs_dict, sig_chans_per_subject\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's manually make the occ filtered sig electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_electrodes_per_subject_roi['occ_filtered'] = {\n",
    "    'D0057': [],\n",
    "    'D0059': [],\n",
    "    'D0071': ['RO1', 'RO10'], #RO10 is iffy, big drop from fix onset\n",
    "    'D0077': ['ROPM1', 'ROPM8'],\n",
    "    'D0090': ['RTPO1', 'RTPI1'],\n",
    "    'D0100': ['LOAI12', 'LOAI13', 'LOAI14', 'LOAI15', 'LOMI9', 'LOMI11', 'LOPI8', 'LOPI9', 'LOPM8', 'LOPM9', 'LPPI7', 'LPPI8', 'LPPI9'],\n",
    "    'D0102': ['RTPI1'],\n",
    "    'D0103': ['LTPI2', 'LTPI3', 'LTPI4']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and now make the best of the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_electrodes_per_subject_roi['occ_best_filtered'] = {\n",
    "    'D0057': [],\n",
    "    'D0059': [],\n",
    "    'D0071': [],\n",
    "    'D0077': [],\n",
    "    'D0090': [],\n",
    "    'D0100': ['LOAI12', 'LOMI9', 'LOPI8', 'LOPI9', 'LOPM8', 'LOPM9'],\n",
    "    'D0102': ['RTPI1'],\n",
    "    'D0103': ['LTPI2', 'LTPI3', 'LTPI4']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary saved to sig_electrodes_per_subject_roi.json\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path where you want to save the dictionary\n",
    "save_path = 'sig_electrodes_per_subject_roi.json'\n",
    "\n",
    "# Use json to save the dictionary\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(sig_electrodes_per_subject_roi, file, indent=4)\n",
    "\n",
    "print(f\"Dictionary saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get electrode counts for each roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of lpfc electrodes across all subjects: 164\n",
      "Total number of significant lpfc electrodes across all subjects: 59\n",
      "Total number of v1 electrodes across all subjects: 19\n",
      "Total number of significant v1 electrodes across all subjects: 11\n",
      "Total number of occ electrodes across all subjects: 76\n",
      "Total number of significant occ electrodes across all subjects: 51\n",
      "Total number of occ_filtered electrodes across all subjects: 0\n",
      "Total number of significant occ_filtered electrodes across all subjects: 23\n",
      "Total number of occ_best_filtered electrodes across all subjects: 0\n",
      "Total number of significant occ_best_filtered electrodes across all subjects: 10\n"
     ]
    }
   ],
   "source": [
    "total_electrodes_info = calculate_total_electrodes(sig_electrodes_per_subject_roi, electrodes_per_subject_roi)\n",
    "for roi, counts in total_electrodes_info.items():\n",
    "    print(f\"Total number of {roi} electrodes across all subjects:\", counts['total_electrodes'])\n",
    "    print(f\"Total number of significant {roi} electrodes across all subjects:\", counts['total_significant_electrodes'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if any subjects have a weird sampling rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject D0057 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0059 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0063 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0065 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0069 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0071 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0077 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0090 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0094 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0100 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0102 has the expected sampling rate: 256.0 Hz.\n",
      "Subject D0103 has the expected sampling rate: 256.0 Hz.\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'subjects_mne_objects' is your dictionary containing MNE objects for each subject\n",
    "sampling_rate = 256\n",
    "subject_rates = check_sampling_rates(subjects_mne_objects, expected_sampling_rate=sampling_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a dat dict like in the Temporal example from rsatoolbox 7/19  \n",
    "#### Data Dictionary (dat) Structure\n",
    "- **roi1**\n",
    "  - **data**: 3D data array for this ROI\n",
    "  - **channel_names**: List of significant channels for this ROI\n",
    "  - **cond_names**: Dictionary where keys are condition names and values are integer indices\n",
    "  - **cond_idx**: 1D array where each entry is an integer index corresponding to a cond_name\n",
    "  - **times**: 1D array of times, corresponding to each sample\n",
    "- **roi2**\n",
    "  - **data**: 3D data array for this ROI\n",
    "  - **channel_names**: List of significant channels for this ROI\n",
    "  - **cond_names**: Dictionary where keys are condition names and values are integer indices\n",
    "  - **cond_idx**: 1D array where each entry is an integer index corresponding to a cond_name\n",
    "  - **times**: 1D array of times, corresponding to each sample\n",
    "- **roiX**\n",
    "  - **data**: 3D data array for this ROI\n",
    "  - **channel_names**: List of significant channels for this ROI\n",
    "  - **cond_names**: Dictionary where keys are condition names and values are integer indices\n",
    "  - **cond_idx**: 1D array where each entry is an integer index corresponding to a cond_name\n",
    "  - **times**: 1D array of times, corresponding to each sample\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example call to the function (you need to replace the arguments with actual data)\n",
    "# dat = prepare_data_for_temporal_dataset(subjects_mne_objects, condition_names, rois, subjects, sig_electrodes_per_subject_roi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make roi_labeled_arrays, a dict where the keys are rois and the values are LabeledArrays. Index the same way as a nested dict. Use .labels to get labels from current level.\n",
    "\n",
    "\n",
    "#### roi_labeled_arrays structure\n",
    "- **roi1**: ROI name, string\n",
    "  - **conditions**: condition name\n",
    "    - **trials**: This is the maximal number of trials across subjects for any condition, filled with nans for subjects who don't have this many trials\n",
    "      - **channels**: This is the number of channels in the roi, each channel is labeled as subject-channel name. Concatenated across subjects.\n",
    "        - **samples**: 1 sample as a float. This is the time for this sample.\n",
    "\n",
    "- **roi2**: ROI name, string\n",
    "  - **conditions**: condition name\n",
    "    - **trials**: This is the maximal number of trials across subjects for any condition, filled with nans for subjects who don't have this many trials\n",
    "      - **channels**: This is the number of channels in the roi, each channel is labeled as subject-channel name. Concatenated across subjects.\n",
    "        - **samples**: 1 sample as a float. This is the time for this sample.\n",
    "\n",
    "- **roiX**: ROI name, string\n",
    "  - **conditions**: condition name\n",
    "    - **trials**: This is the maximal number of trials across subjects for any condition, filled with nans for subjects who don't have this many trials\n",
    "      - **channels**: This is the number of channels in the roi, each channel is labeled as subject-channel name. Concatenated across subjects.\n",
    "        - **samples**: 1 sample as a float. This is the time for this sample.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_trials_per_condition(\n",
    "    subjects_mne_objects, condition_names, subjects,\n",
    "    sig_electrodes_per_subject_roi, roi, obs_axs\n",
    "):\n",
    "    \"\"\"\n",
    "    Find the maximum number of trials per condition across all subjects for a given ROI.\n",
    "    \"\"\"\n",
    "    max_trials_per_condition = {condition: 0 for condition in condition_names}\n",
    "\n",
    "    for sub in subjects:\n",
    "        sig_electrodes = sig_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "        if not sig_electrodes:\n",
    "            continue\n",
    "        for condition_name in condition_names:\n",
    "            epochs = subjects_mne_objects[sub][condition_name]['HG_ev1_power_rescaled'].copy().pick(sig_electrodes)\n",
    "            epochs_data = epochs.get_data(copy=True)\n",
    "            n_trials = epochs_data.shape[obs_axs - 1]\n",
    "            max_trials_per_condition[condition_name] = max(\n",
    "                max_trials_per_condition[condition_name], n_trials\n",
    "            )\n",
    "    return max_trials_per_condition\n",
    "\n",
    "def make_subject_labeled_array(\n",
    "    sub, subjects_mne_objects, condition_names, sig_electrodes_per_subject_roi,\n",
    "    roi, max_trials_per_condition, obs_axs, chans_axs, time_axs, rng\n",
    "):\n",
    "    \"\"\"\n",
    "    Process data for a subject in a given ROI.\n",
    "\n",
    "    This function performs the following steps for the given subject:\n",
    "    1. Retrieves the significant electrodes in the specified ROI for the subject.\n",
    "    2. For each condition:\n",
    "        a. Extracts the epoch data for the significant electrodes.\n",
    "        b. Randomizes the trial order using the provided random state.\n",
    "        c. Pads the data with NaNs to match the maximum number of trials for that condition.\n",
    "    3. Collects the processed data for all conditions into a dictionary.\n",
    "    4. Creates a LabeledArray from the processed data, assigning appropriate channel and time labels.\n",
    "\n",
    "    Returns a LabeledArray for the subject.\n",
    "    \"\"\"\n",
    "    sig_electrodes = sig_electrodes_per_subject_roi.get(roi, {}).get(sub, [])\n",
    "    if not sig_electrodes:\n",
    "        return None\n",
    "\n",
    "    subject_nested_dict = {}\n",
    "\n",
    "    # Get channel names for this subject's ROI\n",
    "    sub_channel_names = [f\"{sub}-{sig_electrode}\" for sig_electrode in sig_electrodes]\n",
    "\n",
    "    # Loop through each condition\n",
    "    for condition_name in condition_names:\n",
    "        # Extract the epoch data for the current condition and subject\n",
    "        epochs = subjects_mne_objects[sub][condition_name]['HG_ev1_power_rescaled'].copy().pick(sig_electrodes)\n",
    "        epochs_data = epochs.get_data(copy=True)\n",
    "\n",
    "        # Randomize the trial order\n",
    "        n_trials = epochs_data.shape[obs_axs - 1]\n",
    "        print(f'in roi {roi}, subject {sub} has {n_trials} trials for condition {condition_name}')\n",
    "        trial_indices = np.arange(n_trials)\n",
    "        rng.shuffle(trial_indices)\n",
    "        epochs_data = epochs_data.take(trial_indices, axis=obs_axs - 1)\n",
    "\n",
    "        # Get the target number of trials for padding\n",
    "        max_trials = max_trials_per_condition[condition_name]\n",
    "\n",
    "        # Pad with NaNs if necessary\n",
    "        if n_trials < max_trials:\n",
    "            padded_shape = list(epochs_data.shape)\n",
    "            padded_shape[obs_axs - 1] = max_trials\n",
    "            padded_data = np.full(padded_shape, np.nan)\n",
    "            indexer = [slice(None)] * epochs_data.ndim\n",
    "            indexer[obs_axs - 1] = slice(0, n_trials)\n",
    "            padded_data[tuple(indexer)] = epochs_data\n",
    "        else:\n",
    "            padded_data = epochs_data\n",
    "\n",
    "        subject_nested_dict[condition_name] = padded_data\n",
    "\n",
    "    # Get time labels\n",
    "    times = epochs.times\n",
    "    str_times = [str(time) for time in times]\n",
    "    np_array_str_times = np.array(str_times)\n",
    "\n",
    "    # Create a LabeledArray for the subject\n",
    "    subject_labeled_array = create_subject_labeled_array_from_dict(\n",
    "        subject_nested_dict, sub_channel_names, np_array_str_times, chans_axs, time_axs\n",
    "    )\n",
    "\n",
    "    return subject_labeled_array\n",
    "\n",
    "def create_subject_labeled_array_from_dict(\n",
    "    subject_nested_dict, sub_channel_names, np_array_str_times, chans_axs, time_axs\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a LabeledArray for a subject with given data and labels.\n",
    "    \"\"\"\n",
    "    subject_labeled_array = LabeledArray.from_dict(subject_nested_dict)\n",
    "    subject_labeled_array.labels[chans_axs].values = sub_channel_names  # Channels axis\n",
    "    subject_labeled_array.labels[time_axs].values = np_array_str_times  # Time axis\n",
    "    return subject_labeled_array\n",
    "\n",
    "def concatenate_subject_labeled_arrays(\n",
    "    roi_labeled_array, subject_labeled_array, chans_axs\n",
    "):\n",
    "    \"\"\"\n",
    "    Concatenate a subject's LabeledArray to the ROI's LabeledArray along the channels axis.\n",
    "    \"\"\"\n",
    "    if roi_labeled_array is None:\n",
    "        return subject_labeled_array\n",
    "    else:\n",
    "        return roi_labeled_array.concatenate(subject_labeled_array, axis=chans_axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_data_in_labeled_array_per_roi_subject(\n",
    "    subjects_mne_objects, condition_names, rois, subjects,\n",
    "    sig_electrodes_per_subject_roi, obs_axs=1, chans_axs=2, time_axs=3,\n",
    "    random_state=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Organize the MNE data into separate LabeledArrays for each ROI and subject,\n",
    "    with randomized trial ordering within each subject before concatenation.\n",
    "    Concatenates subject data along the channels axis.\n",
    "\n",
    "    Parameters:\n",
    "    - subjects_mne_objects: Dictionary of MNE objects, structured as {subject: {condition: MNE epoch objects}}\n",
    "    - condition_names: List of condition names.\n",
    "    - rois: List of region of interest (ROI) names.\n",
    "    - subjects: List of subjects.\n",
    "    - sig_electrodes_per_subject_roi: Dictionary mapping ROIs to subjects and their corresponding electrodes.\n",
    "    - obs_axs: The trials dimension (1-based indexing).\n",
    "    - chans_axs: The channels dimension (1-based indexing).\n",
    "    - time_axs: The time dimension (1-based indexing).\n",
    "    - random_state: Optional; an integer seed, NumPy RandomState, or None for random shuffling.\n",
    "\n",
    "    Returns:\n",
    "    - roi_labeled_arrays: Dictionary of LabeledArrays for each ROI.\n",
    "                          Each LabeledArray has dimensions: [Conditions, Trials, Channels, Timepoints]\n",
    "    \"\"\"\n",
    "    # Set up the random state\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    roi_labeled_arrays = {}\n",
    "\n",
    "    # Loop through each ROI\n",
    "    for roi in rois:\n",
    "        # First pass: Find the max number of trials per condition across all subjects\n",
    "        max_trials_per_condition = get_max_trials_per_condition(\n",
    "            subjects_mne_objects, condition_names, subjects,\n",
    "            sig_electrodes_per_subject_roi, roi, obs_axs\n",
    "        )\n",
    "\n",
    "        # Initialize the ROI LabeledArray\n",
    "        roi_labeled_array = None\n",
    "\n",
    "        # Second pass: Process each subject's data\n",
    "        for sub in subjects:\n",
    "            subject_labeled_array = make_subject_labeled_array(\n",
    "                sub, subjects_mne_objects, condition_names, sig_electrodes_per_subject_roi,\n",
    "                roi, max_trials_per_condition, obs_axs, chans_axs, time_axs, rng\n",
    "            )\n",
    "            if subject_labeled_array is None:\n",
    "                continue  # Skip if subject has no data for this ROI\n",
    "\n",
    "            # Concatenate subject's data into the ROI LabeledArray\n",
    "            roi_labeled_array = concatenate_subject_labeled_arrays(\n",
    "                roi_labeled_array, subject_labeled_array, chans_axs\n",
    "            )\n",
    "\n",
    "        # Add the concatenated LabeledArray to the ROI dictionary\n",
    "        if roi_labeled_array is not None:\n",
    "            roi_labeled_arrays[roi] = roi_labeled_array\n",
    "\n",
    "    return roi_labeled_arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in roi lpfc, subject D0057 has 59 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0057 has 54 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0057 has 53 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0057 has 34 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0057 has 51 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0057 has 60 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0057 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0057 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0059 has 48 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0059 has 57 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0059 has 62 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0059 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0059 has 52 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0059 has 55 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0059 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0059 has 56 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0063 has 29 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0063 has 42 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0063 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0063 has 60 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0063 has 49 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0063 has 58 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0063 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0063 has 45 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0065 has 26 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0065 has 27 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0065 has 41 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0065 has 50 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0065 has 43 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0065 has 43 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0065 has 45 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0065 has 41 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0071 has 50 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0071 has 58 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0071 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0071 has 58 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0090 has 52 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0090 has 45 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0090 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0090 has 42 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0090 has 61 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0090 has 57 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0090 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0090 has 64 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0094 has 42 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0094 has 44 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0094 has 53 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0094 has 52 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0094 has 51 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0094 has 53 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0094 has 45 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0094 has 38 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0102 has 39 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0102 has 13 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0102 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0102 has 50 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0102 has 49 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0102 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0102 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0102 has 12 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0103 has 32 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0103 has 41 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0103 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0103 has 56 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi lpfc, subject D0103 has 53 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi lpfc, subject D0103 has 44 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi lpfc, subject D0103 has 36 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi lpfc, subject D0103 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi v1, subject D0071 has 50 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi v1, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi v1, subject D0071 has 58 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi v1, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi v1, subject D0071 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi v1, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi v1, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi v1, subject D0071 has 58 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi v1, subject D0077 has 44 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi v1, subject D0077 has 40 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi v1, subject D0077 has 46 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi v1, subject D0077 has 44 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi v1, subject D0077 has 50 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi v1, subject D0077 has 46 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi v1, subject D0077 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi v1, subject D0077 has 43 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi v1, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi v1, subject D0100 has 48 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi v1, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi v1, subject D0100 has 52 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi v1, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi v1, subject D0100 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi v1, subject D0100 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi v1, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ, subject D0065 has 26 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ, subject D0065 has 27 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ, subject D0065 has 41 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ, subject D0065 has 50 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ, subject D0065 has 43 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ, subject D0065 has 43 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ, subject D0065 has 45 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ, subject D0065 has 41 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ, subject D0071 has 50 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ, subject D0071 has 58 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ, subject D0071 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ, subject D0071 has 58 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ, subject D0077 has 44 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ, subject D0077 has 40 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ, subject D0077 has 46 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ, subject D0077 has 44 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ, subject D0077 has 50 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ, subject D0077 has 46 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ, subject D0077 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ, subject D0077 has 43 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ, subject D0090 has 52 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ, subject D0090 has 45 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ, subject D0090 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ, subject D0090 has 42 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ, subject D0090 has 61 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ, subject D0090 has 57 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ, subject D0090 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ, subject D0090 has 64 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ, subject D0100 has 48 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ, subject D0100 has 52 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ, subject D0100 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ, subject D0100 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ, subject D0102 has 39 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ, subject D0102 has 13 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ, subject D0102 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ, subject D0102 has 50 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ, subject D0102 has 49 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ, subject D0102 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ, subject D0102 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ, subject D0102 has 12 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ, subject D0103 has 32 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ, subject D0103 has 41 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ, subject D0103 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ, subject D0103 has 56 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ, subject D0103 has 53 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ, subject D0103 has 44 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ, subject D0103 has 36 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ, subject D0103 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0071 has 50 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0071 has 58 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0071 has 49 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0071 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0071 has 59 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0071 has 58 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0077 has 44 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0077 has 40 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0077 has 46 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0077 has 44 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0077 has 50 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0077 has 46 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0077 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0077 has 43 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0090 has 52 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0090 has 45 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0090 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0090 has 42 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0090 has 61 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0090 has 57 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0090 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0090 has 64 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0100 has 48 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0100 has 52 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0100 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0100 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0102 has 39 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0102 has 13 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0102 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0102 has 50 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0102 has 49 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0102 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0102 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0102 has 12 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0103 has 32 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0103 has 41 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0103 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0103 has 56 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_filtered, subject D0103 has 53 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_filtered, subject D0103 has 44 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_filtered, subject D0103 has 36 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_filtered, subject D0103 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_best_filtered, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_best_filtered, subject D0100 has 48 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_best_filtered, subject D0100 has 54 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_best_filtered, subject D0100 has 52 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_best_filtered, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_best_filtered, subject D0100 has 59 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_best_filtered, subject D0100 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_best_filtered, subject D0100 has 52 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_best_filtered, subject D0102 has 39 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_best_filtered, subject D0102 has 13 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_best_filtered, subject D0102 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_best_filtered, subject D0102 has 50 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_best_filtered, subject D0102 has 49 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_best_filtered, subject D0102 has 47 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_best_filtered, subject D0102 has 42 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_best_filtered, subject D0102 has 12 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n",
      "in roi occ_best_filtered, subject D0103 has 32 trials for condition Stimulus/BigLetters/SmallLetterh/Taskg\n",
      "in roi occ_best_filtered, subject D0103 has 41 trials for condition Stimulus/BigLetters/SmallLetterh/Taskl\n",
      "in roi occ_best_filtered, subject D0103 has 47 trials for condition Stimulus/BigLetters/SmallLetters/Taskg\n",
      "in roi occ_best_filtered, subject D0103 has 56 trials for condition Stimulus/BigLetters/SmallLetters/Taskl\n",
      "in roi occ_best_filtered, subject D0103 has 53 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskg\n",
      "in roi occ_best_filtered, subject D0103 has 44 trials for condition Stimulus/BigLetterh/SmallLetterh/Taskl\n",
      "in roi occ_best_filtered, subject D0103 has 36 trials for condition Stimulus/BigLetterh/SmallLetters/Taskg\n",
      "in roi occ_best_filtered, subject D0103 has 50 trials for condition Stimulus/BigLetterh/SmallLetters/Taskl\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "roi_labeled_arrays = put_data_in_labeled_array_per_roi_subject(\n",
    "    subjects_mne_objects,\n",
    "    condition_names,\n",
    "    rois,\n",
    "    subjects,\n",
    "    sig_electrodes_per_subject_roi,\n",
    "    obs_axs=1,  # Trials dimension (1-based indexing)\n",
    "    chans_axs=2,  # Channels dimension (1-based indexing)\n",
    "    time_axs=3,   # Time dimension (1-based indexing)\n",
    "    random_state=42  # For reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 64, 59, 641)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_labeled_arrays['lpfc'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove trials with nans from roi labeled arrays if just getting the minimum number of trials for all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nans_from_labeled_array(labeled_array, obs_axs=1, chans_axs=2, time_axs=3):\n",
    "    \"\"\"\n",
    "    Remove trials that have NaN values from a LabeledArray.\n",
    "\n",
    "    Parameters:\n",
    "    - labeled_array: A LabeledArray where the 0th axis labels are conditions, 1st axis labels are trials, \n",
    "                     2nd axis labels are channels, and 3rd axis labels are timepoints.\n",
    "    - obs_axs: The trials dimension (1-based indexing).\n",
    "    - chans_axs: The channels dimension (1-based indexing).\n",
    "    - time_axs: The time dimension (1-based indexing).\n",
    "\n",
    "    Returns:\n",
    "    - labeled_array_no_nans: A LabeledArray with only trials that have no NaN values.\n",
    "    \"\"\"\n",
    "    # Convert to zero-based indexing\n",
    "    obs_axs -= 1\n",
    "    chans_axs -= 1\n",
    "    time_axs -= 1\n",
    "\n",
    "    # Initialize a dictionary to store data without NaNs for each condition\n",
    "    reshaped_data_dict = {}\n",
    "\n",
    "    # Extract the condition labels (which are in labeled_array.labels[0])\n",
    "    condition_names = labeled_array.labels[0]\n",
    "\n",
    "    # Loop over each condition\n",
    "    for condition_name in condition_names:\n",
    "        # Extract the data for the current condition\n",
    "        condition_data = labeled_array[condition_name] # Shape: (Trials, Channels, Timepoints)\n",
    "\n",
    "        # Find the indices of trials that do not contain NaNs\n",
    "        # Reduce over channels and time axes to check if any NaN exists in a trial\n",
    "        valid_trial_indices = ~np.isnan(condition_data).any(axis=(chans_axs, time_axs))\n",
    "\n",
    "        # valid_trial_indices is a boolean array of shape (Trials,)\n",
    "        # Select only the valid trials\n",
    "        condition_data_clean = condition_data[valid_trial_indices, :, :]\n",
    "\n",
    "        # Store the processed data for this condition\n",
    "        reshaped_data_dict[condition_name] = condition_data_clean\n",
    "\n",
    "    # Create a new LabeledArray from the reshaped data dictionary\n",
    "    labeled_array_no_nans = LabeledArray.from_dict(reshaped_data_dict)\n",
    "\n",
    "    return labeled_array_no_nans\n",
    "\n",
    "def remove_nans_from_all_roi_labeled_arrays(roi_labeled_arrays, obs_axs=1, chans_axs=2, time_axs=3):\n",
    "    \"\"\"\n",
    "    Loop through all ROIs and apply the NaN removal function to each LabeledArray.\n",
    "\n",
    "    Parameters:\n",
    "    - roi_labeled_arrays: Dictionary of LabeledArrays for each ROI.\n",
    "    - obs_axs: The trials dimension (1-based indexing).\n",
    "    - chans_axs: The channels dimension (1-based indexing).\n",
    "    - time_axs: The time dimension (1-based indexing).\n",
    "\n",
    "    Returns:\n",
    "    - labeled_arrays_no_nans: Dictionary where keys are ROIs and values are LabeledArrays with NaNs removed.\n",
    "    \"\"\"\n",
    "    roi_labeled_arrays_no_nans = {}\n",
    "    \n",
    "    # Loop through each ROI in the dictionary\n",
    "    for roi, labeled_array in roi_labeled_arrays.items():\n",
    "        # Apply the NaN removal function to the current labeled array\n",
    "        labeled_array_no_nans = remove_nans_from_labeled_array(\n",
    "            labeled_array, obs_axs=obs_axs, chans_axs=chans_axs, time_axs=time_axs\n",
    "        )\n",
    "\n",
    "        # Store the reshaped data for this ROI\n",
    "        roi_labeled_arrays_no_nans[roi] = labeled_array_no_nans\n",
    "\n",
    "    return roi_labeled_arrays_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-3.04644763e-01, -4.27678347e-01, -4.97747958e-01, ...,\n",
       "          -1.00266480e+00, -1.08392704e+00, -1.14953256e+00],\n",
       "         [-1.04423034e+00, -1.01916778e+00, -1.01196134e+00, ...,\n",
       "           1.71241403e+00,  1.47226834e+00,  1.34279430e+00],\n",
       "         [ 2.72478282e-01,  2.77666748e-01,  2.49155253e-01, ...,\n",
       "          -3.45492065e-01, -3.30436707e-01, -3.06903750e-01],\n",
       "         ...,\n",
       "         [ 1.80977666e+00,  1.44853127e+00,  1.10428512e+00, ...,\n",
       "          -2.60263056e-01, -1.99117616e-01, -1.37402713e-01],\n",
       "         [-4.53894764e-01, -4.19212759e-01, -3.50485176e-01, ...,\n",
       "          -1.52206630e-01, -1.01805553e-01,  2.50967331e-02],\n",
       "         [-1.67640612e-01, -2.16709301e-01, -2.95076489e-01, ...,\n",
       "           1.13752592e+00,  1.20565796e+00,  1.28719842e+00]],\n",
       "\n",
       "        [[ 1.87286711e+00,  1.73476148e+00,  1.61565661e+00, ...,\n",
       "           4.61819649e-01,  6.14762008e-01,  7.47779608e-01],\n",
       "         [-1.35569125e-01, -3.05584520e-01, -4.93779093e-01, ...,\n",
       "           4.53342050e-01,  4.26055521e-01,  3.91638637e-01],\n",
       "         [ 2.70633698e-01,  1.58874467e-01,  3.33776213e-02, ...,\n",
       "           3.40141916e+00,  3.40166926e+00,  3.36388278e+00],\n",
       "         ...,\n",
       "         [ 6.34829581e-01,  7.07422495e-01,  7.23745883e-01, ...,\n",
       "          -7.46169627e-01, -7.30397940e-01, -7.33122468e-01],\n",
       "         [-2.53407031e-01, -1.32113069e-01, -8.35883617e-03, ...,\n",
       "           1.69347870e+00,  1.50515866e+00,  1.29570830e+00],\n",
       "         [ 5.12518942e-01,  4.13099289e-01,  3.19956452e-01, ...,\n",
       "          -3.19431573e-01, -3.40913922e-01, -3.47768545e-01]],\n",
       "\n",
       "        [[-7.18845665e-01, -8.02897274e-01, -9.11724687e-01, ...,\n",
       "          -1.67448676e+00, -1.70729840e+00, -1.71870029e+00],\n",
       "         [-3.16234291e-01, -2.23985508e-01, -1.51796833e-01, ...,\n",
       "           1.37806332e+00,  1.31798279e+00,  1.19436586e+00],\n",
       "         [-1.86886147e-01, -2.41201699e-01, -2.68073082e-01, ...,\n",
       "          -1.38409889e+00, -1.37278938e+00, -1.34866917e+00],\n",
       "         ...,\n",
       "         [-6.87597767e-02, -1.42231032e-01, -2.05979198e-01, ...,\n",
       "           8.75011921e-01,  9.88078058e-01,  1.05868125e+00],\n",
       "         [ 4.73652780e-01,  5.05607188e-01,  4.96320784e-01, ...,\n",
       "           2.49075610e-02,  1.57574892e-01,  2.71149755e-01],\n",
       "         [ 1.49369240e-01,  2.70253718e-01,  3.65733683e-01, ...,\n",
       "           4.40701753e-01,  5.10220349e-01,  6.04009390e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]]],\n",
       "\n",
       "\n",
       "       [[[-3.39359611e-01, -2.50467509e-01,  2.83506084e-02, ...,\n",
       "           2.32904434e+00,  2.31623125e+00,  2.21749783e+00],\n",
       "         [-9.07301456e-02, -1.83024630e-01, -3.07022721e-01, ...,\n",
       "           1.18226731e+00,  1.08752823e+00,  9.80668545e-01],\n",
       "         [-3.85757267e-01, -3.72646481e-01, -3.64324003e-01, ...,\n",
       "          -1.07459283e+00, -1.08219779e+00, -1.04579210e+00],\n",
       "         ...,\n",
       "         [ 7.25305498e-01,  8.19369972e-01,  9.11553442e-01, ...,\n",
       "           2.92920589e+00,  3.03221035e+00,  3.04830027e+00],\n",
       "         [-5.57720304e-01, -5.12480855e-01, -4.61563408e-01, ...,\n",
       "           9.67320502e-01,  8.07424366e-01,  6.28338158e-01],\n",
       "         [-4.68978733e-01, -3.71628433e-01, -2.93170959e-01, ...,\n",
       "          -9.10547972e-01, -8.29365909e-01, -7.47700751e-01]],\n",
       "\n",
       "        [[-7.21614420e-01, -7.40517974e-01, -7.42304027e-01, ...,\n",
       "          -7.28001356e-01, -8.13351154e-01, -9.06616986e-01],\n",
       "         [ 8.44825432e-02,  9.56699401e-02,  1.00558884e-01, ...,\n",
       "          -3.37366879e-01, -3.05421591e-01, -2.71556020e-01],\n",
       "         [-3.22571009e-01, -3.58472586e-01, -3.91740292e-01, ...,\n",
       "          -2.95138001e-01, -2.58187056e-01, -1.77723423e-01],\n",
       "         ...,\n",
       "         [-4.93085533e-02, -1.95285246e-01, -3.50847661e-01, ...,\n",
       "          -8.16003740e-01, -7.59666264e-01, -7.07689464e-01],\n",
       "         [-1.26564121e+00, -1.29037857e+00, -1.30970895e+00, ...,\n",
       "           8.11047852e-01,  7.87933707e-01,  7.19255388e-01],\n",
       "         [ 2.44711302e-02,  8.90792906e-02,  1.46740258e-01, ...,\n",
       "          -9.15427029e-01, -9.17266726e-01, -9.31881785e-01]],\n",
       "\n",
       "        [[-6.94220662e-01, -7.15646565e-01, -7.36428738e-01, ...,\n",
       "          -4.52457488e-01, -5.84992468e-01, -6.96461618e-01],\n",
       "         [ 1.39425397e-01,  1.61307991e-01,  1.67154625e-01, ...,\n",
       "          -2.29288816e-01, -3.15533102e-01, -4.08290416e-01],\n",
       "         [-1.01137176e-01,  4.84183468e-02,  1.80038124e-01, ...,\n",
       "          -3.98086190e-01, -4.36200976e-01, -4.73722041e-01],\n",
       "         ...,\n",
       "         [-3.60484868e-01, -4.48015451e-01, -5.40153384e-01, ...,\n",
       "          -1.02669001e+00, -1.01481473e+00, -9.91735101e-01],\n",
       "         [-8.45938444e-01, -8.80961120e-01, -8.95600140e-01, ...,\n",
       "          -3.71430963e-01, -3.79858106e-01, -3.77233684e-01],\n",
       "         [ 1.66969764e+00,  1.83601832e+00,  1.97476530e+00, ...,\n",
       "           1.50188088e+00,  1.62256086e+00,  1.70747221e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]]],\n",
       "\n",
       "\n",
       "       [[[-8.45203936e-01, -8.34776521e-01, -8.39504600e-01, ...,\n",
       "          -6.56200111e-01, -6.60706103e-01, -6.87629759e-01],\n",
       "         [ 3.11213523e-01,  3.68326813e-01,  4.00526285e-01, ...,\n",
       "          -1.15014516e-01, -4.57112901e-02,  2.06927769e-02],\n",
       "         [-6.09830558e-01, -6.63962066e-01, -7.10076272e-01, ...,\n",
       "          -1.58532992e-01, -1.75075993e-01, -2.14212090e-01],\n",
       "         ...,\n",
       "         [-3.57734084e-01, -5.05261302e-01, -6.69132411e-01, ...,\n",
       "          -9.96217966e-01, -9.20041203e-01, -8.23948741e-01],\n",
       "         [ 1.03023566e-01,  2.77397424e-01,  3.96158099e-01, ...,\n",
       "          -1.51548529e+00, -1.53714776e+00, -1.54405510e+00],\n",
       "         [ 2.99417764e-01,  3.03395718e-01,  2.48924077e-01, ...,\n",
       "           5.89601040e-01,  4.26465482e-01,  2.19868138e-01]],\n",
       "\n",
       "        [[ 3.41671675e-01,  3.24763745e-01,  2.75769085e-01, ...,\n",
       "          -7.42866397e-01, -5.74174106e-01, -4.17606741e-01],\n",
       "         [-2.91762084e-01, -2.38240927e-01, -2.17798531e-01, ...,\n",
       "          -8.61832321e-01, -7.93361485e-01, -6.97681963e-01],\n",
       "         [ 2.60120726e+00,  2.21437740e+00,  1.85945749e+00, ...,\n",
       "          -7.81373799e-01, -7.93603957e-01, -8.01072478e-01],\n",
       "         ...,\n",
       "         [-3.37108731e-01, -4.33299392e-01, -5.34446657e-01, ...,\n",
       "           2.42124772e+00,  1.94561040e+00,  1.46277916e+00],\n",
       "         [-2.77375072e-01, -4.50873733e-01, -5.87348938e-01, ...,\n",
       "           8.72062147e-01,  8.24202955e-01,  7.01866150e-01],\n",
       "         [-7.26508498e-01, -6.50252044e-01, -5.33877611e-01, ...,\n",
       "          -6.48354590e-01, -6.43734753e-01, -6.08063877e-01]],\n",
       "\n",
       "        [[-8.54982138e-01, -9.74847734e-01, -1.05440688e+00, ...,\n",
       "          -4.39607322e-01, -5.64238071e-01, -6.90003574e-01],\n",
       "         [ 7.99884975e-01,  6.74566805e-01,  5.16301811e-01, ...,\n",
       "          -6.72390878e-01, -5.93458831e-01, -4.95236158e-01],\n",
       "         [-1.74910039e-01, -3.03992242e-01, -4.16412145e-01, ...,\n",
       "          -4.25996244e-01, -4.48759407e-01, -4.80427325e-01],\n",
       "         ...,\n",
       "         [-1.99260235e-01, -1.57904699e-01, -7.33406320e-02, ...,\n",
       "           2.07680508e-01,  2.97938675e-01,  4.03732747e-01],\n",
       "         [ 1.94090349e-03, -9.28389132e-02, -2.03530386e-01, ...,\n",
       "           1.70025200e-01,  4.06195134e-01,  6.27790570e-01],\n",
       "         [ 1.67327785e+00,  1.59934223e+00,  1.51429009e+00, ...,\n",
       "          -1.19435990e+00, -1.21293211e+00, -1.23359585e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 1.32304561e+00,  1.46838665e+00,  1.58818233e+00, ...,\n",
       "           1.97722530e+00,  1.62368345e+00,  1.28505325e+00],\n",
       "         [ 2.08229929e-01,  1.81504115e-01,  1.39913976e-01, ...,\n",
       "           2.49356174e+00,  2.61392403e+00,  2.64208627e+00],\n",
       "         [ 8.61811280e-01,  8.27987373e-01,  7.59413064e-01, ...,\n",
       "          -6.86233819e-01, -6.19097173e-01, -5.46967506e-01],\n",
       "         ...,\n",
       "         [ 1.22663736e+00,  1.22596467e+00,  1.25431740e+00, ...,\n",
       "          -4.07880932e-01, -4.61134940e-01, -5.37768781e-01],\n",
       "         [ 1.16272673e-01,  2.76976287e-01,  3.93721789e-01, ...,\n",
       "          -9.70359504e-01, -9.08753574e-01, -8.46184790e-01],\n",
       "         [ 3.58240664e-01,  3.89252722e-01,  4.01523739e-01, ...,\n",
       "          -2.23308027e-01, -3.99063736e-01, -5.47804415e-01]],\n",
       "\n",
       "        [[-5.41481435e-01, -5.17651200e-01, -4.77963269e-01, ...,\n",
       "          -3.56473923e-01, -6.19112015e-01, -7.91117728e-01],\n",
       "         [-5.47739267e-02, -2.52929837e-01, -4.04540569e-01, ...,\n",
       "          -6.09338880e-01, -6.83361769e-01, -7.60911047e-01],\n",
       "         [-1.43706612e-02,  5.15806451e-02,  9.93607789e-02, ...,\n",
       "          -1.94406852e-01, -2.87930787e-01, -3.36896420e-01],\n",
       "         ...,\n",
       "         [-1.34022450e+00, -1.28354180e+00, -1.21641505e+00, ...,\n",
       "          -3.09423923e-01, -1.18292704e-01,  7.95120150e-02],\n",
       "         [-3.39081287e-01, -3.14892918e-01, -2.94162065e-01, ...,\n",
       "          -6.15293562e-01, -5.99252582e-01, -6.01364493e-01],\n",
       "         [-2.56940663e-01, -1.95152655e-01, -1.55426875e-01, ...,\n",
       "          -1.31590545e+00, -1.29997241e+00, -1.26130748e+00]],\n",
       "\n",
       "        [[ 1.03102056e-02,  4.24090168e-03,  4.23028320e-02, ...,\n",
       "           1.45912215e-01,  5.29897511e-02, -3.42850611e-02],\n",
       "         [ 1.03331578e+00,  9.41258132e-01,  8.41867864e-01, ...,\n",
       "          -1.61728546e-01, -2.99405195e-02,  9.46575403e-02],\n",
       "         [-9.80238497e-01, -9.91751969e-01, -9.94484305e-01, ...,\n",
       "          -4.60146874e-01, -3.99544388e-01, -3.33300680e-01],\n",
       "         ...,\n",
       "         [ 2.86529690e-01,  4.55106437e-01,  5.89924932e-01, ...,\n",
       "           6.02962911e-01,  3.34453702e-01,  1.63347915e-01],\n",
       "         [-9.64809120e-01, -8.21226239e-01, -6.17603064e-01, ...,\n",
       "           1.12119980e-01,  2.50903636e-01,  3.75569344e-01],\n",
       "         [ 2.65132046e+00,  2.76310349e+00,  2.81493545e+00, ...,\n",
       "          -4.58888412e-01, -5.92707098e-01, -7.05135882e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-6.30147338e-01, -5.74070513e-01, -5.46694040e-01, ...,\n",
       "          -1.07926869e+00, -1.14646232e+00, -1.12437010e+00],\n",
       "         [ 3.69984925e-01,  8.23613405e-02, -1.64861888e-01, ...,\n",
       "           2.08052564e+00,  2.05005169e+00,  1.96827245e+00],\n",
       "         [-5.91067016e-01, -4.92863476e-01, -3.74848992e-01, ...,\n",
       "           3.46662951e+00,  3.34537816e+00,  3.25358200e+00],\n",
       "         ...,\n",
       "         [-5.46708226e-01, -4.48419005e-01, -3.51019084e-01, ...,\n",
       "           5.62289178e-01,  6.38317227e-01,  6.79140568e-01],\n",
       "         [ 2.40680382e-01,  2.37404987e-01,  2.05392271e-01, ...,\n",
       "          -5.42006969e-01, -5.26386738e-01, -4.99781221e-01],\n",
       "         [-2.69008577e-01, -1.83764741e-01, -1.26749977e-01, ...,\n",
       "           5.55652864e-02,  3.36512178e-01,  6.15673780e-01]],\n",
       "\n",
       "        [[-1.84676826e-01, -2.30793133e-01, -2.43523583e-01, ...,\n",
       "          -2.26034541e-02, -1.64376229e-01, -2.30028048e-01],\n",
       "         [-1.14579165e+00, -1.16716158e+00, -1.18362892e+00, ...,\n",
       "           4.54760742e+00,  5.21273088e+00,  5.85930204e+00],\n",
       "         [ 3.07321668e-01,  4.19213057e-01,  5.09706259e-01, ...,\n",
       "           1.98639798e+00,  1.98071408e+00,  2.04108620e+00],\n",
       "         ...,\n",
       "         [ 6.74600422e-01,  8.38150501e-01,  9.76034343e-01, ...,\n",
       "           3.10103983e-01,  1.34264082e-01, -9.95296147e-03],\n",
       "         [ 2.98472673e-01,  1.57701015e-01,  2.96609774e-02, ...,\n",
       "          -1.36805248e+00, -1.35254049e+00, -1.31529856e+00],\n",
       "         [-1.22036964e-01, -1.40019059e-01, -1.08453482e-01, ...,\n",
       "          -1.20536363e+00, -1.16661239e+00, -1.11886179e+00]],\n",
       "\n",
       "        [[-1.20127308e+00, -1.23593092e+00, -1.27132320e+00, ...,\n",
       "          -8.07364941e-01, -7.70362079e-01, -7.35693336e-01],\n",
       "         [-1.04347587e+00, -1.02429187e+00, -1.01478958e+00, ...,\n",
       "          -7.40725100e-01, -7.01166928e-01, -6.10145986e-01],\n",
       "         [-2.43726205e-02,  8.12297463e-02,  1.69799060e-01, ...,\n",
       "           7.18330085e-01,  7.51885414e-01,  7.44284570e-01],\n",
       "         ...,\n",
       "         [-1.30736023e-01, -3.15031290e-01, -4.88430381e-01, ...,\n",
       "          -2.38005724e-02,  4.64094952e-02,  1.05863467e-01],\n",
       "         [-9.92581248e-02, -1.59657419e-01, -2.41869509e-01, ...,\n",
       "          -7.89623082e-01, -7.32723415e-01, -6.50844991e-01],\n",
       "         [ 3.36828887e-01,  2.58010805e-01,  1.51372477e-01, ...,\n",
       "          -1.24186552e+00, -1.19192135e+00, -1.14284670e+00]]],\n",
       "\n",
       "\n",
       "       [[[-3.12144220e-01, -3.31654251e-01, -3.44906092e-01, ...,\n",
       "           8.16778064e-01,  7.56066978e-01,  6.91660345e-01],\n",
       "         [-6.71428680e-01, -4.38257962e-01, -1.85822725e-01, ...,\n",
       "           4.20992589e-03, -5.42616509e-02, -8.72673690e-02],\n",
       "         [-2.20893249e-01, -3.35227519e-01, -4.49555069e-01, ...,\n",
       "          -9.40445721e-01, -9.18536305e-01, -8.87573421e-01],\n",
       "         ...,\n",
       "         [-9.32984412e-01, -8.16619337e-01, -6.83915734e-01, ...,\n",
       "           8.71419251e-01,  1.04534519e+00,  1.16568029e+00],\n",
       "         [-2.54562587e-01, -5.82055971e-02,  1.19176164e-01, ...,\n",
       "           2.96040964e+00,  2.57473969e+00,  2.12000489e+00],\n",
       "         [-4.91570890e-01, -5.09059906e-01, -5.21896541e-01, ...,\n",
       "           1.54469419e+00,  1.62551999e+00,  1.66245735e+00]],\n",
       "\n",
       "        [[-2.27398455e-01, -3.48154604e-01, -4.73946482e-01, ...,\n",
       "          -1.13066959e+00, -1.07894886e+00, -1.04618716e+00],\n",
       "         [ 7.38588393e-01,  6.01847351e-01,  4.62598205e-01, ...,\n",
       "          -8.09868813e-01, -8.96494865e-01, -9.62652922e-01],\n",
       "         [-1.94604486e-01, -2.25873306e-01, -2.67662466e-01, ...,\n",
       "           7.77672231e-01,  5.79314649e-01,  3.74090999e-01],\n",
       "         ...,\n",
       "         [-1.16685998e+00, -1.22002995e+00, -1.26524150e+00, ...,\n",
       "          -9.85295594e-01, -9.98037517e-01, -1.00247097e+00],\n",
       "         [-3.62230867e-01, -4.65161920e-01, -5.63807607e-01, ...,\n",
       "          -9.05259609e-01, -8.08152616e-01, -6.91153347e-01],\n",
       "         [ 2.39048406e-01,  1.04986615e-01, -1.42897153e-03, ...,\n",
       "          -1.55098975e-01, -6.75054640e-02,  1.61755502e-01]],\n",
       "\n",
       "        [[ 5.85362732e-01,  6.59102678e-01,  7.26687431e-01, ...,\n",
       "           4.19178516e-01,  4.46725756e-01,  4.59677666e-01],\n",
       "         [-2.42291421e-01, -1.85176179e-01, -1.27623796e-01, ...,\n",
       "          -1.03248239e+00, -9.15575862e-01, -7.67578483e-01],\n",
       "         [ 2.14178234e-01,  1.81649953e-01,  1.54699877e-01, ...,\n",
       "           1.98743200e+00,  2.14755917e+00,  2.31347823e+00],\n",
       "         ...,\n",
       "         [-1.98865786e-01, -2.72319108e-01, -3.58238697e-01, ...,\n",
       "          -9.13579822e-01, -8.94505918e-01, -8.70129943e-01],\n",
       "         [-7.33880639e-01, -6.21480405e-01, -5.36004305e-01, ...,\n",
       "          -1.28522289e+00, -1.21295929e+00, -1.14013779e+00],\n",
       "         [ 3.20503265e-01,  2.71262765e-01,  2.12962791e-01, ...,\n",
       "           1.01401007e+00,  9.57443655e-01,  8.69337082e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]]],\n",
       "\n",
       "\n",
       "       [[[-1.50685549e+00, -1.51259387e+00, -1.52224743e+00, ...,\n",
       "          -1.01946628e+00, -1.05910683e+00, -1.07110548e+00],\n",
       "         [ 3.31653029e-01,  4.51413423e-01,  5.23247421e-01, ...,\n",
       "           1.00192702e+00,  1.05947602e+00,  1.08349872e+00],\n",
       "         [ 1.45378739e-01,  7.02552348e-02, -1.19706970e-02, ...,\n",
       "          -1.84552506e-01, -2.69124925e-01, -3.74051243e-01],\n",
       "         ...,\n",
       "         [-4.90956277e-01, -3.67197454e-01, -2.55479962e-01, ...,\n",
       "           6.00089192e-01,  4.38876033e-01,  2.64046013e-01],\n",
       "         [ 2.05281186e+00,  1.75573552e+00,  1.39832807e+00, ...,\n",
       "           2.09211683e+00,  1.89423406e+00,  1.66078746e+00],\n",
       "         [-3.97054069e-02,  2.46216990e-02,  7.22195208e-02, ...,\n",
       "          -1.25673938e+00, -1.24394715e+00, -1.21978104e+00]],\n",
       "\n",
       "        [[ 1.43841708e+00,  1.53086996e+00,  1.58423090e+00, ...,\n",
       "          -1.10495353e+00, -1.16472864e+00, -1.20042324e+00],\n",
       "         [-3.05092096e-01, -2.23903134e-01, -1.46730095e-01, ...,\n",
       "           5.57967126e-02, -8.28932673e-02, -1.90663636e-01],\n",
       "         [ 1.05080438e+00,  9.49500382e-01,  8.23449969e-01, ...,\n",
       "          -4.67361540e-01, -4.40691829e-01, -4.33118790e-01],\n",
       "         ...,\n",
       "         [-9.05977428e-01, -8.08717728e-01, -7.06145823e-01, ...,\n",
       "           7.47492611e-01,  7.38009334e-01,  6.98260546e-01],\n",
       "         [-8.85622561e-01, -9.76407528e-01, -1.05436921e+00, ...,\n",
       "          -8.53741467e-01, -7.62529910e-01, -6.52472436e-01],\n",
       "         [-1.03199470e+00, -9.77978826e-01, -9.18000996e-01, ...,\n",
       "          -8.01083982e-01, -7.80927420e-01, -7.49655843e-01]],\n",
       "\n",
       "        [[-1.01987684e+00, -8.94358635e-01, -7.69280076e-01, ...,\n",
       "          -1.03704818e-01,  2.43672654e-01,  6.46100760e-01],\n",
       "         [-4.72717613e-01, -4.67257738e-01, -4.28077519e-01, ...,\n",
       "           3.76819396e+00,  3.66083980e+00,  3.47471404e+00],\n",
       "         [ 7.05746710e-02,  1.42870381e-01,  2.10859939e-01, ...,\n",
       "           2.06237078e+00,  2.55374670e+00,  3.14236784e+00],\n",
       "         ...,\n",
       "         [-1.00191379e+00, -1.09426963e+00, -1.16739035e+00, ...,\n",
       "          -5.87619483e-01, -4.52477366e-01, -3.37860793e-01],\n",
       "         [-2.81380445e-01, -1.91997781e-01, -1.17270768e-01, ...,\n",
       "          -1.14159560e+00, -1.11728370e+00, -1.06965756e+00],\n",
       "         [-7.62741864e-01, -7.51686692e-01, -7.57699728e-01, ...,\n",
       "           2.05723691e+00,  2.25827312e+00,  2.38539004e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]],\n",
       "\n",
       "        [[            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         ...,\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan],\n",
       "         [            nan,             nan,             nan, ...,\n",
       "                      nan,             nan,             nan]]]])\n",
       "labels(['Stimulus/BigLetters/SmallLetterh/Taskg', 'Stimulus/BigLetters/SmallLetterh/Taskl', 'Stimulus/BigLetters/SmallLetters/Taskg', 'Stimulus/BigLetters/SmallLetters/Taskl', 'Stimulus/BigLetterh/SmallLetterh/Taskg', 'Stimulus/BigLetterh/SmallLetterh/Taskl', 'Stimulus/BigLetterh/SmallLetters/Taskg', 'Stimulus/BigLetterh/SmallLetters/Taskl']\n",
       "       ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33']\n",
       "       ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58']\n",
       "       ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '100', '101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '125', '126', '127', '128', '129', '130', '131', '132', '133', '134', '135', '136', '137', '138', '139', '140', '141', '142', '143', '144', '145', '146', '147', '148', '149', '150', '151', '152', '153', '154', '155', '156', '157', '158', '159', '160', '161', '162', '163', '164', '165', '166', '167', '168', '169', '170', '171', '172', '173', '174', '175', '176', '177', '178', '179', '180', '181', '182', '183', '184', '185', '186', '187', '188', '189', '190', '191', '192', '193', '194', '195', '196', '197', '198', '199', '200', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212', '213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '225', '226', '227', '228', '229', '230', '231', '232', '233', '234', '235', '236', '237', '238', '239', '240', '241', '242', '243', '244', '245', '246', '247', '248', '249', '250', '251', '252', '253', '254', '255', '256', '257', '258', '259', '260', '261', '262', '263', '264', '265', '266', '267', '268', '269', '270', '271', '272', '273', '274', '275', '276', '277', '278', '279', '280', '281', '282', '283', '284', '285', '286', '287', '288', '289', '290', '291', '292', '293', '294', '295', '296', '297', '298', '299', '300', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '326', '327', '328', '329', '330', '331', '332', '333', '334', '335', '336', '337', '338', '339', '340', '341', '342', '343', '344', '345', '346', '347', '348', '349', '350', '351', '352', '353', '354', '355', '356', '357', '358', '359', '360', '361', '362', '363', '364', '365', '366', '367', '368', '369', '370', '371', '372', '373', '374', '375', '376', '377', '378', '379', '380', '381', '382', '383', '384', '385', '386', '387', '388', '389', '390', '391', '392', '393', '394', '395', '396', '397', '398', '399', '400', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '424', '425', '426', '427', '428', '429', '430', '431', '432', '433', '434', '435', '436', '437', '438', '439', '440', '441', '442', '443', '444', '445', '446', '447', '448', '449', '450', '451', '452', '453', '454', '455', '456', '457', '458', '459', '460', '461', '462', '463', '464', '465', '466', '467', '468', '469', '470', '471', '472', '473', '474', '475', '476', '477', '478', '479', '480', '481', '482', '483', '484', '485', '486', '487', '488', '489', '490', '491', '492', '493', '494', '495', '496', '497', '498', '499', '500', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '524', '525', '526', '527', '528', '529', '530', '531', '532', '533', '534', '535', '536', '537', '538', '539', '540', '541', '542', '543', '544', '545', '546', '547', '548', '549', '550', '551', '552', '553', '554', '555', '556', '557', '558', '559', '560', '561', '562', '563', '564', '565', '566', '567', '568', '569', '570', '571', '572', '573', '574', '575', '576', '577', '578', '579', '580', '581', '582', '583', '584', '585', '586', '587', '588', '589', '590', '591', '592', '593', '594', '595', '596', '597', '598', '599', '600', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615', '616', '617', '618', '619', '620', '621', '622', '623', '624', '625', '626', '627', '628', '629', '630', '631', '632', '633', '634', '635', '636', '637', '638', '639', '640'])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi_labeled_arrays_no_nans = remove_nans_from_all_roi_labeled_arrays(roi_labeled_arrays, obs_axs=1, chans_axs=2, time_axs=3)\n",
    "roi_labeled_arrays_no_nans['lpfc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "11/6 need to update the obs_axs here to work with obs_axs=1 and also all the way down too \n",
    "(though I'm not sure why the obs_axs is 0 for decoding, maybe cuz I make arrays for each condition?)\n",
    "'''\n",
    "def concatenate_conditions_by_string(roi_labeled_arrays, roi, strings_to_find, obs_axs=1):\n",
    "    \"\"\"\n",
    "    Concatenate trials across condition names that contain specific strings.\n",
    "    Assign labels based on the groupings of the conditions.\n",
    "\n",
    "    Parameters:\n",
    "    - roi_labeled_arrays: Dictionary of LabeledArrays for each ROI.\n",
    "    - roi: The specific ROI to process.\n",
    "    - strings_to_find: List of strings or list of lists of strings to search for in condition names.\n",
    "                      If a list of strings is provided, each string is treated as its own condition group.\n",
    "                      If a list of lists is provided, each sublist represents a group of conditions.\n",
    "    - obs_axs (int) : The trials dimension. Concatenation will happen along this axis. This is the 1st dimension (not 0th) because conditions in the labeled array is the 0th. But we will subtract 1 if not considering conditions as a dimension (looping over conditions)\n",
    "    \n",
    "    Returns:\n",
    "    - concatenated_data: The concatenated trials by (channels, timepoints, or whatever your other dimensions are) across the matching conditions.\n",
    "    - labels: A numpy array of labels (0, 1, 2, ...) corresponding to each group of conditions.\n",
    "    - cats: Dictionary of {condition_name: index} for decoding.\n",
    "    \"\"\"\n",
    "    concatenated_data = []\n",
    "    labels = []\n",
    "    cats = {}\n",
    "\n",
    "    # subtract 1 from the obs_axs index because we're not considering conditions as a dimension\n",
    "    obs_axs -= 1\n",
    "    # Track current label index\n",
    "    current_label = 0\n",
    "\n",
    "    # Normalize strings_to_find so each entry is a list (whether it's a string or a list of strings)\n",
    "    if isinstance(strings_to_find, list) and all(isinstance(s, str) for s in strings_to_find):\n",
    "        # If it's a flat list of strings, convert each string into its own single-item list\n",
    "        strings_to_find = [[s] for s in strings_to_find]\n",
    "\n",
    "    # Iterate over each group (whether it's a single string or a list of strings)\n",
    "    for string_group in strings_to_find:\n",
    "        # Find condition names that match any of the strings in the current string_group\n",
    "        matching_conditions = [cond for cond in roi_labeled_arrays[roi].keys() if any(s in cond for s in string_group)]\n",
    "\n",
    "        if not matching_conditions:\n",
    "            continue\n",
    "\n",
    "        # Concatenate data for all matching conditions\n",
    "        data_to_concatenate = []\n",
    "        for cond in matching_conditions:\n",
    "            # Extract data for the current condition\n",
    "            data = roi_labeled_arrays[roi][cond]  # Shape: (trials, channels, timepoints)\n",
    "            data_to_concatenate.append(data)\n",
    "            \n",
    "            # Update labels for the current condition group\n",
    "            labels.extend([current_label] * data.shape[0])\n",
    "        \n",
    "        # Check if we have data to concatenate for this condition group\n",
    "        if data_to_concatenate:\n",
    "            concatenated_data.append(np.concatenate(data_to_concatenate, axis=obs_axs))\n",
    "\n",
    "        # Assign current label to the condition group (based on the first string in the group for reference)\n",
    "        cats[tuple(string_group)] = current_label\n",
    "        current_label += 1\n",
    "\n",
    "    # Ensure there is data to concatenate\n",
    "    if not concatenated_data:\n",
    "        raise ValueError(f\"No matching conditions found for ROI: {roi} and strings: {strings_to_find}\")\n",
    "\n",
    "    # Concatenate all condition data along the trials axis\n",
    "    concatenated_data = np.concatenate(concatenated_data, axis=obs_axs)\n",
    "    \n",
    "    return concatenated_data, np.array(labels), cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up decoding output directory and conditions to compare 9/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "save_dir = os.path.join(LAB_root, 'BIDS-1.1_GlobalLocal', 'BIDS', 'derivatives', 'decoding', 'figs')\n",
    "\n",
    "if conditions == stimulus_experiment_conditions:\n",
    "    condition_comparisons = {}\n",
    "    condition_comparisons['congruency'] = [['c25.0', 'c75.0'], ['i25.0', 'i75.0']]\n",
    "    condition_comparisons['switchType'] = [['r25.0', 'r75.0'], ['s25.0', 's75.0']]\n",
    "    \n",
    "elif conditions == stimulus_conditions:\n",
    "    condition_comparisons = {}\n",
    "    condition_comparisons['BigLetter'] = ['BigLetters', 'BigLetterh']\n",
    "    condition_comparisons['SmallLetter'] = ['SmallLetters', 'SmallLetterh']\n",
    "    condition_comparisons['Task'] = ['Taskg', 'Taskl']\n",
    "    \n",
    "    # strings_to_find = ['BigLetters', 'BigLetterh']\n",
    "    # condition_0_name = 'BigLetters'\n",
    "    # condition_1_name = 'BigLetterh'\n",
    "\n",
    "    # strings_to_find = ['SmallLetters', 'SmallLetterh']\n",
    "    # condition_0_name = 'SmallLetters'\n",
    "    # condition_1_name = 'SmallLetterh'\n",
    "\n",
    "    # strings_to_find = ['Taskg', 'Taskl']\n",
    "    # condition_0_name = 'Taskg'\n",
    "    # condition_1_name = 'Taskl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do decoding on the reshaped time indexed arrays 9/12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's try a class for storing and plotting the decoding scores for each roi 9/13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROIScoreData:\n",
    "    def __init__(self, roi, bin_size):\n",
    "        self.roi = roi\n",
    "        self.bin_size = bin_size\n",
    "        self.bin_centers = []\n",
    "        self.accuracy_scores = []\n",
    "        self.precision_scores = []\n",
    "        self.recall_scores = []\n",
    "        self.f1_scores = []\n",
    "        self.d_prime_scores = []\n",
    "\n",
    "    def add_scores(self, bin_center, accuracy, precision, recall, f1, d_prime):\n",
    "        self.bin_centers.append(bin_center)\n",
    "        self.accuracy_scores.append(accuracy)\n",
    "        self.precision_scores.append(precision)\n",
    "        self.recall_scores.append(recall)\n",
    "        self.f1_scores.append(f1)\n",
    "        self.d_prime_scores.append(d_prime)\n",
    "\n",
    "    def plot_scores(self, strings_to_find, save_dir):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "\n",
    "        # Plot accuracy\n",
    "        plt.plot(self.bin_centers, self.accuracy_scores, label='Accuracy', marker='o')\n",
    "\n",
    "        # # Plot precision\n",
    "        # plt.plot(self.bin_centers, self.precision_scores, label='Precision', marker='o')\n",
    "\n",
    "        # # Plot recall\n",
    "        # plt.plot(self.bin_centers, self.recall_scores, label='Recall', marker='o')\n",
    "\n",
    "        # # Plot f1 score\n",
    "        # plt.plot(self.bin_centers, self.f1_scores, label='F1 Score', marker='o')\n",
    "\n",
    "        # Plot d-prime\n",
    "        plt.plot(self.bin_centers, self.d_prime_scores, label='D-Prime', marker='o')\n",
    "\n",
    "        # Set plot details\n",
    "        plt.xlabel('Time Bin Centers (s)')\n",
    "        plt.ylabel('Score')\n",
    "        plt.title(f'{condition_0_name} vs. {condition_1_name} Decoding Over Time for ROI: {self.roi}')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.ylim(0,1)\n",
    "\n",
    "        # Save the figure\n",
    "        file_name = f'{self.roi}_{condition_0_name}_vs_{condition_1_name}_decoding_over_time_dprime_acc.png'\n",
    "        plt.savefig(os.path.join(save_dir, file_name))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_plot_confusion_matrix_for_rois_jim(roi_labeled_arrays, rois, condition_comparison, strings_to_find, save_dir, time_interval_name=None, n_splits=5, n_repeats=5, obs_axs=0):\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix for each ROI and return it. Does this using all time points for training.\n",
    "\n",
    "    Parameters:\n",
    "    - roi_labeled_arrays: Dictionary containing the reshaped data for each ROI.\n",
    "    - rois: List of regions of interest (ROIs) to process.\n",
    "    - condition_comparison: the condition that we're comparing labels for (i.e., BigLetter)\n",
    "    - strings_to_find: List of strings or string groups to identify condition labels.\n",
    "    - save_dir: Directory to save the confusion matrix plots.\n",
    "    - time_interval_name: Optional string to add to the filename for the time interval (e.g., 'pre_stimulus' or 'post_stimulus').\n",
    "    - obs_axs: the trials axis\n",
    "\n",
    "    Returns:\n",
    "    - confusion_matrices: Dictionary containing confusion matrices for each ROI.\n",
    "    \"\"\"\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    # reshaped_roi_labeled_arrays_for_decoding = reshape_all_rois_for_decoding(roi_labeled_arrays)\n",
    "\n",
    "    for roi in rois:\n",
    "        print(f\"Processing ROI: {roi}\")\n",
    "        \n",
    "        # Concatenate the trials and get labels\n",
    "        # concatenated_data, labels, cats = concatenate_conditions_by_string(reshaped_roi_labeled_arrays_for_decoding, roi, strings_to_find)\n",
    "        concatenated_data, labels, cats = concatenate_conditions_by_string(roi_labeled_arrays, roi, strings_to_find, obs_axs) # don't reshape\n",
    "\n",
    "        print(f\"Concatenated data shape for {roi}: {concatenated_data.shape}\")\n",
    "        \n",
    "        # Calculate trial and nan trial counts per condition\n",
    "        trial_counts = {}\n",
    "        nan_counts_per_channel = {}\n",
    "\n",
    "        for string_group in strings_to_find:\n",
    "            # Get the label associated with the current string group\n",
    "            condition_label = cats[tuple(string_group) if isinstance(string_group, list) else (string_group,)]\n",
    "            \n",
    "            # Select trials for the current condition group\n",
    "            condition_trials = labels == condition_label\n",
    "            data_for_condition = concatenated_data[condition_trials]\n",
    "            \n",
    "            # Count total trials for the current condition\n",
    "            trial_counts[condition_label] = np.sum(condition_trials)\n",
    "            \n",
    "            # Count NaNs per channel\n",
    "            nan_counts_per_channel[condition_label] = np.isnan(data_for_condition).sum(axis=0)\n",
    "            print(f'Condition {string_group} has {trial_counts[condition_label]} trials')\n",
    "            print(f'NaN counts per channel for {string_group}: {nan_counts_per_channel[condition_label]}')\n",
    "\n",
    "        # Determine the maximum trial count across conditions\n",
    "        max_trial_count = max(trial_counts.values())\n",
    "        \n",
    "        # Balance trial counts by adding NaN trials where needed\n",
    "        for condition_label, count in trial_counts.items():\n",
    "            # Calculate the number of trials to add for this condition\n",
    "            trials_to_add = max_trial_count - count\n",
    "            \n",
    "            if trials_to_add > 0:\n",
    "                # Create NaN trials with the same shape as `concatenated_data` and add them\n",
    "                nan_trial_shape = (trials_to_add,) + concatenated_data.shape[1:]\n",
    "                nan_trials = np.full(nan_trial_shape, np.nan)\n",
    "                \n",
    "                # Append NaN trials to `concatenated_data` and update `labels` accordingly\n",
    "                concatenated_data = np.concatenate([concatenated_data, nan_trials], axis=0)\n",
    "                labels = np.concatenate([labels, [condition_label] * trials_to_add])\n",
    "        \n",
    "        # Create a Decoder and run cross-validation\n",
    "        decoder = Decoder(cats, 0.80, oversample=True, n_splits=n_splits, n_repeats=n_repeats)\n",
    "\n",
    "        # Use the concatenated data for the decoder\n",
    "        cm = decoder.cv_cm_jim(concatenated_data, labels, normalize='true', obs_axs=obs_axs)\n",
    "        cm_avg = np.mean(cm, axis=0)\n",
    "\n",
    "        # Store the confusion matrix in the dictionary\n",
    "        confusion_matrices[roi] = cm_avg\n",
    "\n",
    "        # Convert tuple labels to simple strings for display\n",
    "        display_labels = [\n",
    "            key[0] if isinstance(key, tuple) and len(key) == 1 else str(key)\n",
    "            for key in cats.keys()\n",
    "        ]\n",
    "        \n",
    "        # Plot the Confusion Matrix\n",
    "        fig, ax = plt.subplots()\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm_avg, display_labels=display_labels)\n",
    "        disp.plot(ax=ax)\n",
    "\n",
    "        # Save the figure with the time interval in the filename\n",
    "        time_str = f\"_{time_interval_name}\" if time_interval_name else \"\"\n",
    "        file_name = f'{roi}_{condition_comparison}{time_str}_time_averaged_confusion_matrix_{n_splits}splits_{n_repeats}repeats.png'\n",
    "        plt.savefig(os.path.join(save_dir, file_name))\n",
    "        plt.close()\n",
    "\n",
    "    return confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ROI: lpfc\n",
      "Concatenated data shape for lpfc: (512, 59, 641)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Need at least 3 non-nan values, but only have 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Call the old cm function with the appropriate parameters\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m condition_comparison, strings_to_find \u001b[38;5;129;01min\u001b[39;00m condition_comparisons\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 3\u001b[0m     confusion_matrices \u001b[38;5;241m=\u001b[39m \u001b[43mget_and_plot_confusion_matrix_for_rois_jim\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mroi_labeled_arrays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroi_labeled_arrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcondition_comparison\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_comparison\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrings_to_find\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrings_to_find\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_interval_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# If not dealing with specific time intervals\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobs_axs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[85], line 75\u001b[0m, in \u001b[0;36mget_and_plot_confusion_matrix_for_rois_jim\u001b[1;34m(roi_labeled_arrays, rois, condition_comparison, strings_to_find, save_dir, time_interval_name, n_splits, n_repeats, obs_axs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Create a Decoder and run cross-validation\u001b[39;00m\n\u001b[0;32m     74\u001b[0m decoder \u001b[38;5;241m=\u001b[39m Decoder(cats, \u001b[38;5;241m0.80\u001b[39m, oversample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_splits\u001b[38;5;241m=\u001b[39mn_splits, n_repeats\u001b[38;5;241m=\u001b[39mn_repeats)\n\u001b[1;32m---> 75\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_cm_jim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcatenated_balanced_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbalanced_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_axs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs_axs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m cm_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cm, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;66;03m# Store the confusion matrix in the dictionary\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[77], line 81\u001b[0m, in \u001b[0;36mDecoder.cv_cm_jim\u001b[1;34m(self, x_data, labels, normalize, obs_axs)\u001b[0m\n\u001b[0;32m     79\u001b[0m obs_axs \u001b[38;5;241m=\u001b[39m x_data\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m obs_axs \u001b[38;5;28;01mif\u001b[39;00m obs_axs \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m obs_axs\n\u001b[0;32m     80\u001b[0m idx \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(x_data\u001b[38;5;241m.\u001b[39mndim)]\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f, (train_idx, test_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msplit(x_data\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;241m0\u001b[39m, obs_axs), labels)):\n\u001b[0;32m     82\u001b[0m     x_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake(x_data, train_idx, obs_axs)\n\u001b[0;32m     83\u001b[0m     x_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtake(x_data, test_idx, obs_axs)\n",
      "File \u001b[1;32m~\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\calc\\oversample.py:78\u001b[0m, in \u001b[0;36mMinimumNaNSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (n_non_nan \u001b[38;5;241m:=\u001b[39m not_where\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m<\u001b[39m (n_min \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_non_nan \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     77\u001b[0m                                           \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeed at least \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_min\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m non-nan values, but only\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_non_nan\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     81\u001b[0m check \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m t: np\u001b[38;5;241m.\u001b[39msetdiff1d(not_where, t,\n\u001b[0;32m     82\u001b[0m                                          assume_unique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[0;32m     83\u001b[0m          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m t: np\u001b[38;5;241m.\u001b[39mintersect1d(not_where, t,\n\u001b[0;32m     84\u001b[0m                                           assume_unique\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)}\n\u001b[0;32m     86\u001b[0m splits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n",
      "\u001b[1;31mValueError\u001b[0m: Need at least 3 non-nan values, but only have 0"
     ]
    }
   ],
   "source": [
    "# Call the old cm function with the appropriate parameters\n",
    "for condition_comparison, strings_to_find in condition_comparisons.items():\n",
    "    confusion_matrices = get_and_plot_confusion_matrix_for_rois_jim(\n",
    "        roi_labeled_arrays=roi_labeled_arrays,\n",
    "        rois=rois,\n",
    "        condition_comparison=condition_comparison,\n",
    "        strings_to_find=strings_to_find,\n",
    "        save_dir=save_dir,\n",
    "        time_interval_name=None,  # If not dealing with specific time intervals\n",
    "        n_splits=5,\n",
    "        n_repeats=10,\n",
    "        obs_axs=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prestimulus vs poststimulus confusion matrices 9/21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_in_time_range(labeled_array, time_range):\n",
    "    \"\"\"\n",
    "    Extract data from a LabeledArray where the time points fall within a given range, using the LabeledArray `take` function.\n",
    "    \n",
    "    Parameters:\n",
    "    - labeled_array: The LabeledArray containing time points as labels.\n",
    "    - time_range: A tuple (start_time, end_time) representing the range of time.\n",
    "    \n",
    "    Returns:\n",
    "    - filtered_data: A LabeledArray containing only the data where the timepoints are within the specified range.\n",
    "    \"\"\"\n",
    "    start_time, end_time = time_range\n",
    "\n",
    "    # Assume that the time labels are stored in the 4th dimension (index 3)\n",
    "    time_points = np.array(labeled_array.labels[3], dtype=float)  # convert to floats, ensure conversion to float numpy array\n",
    "\n",
    "    # Find the indices of time points within the specified range\n",
    "    time_indices = np.where((time_points >= start_time) & (time_points <= end_time))[0]\n",
    "\n",
    "    # Use the take function to select the time indices along the time axis (axis=3)\n",
    "    filtered_data = labeled_array.take(time_indices, axis=3)\n",
    "\n",
    "    return filtered_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ROI: lpfc\n",
      "Concatenated data shape for lpfc: (512, 59, 257)\n",
      "Taskg has 256 trials\n",
      "Taskl has 256 trials\n",
      "Processing ROI: v1\n",
      "Concatenated data shape for v1: (472, 11, 257)\n",
      "Taskg has 236 trials\n",
      "Taskl has 236 trials\n",
      "Processing ROI: occ\n",
      "Concatenated data shape for occ: (512, 51, 257)\n",
      "Taskg has 256 trials\n",
      "Taskl has 256 trials\n",
      "Processing ROI: occ_filtered\n",
      "Concatenated data shape for occ_filtered: (512, 23, 257)\n",
      "Taskg has 256 trials\n",
      "Taskl has 256 trials\n",
      "Processing ROI: occ_best_filtered\n",
      "Concatenated data shape for occ_best_filtered: (472, 10, 257)\n",
      "Taskg has 236 trials\n",
      "Taskl has 236 trials\n",
      "Processing ROI: lpfc\n",
      "Concatenated data shape for lpfc: (512, 59, 385)\n",
      "Taskg has 256 trials\n",
      "Taskl has 256 trials\n",
      "Processing ROI: v1\n",
      "Concatenated data shape for v1: (472, 11, 385)\n",
      "Taskg has 236 trials\n",
      "Taskl has 236 trials\n",
      "Processing ROI: occ\n",
      "Concatenated data shape for occ: (512, 51, 385)\n",
      "Taskg has 256 trials\n",
      "Taskl has 256 trials\n",
      "Processing ROI: occ_filtered\n",
      "Concatenated data shape for occ_filtered: (512, 23, 385)\n",
      "Taskg has 256 trials\n",
      "Taskl has 256 trials\n",
      "Processing ROI: occ_best_filtered\n",
      "Concatenated data shape for occ_best_filtered: (472, 10, 385)\n",
      "Taskg has 236 trials\n",
      "Taskl has 236 trials\n"
     ]
    }
   ],
   "source": [
    "# Define the time intervals of interest\n",
    "pre_stimulus_interval = (-1.0, 0.0)  # Pre-stimulus: time -1 to 0 seconds\n",
    "post_stimulus_interval = (0.0, 1.5)  # Post-stimulus: time 0 to 1.5 seconds\n",
    "pre_stimulus_roi_labeled_arrays = {}\n",
    "post_stimulus_roi_labeled_arrays = {}\n",
    "\n",
    "for roi, labeled_array in roi_labeled_arrays.items():\n",
    "    pre_stimulus_roi_labeled_arrays[roi] = get_data_in_time_range(labeled_array, pre_stimulus_interval)\n",
    "    post_stimulus_roi_labeled_arrays[roi] = get_data_in_time_range(labeled_array, post_stimulus_interval)\n",
    "\n",
    "\n",
    "pre_stimulus_confusion_matrices = get_and_plot_confusion_matrix_for_rois_jim(\n",
    "    roi_labeled_arrays=pre_stimulus_roi_labeled_arrays,\n",
    "    rois=rois,\n",
    "    strings_to_find=strings_to_find,\n",
    "    condition_0_name=condition_0_name,\n",
    "    condition_1_name=condition_1_name,\n",
    "    save_dir=save_dir,\n",
    "    time_interval_name='pre_stimulus',  # If not dealing with specific time intervals\n",
    "    n_splits=5,\n",
    "    n_repeats=10\n",
    ")\n",
    "\n",
    "post_stimulus_confusion_matrices = get_and_plot_confusion_matrix_for_rois_jim(\n",
    "    roi_labeled_arrays=post_stimulus_roi_labeled_arrays,\n",
    "    rois=rois,\n",
    "    strings_to_find=strings_to_find,\n",
    "    condition_0_name=condition_0_name,\n",
    "    condition_1_name=condition_1_name,\n",
    "    save_dir=save_dir,\n",
    "    time_interval_name='post_stimulus',  # If not dealing with specific time intervals\n",
    "    n_splits=5,\n",
    "    n_repeats=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define colors for plotting (not used yet as of 8/21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors for the model names\n",
    "colors = {\n",
    "    'congruency': 'red',\n",
    "    'switchType': 'blue',\n",
    "    'congruencyProportion': 'pink',\n",
    "    'switchProportion': 'skyblue',\n",
    "    'congruency_congruencyProportion': 'hotpink',\n",
    "    'congruency_congruency_proportion': 'hotpink',\n",
    "    'switchType_switchProportion': 'gray',\n",
    "    'switch_type_switch_proportion': 'gray',\n",
    "    'bigLetter': 'green',\n",
    "    'big_letter': 'green',\n",
    "    'smallLetter': 'orange',\n",
    "    'small_letter': 'orange',\n",
    "    'task': 'gray',\n",
    "    'c75.0': 'pink',\n",
    "    'i75.0': 'pink',\n",
    "    'c25.0': 'gold',\n",
    "    'i25.0': 'gold',\n",
    "    'r25.0': 'lightblue',\n",
    "    's25.0': 'lightblue',\n",
    "    'r75.0': 'purple',\n",
    "    's75.0': 'purple'\n",
    "}\n",
    "\n",
    "# Define linestyles for the model names\n",
    "linestyles = {\n",
    "    'big letter S': '-',\n",
    "    'BigLetters': '-',\n",
    "\n",
    "    'big letter H': '--',\n",
    "    'BigLetterh': '--',\n",
    "\n",
    "    'small letter S': '-',\n",
    "    'SmallLetters': '-',\n",
    "\n",
    "    'small letter H': '--',\n",
    "    'SmallLetterh': '--',\n",
    "\n",
    "    'task G': '-',\n",
    "    'Taskg': '-',\n",
    "\n",
    "    'task L': '--',\n",
    "    'Taskl': '--',\n",
    "\n",
    "    'congruent': '-',\n",
    "    'c': '-',\n",
    "\n",
    "    'incongruent': '--',\n",
    "    'i': '--',\n",
    "\n",
    "    'repeat': '-',\n",
    "    'r': '-',\n",
    "\n",
    "    'switch': '--',\n",
    "    's': '--',\n",
    "\n",
    "    'c25.0': '-',\n",
    "    'c75.0': '-',\n",
    "    'i25.0': '--',\n",
    "    'i75.0': '--'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test this for stats though i think should be an easier way using the get_scores with shuffle=True. 11/1 don't use this, try using aaron's methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def time_sliding_decoding_with_significance(decoder, x_data, labels, conds, n_shuffles=100, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Perform time-sliding decoding with significance testing using shuffled data.\n",
    "\n",
    "    Parameters:\n",
    "    - decoder: The Decoder object for performing decoding.\n",
    "    - x_data: The data array of shape (trials, channels, timepoints).\n",
    "    - labels: Array of trial labels.\n",
    "    - conds: List of conditions or labels to decode.\n",
    "    - n_shuffles: Number of shuffling iterations for significance testing.\n",
    "    - alpha: Significance level for permutation testing.\n",
    "\n",
    "    Returns:\n",
    "    - true_scores: The decoding accuracy for the true labels.\n",
    "    - shuffle_scores: Decoding accuracy across shuffles.\n",
    "    - significance: Boolean array indicating significant time points.\n",
    "    \"\"\"\n",
    "    # Step 1: Perform decoding with true labels\n",
    "    true_scores = decoder.cv_cm(x_data, labels, normalize='true', obs_axs=0)\n",
    "\n",
    "    # Step 2: Perform decoding with shuffled labels\n",
    "    shuffle_scores = np.zeros((n_shuffles, true_scores.shape[-1]))  # (n_shuffles, timepoints)\n",
    "    for i in range(n_shuffles):\n",
    "        np.random.shuffle(labels)  # Shuffle the labels in-place\n",
    "        shuffle_result = decoder.cv_cm(x_data, labels, normalize='true', obs_axs=0)\n",
    "        shuffle_scores[i, :] = np.mean(shuffle_result, axis=(0, 1))  # Average across folds and repeats\n",
    "\n",
    "    # Step 3: Statistical testing (e.g., cluster-based permutation test)\n",
    "    true_mean = np.mean(true_scores, axis=(0, 1))  # Average across folds and repeats\n",
    "    shuffle_mean = np.mean(shuffle_scores, axis=0)\n",
    "\n",
    "    # Use permutation cluster testing to find significant time points\n",
    "    significance, _ = time_perm_cluster(true_mean, shuffle_scores, alpha=alpha)\n",
    "\n",
    "    return true_mean, shuffle_scores, significance\n",
    "\n",
    "def plot_decoding_with_significance(true_scores, shuffle_scores, significance, conds, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Plot the decoding accuracy with shaded regions indicating significance.\n",
    "\n",
    "    Parameters:\n",
    "    - true_scores: The mean decoding accuracy for the true labels.\n",
    "    - shuffle_scores: The decoding accuracy for shuffled labels.\n",
    "    - significance: Boolean array indicating significant time points.\n",
    "    - conds: List of condition names.\n",
    "    - alpha: Significance level used for statistical testing.\n",
    "    \"\"\"\n",
    "    time_points = np.arange(true_scores.shape[-1])\n",
    "\n",
    "    # Plot the true decoding scores\n",
    "    plt.plot(time_points, true_scores, label='True Decoding Accuracy', color='b')\n",
    "\n",
    "    # Plot the mean and standard deviation of shuffled scores\n",
    "    shuffle_mean = np.mean(shuffle_scores, axis=0)\n",
    "    shuffle_std = np.std(shuffle_scores, axis=0)\n",
    "    plt.fill_between(time_points, shuffle_mean - shuffle_std, shuffle_mean + shuffle_std,\n",
    "                     color='gray', alpha=0.5, label='Shuffled Decoding (Mean  SD)')\n",
    "\n",
    "    # Highlight significant time points\n",
    "    plt.fill_between(time_points, 0, 1, where=significance, color='red', alpha=0.3, transform=plt.gca().get_xaxis_transform(),\n",
    "                     label=f'Significant (p < {alpha})')\n",
    "\n",
    "    # Plot settings\n",
    "    plt.axhline(0.25, color='k', linestyle='--', label='Chance Level')\n",
    "    plt.xlabel('Time Points')\n",
    "    plt.ylabel('Decoding Accuracy')\n",
    "    plt.title('Time-Sliding Decoding with Significance')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "if __name__ == '__main__':\n",
    "    # Assuming `decoder`, `x_data`, and `labels` are defined\n",
    "    # conds = ['condition1', 'condition2']  # Modify as needed\n",
    "    true_scores, shuffle_scores, significance = time_sliding_decoding_with_significance(\n",
    "        decoder, x_data, labels, conds, n_shuffles=100, alpha=0.05)\n",
    "\n",
    "    # Plot the results\n",
    "    plot_decoding_with_significance(true_scores, shuffle_scores, significance, conds, alpha=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10/29 use aarons init cv cm code that has the shuffle option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_plot_confusion_matrix_for_rois_aaron(roi_labeled_arrays, rois, strings_to_find, condition_0_name, condition_1_name, save_dir, time_interval_name=None, explained_variance=0.80, n_splits=5, n_repeats=5, n_shuffle_repeats=20, obs_axs=0):\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix for each ROI and return it. Does this using all time points for training.\n",
    "\n",
    "    Parameters:\n",
    "    - roi_labeled_arrays: Dictionary containing the reshaped data for each ROI.\n",
    "    - rois: List of regions of interest (ROIs) to process.\n",
    "    - strings_to_find: List of strings or string groups to identify conditions.\n",
    "    - condition_0_name: Name for condition 0 (used for labeling).\n",
    "    - condition_1_name: Name for condition 1 (used for labeling).\n",
    "    - save_dir: Directory to save the confusion matrix plots.\n",
    "    - time_interval_name: Optional string to add to the filename for the time interval (e.g., 'pre_stimulus' or 'post_stimulus').\n",
    "    - obs_axs: the trials axis of your time binned arrays\n",
    "\n",
    "    Returns:\n",
    "    - confusion_matrices: Dictionary containing confusion matrices for each ROI.\n",
    "    \"\"\"\n",
    "    confusion_matrices = {}\n",
    "\n",
    "    for roi in rois:\n",
    "        print(f\"Processing ROI: {roi}\")\n",
    "        \n",
    "        # Concatenate the trials and get labels\n",
    "        # concatenated_data, labels, cats = concatenate_conditions_by_string(reshaped_roi_labeled_arrays_for_decoding, roi, strings_to_find)\n",
    "        concatenated_data, labels, cats = concatenate_conditions_by_string(roi_labeled_arrays, roi, strings_to_find) # don't reshape\n",
    "\n",
    "        print(f\"Concatenated data shape for {roi}: {concatenated_data.shape}\")\n",
    "        \n",
    "        # Iterate over the groups in strings_to_find\n",
    "        for string_group in strings_to_find:\n",
    "            # If it's a single string (old behavior)\n",
    "            if isinstance(string_group, str):\n",
    "                # Count trials for the single condition group\n",
    "                num_trials = len([label for label in labels if label == cats[(string_group,)]])\n",
    "                print(f\"{string_group} has {num_trials} trials\")\n",
    "            \n",
    "            # If it's a list of strings (new behavior)\n",
    "            elif isinstance(string_group, list):\n",
    "                # Count trials for the group of strings (e.g., ['i25.0', 'i75.0'])\n",
    "                num_trials = len([label for label in labels if label == cats[tuple(string_group)]])\n",
    "                print(f\"{string_group} has {num_trials} trials\")\n",
    "\n",
    "        # Create a Decoder and run cross-validation. Check if Aaron makes a new Decoder for the shuffled labels.\n",
    "        decoder = Decoder(cats, explained_variance, oversample=True, n_splits=n_splits, n_repeats=n_repeats)\n",
    "        decoder_shuffled = Decoder(cats, explained_variance, oversample=True, n_splits=n_splits, n_repeats=n_shuffle_repeats)\n",
    "\n",
    "        # Use the concatenated data for the decoder using aaron's cv cm function with the shuffle option\n",
    "        cm = decoder.cv_cm_aaron(concatenated_data, labels, normalize='true', shuffle=False, obs_axs=obs_axs)\n",
    "        cm_shuffle = decoder_shuffled.cv_cm_aaron(concatenated_data, labels, normalize='true', shuffle=True, obs_axs=obs_axs)\n",
    "        cm_avg = np.mean(cm, axis=0)\n",
    "        cm_shuffle_avg = np.mean(cm_shuffle, axis=0)\n",
    "\n",
    "        # Store the real and shuffle confusion matrices as a dictionary\n",
    "        confusion_matrices[roi] = {'real': cm_avg, 'shuffle': cm_shuffle_avg}\n",
    "        \n",
    "        # Plot both cm_avg and cm_shuffle_avg for comparison\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        display_labels = [\n",
    "            key[0] if isinstance(key, tuple) and len(key) == 1 else str(key)\n",
    "            for key in cats.keys()\n",
    "        ]\n",
    "\n",
    "        # Plot original confusion matrix\n",
    "        disp_real = ConfusionMatrixDisplay(confusion_matrix=cm_avg, display_labels=display_labels)\n",
    "        disp_real.plot(ax=axs[0], cmap=\"Blues\", values_format=\".2f\")\n",
    "        axs[0].set_title(f\"{roi} Confusion Matrix (Real)\")\n",
    "\n",
    "        # Plot shuffled confusion matrix\n",
    "        disp_shuffle = ConfusionMatrixDisplay(confusion_matrix=cm_shuffle_avg, display_labels=display_labels)\n",
    "        disp_shuffle.plot(ax=axs[1], cmap=\"Oranges\", values_format=\".2f\")\n",
    "        axs[1].set_title(f\"{roi} Confusion Matrix (Shuffled)\")\n",
    "\n",
    "        # Save the figure\n",
    "        time_str = f\"_{time_interval_name}\" if time_interval_name else \"\"\n",
    "        file_name = f'{roi}_{condition_0_name}_vs_{condition_1_name}{time_str}_time_averaged_confusion_matrix_comparison_{n_splits}splits_{n_repeats}repeats.png'\n",
    " \n",
    "        plt.savefig(os.path.join(save_dir, file_name))\n",
    "        plt.show()\n",
    "\n",
    "    return confusion_matrices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ROI: lpfc\n",
      "Concatenated data shape for lpfc: (512, 59, 641)\n",
      "Taskg has 256 trials\n",
      "Taskl has 256 trials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Call the new function with the appropriate parameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m confusion_matrices \u001b[38;5;241m=\u001b[39m \u001b[43mget_and_plot_confusion_matrix_for_rois_aaron\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mroi_labeled_arrays\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mroi_labeled_arrays\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrois\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrois\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrings_to_find\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrings_to_find\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition_0_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_0_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcondition_1_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcondition_1_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtime_interval_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# If not dealing with specific time intervals\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplained_variance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.80\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_shuffle_repeats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobs_axs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[45], line 360\u001b[0m, in \u001b[0;36mget_and_plot_confusion_matrix_for_rois_aaron\u001b[1;34m(roi_labeled_arrays, rois, strings_to_find, condition_0_name, condition_1_name, save_dir, time_interval_name, explained_variance, n_splits, n_repeats, n_shuffle_repeats, obs_axs)\u001b[0m\n\u001b[0;32m    357\u001b[0m decoder_shuffled \u001b[38;5;241m=\u001b[39m Decoder(cats, explained_variance, oversample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, n_splits\u001b[38;5;241m=\u001b[39mn_splits, n_repeats\u001b[38;5;241m=\u001b[39mn_shuffle_repeats)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;66;03m# Use the concatenated data for the decoder using aaron's cv cm function with the shuffle option\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m cm \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_cm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcatenated_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs_axs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobs_axs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m cm_shuffle \u001b[38;5;241m=\u001b[39m decoder_shuffled\u001b[38;5;241m.\u001b[39mcv_cm(concatenated_data, labels, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, obs_axs\u001b[38;5;241m=\u001b[39mobs_axs)\n\u001b[0;32m    362\u001b[0m cm_avg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(cm, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[45], line 84\u001b[0m, in \u001b[0;36mDecoder.cv_cm\u001b[1;34m(self, x_data, labels, normalize, obs_axs, n_jobs, average_repetitions, window, shuffle, oversample)\u001b[0m\n\u001b[0;32m     79\u001b[0m     results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, return_as\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)(\n\u001b[0;32m     80\u001b[0m         delayed(proc)(train_idx, test_idx, l)\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (train_idx, test_idx), l \u001b[38;5;129;01min\u001b[39;00m idxs)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# Collect the results\u001b[39;00m\n\u001b[1;32m---> 84\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, result \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n\u001b[0;32m     85\u001b[0m     rep, fold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdivmod\u001b[39m(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits)\n\u001b[0;32m     86\u001b[0m     mats[:, rep, fold] \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[1;32mIn[45], line 77\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     76\u001b[0m     idxs \u001b[38;5;241m=\u001b[39m tqdm(idxs, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_repeats)\n\u001b[1;32m---> 77\u001b[0m     results \u001b[38;5;241m=\u001b[39m (\u001b[43mproc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m (train_idx, test_idx), l \u001b[38;5;129;01min\u001b[39;00m idxs)\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m     results \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, return_as\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)(\n\u001b[0;32m     80\u001b[0m         delayed(proc)(train_idx, test_idx, l)\n\u001b[0;32m     81\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m (train_idx, test_idx), l \u001b[38;5;129;01min\u001b[39;00m idxs)\n",
      "Cell \u001b[1;32mIn[45], line 66\u001b[0m, in \u001b[0;36mDecoder.cv_cm.<locals>.proc\u001b[1;34m(train_idx, test_idx, l)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mproc\u001b[39m(train_idx, test_idx, l):\n\u001b[0;32m     65\u001b[0m     x_stacked, y_train, y_test \u001b[38;5;241m=\u001b[39m sample_fold(train_idx, test_idx, data, l, \u001b[38;5;241m0\u001b[39m, oversample)\n\u001b[1;32m---> 66\u001b[0m     windowed \u001b[38;5;241m=\u001b[39m \u001b[43mwindower\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_stacked\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((windowed\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], n_cats, n_cats), dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, x_window \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(windowed):\n",
      "Cell \u001b[1;32mIn[45], line 155\u001b[0m, in \u001b[0;36mwindower\u001b[1;34m(x_data, window_size, axis, insert_at)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;66;03m# Compute the shape and strides for the sliding window view\u001b[39;00m\n\u001b[0;32m    154\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(x_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m--> 155\u001b[0m shape[axis] \u001b[38;5;241m=\u001b[39m \u001b[43mx_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    156\u001b[0m shape\u001b[38;5;241m.\u001b[39minsert(axis, window_size)\n\u001b[0;32m    157\u001b[0m strides \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(x_data\u001b[38;5;241m.\u001b[39mstrides)\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "# Call the new function with the appropriate parameters\n",
    "confusion_matrices = get_and_plot_confusion_matrix_for_rois_aaron(\n",
    "    roi_labeled_arrays=roi_labeled_arrays,\n",
    "    rois=rois,\n",
    "    strings_to_find=strings_to_find,\n",
    "    condition_0_name=condition_0_name,\n",
    "    condition_1_name=condition_1_name,\n",
    "    save_dir=save_dir,\n",
    "    time_interval_name=None,  # If not dealing with specific time intervals\n",
    "    explained_variance=0.80,\n",
    "    n_splits=5,\n",
    "    n_repeats=10,\n",
    "    n_shuffle_repeats=20,\n",
    "    obs_axs=0\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
