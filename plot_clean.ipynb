{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example line noise filtering script\n",
        "\n",
        "Filters the 60Hz line noise from the data, as well as the harmonics. Includes\n",
        "environment checks for SLURM jobs for convenience\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.path)\n",
        "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
        "\n",
        "import mne\n",
        "import os\n",
        "from ieeg.mt_filter import line_filter\n",
        "from ieeg.io import get_data, raw_from_layout, save_derivative, update\n",
        "from ieeg import viz\n",
        "from bids import BIDSLayout\n",
        "# from ieeg.viz.utils import figure_compare\n",
        "from ieeg.navigate import trial_ieeg, channel_outlier_marker, crop_empty_data, outliers_to_nan\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "if 'SLURM_ARRAY_TASK_ID' in os.environ.keys():\n",
        "    LAB_root = os.path.join(HOME, \"workspace\", \"CoganLab\")\n",
        "    subject = int(os.environ['SLURM_ARRAY_TASK_ID'])\n",
        "else:  # if not then set box directory\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "    subject = 57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### try new code from ieeg examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103', 'D0107A', 'D0110']\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-01_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-01_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-02_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: participants.tsv file not found for C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-01_ieeg.edf\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-02_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-03_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: participants.tsv file not found for C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-02_ieeg.edf\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-03_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_space-ACPC_electrodes.tsv.\n",
            "Extracting EDF parameters from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-04_ieeg.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: participants.tsv file not found for C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-03_ieeg.edf\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading events from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-04_events.tsv.\n",
            "Reading channel info from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_channels.tsv.\n",
            "Reading electrode coords from C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_space-ACPC_electrodes.tsv.\n",
            "Reading 0 ... 7464959  =      0.000 ...  3645.000 secs...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\jz421\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:113: RuntimeWarning: participants.tsv file not found for C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\sub-D0107A\\ieeg\\sub-D0107A_task-GlobalLocal_acq-01_run-04_ieeg.edf\n",
            "  new_raw = read_raw_bids(bids_path=BIDS_path, verbose=verbose)\n",
            "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
            "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   32.3s\n",
            "[Parallel(n_jobs=6)]: Done   2 tasks      | elapsed:   32.4s\n",
            "[Parallel(n_jobs=6)]: Done   3 tasks      | elapsed:   32.6s\n",
            "[Parallel(n_jobs=6)]: Done   4 tasks      | elapsed:   32.7s\n",
            "[Parallel(n_jobs=6)]: Done   5 tasks      | elapsed:   32.9s\n",
            "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   33.0s\n",
            "[Parallel(n_jobs=6)]: Done   7 tasks      | elapsed:   55.7s\n",
            "[Parallel(n_jobs=6)]: Done   8 tasks      | elapsed:   55.8s\n",
            "[Parallel(n_jobs=6)]: Done   9 tasks      | elapsed:   55.9s\n",
            "[Parallel(n_jobs=6)]: Done  10 tasks      | elapsed:   56.1s\n",
            "[Parallel(n_jobs=6)]: Done  11 tasks      | elapsed:   56.2s\n",
            "[Parallel(n_jobs=6)]: Done  12 tasks      | elapsed:   56.4s\n",
            "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  14 tasks      | elapsed:  1.3min\n",
            "[Parallel(n_jobs=6)]: Done  15 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  16 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  17 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  18 tasks      | elapsed:  1.4min\n",
            "[Parallel(n_jobs=6)]: Done  19 tasks      | elapsed:  1.7min\n",
            "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  21 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  22 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  23 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  24 tasks      | elapsed:  1.8min\n",
            "[Parallel(n_jobs=6)]: Done  25 tasks      | elapsed:  2.1min\n",
            "[Parallel(n_jobs=6)]: Done  26 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  27 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  28 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  30 tasks      | elapsed:  2.2min\n",
            "[Parallel(n_jobs=6)]: Done  31 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  32 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  33 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  34 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  35 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  36 tasks      | elapsed:  2.6min\n",
            "[Parallel(n_jobs=6)]: Done  37 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  39 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  40 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  41 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  42 tasks      | elapsed:  3.0min\n",
            "[Parallel(n_jobs=6)]: Done  43 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  44 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  45 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  46 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  47 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=6)]: Done  48 tasks      | elapsed:  3.5min\n",
            "[Parallel(n_jobs=6)]: Done  49 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=6)]: Done  50 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=6)]: Done  51 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=6)]: Done  52 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=6)]: Done  53 tasks      | elapsed:  3.8min\n",
            "[Parallel(n_jobs=6)]: Done  54 tasks      | elapsed:  3.9min\n",
            "[Parallel(n_jobs=6)]: Done  55 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=6)]: Done  56 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=6)]: Done  57 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=6)]: Done  58 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=6)]: Done  59 tasks      | elapsed:  4.2min\n",
            "[Parallel(n_jobs=6)]: Done  60 tasks      | elapsed:  4.3min\n",
            "[Parallel(n_jobs=6)]: Done  61 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  62 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  63 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  64 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  65 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  66 tasks      | elapsed:  4.7min\n",
            "[Parallel(n_jobs=6)]: Done  67 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  68 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  69 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  70 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  71 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  72 tasks      | elapsed:  5.1min\n",
            "[Parallel(n_jobs=6)]: Done  73 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  74 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  75 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  76 tasks      | elapsed:  5.5min\n",
            "[Parallel(n_jobs=6)]: Done  77 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  78 tasks      | elapsed:  5.6min\n",
            "[Parallel(n_jobs=6)]: Done  79 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  80 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  81 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  82 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  83 tasks      | elapsed:  6.0min\n",
            "[Parallel(n_jobs=6)]: Done  84 tasks      | elapsed:  6.1min\n",
            "[Parallel(n_jobs=6)]: Done  85 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=6)]: Done  86 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=6)]: Done  87 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=6)]: Done  88 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=6)]: Done  89 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=6)]: Done  90 tasks      | elapsed:  6.5min\n",
            "[Parallel(n_jobs=6)]: Done  91 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=6)]: Done  92 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=6)]: Done  93 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=6)]: Done  94 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=6)]: Done  95 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=6)]: Done  96 tasks      | elapsed:  6.9min\n",
            "[Parallel(n_jobs=6)]: Done  97 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=6)]: Done  98 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=6)]: Done  99 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=6)]: Done 100 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=6)]: Done 101 tasks      | elapsed:  7.3min\n",
            "[Parallel(n_jobs=6)]: Done 102 tasks      | elapsed:  7.4min\n",
            "[Parallel(n_jobs=6)]: Done 103 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done 104 tasks      | elapsed:  7.7min\n",
            "[Parallel(n_jobs=6)]: Done 105 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 106 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 107 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 108 tasks      | elapsed:  7.8min\n",
            "[Parallel(n_jobs=6)]: Done 109 tasks      | elapsed:  8.1min\n",
            "[Parallel(n_jobs=6)]: Done 110 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=6)]: Done 111 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=6)]: Done 112 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=6)]: Done 113 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=6)]: Done 114 tasks      | elapsed:  8.2min\n",
            "[Parallel(n_jobs=6)]: Done 115 tasks      | elapsed:  8.5min\n",
            "[Parallel(n_jobs=6)]: Done 116 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done 117 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done 118 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done 119 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done 120 tasks      | elapsed:  8.6min\n",
            "[Parallel(n_jobs=6)]: Done 121 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done 122 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done 123 tasks      | elapsed:  9.0min\n",
            "[Parallel(n_jobs=6)]: Done 124 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=6)]: Done 125 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=6)]: Done 126 tasks      | elapsed:  9.1min\n",
            "[Parallel(n_jobs=6)]: Done 127 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=6)]: Done 128 tasks      | elapsed:  9.6min\n",
            "[Parallel(n_jobs=6)]: Done 129 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=6)]: Done 130 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=6)]: Done 131 tasks      | elapsed:  9.7min\n",
            "[Parallel(n_jobs=6)]: Done 132 tasks      | elapsed:  9.8min\n",
            "[Parallel(n_jobs=6)]: Done 133 tasks      | elapsed: 10.1min\n",
            "[Parallel(n_jobs=6)]: Done 134 tasks      | elapsed: 10.2min\n"
          ]
        },
        {
          "ename": "PicklingError",
          "evalue": "Could not pickle the task to send it to the workers.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
            "\u001b[1;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\queues.py\", line 159, in _feed\n    obj_ = dumps(obj, reducers=reducers)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 215, in dumps\n    dump(obj, buf, reducers=reducers, protocol=protocol)\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\reduction.py\", line 208, in dump\n    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\externals\\cloudpickle\\cloudpickle_fast.py\", line 632, in dump\n    return Pickler.dump(self, obj)\n           ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\_memmapping_reducer.py\", line 446, in __call__\n    for dumped_filename in dump(a, filename):\n                           ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 553, in dump\n    NumpyPickler(f, protocol=protocol).dump(value)\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\pickle.py\", line 487, in dump\n    self.save(obj)\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 352, in save\n    wrapper.write_array(obj, self)\n  File \"c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 134, in write_array\n    pickler.file_handle.write(chunk.tobytes('C'))\nOSError: [Errno 28] No space left on device\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[11], line 55\u001b[0m\n\u001b[0;32m     39\u001b[0m raw \u001b[38;5;241m=\u001b[39m raw_from_layout(layout, subject\u001b[38;5;241m=\u001b[39msubj, extension\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.edf\u001b[39m\u001b[38;5;124m\"\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, preload\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# this is to exclude the eeg channels\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# List of channels you want to exclude. Gonna have to run this once, then grab the channels from the error message.\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# channels_to_exclude = ['T5', 'T6', 'FZ', 'CZ', 'PZ', 'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', '02', 'F7', 'F8', 'T3', 'T4']\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# can delete picks parameter if not excluding the eeg channels\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mline_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmt_bandwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilter_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m700ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfreqs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m120\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m180\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnotch_widths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# # %%\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# # plot the data before and after filtering\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# figure_compare([raw, filt],\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m \n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# filter again to get rid of harmonics\u001b[39;00m\n\u001b[0;32m     75\u001b[0m line_filter(raw,\n\u001b[0;32m     76\u001b[0m             mt_bandwidth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10.\u001b[39m,\n\u001b[0;32m     77\u001b[0m             n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m             notch_widths\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m     82\u001b[0m             copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
            "File \u001b[1;32m<decorator-gen-265>:10\u001b[0m, in \u001b[0;36mline_filter\u001b[1;34m(raw, fs, freqs, filter_length, notch_widths, mt_bandwidth, p_value, picks, n_jobs, adaptive, low_bias, copy, verbose)\u001b[0m\n",
            "File \u001b[1;32m~\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\mt_filter.py:157\u001b[0m, in \u001b[0;36mline_filter\u001b[1;34m(raw, fs, freqs, filter_length, notch_widths, mt_bandwidth, p_value, picks, n_jobs, adaptive, low_bias, copy, verbose)\u001b[0m\n\u001b[0;32m    151\u001b[0m filter_length: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(mt_utils\u001b[38;5;241m.\u001b[39mto_samples(filter_length, fs),\n\u001b[0;32m    152\u001b[0m                          x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    154\u001b[0m process \u001b[38;5;241m=\u001b[39m WindowingRemover(fs, freqs, notch_widths, filter_length,\n\u001b[0;32m    155\u001b[0m                            adaptive, low_bias, mt_bandwidth, p_value)\n\u001b[1;32m--> 157\u001b[0m filt\u001b[38;5;241m.\u001b[39m_data[data_idx] \u001b[38;5;241m=\u001b[39m \u001b[43mmt_spectrum_proc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filt\n",
            "File \u001b[1;32m~\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\mt_filter.py:168\u001b[0m, in \u001b[0;36mmt_spectrum_proc\u001b[1;34m(x, process, picks, n_jobs)\u001b[0m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;66;03m# set up array for filtering, reshape to 2D, operate on last axis\u001b[39;00m\n\u001b[0;32m    166\u001b[0m x, orig_shape, picks \u001b[38;5;241m=\u001b[39m _prep_for_filtering(x, picks)\n\u001b[1;32m--> 168\u001b[0m \u001b[43mproc_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChannels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    170\u001b[0m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m=\u001b[39m orig_shape\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32m~\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\process.py:219\u001b[0m, in \u001b[0;36mproc_array\u001b[1;34m(func, arr_in, axes, n_jobs, desc, inplace, **kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m gen \u001b[38;5;241m=\u001b[39m Parallel(n_jobs, return_as\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m)(\n\u001b[0;32m    216\u001b[0m     delayed(func)(x_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m x_ \u001b[38;5;129;01min\u001b[39;00m array_gen)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Create process pool and apply the function in parallel\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m out, ind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(gen, cross_sect_ind):\n\u001b[0;32m    220\u001b[0m     arr_out[ind] \u001b[38;5;241m=\u001b[39m out\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr_out\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:1699\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1692\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_retrieval():\n\u001b[0;32m   1693\u001b[0m \n\u001b[0;32m   1694\u001b[0m     \u001b[38;5;66;03m# If the callback thread of a worker has signaled that its task\u001b[39;00m\n\u001b[0;32m   1695\u001b[0m     \u001b[38;5;66;03m# triggered an exception, or if the retrieval loop has raised an\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m     \u001b[38;5;66;03m# exception (e.g. `GeneratorExit`), exit the loop and surface the\u001b[39;00m\n\u001b[0;32m   1697\u001b[0m     \u001b[38;5;66;03m# worker traceback.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aborting:\n\u001b[1;32m-> 1699\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1700\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1702\u001b[0m     \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:1734\u001b[0m, in \u001b[0;36mParallel._raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1730\u001b[0m \u001b[38;5;66;03m# If this error job exists, immediatly raise the error by\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;66;03m# calling get_result. This job might not exists if abort has been\u001b[39;00m\n\u001b[0;32m   1732\u001b[0m \u001b[38;5;66;03m# called directly or if the generator is gc'ed.\u001b[39;00m\n\u001b[0;32m   1733\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_job \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1734\u001b[0m     \u001b[43merror_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:736\u001b[0m, in \u001b[0;36mBatchCompletionCallBack.get_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    730\u001b[0m backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel\u001b[38;5;241m.\u001b[39m_backend\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39msupports_retrieve_callback:\n\u001b[0;32m    733\u001b[0m     \u001b[38;5;66;03m# We assume that the result has already been retrieved by the\u001b[39;00m\n\u001b[0;32m    734\u001b[0m     \u001b[38;5;66;03m# callback thread, and is stored internally. It's just waiting to\u001b[39;00m\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# be returned.\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_return_or_raise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# For other backends, the main thread needs to run the retrieval step.\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\joblib\\parallel.py:754\u001b[0m, in \u001b[0;36mBatchCompletionCallBack._return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    753\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m TASK_ERROR:\n\u001b[1;32m--> 754\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[1;31mPicklingError\u001b[0m: Could not pickle the task to send it to the workers."
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Line noise filtering script\n",
        "===================================\n",
        "\n",
        "Filters the 60Hz line noise from the data, as well as the harmonics. Includes\n",
        "environment checks for SLURM jobs for convenience\n",
        "\"\"\"\n",
        "\n",
        "import mne\n",
        "import os\n",
        "from ieeg.io import save_derivative, raw_from_layout\n",
        "from ieeg.mt_filter import line_filter\n",
        "# from ieeg.viz.utils import figure_compare\n",
        "from bids import BIDSLayout\n",
        "\n",
        "# %%\n",
        "# Set up paths\n",
        "# ------------\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "\n",
        "## Load Data\n",
        "layout = get_data(\"GlobalLocal\", LAB_root)\n",
        "subjects = layout.get_subjects()\n",
        "subjects.sort()\n",
        "print(subjects)\n",
        "\n",
        "\n",
        "#this is prob gonna fail at d0100 cuz eeg channels\n",
        "subjects = ['D0107A']\n",
        "for subj in subjects:\n",
        "    # Load the raw data without excluding any channels\n",
        "    raw = raw_from_layout(layout, subject=subj, extension=\".edf\", desc=None, preload=True)\n",
        "\n",
        "    # this is to exclude the eeg channels\n",
        "    # List of channels you want to exclude. Gonna have to run this once, then grab the channels from the error message.\n",
        "    # channels_to_exclude = ['T5', 'T6', 'FZ', 'CZ', 'PZ', 'FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', '02', 'F7', 'F8', 'T3', 'T4']\n",
        "    # Drop the channels you want to exclude\n",
        "    # raw.drop_channels(channels_to_exclude)\n",
        "\n",
        "    # %%\n",
        "    # Filter Data\n",
        "    # -----------\n",
        "    # A filter length of 700 ms does a good job of removing 60Hz line noise, while\n",
        "    # a Filter length of 20000 ms does a good job of removing the harmonics (120Hz,\n",
        "    # 180Hz, 240Hz)\n",
        "\n",
        "    # can delete picks parameter if not excluding the eeg channels\n",
        "    line_filter(raw,\n",
        "                mt_bandwidth=10.,\n",
        "                n_jobs=6,\n",
        "                filter_length='700ms',\n",
        "                verbose=10,\n",
        "                freqs=[60, 120, 180],\n",
        "                notch_widths=20,\n",
        "                copy=False)\n",
        "\n",
        "    # # %%\n",
        "    # # plot the data before and after filtering\n",
        "    # figure_compare([raw, filt],\n",
        "    #             labels=[\"Un\", \"\"],\n",
        "    #             avg=True,\n",
        "    #             n_jobs=6,\n",
        "    #             verbose=10,\n",
        "    #             proj=True,\n",
        "    #             fmax=250)\n",
        "\n",
        "    # filter again to get rid of harmonics\n",
        "    line_filter(raw,\n",
        "                mt_bandwidth=10.,\n",
        "                n_jobs=6,\n",
        "                filter_length='20000ms',\n",
        "                verbose=10,\n",
        "                freqs=[60],\n",
        "                notch_widths=20,\n",
        "                copy=False)\n",
        "\n",
        "    # plot raw vs filt in a separate notebook later, don't want to load in two datasets into memory\n",
        "    # # plot the data before and after filtering again\n",
        "    # figure_compare([raw, filt],\n",
        "    #                labels=[\"Un\", \"\"],\n",
        "    #                avg=True,\n",
        "    #                n_jobs=6,\n",
        "    #                verbose=10,\n",
        "    #                proj=True,\n",
        "    #                fmax=250)\n",
        "\n",
        "    # save the data\n",
        "    save_derivative(raw, layout, \"clean\", True)\n",
        "\n",
        "    # channel_outlier_marker(raw, 3, 2, save=True) #uhh try this again\n",
        "\n",
        "    # filt.info['bads'] += channel_outlier_marker(filt, 3, 2, save=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# this is for testing, directly load the raw and do channel outlier marker on it\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "if os.name == 'nt':  # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else:  # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                            \"CoganLab\")\n",
        "\n",
        "task='GlobalLocal'\n",
        "subj = 'D0057'\n",
        "\n",
        "layout = get_data(task, root=LAB_root)\n",
        "raw = raw_from_layout(layout, subject=subj, extension=\".edf\", desc=None, preload=True)\n",
        "\n",
        "channel_outlier_marker(raw, 3, 2, save=True) #uhh try this again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "channel_outlier_marker(raw, 3, 2, save=True) #uhh try this again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ieeg.viz.utils import figure_compare\n",
        "\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "task='GlobalLocal'\n",
        "\n",
        "if os.name == 'nt':  # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else:  # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
        "                            \"CoganLab\")\n",
        "    \n",
        "layout = get_data(task, root=LAB_root)\n",
        "actual_raw = raw_from_layout(layout, subject=subj, extension=\".edf\", desc=None, preload=True)\n",
        "\n",
        "figure_compare([actual_raw, raw],\n",
        "               labels=[\"Un\", \"\"],\n",
        "               avg=True,\n",
        "               n_jobs=6,\n",
        "               verbose=10,\n",
        "               proj=True,\n",
        "               fmax=250)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "delete the below cell after it runs (02/20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filenames = layout.get(return_type='filename', suffix='channels', extension='tsv', subject=subj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bads = ['LTPS8', 'FP1', 'C4', 'T4', 'O2', 'LTMM1', 'F7', 'C3']\n",
        "raw.info['bads'] = bads\n",
        "file_paths = [r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0100\\ieeg\\sub-D0100_task-GlobalLocal_acq-01_run-01_desc-clean_channels.tsv', r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0100\\ieeg\\sub-D0100_task-GlobalLocal_acq-01_run-02_desc-clean_channels.tsv', r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0100\\ieeg\\sub-D0100_task-GlobalLocal_acq-01_run-03_desc-clean_channels.tsv', r'C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\clean\\sub-D0100\\ieeg\\sub-D0100_task-GlobalLocal_acq-01_run-04_desc-clean_channels.tsv']\n",
        "\n",
        "for file_path in file_paths:\n",
        "    update(file_path, bads, status='bad')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### the code below is broken 1/25/24 cuz new ieeg updates i think"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "## Load Data\n",
        "layout = get_data(\"GlobalLocal\", LAB_root)\n",
        "subjects = layout.get_subjects()\n",
        "subjects.sort()\n",
        "print(subjects)\n",
        "\n",
        "for subj in subjects:\n",
        "    raw = raw_from_layout(layout, subject=subj, extension=\".edf\", desc=None,\n",
        "                      preload=True)\n",
        "\n",
        "    ## filter data\n",
        "    filt = line_filter(raw, mt_bandwidth=10., n_jobs=-1, copy=False, verbose=10,\n",
        "                filter_length='700ms', freqs=[60], notch_widths=20)\n",
        "    \n",
        "    filt.info['bads'] += channel_outlier_marker(filt, 3, 2, save=True)\n",
        "\n",
        "\n",
        "    # line_filter(raw, mt_bandwidth=10., n_jobs=-1, copy=False, verbose=10,\n",
        "    #             filter_length='20s', freqs=[60, 120, 180, 240],\n",
        "    #             notch_widths=20)\n",
        "\n",
        "    save_derivative(filt, layout, \"clean\", overwrite=True)\n",
        "\n",
        "    print(\"Data saved successfully.\")\n",
        "\n",
        "\n",
        "\n",
        "# # Save data to save_dir\n",
        "# file_names = [\"data_raw.fif\", \"data_filt.fif\"]  # Specify the desired file names\n",
        "# for d, file_name in zip(data, file_names):\n",
        "#     file_path = os.path.join(save_dir, file_name)\n",
        "#     d.save(file_path, overwrite=True)\n",
        "\n",
        "\n",
        "# for subj in subjects:\n",
        "#     # if subj != \"D0022\":\n",
        "#     #     continue\n",
        "#     # Load the data\n",
        "#     raw = raw_from_layout(layout, subject=subj,\n",
        "#                            extension='.edf', preload=True)\n",
        "#     filt = line_filter(raw, mt_bandwidth=10., n_jobs=6,\n",
        "#                    filter_length='700ms', verbose=10,\n",
        "#                    freqs=[60], notch_widths=20)\n",
        "\n",
        "\n",
        "#     data = [raw, filt]\n",
        "#     viz.utils.figure_compare(data, [\"Un\", \"\"], avg=True, n_jobs=6,\n",
        "#                    verbose=10, proj=True, fmax=250)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "## Load Data\n",
        "layout = get_data(\"GlobalLocal\", LAB_root)\n",
        "subjects = layout.get_subjects()\n",
        "subjects.sort()\n",
        "print(subjects)\n",
        "\n",
        "subj = 'D0102'\n",
        "raw = raw_from_layout(layout, subject=subj, extension=\".edf\", desc=None,\n",
        "                    preload=True)\n",
        "\n",
        "## filter data\n",
        "filt = line_filter(raw, mt_bandwidth=10., n_jobs=-1, copy=False, verbose=10,\n",
        "            filter_length='700ms', freqs=[60], notch_widths=20)\n",
        "\n",
        "filt.info['bads'] += channel_outlier_marker(filt, 3, 2, save=True)\n",
        "\n",
        "\n",
        "# line_filter(raw, mt_bandwidth=10., n_jobs=-1, copy=False, verbose=10,\n",
        "#             filter_length='20s', freqs=[60, 120, 180, 240],\n",
        "#             notch_widths=20)\n",
        "\n",
        "save_derivative(filt, layout, \"clean\", overwrite=True)\n",
        "\n",
        "print(\"Data saved successfully.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### just one subject for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", LAB_root)\n",
        "subj = \"D0057\"\n",
        "raw = raw_from_layout(layout, subject=subj, extension=\".edf\", desc=None,\n",
        "                    preload=True)\n",
        "\n",
        "## filter data\n",
        "filt = line_filter(raw, mt_bandwidth=10., n_jobs=-1, copy=False, verbose=10,\n",
        "            filter_length='700ms', freqs=[60], notch_widths=20)\n",
        "\n",
        "# line_filter(raw, mt_bandwidth=10., n_jobs=-1, copy=False, verbose=10,\n",
        "#             filter_length='20s', freqs=[60, 120, 180, 240],\n",
        "#             notch_widths=20)\n",
        "\n",
        "# do channel outlier marker with max_rounds of 2\n",
        "filt.info['bads'] += channel_outlier_marker(filt, 3, 2, save=True)\n",
        "\n",
        "# filt.drop_channels(filt.info['bads'])\n",
        "\n",
        "# update(filt, layout, \"bad\")\n",
        "\n",
        "\n",
        "# and then feed into preprocess.py and then feed into wavelet/HG/stats\n",
        "\n",
        "# update in check_chans saves the bad channels\n",
        "# save_derivative(filt, layout, \"clean\", overwrite=True)\n",
        "\n",
        "print(\"Data saved successfully.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "save_derivative(filt, layout, \"clean\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# trying to make pre-experiment baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add experiment start event to the events.tsv file\n",
        "\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "# Step 1: Read the existing file\n",
        "sub = 'D0071'  # Replace this with the actual subject ID\n",
        "\n",
        "events_path = os.path.join(layout.root, 'derivatives', 'clean', f'sub-{sub}', 'ieeg', \n",
        "                           f'sub-{sub}_task-GlobalLocal_acq-01_run-01_desc-clean_events.tsv')\n",
        "\n",
        "df = pd.read_csv(events_path, sep='\\t')\n",
        "\n",
        "# Step 2: Create a new DataFrame for the custom event\n",
        "new_row = pd.DataFrame({\n",
        "    'onset': [0],\n",
        "    'duration': [0],\n",
        "    'trial_type': ['experimentStart'],\n",
        "    'value': [None],\n",
        "    'sample': [None]\n",
        "})\n",
        "\n",
        "# Concatenate the new row with the existing DataFrame\n",
        "df = pd.concat([new_row, df]).reset_index(drop=True)\n",
        "\n",
        "# Step 3: Write the updated DataFrame back to the events.tsv file\n",
        "df.to_csv(events_path, sep='\\t', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(filt.annotations[0])  # this will show you all annotations and their onset times"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_selection = raw.copy().crop(tmin=0, tmax=300) #grab the first x seconds of the dataset. Onset is like 1300 seconds for D0057's first Stimulus event so I think we're good even if we do like 500 for everyone.\n",
        "\n",
        "filt_selection = filt.copy().crop(tmin=0, tmax=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Copy cropped data\n",
        "good = filt_selection.copy()\n",
        "\n",
        "# good.drop_channels(good.info['bads'])\n",
        "good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "good.drop_channels(good.info['bads'])\n",
        "good.load_data()\n",
        "\n",
        "ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "# Remove intermediates from mem\n",
        "good.plot()\n",
        "\n",
        " # make stimulus baseline EpochsTFR\n",
        "times=[-1,3] #this is for 0.5 sec of padding on each side\n",
        "trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "outliers_to_nan(trials, outliers=10)\n",
        "base = wavelet_scaleogram(trials, n_jobs=-2, decim=int(good.info['sfreq'] / 100))\n",
        "crop_pad(base, \"0.5s\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
