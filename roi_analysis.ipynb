{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin', 'C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "from misc_functions import load_sig_chans, channel_names_to_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the outer dictionary.\n",
    "subjects_electrodestoROIs_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make subjects rois to electrodes dict. Don't need to run this more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
    "\n",
    "for sub in subjects:\n",
    "    # sub = 'D0059'\n",
    "    task = 'GlobalLocal'\n",
    "    output_name = \"Response_fixationCrossBase_1sec_mirror\"\n",
    "    events = [\"Response\"]\n",
    "    times = (-1,1.5)\n",
    "    base_times = [-1,0]\n",
    "    LAB_root = None\n",
    "    channels = None\n",
    "    full_trial_base = False\n",
    "\n",
    "\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        if os.name == 'nt':  # windows\n",
    "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "        else:  # mac\n",
    "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                    \"CoganLab\")\n",
    "\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
    "                        extension='.edf', desc='clean', preload=False)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    good = crop_empty_data(filt)\n",
    "    # %%\n",
    "\n",
    "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
    "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
    "\n",
    "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
    "    good.drop_channels(good.info['bads'])\n",
    "\n",
    "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
    "\n",
    "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.load_data()\n",
    "\n",
    "    # If channels is None, use all channels\n",
    "    if channels is None:\n",
    "        channels = good.ch_names\n",
    "    else:\n",
    "        # Validate the provided channels\n",
    "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
    "        if invalid_channels:\n",
    "            raise ValueError(\n",
    "                f\"The following channels are not valid: {invalid_channels}\")\n",
    "\n",
    "        # Use only the specified channels\n",
    "        good.pick_channels(channels)\n",
    "\n",
    "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
    "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
    "\n",
    "    default_dict = gen_labels(good.info)\n",
    "    \n",
    "    # Create rawROI_dict for the subject\n",
    "    rawROI_dict = defaultdict(list)\n",
    "    for key, value in default_dict.items():\n",
    "        rawROI_dict[value].append(key)\n",
    "    rawROI_dict = dict(rawROI_dict)\n",
    "\n",
    "    # Filter out keys containing \"White-Matter\"\n",
    "    filtROI_dict = {key: value for key, value in rawROI_dict.items() if \"White-Matter\" not in key}\n",
    "\n",
    "    # Store the dictionaries in the subjects dictionary\n",
    "    subjects_electrodestoROIs_dict[sub] = {\n",
    "        'default_dict': dict(default_dict),\n",
    "        'rawROI_dict': dict(rawROI_dict),\n",
    "        'filtROI_dict': dict(filtROI_dict)\n",
    "    }\n",
    "\n",
    "\n",
    "# Save to a JSON file\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(subjects_electrodestoROIs_dict, file, indent=4)\n",
    "\n",
    "print(f\"Saved subjects_dict to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load subjects electrodes to rois dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data from subjects_electrodestoROIs_dict.json\n"
     ]
    }
   ],
   "source": [
    "# Load from a JSON file\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    subjects_electrodestoROIs_dict = json.load(file)\n",
    "\n",
    "print(f\"Loaded data from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load high gamma data so we can do roi analysis on it\n",
    "once we have more subjects, turn this into a function and loop over all subjects.  \n",
    "this code is a crime against humanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0057\\D0057_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0059\\D0059_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0063\\D0063_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0065\\D0065_Stimulus_c25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "224 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_base-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...       0.00 ms\n",
      "        0 CTF compensation matrices available\n",
      "Not setting metadata\n",
      "448 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Reading C:\\Users\\jz421\\Box\\CoganLab\\BIDS-1.1_GlobalLocal\\BIDS\\derivatives\\freqFilt\\figs\\D0069\\D0069_Stimulus_i25and75_fixationCrossBase_1sec_mirror_HG_ev1_rescaled-epo.fif ...\n",
      "    Found the data of interest:\n",
      "        t =   -1000.00 ...    1500.00 ms\n",
      "        0 CTF compensation matrices available\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_mne_objects(sub, output_name, task, LAB_root=None):\n",
    "    \"\"\"\n",
    "    Load MNE objects for a given subject and output name.\n",
    "\n",
    "    Parameters:\n",
    "    - sub (str): Subject identifier.\n",
    "    - output_name (str): Output name used in the file naming.\n",
    "    - task (str): Task identifier.\n",
    "    - LAB_root (str, optional): Root directory for the lab. If None, it will be determined based on the OS.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing loaded MNE objects.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine LAB_root based on the operating system\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "    \n",
    "    # Ensure save directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Define file paths\n",
    "    HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
    "    HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
    "    HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
    "\n",
    "    # Load the objects\n",
    "    HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
    "    HG_base = mne.read_epochs(HG_base_file)\n",
    "    HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
    "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
    "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
    "\n",
    "    return {\n",
    "        'HG_ev1': HG_ev1,\n",
    "        'HG_base': HG_base,\n",
    "        'HG_ev1_rescaled': HG_ev1_rescaled,\n",
    "        'HG_ev1_evoke': HG_ev1_evoke,\n",
    "        'HG_ev1_evoke_rescaled': HG_ev1_evoke_rescaled\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# sub = 'D0057'\n",
    "# output_name = \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"\n",
    "# task = 'GlobalLocal'\n",
    "loaded_objects_D0057_i = load_mne_objects('D0057', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0057_c = load_mne_objects('D0057', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "loaded_objects_D0059_i = load_mne_objects('D0059', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0059_c = load_mne_objects('D0059', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "loaded_objects_D0063_i = load_mne_objects('D0063', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0063_c = load_mne_objects('D0063', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "loaded_objects_D0065_i = load_mne_objects('D0065', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0065_c = load_mne_objects('D0065', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "loaded_objects_D0069_i = load_mne_objects('D0069', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0069_c = load_mne_objects('D0069', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "loaded_objects_D0071_i = load_mne_objects('D0071', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0071_c = load_mne_objects('D0071', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "\n",
    "# Access the objects\n",
    "HG_ev1_D0057_i = loaded_objects_D0057_i['HG_ev1']\n",
    "HG_base_D0057_i = loaded_objects_D0057_i['HG_base']\n",
    "HG_ev1_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "HG_ev1_D0057_c = loaded_objects_D0057_c['HG_ev1']\n",
    "HG_base_D0057_c = loaded_objects_D0057_c['HG_base']\n",
    "HG_ev1_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0059_i = loaded_objects_D0059_i['HG_ev1']\n",
    "# HG_base_D0059_i = loaded_objects_D0059_i['HG_base']\n",
    "# HG_ev1_rescaled_D0059_i = loaded_objects_D0059_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0059_i = loaded_objects_D0059_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0059_i = loaded_objects_D0059_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0059_c = loaded_objects_D0059_c['HG_ev1']\n",
    "# HG_base_D0059_c = loaded_objects_D0059_c['HG_base']\n",
    "# HG_ev1_rescaled_D0059_c = loaded_objects_D0059_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0059_c = loaded_objects_D0059_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0059_c = loaded_objects_D0059_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0063_i = loaded_objects_D0063_i['HG_ev1']\n",
    "# HG_base_D0063_i = loaded_objects_D0063_i['HG_base']\n",
    "# HG_ev1_rescaled_D0063_i = loaded_objects_D0063_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0063_i = loaded_objects_D0063_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0063_i = loaded_objects_D0063_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0063_c = loaded_objects_D0063_c['HG_ev1']\n",
    "# HG_base_D0063_c = loaded_objects_D0063_c['HG_base']\n",
    "# HG_ev1_rescaled_D0063_c = loaded_objects_D0063_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0063_c = loaded_objects_D0063_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0063_c = loaded_objects_D0063_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0065_i = loaded_objects_D0065_i['HG_ev1']\n",
    "# HG_base_D0065_i = loaded_objects_D0065_i['HG_base']\n",
    "# HG_ev1_rescaled_D0065_i = loaded_objects_D0065_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0065_i = loaded_objects_D0065_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0065_i = loaded_objects_D0065_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0065_c = loaded_objects_D0065_c['HG_ev1']\n",
    "# HG_base_D0065_c = loaded_objects_D0065_c['HG_base']\n",
    "# HG_ev1_rescaled_D0065_c = loaded_objects_D0065_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0065_c = loaded_objects_D0065_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0065_c = loaded_objects_D0065_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0069_i = loaded_objects_D0069_i['HG_ev1']\n",
    "# HG_base_D0069_i = loaded_objects_D0069_i['HG_base']\n",
    "# HG_ev1_rescaled_D0069_i = loaded_objects_D0069_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0069_i = loaded_objects_D0069_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0069_i = loaded_objects_D0069_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0069_c = loaded_objects_D0069_c['HG_ev1']\n",
    "# HG_base_D0069_c = loaded_objects_D0069_c['HG_base']\n",
    "# HG_ev1_rescaled_D0069_c = loaded_objects_D0069_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0069_c = loaded_objects_D0069_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0069_c = loaded_objects_D0069_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0071_i = loaded_objects_D0071_i['HG_ev1']\n",
    "# HG_base_D0071_i = loaded_objects_D0071_i['HG_base']\n",
    "# HG_ev1_rescaled_D0071_i = loaded_objects_D0071_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0071_i = loaded_objects_D0071_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0071_i = loaded_objects_D0071_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0071_c = loaded_objects_D0071_c['HG_ev1']\n",
    "# HG_base_D0071_c = loaded_objects_D0071_c['HG_base']\n",
    "# HG_ev1_rescaled_D0071_c = loaded_objects_D0071_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0071_c = loaded_objects_D0071_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0071_c = loaded_objects_D0071_c['HG_ev1_evoke_rescaled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load evoked and stuff for all subjects in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data for subject: D0057\n",
      "  Loading output: Stimulus_i25and75_fixationCrossBase_1sec_mirror\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\roi_analysis.ipynb Cell 10\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m output_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mStimulus_i25and75_fixationCrossBase_1sec_mirror\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mStimulus_c25and75_fixationCrossBase_1sec_mirror\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m task \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mGlobalLocal\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m subjects_mne_objects \u001b[39m=\u001b[39m create_subjects_mne_objects_dict(subjects, output_names, task)\n",
      "\u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\roi_analysis.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mfor\u001b[39;00m output_name \u001b[39min\u001b[39;00m output_names:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m  Loading output: \u001b[39m\u001b[39m{\u001b[39;00moutput_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)  \u001b[39m# Debugging print\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     mne_objects \u001b[39m=\u001b[39m load_mne_objects(sub, output_name, task, LAB_root)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39m# Debugging prints for data shapes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m    HG_ev1 shape: \u001b[39m\u001b[39m{\u001b[39;00mmne_objects[\u001b[39m'\u001b[39m\u001b[39mHG_ev1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget_data()\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\roi_analysis.ipynb Cell 10\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     LAB_root \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(HOME, \u001b[39m\"\u001b[39m\u001b[39mBox\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCoganLab\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnt\u001b[39m\u001b[39m'\u001b[39m \u001b[39melse\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(HOME, \u001b[39m\"\u001b[39m\u001b[39mLibrary\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCloudStorage\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBox-Box\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCoganLab\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# Get data layout\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m layout \u001b[39m=\u001b[39m get_data(task, root\u001b[39m=\u001b[39;49mLAB_root)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m save_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(layout\u001b[39m.\u001b[39mroot, \u001b[39m'\u001b[39m\u001b[39mderivatives\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfreqFilt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfigs\u001b[39m\u001b[39m'\u001b[39m, sub)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X12sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Ensure save directory exists\u001b[39;00m\n",
      "File \u001b[1;32m~\\Desktop\\GlobalLocal\\IEEG_Pipelines\\ieeg\\io.py:190\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(task, root)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m BIDS_root \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    188\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCould not find BIDS directory in \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m for task \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m                             \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(root, task))\n\u001b[1;32m--> 190\u001b[0m layout \u001b[39m=\u001b[39m BIDSLayout(BIDS_root, derivatives\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    191\u001b[0m \u001b[39mreturn\u001b[39;00m layout\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\bids\\layout\\layout.py:182\u001b[0m, in \u001b[0;36mBIDSLayout.__init__\u001b[1;34m(self, root, validate, absolute_paths, derivatives, config, sources, regex_search, database_path, reset_database, indexer, is_derivative, **indexer_kwargs)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[39mif\u001b[39;00m derivatives \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    181\u001b[0m     derivatives \u001b[39m=\u001b[39m root \u001b[39m/\u001b[39m \u001b[39m'\u001b[39m\u001b[39mderivatives\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 182\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_derivatives(\n\u001b[0;32m    183\u001b[0m     derivatives, parent_database_path\u001b[39m=\u001b[39;49mdatabase_path,\n\u001b[0;32m    184\u001b[0m     validate\u001b[39m=\u001b[39;49mvalidate, absolute_paths\u001b[39m=\u001b[39;49mabsolute_paths,\n\u001b[0;32m    185\u001b[0m     derivatives\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, sources\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, config\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    186\u001b[0m     regex_search\u001b[39m=\u001b[39;49mregex_search, reset_database\u001b[39m=\u001b[39;49mreset_database,\n\u001b[0;32m    187\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mindexer_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\bids\\layout\\layout.py:537\u001b[0m, in \u001b[0;36mBIDSLayout.add_derivatives\u001b[1;34m(self, path, parent_database_path, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mderivatives:\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m BIDSDerivativesValidationError(\n\u001b[0;32m    534\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPipeline name \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m!s}\u001b[39;00m\u001b[39m) has already been added to this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mBIDSLayout. Every added pipeline must have a unique name!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    536\u001b[0m     )\n\u001b[1;32m--> 537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mderivatives[name] \u001b[39m=\u001b[39m BIDSLayout(path, is_derivative\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\bids\\layout\\layout.py:176\u001b[0m, in \u001b[0;36mBIDSLayout.__init__\u001b[1;34m(self, root, validate, absolute_paths, derivatives, config, sources, regex_search, database_path, reset_database, indexer, is_derivative, **indexer_kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[39mif\u001b[39;00m indexer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m         indexer \u001b[39m=\u001b[39m BIDSLayoutIndexer(\n\u001b[0;32m    174\u001b[0m             validate\u001b[39m=\u001b[39mvalidate \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_derivative, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mindexer_kwargs\n\u001b[0;32m    175\u001b[0m         )\n\u001b[1;32m--> 176\u001b[0m     indexer(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    178\u001b[0m \u001b[39m# Add derivatives if any are found\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \u001b[39mif\u001b[39;00m derivatives:\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\bids\\layout\\index.py:150\u001b[0m, in \u001b[0;36mBIDSLayoutIndexer.__call__\u001b[1;34m(self, layout)\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_layout\u001b[39m.\u001b[39m_root, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config)\n\u001b[0;32m    149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex_metadata:\n\u001b[1;32m--> 150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index_metadata()\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\bids\\layout\\index.py:393\u001b[0m, in \u001b[0;36mBIDSLayoutIndexer._index_metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[39m# Missing data files can tolerate absent metadata files,\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[39m# but we will try to load it anyway\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m virtual_datafile \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m bf\u001b[39m.\u001b[39;49m_path\u001b[39m.\u001b[39;49mexists()\n\u001b[0;32m    395\u001b[0m \u001b[39m# Create DB records for metadata associations\u001b[39;00m\n\u001b[0;32m    396\u001b[0m js_file \u001b[39m=\u001b[39m payloads[\u001b[39m0\u001b[39m][\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\pathlib.py:1235\u001b[0m, in \u001b[0;36mPath.exists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1231\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1232\u001b[0m \u001b[39mWhether this path exists.\u001b[39;00m\n\u001b[0;32m   1233\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1234\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstat()\n\u001b[0;32m   1236\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _ignore_error(e):\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\pathlib.py:1013\u001b[0m, in \u001b[0;36mPath.stat\u001b[1;34m(self, follow_symlinks)\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstat\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m, follow_symlinks\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1009\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[39m    Return the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[39m    os.stat() does.\u001b[39;00m\n\u001b[0;32m   1012\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1013\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39mstat(\u001b[39mself\u001b[39m, follow_symlinks\u001b[39m=\u001b[39mfollow_symlinks)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "def create_subjects_mne_objects_dict(subjects, output_names, task, LAB_root=None):\n",
    "    subjects_mne_objects = {}\n",
    "\n",
    "    for sub in subjects:\n",
    "        print(f\"Loading data for subject: {sub}\")  # Debugging print\n",
    "        sub_mne_objects = {}\n",
    "        for output_name in output_names:\n",
    "            print(f\"  Loading output: {output_name}\")  # Debugging print\n",
    "            mne_objects = load_mne_objects(sub, output_name, task, LAB_root)\n",
    "\n",
    "            # Debugging prints for data shapes\n",
    "            print(f\"    HG_ev1 shape: {mne_objects['HG_ev1'].get_data().shape}\")\n",
    "            print(f\"    HG_base shape: {mne_objects['HG_base'].get_data().shape}\")\n",
    "            print(f\"    HG_ev1_rescaled shape: {mne_objects['HG_ev1_rescaled'].get_data().shape}\")\n",
    "            print(f\"    HG_ev1_evoke shape: {mne_objects['HG_ev1_evoke'].data.shape}\")\n",
    "            print(f\"    HG_ev1_evoke_rescaled shape: {mne_objects['HG_ev1_evoke_rescaled'].data.shape}\")\n",
    "\n",
    "            sub_mne_objects[output_name] = mne_objects\n",
    "        subjects_mne_objects[sub] = sub_mne_objects\n",
    "\n",
    "    return subjects_mne_objects\n",
    "\n",
    "# Example usage\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
    "output_names = [\"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\"]\n",
    "task = 'GlobalLocal'\n",
    "\n",
    "subjects_mne_objects = create_subjects_mne_objects_dict(subjects, output_names, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded significant channels for subject D0057\n",
      "Loaded significant channels for subject D0059\n",
      "Loaded significant channels for subject D0063\n",
      "Loaded significant channels for subject D0065\n",
      "Loaded significant channels for subject D0069\n",
      "Loaded significant channels for subject D0071\n"
     ]
    }
   ],
   "source": [
    "def get_sig_chans(sub, task, LAB_root=None):\n",
    "    # Determine LAB_root based on the operating system\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "\n",
    "    stim_filename = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
    "    stim_sig_chans = load_sig_chans(stim_filename)\n",
    "    return stim_sig_chans\n",
    "\n",
    "\n",
    "# List of subjects\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
    "\n",
    "# Initialize an empty dictionary to store significant channels per subject\n",
    "sig_chans_per_subject = {}\n",
    "\n",
    "# Populate the dictionary using get_sig_chans for each subject\n",
    "for sub in subjects:\n",
    "    sig_chans_per_subject[sub] = get_sig_chans(sub, 'GlobalLocal')\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlpfc_electrodes_per_subject = {}\n",
    "\n",
    "for sub in subjects_electrodestoROIs_dict:\n",
    "    dlpfc = {key: value for key, value in subjects_electrodestoROIs_dict[sub]['filtROI_dict'].items() \n",
    "             if any(roi in key for roi in [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"])}\n",
    "\n",
    "    # Aggregate electrodes into a list for each subject\n",
    "    dlpfc_electrodes = []\n",
    "    for electrodes in dlpfc.values():\n",
    "        dlpfc_electrodes.extend(electrodes)\n",
    "\n",
    "    dlpfc_electrodes_per_subject[sub] = dlpfc_electrodes\n",
    "    print(f'For subject {sub}, dlpfc electrodes are: {dlpfc_electrodes}')\n",
    "\n",
    "# dlpfc_electrodes_per_subject now contains the list of electrodes for each subject\n",
    "\n",
    "# Assuming sig_chans_per_subject is a dictionary with subjects as keys and lists of significant channels as values\n",
    "\n",
    "sig_dlpfc_electrodes_per_subject = {}\n",
    "\n",
    "for sub, dlpfc_electrodes in dlpfc_electrodes_per_subject.items():\n",
    "    # Retrieve the list of significant channels for the subject\n",
    "    sig_chans = sig_chans_per_subject.get(sub, [])\n",
    "\n",
    "    # Find the intersection of DLPFC electrodes and significant channels for the subject\n",
    "    sig_dlpfc_electrodes = [elec for elec in dlpfc_electrodes if elec in sig_chans]\n",
    "\n",
    "    # Store the significant DLPFC electrodes for the subject\n",
    "    sig_dlpfc_electrodes_per_subject[sub] = sig_dlpfc_electrodes\n",
    "\n",
    "    # Print results for each subject\n",
    "    print(f\"Subject {sub} significant DLPFC electrodes: {sig_dlpfc_electrodes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlpfc_electrodes_per_subject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make plot of only specific channels, averaged together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is across subjects which is wrong. Delete later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# def compute_average_and_sem(evoked_rescaled_data, selected_channels):\n",
    "#     \"\"\"\n",
    "#     Compute the average and standard error of the mean for selected channels in an Evoked object.\n",
    "\n",
    "#     Parameters:\n",
    "#     - evoked_rescaled_data (mne.Evoked): The Evoked object containing the data.\n",
    "#     - selected_channels (list of str): A list of channel names to include in the computation.\n",
    "\n",
    "#     Returns:\n",
    "#     - average_data (numpy.ndarray): The average data across the selected channels.\n",
    "#     - sem_data (numpy.ndarray): The standard error of the mean for the selected channels.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Find the indices of these channels in the Evoked object\n",
    "#     channel_indices = [evoked_rescaled_data.ch_names.index(ch) for ch in selected_channels if ch in evoked_rescaled_data.ch_names]\n",
    "\n",
    "#     # Check if all channels were found\n",
    "#     if len(channel_indices) != len(selected_channels):\n",
    "#         missing_ch = set(selected_channels) - set(evoked_rescaled_data.ch_names)\n",
    "#         raise ValueError(f\"Some channels not found in Evoked object: {missing_ch}\")\n",
    "\n",
    "#     # Extract data for these channels\n",
    "#     selected_data = evoked_rescaled_data.data[channel_indices, :]\n",
    "\n",
    "#     # Compute the average and standard error\n",
    "#     average_data = selected_data.mean(axis=0)\n",
    "#     sem_data = selected_data.std(axis=0) / np.sqrt(len(channel_indices))\n",
    "\n",
    "#     return average_data, sem_data\n",
    "\n",
    "# # Example usage\n",
    "# average_mPFC_D0057_i, sem_mPFC_D0057_i = compute_average_and_sem(HG_ev1_evoke_rescaled_D0057_i, ['RPI14', 'RAMF10', 'RAMF11', 'RAMF12'])\n",
    "# average_mPFC_D0057_c, sem_mPFC_D0057_c = compute_average_and_sem(HG_ev1_evoke_rescaled_D0057_c, ['RPI14', 'RAMF10', 'RAMF11', 'RAMF12'])\n",
    "# def compute_average_and_sem_subject(subjects_mne_objects, sub, output_name, sig_roi_electrodes_per_subject):\n",
    "#     \"\"\"\n",
    "#     Compute the average and standard error of the mean for a subject's significant roi electrodes.\n",
    "\n",
    "#     Parameters:\n",
    "#     - subjects_mne_objects (dict): Dictionary containing MNE objects for each subject.\n",
    "#     - sub (str): Subject ID.\n",
    "#     - output_name (str): Output name corresponding to the specific analysis.\n",
    "#     - sig_roi_electrodes_per_subject (dict): Dictionary containing significant roi electrodes for each subject.\n",
    "\n",
    "#     Returns:\n",
    "#     - average_data (numpy.ndarray): The average data across the significant roi electrodes for the subject.\n",
    "#     - sem_data (numpy.ndarray): The standard error of the mean for the significant roi electrodes for the subject.\n",
    "#     \"\"\"\n",
    "#     selected_channels = sig_roi_electrodes_per_subject.get(sub, [])\n",
    "#     sub_objects = subjects_mne_objects.get(sub, {})\n",
    "#     evoked_rescaled_data = sub_objects.get(output_name, {}).get('HG_ev1_evoke_rescaled')\n",
    "\n",
    "#     if not evoked_rescaled_data or not selected_channels:\n",
    "#         return None, None\n",
    "\n",
    "#     return compute_average_and_sem(evoked_rescaled_data, selected_channels)\n",
    "\n",
    "# def compute_overall_average_and_sem(average_sem_data):\n",
    "#     \"\"\"\n",
    "#     Compute the overall average and standard error of the mean across subjects.\n",
    "\n",
    "#     Parameters:\n",
    "#     - average_sem_data (list of tuples): List of tuples containing average and SEM data for each subject.\n",
    "\n",
    "#     Returns:\n",
    "#     - overall_average (numpy.ndarray): The overall average data across subjects.\n",
    "#     - overall_sem (numpy.ndarray): The overall standard error of the mean across subjects.\n",
    "#     \"\"\"\n",
    "#     all_averages = np.array([avg for avg, sem in average_sem_data if avg is not None])\n",
    "#     overall_average = all_averages.mean(axis=0)\n",
    "\n",
    "#     # Compute overall SEM using pooled standard deviation\n",
    "#     all_sems = np.array([sem for avg, sem in average_sem_data if sem is not None])\n",
    "#     overall_sem = np.sqrt(np.sum(all_sems**2, axis=0)) / len(all_sems)\n",
    "\n",
    "#     return overall_average, overall_sem\n",
    "\n",
    "# # Compute averages and SEMs for each subject and condition\n",
    "# average_sem_dlPFC_data_congruent = []\n",
    "# average_sem_dlPFC_data_incongruent = []\n",
    "\n",
    "# for sub in dlpfc_electrodes_per_subject.keys():\n",
    "#     for output_name in output_names:\n",
    "#         avg, sem = compute_average_and_sem_subject(subjects_mne_objects, sub, output_name, dlpfc_electrodes_per_subject)\n",
    "#         if avg is not None and sem is not None:\n",
    "#             if \"_c\" in output_name:  # Replace with actual identifier\n",
    "#                 average_sem_dlPFC_data_congruent.append((avg, sem))\n",
    "#             elif \"_i\" in output_name:  # Replace with actual identifier\n",
    "#                 average_sem_dlPFC_data_incongruent.append((avg, sem))\n",
    "\n",
    "# # Compute the separate averages and SEMs for congruent and incongruent conditions\n",
    "# overall_average_dlPFC_congruent, overall_sem_dlPFC_congruent = compute_overall_average_and_sem(average_sem_dlPFC_data_congruent)\n",
    "# overall_average_dlPFC_incongruent, overall_sem_dlPFC_incongruent = compute_overall_average_and_sem(average_sem_dlPFC_data_incongruent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do stats\n",
    "\n",
    "current approach is to run time_perm_cluster on significant dlpfc electrodes for each subject, comparing congruent and incongruent conditions. Then, average p-values across all subjects. Discuss this with Greg, probably wrong approach.\n",
    "\n",
    "**1/23 new approach is to average across all trials for sig dlpfc electrodes, comparing incongruent and congruent conditions. Then, run stats on this new avg electrode value x time array.\n",
    "\n",
    "Also, I'm using HG_ev1_rescaled instead of HG_ev1 to compare congruent and incongruent, so that they're normalized with a common baseline. I think this is better than comparing the raw HG traces directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is avg across electrode, don't do that. Avg across timepoints instead. Delete this once the other method works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is 1/23 new approach of avg across trials first\n",
    "\n",
    "do stats and plotting together. Stats needs trial avg data, plotting just needs congruent_data without trial averaging (initially at least)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "(224, 27, 5121)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_10912\\974801574.py:1: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  congruent_epochs = subjects_mne_objects['D0063']['Stimulus_c25and75_fixationCrossBase_1sec_mirror']['HG_ev1_rescaled'].pick_channels(dlpfc_electrodes_per_subject['D0063'])\n"
     ]
    }
   ],
   "source": [
    "congruent_epochs = subjects_mne_objects['D0063']['Stimulus_c25and75_fixationCrossBase_1sec_mirror']['HG_ev1_rescaled'].pick_channels(dlpfc_electrodes_per_subject['D0063'])\n",
    "print(congruent_epochs.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_10912\\3644521502.py:13: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  congruent_epochs = subjects_mne_objects[sub]['Stimulus_c25and75_fixationCrossBase_1sec_mirror']['HG_ev1_rescaled'].pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n",
      "C:\\Users\\jz421\\AppData\\Local\\Temp\\ipykernel_10912\\3644521502.py:14: FutureWarning: The default for pick_channels will change from ordered=False to ordered=True in 1.5 and this will result in a change of behavior because the resulting channel order will not match. Either use a channel order that matches your instance or pass ordered=False.\n",
      "  incongruent_epochs = subjects_mne_objects[sub]['Stimulus_i25and75_fixationCrossBase_1sec_mirror']['HG_ev1_rescaled'].pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store data\n",
    "congruent_data_trialAvg_list = []\n",
    "incongruent_data_trialAvg_list = []\n",
    "\n",
    "for sub in subjects:\n",
    "    # Skip this subject if no dlpfc electrodes\n",
    "    if not sig_dlpfc_electrodes_per_subject[sub]:\n",
    "        continue\n",
    "\n",
    "    # Load trial-level data for each condition and pick significant DLPFC electrodes\n",
    "    congruent_epochs = subjects_mne_objects[sub]['Stimulus_c25and75_fixationCrossBase_1sec_mirror']['HG_ev1_rescaled'].pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n",
    "    incongruent_epochs = subjects_mne_objects[sub]['Stimulus_i25and75_fixationCrossBase_1sec_mirror']['HG_ev1_rescaled'].pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n",
    "\n",
    "    # Average across the trials dimension, ignoring NaNs\n",
    "    congruent_data_trialAvg_list.append(np.nanmean(congruent_epochs.get_data(), axis=0))\n",
    "    incongruent_data_trialAvg_list.append(np.nanmean(incongruent_epochs.get_data(), axis=0))\n",
    "\n",
    "# Concatenate data across all subjects\n",
    "congruent_data_trialAvg = np.concatenate(congruent_data_trialAvg_list, axis=0)\n",
    "incongruent_data_trialAvg = np.concatenate(incongruent_data_trialAvg_list, axis=0)\n",
    "\n",
    "# Calculate mean and SEM across electrodes\n",
    "overall_average_dlPFC_congruent = np.nanmean(congruent_data_trialAvg, axis=0)\n",
    "overall_sem_dlPFC_congruent = np.std(congruent_data_trialAvg, axis=0, ddof=1) / np.sqrt(congruent_data_trialAvg.shape[0])\n",
    "overall_average_dlPFC_incongruent = np.nanmean(incongruent_data_trialAvg, axis=0)\n",
    "overall_sem_dlPFC_incongruent = np.std(incongruent_data_trialAvg, axis=0, ddof=1) / np.sqrt(incongruent_data_trialAvg.shape[0])\n",
    "\n",
    "# Run the permutation test\n",
    "mat = time_perm_cluster(congruent_data_trialAvg, incongruent_data_trialAvg, 0.05, n_jobs=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot and QC stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if no significant differences.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\roi_analysis.ipynb Cell 27\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X63sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mSignificance (0 or 1)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X63sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mPermutation Test Significance Over Time\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X63sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m plt\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3620\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3618\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m ipython_pylab \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3619\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m-> 3620\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:604\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    602\u001b[0m qapp \u001b[39m=\u001b[39m QtWidgets\u001b[39m.\u001b[39mQApplication\u001b[39m.\u001b[39minstance()\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m qapp:\n\u001b[1;32m--> 604\u001b[0m     \u001b[39mwith\u001b[39;49;00m _maybe_allow_interrupt(qapp):\n\u001b[0;32m    605\u001b[0m         qt_compat\u001b[39m.\u001b[39;49m_exec(qapp)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:245\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    243\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m handler_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     old_sigint_handler(\u001b[39m*\u001b[39;49mhandler_args)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mat)\n",
    "plt.xlabel('Timepoints')\n",
    "plt.ylabel('Significance (0 or 1)')\n",
    "plt.title('Permutation Test Significance Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try a basic t-test as a sanity check (ok its also not significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\roi_analysis.ipynb Cell 29\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#Y106sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mStatistical Significance Over Time\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#Y106sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#Y106sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m plt\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3620\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3618\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m ipython_pylab \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3619\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m-> 3620\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:604\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    602\u001b[0m qapp \u001b[39m=\u001b[39m QtWidgets\u001b[39m.\u001b[39mQApplication\u001b[39m.\u001b[39minstance()\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m qapp:\n\u001b[1;32m--> 604\u001b[0m     \u001b[39mwith\u001b[39;49;00m _maybe_allow_interrupt(qapp):\n\u001b[0;32m    605\u001b[0m         qt_compat\u001b[39m.\u001b[39;49m_exec(qapp)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:245\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    243\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m handler_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     old_sigint_handler(\u001b[39m*\u001b[39;49mhandler_args)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "p_values = np.array([ttest_ind(congruent_data[:, tp], incongruent_data[:, tp]).pvalue for tp in range(congruent_data.shape[1])])\n",
    "significance = p_values < 0.05  # Apply a significance threshold, e.g., p < 0.05\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(congruent_data.shape[1]), significance, label='Significance (p < 0.05)')\n",
    "plt.xlabel('Time Point')\n",
    "plt.ylabel('Significance (True/False)')\n",
    "plt.title('Statistical Significance Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now aggregate the significance test results for each subject across subjects. Talk to greg about how to do this...vote count is probably wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming subject_results is a dictionary with keys as subject IDs and values as binary arrays indicating significant time points\n",
    "num_subjects = len(subject_results)\n",
    "num_time_points = len(subject_results[next(iter(subject_results))])  # Assuming all arrays are the same length\n",
    "\n",
    "# Initialize an array to count votes\n",
    "vote_counts = np.zeros(num_time_points)\n",
    "\n",
    "# Count votes\n",
    "for sub in subject_results:\n",
    "    vote_counts += subject_results[sub]\n",
    "\n",
    "# Determine significance based on a threshold (e.g., at least 50% of subjects show significance)\n",
    "threshold = 0.5 * num_subjects  # 50% of subjects\n",
    "significant_time_points = vote_counts >= threshold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot example with mpfc, can delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Use the times from your evoked data\n",
    "times = HG_ev1_evoke_rescaled_D0057_i.times  # Modify as needed to match your data\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot average_mPFC_D0057_i with SEM shading\n",
    "plt.plot(times, average_mPFC_D0057_i, label='Average mPFC Incongruent')\n",
    "plt.fill_between(times, average_mPFC_D0057_i - sem_mPFC_D0057_i, average_mPFC_D0057_i + sem_mPFC_D0057_i, alpha=0.3)\n",
    "\n",
    "# Plot average_mPFC_D0057_c with SEM shading\n",
    "plt.plot(times, average_mPFC_D0057_c, label='Average mPFC Congruent')\n",
    "plt.fill_between(times, average_mPFC_D0057_c - sem_mPFC_D0057_c, average_mPFC_D0057_c + sem_mPFC_D0057_c, alpha=0.3)\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average mPFC Signal with Standard Error for D0057')\n",
    "plt.legend()\n",
    "plt.savefig(save_dir + f'_mPFC_congruency_zscore_D0057.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot dlpfc inc vs. con, avg across all subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jz421\\Desktop\\GlobalLocal\\roi_analysis.ipynb Cell 35\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X26sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X26sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m plt\u001b[39m.\u001b[39msavefig(save_path)  \u001b[39m# Modify save_dir as necessary\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jz421/Desktop/GlobalLocal/roi_analysis.ipynb#X26sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m plt\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    403\u001b[0m \u001b[39mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    404\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mexplicitly there.\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 446\u001b[0m \u001b[39mreturn\u001b[39;00m _get_backend_mod()\u001b[39m.\u001b[39;49mshow(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backend_bases.py:3620\u001b[0m, in \u001b[0;36m_Backend.show\u001b[1;34m(cls, block)\u001b[0m\n\u001b[0;32m   3618\u001b[0m     block \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m ipython_pylab \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_interactive()\n\u001b[0;32m   3619\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m-> 3620\u001b[0m     \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mmainloop()\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\backend_qt.py:604\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m    602\u001b[0m qapp \u001b[39m=\u001b[39m QtWidgets\u001b[39m.\u001b[39mQApplication\u001b[39m.\u001b[39minstance()\n\u001b[0;32m    603\u001b[0m \u001b[39mif\u001b[39;00m qapp:\n\u001b[1;32m--> 604\u001b[0m     \u001b[39mwith\u001b[39;49;00m _maybe_allow_interrupt(qapp):\n\u001b[0;32m    605\u001b[0m         qt_compat\u001b[39m.\u001b[39;49m_exec(qapp)\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\contextlib.py:144\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         \u001b[39mnext\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgen)\n\u001b[0;32m    145\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\matplotlib\\backends\\qt_compat.py:245\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    243\u001b[0m signal\u001b[39m.\u001b[39msignal(signal\u001b[39m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[0;32m    244\u001b[0m \u001b[39mif\u001b[39;00m handler_args \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 245\u001b[0m     old_sigint_handler(\u001b[39m*\u001b[39;49mhandler_args)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlPFC_congruency_zscore.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063']['Stimulus_c25and75_fixationCrossBase_1sec_mirror']['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0063_c.times  # Modify as needed to match your data\n",
    "\n",
    "# Plot overall_average_dlPFC_congruent with SEM shading\n",
    "plt.plot(times, overall_average_dlPFC_congruent, label='Average dlPFC Congruent')\n",
    "plt.fill_between(times, overall_average_dlPFC_congruent - overall_sem_dlPFC_congruent, \n",
    "                 overall_average_dlPFC_congruent + overall_sem_dlPFC_congruent, alpha=0.3)\n",
    "\n",
    "# Plot overall_average_dlPFC_incongruent with SEM shading\n",
    "plt.plot(times, overall_average_dlPFC_incongruent, label='Average dlPFC Incongruent')\n",
    "plt.fill_between(times, overall_average_dlPFC_incongruent - overall_sem_dlPFC_incongruent, \n",
    "                 overall_average_dlPFC_incongruent + overall_sem_dlPFC_incongruent, alpha=0.3)\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlPFC Signal with Standard Error (Congruent vs Incongruent)')\n",
    "plt.legend()\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbco