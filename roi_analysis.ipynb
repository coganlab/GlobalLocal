{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal', 'C:\\\\Users\\\\jz421\\\\Desktop\\\\GlobalLocal\\\\IEEG_Pipelines', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\python311.zip', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\DLLs', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg', '', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\win32\\\\lib', 'C:\\\\Users\\\\jz421\\\\AppData\\\\Roaming\\\\Python\\\\Python311\\\\site-packages\\\\Pythonwin', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\win32\\\\lib', 'c:\\\\Users\\\\jz421\\\\AppData\\\\Local\\\\anaconda3\\\\envs\\\\ieeg\\\\Lib\\\\site-packages\\\\Pythonwin']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jz421\\AppData\\Local\\anaconda3\\envs\\ieeg\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster, window_averaged_shuffle\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans, channel_names_to_indices, filter_and_average_epochs, \\\n",
    "      permutation_test, perform_permutation_test_across_electrodes, perform_permutation_test_within_electrodes, add_accuracy_to_epochs, load_mne_objects, \\\n",
    "      create_subjects_mne_objects_dict, extract_significant_effects, convert_dataframe_to_serializable_format, perform_modular_anova, make_plotting_parameters, \\\n",
    "      plot_significance\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "# still need to test if the permutation test functions load in properly.\n",
    "import pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MOVE ALL FUNCTIONS TO THE TOP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the outer dictionary.\n",
    "subjects_electrodestoROIs_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make subjects rois to electrodes dict. Don't need to run this more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "# subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0071', 'D0077', 'D0090', 'D0100', 'D0102', 'D0103']\n",
    "# subjects = ['D0103'] #testing cuz d0065 being weird\n",
    "\n",
    "for sub in subjects:\n",
    "    # sub = 'D0059'\n",
    "    task = 'GlobalLocal'\n",
    "    output_name = \"Response_fixationCrossBase_1sec_mirror\"\n",
    "    events = [\"Response\"]\n",
    "    times = (-1,1.5)\n",
    "    base_times = [-1,0]\n",
    "    LAB_root = None\n",
    "    channels = None\n",
    "    full_trial_base = False\n",
    "\n",
    "\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        if os.name == 'nt':  # windows\n",
    "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "        else:  # mac\n",
    "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                    \"CoganLab\")\n",
    "\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
    "                        extension='.edf', desc='clean', preload=False)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    good = crop_empty_data(filt)\n",
    "    # %%\n",
    "\n",
    "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
    "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
    "\n",
    "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
    "    good.drop_channels(good.info['bads'])\n",
    "\n",
    "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
    "\n",
    "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.load_data()\n",
    "\n",
    "    # If channels is None, use all channels\n",
    "    if channels is None:\n",
    "        channels = good.ch_names\n",
    "    else:\n",
    "        # Validate the provided channels\n",
    "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
    "        if invalid_channels:\n",
    "            raise ValueError(\n",
    "                f\"The following channels are not valid: {invalid_channels}\")\n",
    "\n",
    "        # Use only the specified channels\n",
    "        good.pick_channels(channels)\n",
    "\n",
    "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
    "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
    "\n",
    "    default_dict = gen_labels(good.info)\n",
    "    \n",
    "    # Create rawROI_dict for the subject\n",
    "    rawROI_dict = defaultdict(list)\n",
    "    for key, value in default_dict.items():\n",
    "        rawROI_dict[value].append(key)\n",
    "    rawROI_dict = dict(rawROI_dict)\n",
    "\n",
    "    # Filter out keys containing \"White-Matter\"\n",
    "    filtROI_dict = {key: value for key, value in rawROI_dict.items() if \"White-Matter\" not in key}\n",
    "\n",
    "    # Store the dictionaries in the subjects dictionary\n",
    "    subjects_electrodestoROIs_dict[sub] = {\n",
    "        'default_dict': dict(default_dict),\n",
    "        'rawROI_dict': dict(rawROI_dict),\n",
    "        'filtROI_dict': dict(filtROI_dict)\n",
    "    }\n",
    "\n",
    "\n",
    "# # Save to a JSON file. Uncomment when actually running.\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(subjects_electrodestoROIs_dict, file, indent=4)\n",
    "\n",
    "print(f\"Saved subjects_dict to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load subjects electrodes to rois dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from a JSON file\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    subjects_electrodestoROIs_dict = json.load(file)\n",
    "\n",
    "print(f\"Loaded data from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load high gamma data so we can do roi analysis on it\n",
    "once we have more subjects, turn this into a function and loop over all subjects.  \n",
    "this code is a crime against humanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# sub = 'D0057'\n",
    "# output_name = \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"\n",
    "# task = 'GlobalLocal'\n",
    "loaded_objects_D0057_i = load_mne_objects('D0057', \"Stimulus_c25_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0057_c = load_mne_objects('D0057', \"Stimulus_c75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "# Access the objects\n",
    "HG_ev1_D0057_i = loaded_objects_D0057_i['HG_ev1']\n",
    "HG_base_D0057_i = loaded_objects_D0057_i['HG_base']\n",
    "HG_ev1_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "HG_ev1_D0057_c = loaded_objects_D0057_c['HG_ev1']\n",
    "HG_base_D0057_c = loaded_objects_D0057_c['HG_base']\n",
    "HG_ev1_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke_rescaled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load accuracy arrays so we can filter by only accurate trials  \n",
    "combine this code into add_accuracy_to_epochs later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where your .npy files are saved\n",
    "npy_directory = r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\accArrays'  # Replace with your directory path\n",
    "\n",
    "# Dictionary to hold the data\n",
    "acc_array = {}\n",
    "\n",
    "# Iterate over each file in the directory\n",
    "for file in os.listdir(npy_directory):\n",
    "    if file.endswith('.npy'):\n",
    "        subject_id = file.split('_')[0]  # Extract subject ID from the file name\n",
    "        if subject_id != 'D0107':  # Check if the subject ID is not D0107. Skip D0107 for now because it's not preprocessed yet.\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(npy_directory, file)\n",
    "            # Load the numpy array from the file\n",
    "            acc_array[subject_id] = np.load(file_path)\n",
    "\n",
    "# Now you have a dictionary where each key is the subject ID\n",
    "# and the value is the numpy array of accuracies for that subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.read_csv(r'C:\\Users\\jz421\\Box\\CoganLab\\D_Data\\GlobalLocal\\combinedData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to map blockType to congruencyProportion and switchProportion\n",
    "def map_block_type(row):\n",
    "    if row['blockType'] == 'A':\n",
    "        return pd.Series(['25%', '25%'])\n",
    "    elif row['blockType'] == 'B':\n",
    "        return pd.Series(['25%', '75%'])\n",
    "    elif row['blockType'] == 'C':\n",
    "        return pd.Series(['75%', '25%'])\n",
    "    elif row['blockType'] == 'D':\n",
    "        return pd.Series(['75%', '75%'])\n",
    "    else:\n",
    "        return pd.Series([None, None])\n",
    "\n",
    "# Apply the function to each row and create new columns\n",
    "combined_data[['congruencyProportion', 'switchProportion']] = combined_data.apply(map_block_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load evoked and stuff for all subjects in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example of how to use this with multiple conditions, even matching any value in a list. Although I only ever have two conditions of a type so not super necessary.\n",
    "# # make sure to use the correct column names and values that match with what combinedData uses.\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": [\"s1\", \"s2\"]  # Example where switchType needs to match any value in the list\n",
    "#     },\n",
    "#     \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071', 'D0077', 'D0090', 'D0094', 'D0100', 'D0102', 'D0103']\n",
    "\n",
    "# congruency\n",
    "# output_names = [\"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#     },\n",
    "#     \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# switch\n",
    "# output_names = [\"Stimulus_r25and75_fixationCrossBase_1sec_mirror\", \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_r25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"r\",\n",
    "#     },\n",
    "#     \"Stimulus_s25and75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"s\",\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  ir vs is\n",
    "# output_names = [\"Stimulus_ir_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     },\n",
    "#     \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  cr vs cs\n",
    "# output_names = [\"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_cs_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     },\n",
    "#     \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  is vs cs\n",
    "# output_names = [\"Stimulus_cs_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     },\n",
    "#     \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"s\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# #  ir vs cr\n",
    "# output_names = [\"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_ir_fixationCrossBase_1sec_mirror\"]\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     },\n",
    "#     \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"switchType\": \"r\"\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# # all interaction effects (run this with the anova code. Ugh make everything more modular later.)\n",
    "output_names = [\"Stimulus_ir_fixationCrossBase_1sec_mirror\", \"Stimulus_is_fixationCrossBase_1sec_mirror\", \"Stimulus_cr_fixationCrossBase_1sec_mirror\", \"Stimulus_cs_fixationCrossBase_1sec_mirror\"]\n",
    "\n",
    "output_names_conditions = {\n",
    "    \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"i\",\n",
    "        \"switchType\": \"s\"\n",
    "    },\n",
    "    \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"r\"\n",
    "    },\n",
    "    \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "        \"congruency\": \"c\",\n",
    "        \"switchType\": \"s\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# # block interaction contrasts for lwpc\n",
    "# output_names = [\"Stimulus_c25_fixationCrossBase_1sec_mirror\", \"Stimulus_c75_fixationCrossBase_1sec_mirror\",  \\\n",
    "#                 \"Stimulus_i25_fixationCrossBase_1sec_mirror\", \"Stimulus_i75_fixationCrossBase_1sec_mirror\"]\n",
    "\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_c25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"congruencyProportion\": \"75%\" #this is flipped because the BIDS events are saved in terms of incongruency proportion\n",
    "#     },\n",
    "#     \"Stimulus_c75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"c\",\n",
    "#         \"congruencyProportion\": \"25%\"\n",
    "#     },\n",
    "#     \"Stimulus_i25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"congruencyProportion\": \"75%\"\n",
    "#     },\n",
    "#     \"Stimulus_i75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"congruency\": \"i\",\n",
    "#         \"congruencyProportion\": \"25%\"\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# # block interaction contrasts for lwps\n",
    "# output_names = [\"Stimulus_s25_fixationCrossBase_1sec_mirror\", \"Stimulus_s75_fixationCrossBase_1sec_mirror\",  \\\n",
    "#                 \"Stimulus_r25_fixationCrossBase_1sec_mirror\", \"Stimulus_r75_fixationCrossBase_1sec_mirror\"]\n",
    "\n",
    "# output_names_conditions = {\n",
    "#     \"Stimulus_s25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"s\",\n",
    "#         \"switchProportion\": \"25%\"\n",
    "#     },\n",
    "#     \"Stimulus_s75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"s\",\n",
    "#         \"switchProportion\": \"75%\"\n",
    "#     },\n",
    "#     \"Stimulus_r25_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"r\",\n",
    "#         \"switchProportion\": \"25%\"\n",
    "#     },\n",
    "#     \"Stimulus_r75_fixationCrossBase_1sec_mirror\": {\n",
    "#         \"switchType\": \"r\",\n",
    "#         \"switchProportion\": \"75%\"\n",
    "#     },\n",
    "# }\n",
    "\n",
    "task='GlobalLocal'\n",
    "\n",
    "# Assuming 'combined_data' is your DataFrame and 'subjects' is your list of subject IDs\n",
    "subjects_mne_objects = create_subjects_mne_objects_dict(subjects, output_names_conditions, task=\"GlobalLocal\", combined_data=combined_data, acc_array=acc_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_chans(sub, task, LAB_root=None):\n",
    "    # Determine LAB_root based on the operating system\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "\n",
    "    stim_filename = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
    "    stim_sig_chans = load_sig_chans(stim_filename)\n",
    "    return stim_sig_chans\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary to store significant channels per subject\n",
    "sig_chans_per_subject = {}\n",
    "\n",
    "# Populate the dictionary using get_sig_chans for each subject\n",
    "for sub in subjects:\n",
    "    sig_chans_per_subject[sub] = get_sig_chans(sub, 'GlobalLocal')\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the significant electrodes across subjects for each ROI of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup\n",
    "ACC based on Destrieux et al 2010 definition is G_and_S_cingul-Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_electrodes_by_roi(subjects_electrodes_dict, sig_chans_per_subject, roi_list):\n",
    "    \"\"\"\n",
    "    Filters electrodes based on specified ROIs and returns significant electrodes for each subject.\n",
    "\n",
    "    Args:\n",
    "    subjects_electrodes_dict (dict): A dictionary with subjects as keys and electrode-to-ROI mappings as values.\n",
    "    sig_chans_per_subject (dict): A dictionary with subjects as keys and lists of significant channels as values.\n",
    "    roi_list (list): A list of ROIs to filter electrodes.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with subjects as keys and lists of significant electrodes in specified ROIs as values.\n",
    "    \"\"\"\n",
    "    filtered_electrodes_per_subject = {}\n",
    "\n",
    "    for sub, electrodes_dict in subjects_electrodes_dict.items():\n",
    "        filtered = {key: value for key, value in electrodes_dict['filtROI_dict'].items() \n",
    "                    if any(roi in key for roi in roi_list)}\n",
    "\n",
    "        # Aggregate electrodes into a list for each subject\n",
    "        filtered_electrodes = []\n",
    "        for electrodes in filtered.values():\n",
    "            filtered_electrodes.extend(electrodes)\n",
    "\n",
    "        filtered_electrodes_per_subject[sub] = filtered_electrodes\n",
    "        print(f'For subject {sub}, {\", \".join(roi_list)} electrodes are: {filtered_electrodes}')\n",
    "\n",
    "    # Now filter for significant electrodes\n",
    "    sig_filtered_electrodes_per_subject = {}\n",
    "\n",
    "    for sub, filtered_electrodes in filtered_electrodes_per_subject.items():\n",
    "        # Retrieve the list of significant channels for the subject\n",
    "        sig_chans = sig_chans_per_subject.get(sub, [])\n",
    "\n",
    "        # Find the intersection of filtered electrodes and significant channels for the subject\n",
    "        sig_filtered_electrodes = [elec for elec in filtered_electrodes if elec in sig_chans]\n",
    "\n",
    "        # Store the significant filtered electrodes for the subject\n",
    "        sig_filtered_electrodes_per_subject[sub] = sig_filtered_electrodes\n",
    "        print(f\"Subject {sub} significant {', '.join(roi_list)} electrodes: {sig_filtered_electrodes}\")\n",
    "\n",
    "    return filtered_electrodes_per_subject, sig_filtered_electrodes_per_subject\n",
    "\n",
    "# # Example usage:\n",
    "# dlpfc_rois = [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"] #dorsolateral prefrontal cortex\n",
    "# acc_rois = [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"] #anterior cingulate cortex\n",
    "# parietal_rois = [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"] #superior parietal lobule, intraparietal sulcus, and inferior parietal lobule (split into angular gyrus and supramarginal gyrus)\n",
    "\n",
    "# dlpfc_electrodes_per_subject, sig_dlpfc_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, dlpfc_rois)\n",
    "# # acc_electrodes_per_subject, sig_acc_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, acc_rois)\n",
    "# # parietal_electrodes_per_subject, sig_parietal_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, parietal_rois)\n",
    "\n",
    "# sig_electrodes_per_subject_roi = {}\n",
    "# sig_electrodes_per_subject_roi['dlpfc'] = sig_dlpfc_electrodes_per_subject\n",
    "# sig_electrodes_per_subject_roi['acc'] = sig_acc_electrodes_per_subject\n",
    "# sig_electrodes_per_subject_roi['parietal'] = sig_parietal_electrodes_per_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois_dict = {\n",
    "    # 'dlpfc': [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"],\n",
    "    # 'acc': [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"],\n",
    "    # 'parietal': [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"],\n",
    "    'lpfc': [\"G_front_inf-Opercular\", \"G_front_inf-Orbital\", \"G_front_inf-Triangul\", \"G_front_middle\", \"G_front_sup\", \"Lat_Fis-ant-Horizont\", \"Lat_Fis-ant-Vertical\", \"S_circular_insula_ant\", \"S_circular_insula_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"]\n",
    "}\n",
    "\n",
    "rois = list(rois_dict.keys())\n",
    "\n",
    "electrodes_per_subject_roi = {}\n",
    "sig_electrodes_per_subject_roi = {}\n",
    "\n",
    "for roi_name, roi_regions in rois_dict.items():\n",
    "    # Apply the filter_electrodes_by_roi function for each set of ROI regions\n",
    "    electrodes_per_subject, sig_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, roi_regions)\n",
    "    \n",
    "    # Store the significant electrodes in the result dictionary\n",
    "    electrodes_per_subject_roi[roi_name] = electrodes_per_subject\n",
    "    sig_electrodes_per_subject_roi[roi_name] = sig_electrodes_per_subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_electrodes_per_subject_roi['lpfc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sig electrodes per subject roi lpfc for poster 4/5. Delete once done with poster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the filename\n",
    "# save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "# filename = os.path.join(save_dir, 'roi_dict_sig')\n",
    "\n",
    "# # Write the dictionary to a file\n",
    "# with open(filename, 'w') as f:\n",
    "#     json.dump(sig_electrodes_per_subject_roi, f, indent=4)\n",
    "\n",
    "# filename = os.path.join(save_dir, 'roi_dict_all')\n",
    "# # Write the dictionary to a file\n",
    "# with open(filename, 'w') as f:\n",
    "#     json.dump(electrodes_per_subject_roi, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get total number of electrodes (make this modular with roi later once everything works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_entries = 0\n",
    "# for sub in sig_electrodes_per_subject_roi['dlpfc']:\n",
    "#     # Since each subject's entry is a list, directly add its length\n",
    "#     total_entries += len(sig_electrodes_per_subject_roi['dlpfc'][sub])\n",
    "\n",
    "# print(\"Total number of sig dlpfc electrodes across all subjects:\", total_entries)\n",
    "\n",
    "# total_entries = 0\n",
    "# for sub in sig_electrodes_per_subject_roi['acc']:\n",
    "#     # Since each subject's entry is a list, directly add its length\n",
    "#     total_entries += len(sig_electrodes_per_subject_roi['acc'][sub])\n",
    "\n",
    "# print(\"Total number of sig acc electrodes across all subjects:\", total_entries)\n",
    "\n",
    "# total_entries = 0\n",
    "# for sub in sig_electrodes_per_subject_roi['parietal']:\n",
    "#     # Since each subject's entry is a list, directly add its length\n",
    "#     total_entries += len(sig_electrodes_per_subject_roi['parietal'][sub])\n",
    "\n",
    "# print(\"Total number of sig parietal electrodes across all subjects:\", total_entries)\n",
    "\n",
    "total_entries = 0\n",
    "for sub in sig_electrodes_per_subject_roi['lpfc']:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(sig_electrodes_per_subject_roi['lpfc'][sub])\n",
    "print(\"Total number of sig lpfc electrodes across all subjects:\", total_entries)\n",
    "\n",
    "total_entries = 0\n",
    "for sub in electrodes_per_subject_roi['lpfc']:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(electrodes_per_subject_roi['lpfc'][sub])\n",
    "print(\"Total number of lpfc electrodes across all subjects:\", total_entries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do stats\n",
    "\n",
    "current approach is to run time_perm_cluster on significant dlpfc electrodes for each subject, comparing congruent and incongruent conditions. Then, average p-values across all subjects. Discuss this with Greg, probably wrong approach.\n",
    "\n",
    "**1/23 new approach is to average across all trials for sig dlpfc electrodes, comparing incongruent and congruent conditions. Then, run stats on this new avg electrode value x time array.\n",
    "\n",
    "Also, I'm using HG_ev1_rescaled instead of HG_ev1 to compare congruent and incongruent, so that they're normalized with a common baseline. I think this is better than comparing the raw HG traces directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is 1/23 old approach of avg across trials first. Time perm cluster stats.\n",
    "\n",
    "do stats and plotting together. Stats needs trial avg data, plotting just needs congruent_data without trial averaging (initially at least)  \n",
    "this code is so bad right now, turn into a function later  \n",
    "\n",
    "trialAvg is for the time perm cluster stats  \n",
    "timeAvg_firstHalfSecond_firstHalfSecond_firstHalfSecond_firstHalfSecond_firstHalfSecond is for the window stats (not sure if this is even right)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "turn these into dictionaries instead of a bunch of variables later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to hold mappings\n",
    "overall_electrode_mapping = []\n",
    "\n",
    "# Initialize a dict to hold mappings for each roi\n",
    "electrode_mapping_per_roi = {roi: [] for roi in rois}\n",
    "\n",
    "# Initialize lists for storing data\n",
    "output_0_data_trialAvg_list = {roi: [] for roi in rois}\n",
    "output_1_data_trialAvg_list = {roi: [] for roi in rois}\n",
    "output_0_data_timeAvg_firstHalfSecond_list = {roi: [] for roi in rois}\n",
    "output_1_data_timeAvg_firstHalfSecond_list = {roi: [] for roi in rois}\n",
    "output_0_data_timeAvg_secondHalfSecond_list = {roi: [] for roi in rois}\n",
    "output_1_data_timeAvg_secondHalfSecond_list = {roi: [] for roi in rois}\n",
    "output_0_data_timeAvg_fullSecond_list = {roi: [] for roi in rois}\n",
    "output_1_data_timeAvg_fullSecond_list = {roi: [] for roi in rois}\n",
    "\n",
    "# Time windows\n",
    "start_idx_firstHalfSecond, end_idx_firstHalfSecond = 2048, 3072\n",
    "start_idx_secondHalfSecond, end_idx_secondHalfSecond = 3072, 4096\n",
    "start_idx_fullSecond, end_idx_fullSecond = 2048, 4096\n",
    "\n",
    "\n",
    "for sub in subjects:\n",
    "    for roi in rois:\n",
    "        sig_electrodes = sig_electrodes_per_subject_roi[roi].get(sub, [])\n",
    "\n",
    "        # Skip this roi for the current subject if no significant electrodes are present\n",
    "        if not sig_electrodes:\n",
    "            continue\n",
    "        for electrode in sig_electrodes:\n",
    "            # For each significant electrode, append a tuple to the mapping list\n",
    "            # Tuple format: (Subject ID, ROI, Electrode Name, Index in List)\n",
    "            # The index can be the current length of the list before appending\n",
    "            index = len(overall_electrode_mapping)\n",
    "            overall_electrode_mapping.append((sub, roi, electrode, index))  \n",
    "\n",
    "            # For each significant electrode, append a tuple to the mapping list of the corresponding ROI\n",
    "            # Tuple format: (Subject ID, Electrode Name, Index in List for this ROI)\n",
    "            index = len(electrode_mapping_per_roi[roi])  # Get the current length of the list for this ROI\n",
    "            electrode_mapping_per_roi[roi].append((sub, electrode, index))\n",
    "            \n",
    "        # Load trial-level data for the current condition and pick significant electrodes\n",
    "        output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "        output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "\n",
    "        # Calculate averages for each time window\n",
    "        trial_avg_0, trial_std_0, time_avg_0_firstHalfSecond = filter_and_average_epochs(output_0_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "        trial_avg_1, trial_std_1, time_avg_1_firstHalfSecond = filter_and_average_epochs(output_1_epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "        _, _, time_avg_0_secondHalfSecond = filter_and_average_epochs(output_0_epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "        _, _, time_avg_1_secondHalfSecond = filter_and_average_epochs(output_1_epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "        _, _, time_avg_0_fullSecond = filter_and_average_epochs(output_0_epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "        _, _, time_avg_1_fullSecond = filter_and_average_epochs(output_1_epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "\n",
    "        # Append the results to their respective lists\n",
    "        output_0_data_trialAvg_list[roi].append(trial_avg_0)\n",
    "        output_1_data_trialAvg_list[roi].append(trial_avg_1)\n",
    "        output_0_data_timeAvg_firstHalfSecond_list[roi].append(time_avg_0_firstHalfSecond)\n",
    "        output_1_data_timeAvg_firstHalfSecond_list[roi].append(time_avg_1_firstHalfSecond)\n",
    "        output_0_data_timeAvg_secondHalfSecond_list[roi].append(time_avg_0_secondHalfSecond)\n",
    "        output_1_data_timeAvg_secondHalfSecond_list[roi].append(time_avg_1_secondHalfSecond)\n",
    "        output_0_data_timeAvg_fullSecond_list[roi].append(time_avg_0_fullSecond)\n",
    "        output_1_data_timeAvg_fullSecond_list[roi].append(time_avg_1_fullSecond)\n",
    "\n",
    "# After collecting all data, concatenate across subjects for each roi and condition\n",
    "concatenated_trialAvg_data = {}\n",
    "# concatenated_timeAvg_firstHalfSecond_data = {}\n",
    "# concatenated_timeAvg_secondHalfSecond_data = {}\n",
    "# concatenated_timeAvg_fullSecond_data = {}\n",
    "\n",
    "for roi in ['dlpfc', 'acc', 'parietal']:\n",
    "    concatenated_trialAvg_data[roi] = {\n",
    "        'output_0': np.concatenate(output_0_data_trialAvg_list[roi], axis=0),\n",
    "        'output_1': np.concatenate(output_1_data_trialAvg_list[roi], axis=0)\n",
    "    }\n",
    "\n",
    "# Calculate mean and SEM across electrodes for all time windows and rois\n",
    "overall_averages = {}\n",
    "overall_sems = {}\n",
    "for roi in rois:\n",
    "    overall_averages[roi] = {}\n",
    "    overall_sems[roi] = {}\n",
    "    for output in ['output_0', 'output_1']:\n",
    "        trialAvg_data = concatenated_trialAvg_data[roi][output]\n",
    "        overall_averages[roi][output] = np.nanmean(trialAvg_data, axis=0)\n",
    "        overall_sems[roi][output] = np.std(trialAvg_data, axis=0, ddof=1) / np.sqrt(trialAvg_data.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "time_perm_cluster_results = {}\n",
    "for roi in rois:\n",
    "    time_perm_cluster_results[roi] = time_perm_cluster(\n",
    "        concatenated_trialAvg_data[roi]['output_0'],\n",
    "        concatenated_trialAvg_data[roi]['output_1'], 0.05, n_jobs=6\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do window stats  \n",
    "use the time avg outputs from previous cell  \n",
    "use fdr correction after comparing output 0 and output 1 for each electrode to get a p-values list  \n",
    "\n",
    "DO A SHUFFLE INSTEAD OF PAIRED T-TEST AS OF 2/7/24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shuffle test (perm test). This basically time perm cluster but avg across time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do perm testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the functions perform_permutation_test_within_electrodes and perform_permutation_test_across_electrodes return lists of p-values (and get loaded in properly)\n",
    "p_values = {}\n",
    "for roi in rois:\n",
    "    # Initialize p_values[roi] as a dictionary. Initialize dicts for all time windows.\n",
    "    p_values[roi] = {}\n",
    "    p_values[roi]['firstHalfSecond'] = {}\n",
    "    p_values[roi]['secondHalfSecond'] = {}\n",
    "    p_values[roi]['fullSecond'] = {}\n",
    "\n",
    "    # Perform the tests and store results\n",
    "    p_values[roi]['firstHalfSecond']['within'] = perform_permutation_test_within_electrodes(output_0_data_timeAvg_firstHalfSecond_list[roi], output_1_data_timeAvg_firstHalfSecond_list[roi], n_permutations=10000)\n",
    "    p_values[roi]['firstHalfSecond']['across'] = perform_permutation_test_across_electrodes(output_0_data_timeAvg_firstHalfSecond_list[roi], output_1_data_timeAvg_firstHalfSecond_list[roi], n_permutations=10000)\n",
    "\n",
    "    p_values[roi]['secondHalfSecond']['within'] = perform_permutation_test_within_electrodes(output_0_data_timeAvg_secondHalfSecond_list[roi], output_1_data_timeAvg_secondHalfSecond_list[roi], n_permutations=10000)\n",
    "    p_values[roi]['secondHalfSecond']['across'] = perform_permutation_test_across_electrodes(output_0_data_timeAvg_secondHalfSecond_list[roi], output_1_data_timeAvg_secondHalfSecond_list[roi], n_permutations=10000)\n",
    "\n",
    "    p_values[roi]['fullSecond']['within'] = perform_permutation_test_within_electrodes(output_0_data_timeAvg_fullSecond_list[roi], output_1_data_timeAvg_fullSecond_list[roi], n_permutations=10000)\n",
    "    p_values[roi]['fullSecond']['across'] = perform_permutation_test_across_electrodes(output_0_data_timeAvg_fullSecond_list[roi], output_1_data_timeAvg_fullSecond_list[roi], n_permutations=10000)\n",
    "\n",
    "\n",
    "# I'm pretty sure we should only do within electrode and not across electrodes for the all_p_values list. So don't iterate over test_types here. 3/11.\n",
    "all_p_values = {}\n",
    "all_p_values['firstHalfSecond'] = []\n",
    "all_p_values['secondHalfSecond'] = []\n",
    "all_p_values['fullSecond'] = []\n",
    "\n",
    "for roi in p_values:\n",
    "    for test_type in p_values[roi]['firstHalfSecond']:\n",
    "        p = p_values[roi]['firstHalfSecond'][test_type]\n",
    "        if isinstance(p, list):\n",
    "            all_p_values['firstHalfSecond'].extend(p)\n",
    "        else:  # Assume it's a single float value\n",
    "            all_p_values['firstHalfSecond'].append(p)\n",
    "\n",
    "    for test_type in p_values[roi]['secondHalfSecond']:\n",
    "        p = p_values[roi]['secondHalfSecond'][test_type]\n",
    "        if isinstance(p, list):\n",
    "            all_p_values['secondHalfSecond'].extend(p)\n",
    "        else:  # Assume it's a single float value\n",
    "            all_p_values['secondHalfSecond'].append(p)\n",
    "\n",
    "    for test_type in p_values[roi]['fullSecond']:\n",
    "        p = p_values[roi]['fullSecond'][test_type]\n",
    "        if isinstance(p, list):\n",
    "            all_p_values['fullSecond'].extend(p)\n",
    "        else:  # Assume it's a single float value\n",
    "            all_p_values['fullSecond'].append(p)\n",
    "\n",
    "# Apply FDR correction\n",
    "_, adjusted_p_values_firstHalfSecond = multipletests(all_p_values['firstHalfSecond'], alpha=0.05, method='fdr_bh')[:2]\n",
    "_, adjusted_p_values_secondHalfSecond = multipletestsload(all_p_values['secondHalfSecond'], alpha=0.05, method='fdr_bh')[:2]\n",
    "_, adjusted_p_values_fullSecond = multipletests(all_p_values['fullSecond'], alpha=0.05, method='fdr_bh')[:2]\n",
    "\n",
    "# Incorporating adjusted p-values back into the structure is a bit more complex and depends on how you want to use them next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values['dlpfc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values['acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values['parietal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "integrate adjusted p values back in the p values dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Build an index map while aggregating p-values\n",
    "index_map = {'firstHalfSecond': [], 'secondHalfSecond': [], 'fullSecond': []}\n",
    "\n",
    "# Step 1: Adjusted - Ensure all p-values are treated as lists\n",
    "for roi in p_values:\n",
    "    for time_window in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']:\n",
    "        for test_type in ['within', 'across']:\n",
    "            p_value_list = p_values[roi][time_window][test_type]\n",
    "            # Ensure p_value_list is actually a list\n",
    "            if not isinstance(p_value_list, list):\n",
    "                p_value_list = [p_value_list]\n",
    "            for p_value in p_value_list:\n",
    "                all_p_values[time_window].append(p_value)\n",
    "                index_map[time_window].append((roi, test_type))\n",
    "\n",
    "\n",
    "# Step 3: Reintegrate adjusted p-values back into the p_values structure\n",
    "# Using firstHalfSecond as an example\n",
    "# Adjusted reintegration example for firstHalfSecond\n",
    "for time_window in ['firstHalfSecond', 'secondHalfSecond', 'fullSecond']:\n",
    "    adjusted_ps = locals()[f\"adjusted_p_values_{time_window}\"]  # Retrieve adjusted p-values using dynamic variable names\n",
    "    for i, adjusted_p in enumerate(adjusted_ps):\n",
    "        roi, test_type = index_map[time_window][i]\n",
    "        # Ensure the adjusted key and test_type key exist\n",
    "        if 'adjusted' not in p_values[roi][time_window]:\n",
    "            p_values[roi][time_window]['adjusted'] = {}\n",
    "        if test_type not in p_values[roi][time_window]['adjusted']:\n",
    "            p_values[roi][time_window]['adjusted'][test_type] = []\n",
    "        p_values[roi][time_window]['adjusted'][test_type].append(adjusted_p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values['acc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hmm figure out if need to run this always and how its different than the other one.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do 2x2 anova for interaction effects \n",
    "this requires reloading in all four conditions (four this time cuz interaction contrasts).  \n",
    "ONLY RUN THIS WHEN LOADING IN THE FOUR INTERACTION CONTRASTS RIGHT NOW.  \n",
    "Integrate with other stats and plotting and stuff later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time windows\n",
    "# define these based on epoch start and also sampling rate\n",
    "start_idx_firstHalfSecond, end_idx_firstHalfSecond = 2048, 3072\n",
    "start_idx_secondHalfSecond, end_idx_secondHalfSecond = 3072, 4096\n",
    "start_idx_fullSecond, end_idx_fullSecond = 2048, 4096\n",
    "# Function to create a nested dictionary for each output_name with ROIs as keys\n",
    "def initialize_output_data(rois, output_names):\n",
    "    return {output_name: {roi: [] for roi in rois} for output_name in output_names}\n",
    "\n",
    "# Assuming output_names contains all four conditions\n",
    "# Initializing dictionaries\n",
    "output_data_trialAvg_lists = initialize_output_data(rois, output_names)\n",
    "output_data_trialStd_lists = initialize_output_data(rois, output_names)\n",
    "output_data_timeAvg_firstHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "output_data_timeAvg_secondHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "output_data_timeAvg_fullSecond_lists = initialize_output_data(rois, output_names)\n",
    "\n",
    "# Initialize a dictionary to hold mappings\n",
    "overall_electrode_mapping = []\n",
    "\n",
    "# Initialize a dictionary to hold mappings for each ROI\n",
    "electrode_mapping_per_roi = {roi: [] for roi in rois}\n",
    "for sub in subjects:\n",
    "    for roi in rois:\n",
    "        for output_name in output_names:\n",
    "            # Determine significant electrodes for the current ROI and subject\n",
    "            # sig_electrodes = sig_dlpfc_electrodes_per_subject.get(sub, []) if roi == 'dlpfc' else sig_acc_electrodes_per_subject.get(sub, []) if roi == 'acc' else sig_parietal_electrodes_per_subject.get(sub, [])\n",
    "            \n",
    "            sig_electrodes = sig_electrodes_per_subject_roi[roi].get(sub, [])\n",
    "            print('sub', sub)\n",
    "            print('sig elecs:', sig_electrodes)\n",
    "            \n",
    "            if not sig_electrodes:  # Skip if no significant electrodes\n",
    "                continue\n",
    "                        \n",
    "            for electrode in sig_electrodes:\n",
    "                # For each significant electrode, append a tuple to the mapping list\n",
    "                # Tuple format: (Subject ID, ROI, Electrode Name, Index in List)\n",
    "                # The index can be the current length of the list before appending\n",
    "                index = len(overall_electrode_mapping)\n",
    "                overall_electrode_mapping.append((sub, roi, electrode, output_name, index))  \n",
    "\n",
    "                # For each significant electrode, append a tuple to the mapping list of the corresponding ROI\n",
    "                # Tuple format: (Subject ID, Electrode Name, Index in List for this ROI)\n",
    "                index = len(electrode_mapping_per_roi[roi])  # Get the current length of the list for this ROI\n",
    "                electrode_mapping_per_roi[roi].append((sub, electrode, output_name, index))\n",
    "                \n",
    "            # Load trial-level data for the current condition and pick significant electrodes\n",
    "            epochs = subjects_mne_objects[sub][output_name]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes)\n",
    "            # print(epochs.get_data().shape)\n",
    "            # Calculate averages for each time window\n",
    "            trial_avg, trial_std, time_avg_firstHalfSecond = filter_and_average_epochs(epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "            _, _, time_avg_secondHalfSecond = filter_and_average_epochs(epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "            _, _, time_avg_fullSecond = filter_and_average_epochs(epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "            print('time avg full second shape:', time_avg_fullSecond.shape)\n",
    "\n",
    "            # Append the results to their respective lists\n",
    "            output_data_trialAvg_lists[output_name][roi].append(trial_avg)\n",
    "            output_data_trialStd_lists[output_name][roi].append(trial_std)\n",
    "            output_data_timeAvg_firstHalfSecond_lists[output_name][roi].append(time_avg_firstHalfSecond)\n",
    "            output_data_timeAvg_secondHalfSecond_lists[output_name][roi].append(time_avg_secondHalfSecond)\n",
    "            output_data_timeAvg_fullSecond_lists[output_name][roi].append(time_avg_fullSecond)\n",
    "\n",
    "\n",
    "# After collecting all data, concatenate across subjects for each roi and condition\n",
    "concatenated_trialAvg_data = {}\n",
    "concatenated_trialStd_data = {}\n",
    "\n",
    "for roi in rois:\n",
    "    concatenated_trialAvg_data[roi] = {}\n",
    "    concatenated_trialStd_data[roi] = {}\n",
    "\n",
    "    for output_name in output_names:\n",
    "        concatenated_trialAvg_data[roi][output_name] = np.concatenate(output_data_trialAvg_lists[output_name][roi], axis=0)\n",
    "        concatenated_trialStd_data[roi][output_name] = np.concatenate(output_data_trialStd_lists[output_name][roi], axis=0)\n",
    "\n",
    "\n",
    "# Calculate mean and SEM across electrodes for all time windows and rois\n",
    "overall_averages = {}\n",
    "overall_sems = {}\n",
    "for roi in rois:\n",
    "    overall_averages[roi] = {}\n",
    "    overall_sems[roi] = {}\n",
    "    for output_name in output_names:\n",
    "        trialAvg_data = concatenated_trialAvg_data[roi][output_name]\n",
    "        overall_averages[roi][output_name] = np.nanmean(trialAvg_data, axis=0)\n",
    "        overall_sems[roi][output_name] = np.std(trialAvg_data, axis=0, ddof=1) / np.sqrt(trialAvg_data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the subject indexing is being thrown off by the subjects that DONT have electrodes in this roi. Maybe skip those subjects for the index? Or make subject index consistent across variables.. 4/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get subjects that have data so that indexing isn't thrown off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_electrodes_per_subject_roi['lpfc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "# Determine LAB_root based on the operating system\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "# Example structure for organizing data for ANOVA with four conditions\n",
    "data_for_anova = []\n",
    "\n",
    "\n",
    "# Function to process and append data for ANOVA from time-averaged lists\n",
    "# Adapted function to include Congruency and SwitchType\n",
    "# modifying this to include time windows as another factor 4/4! Use code before 4/4 if don't want to include time windows.\n",
    "def process_and_append_data_for_anova(time_averaged_lists_dict):\n",
    "    for time_window, lists in time_averaged_lists_dict.items():\n",
    "        for output_name in output_names:\n",
    "            print('output name:', output_name)\n",
    "            # Dynamically get condition types and their values for the current output_name\n",
    "            conditions = output_names_conditions[output_name]\n",
    "            \n",
    "            for roi in rois: #this is good cuz it loops through rois 3/6, the trial level one should copy this logic\n",
    "                sig_electrodes_per_subject = sig_electrodes_per_subject_roi[roi]\n",
    "                subjects_with_data = [subject for subject, electrodes in sig_electrodes_per_subject.items() if electrodes] # add this line to skip over subjects without data 4/1\n",
    "                for subject_index, subject_data in enumerate(lists[output_name][roi]):\n",
    "                    subject_id = subjects_with_data[subject_index]\n",
    "\n",
    "                    # Skip this subject if there are no significant electrodes for them in this ROI\n",
    "                    if subject_id not in sig_electrodes_per_subject or not sig_electrodes_per_subject[subject_id]:\n",
    "                        continue\n",
    "\n",
    "                    # Calculate the mean across trials for each electrode\n",
    "                    mean_activity_per_electrode = np.nanmean(subject_data, axis=0)\n",
    "                    # untested making this more modular 2/27\n",
    "                    for electrode_index, mean_activity in enumerate(mean_activity_per_electrode):\n",
    "                        print('electrode index:', electrode_index)\n",
    "                        electrode_name = sig_electrodes_per_subject[subject_id][electrode_index]\n",
    "                        print(electrode_name)\n",
    "                        # Prepare data dictionary, starting with fixed attributes\n",
    "                        data_dict = {\n",
    "                            'SubjectID': subject_id,\n",
    "                            'Electrode': electrode_name,\n",
    "                            'ROI': roi,\n",
    "                            'TimeWindow': time_window,\n",
    "                            'MeanActivity': mean_activity\n",
    "                        }\n",
    "\n",
    "                        # Dynamically add condition types and their values\n",
    "                        data_dict.update(conditions)\n",
    "\n",
    "                        # Append the organized data to the list\n",
    "                        data_for_anova.append(data_dict)\n",
    "\n",
    "# Create a time averaged lists dictionary to pass in to the process and append data for anova function\n",
    "                    \n",
    "# use this one to compare early vs late vs all time\n",
    "# time_averaged_lists = {\n",
    "#         \"FirstHalfSecond\": output_data_timeAvg_firstHalfSecond_lists,\n",
    "#         \"SecondHalfSecond\": output_data_timeAvg_secondHalfSecond_lists,\n",
    "#         \"FullSecond\": output_data_timeAvg_fullSecond_lists\n",
    "# }\n",
    "                    \n",
    "# use this one to just compare early and late time\n",
    "time_averaged_lists_dict = {\n",
    "        \"FirstHalfSecond\": output_data_timeAvg_firstHalfSecond_lists,\n",
    "        \"SecondHalfSecond\": output_data_timeAvg_secondHalfSecond_lists\n",
    "}\n",
    "\n",
    "process_and_append_data_for_anova(time_averaged_lists_dict)\n",
    "# Convert to DataFrame\n",
    "df_for_anova = pd.DataFrame(data_for_anova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now actually run anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_modular_anova_all_time_windows(df, output_names_conditions, save_dir, save_name_prefix):\n",
    "    # Dynamically construct the model formula based on condition keys and include TimeWindow\n",
    "    condition_keys = [key for key in output_names_conditions[next(iter(output_names_conditions))].keys()]\n",
    "    formula_terms = ' + '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "    interaction_terms = ' * '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "    formula = f'MeanActivity ~ {formula_terms} + {interaction_terms}'\n",
    "\n",
    "    # Define the model\n",
    "    model = ols(formula, data=df).fit()\n",
    "\n",
    "    # Perform the ANOVA\n",
    "    anova_results = anova_lm(model, typ=2)\n",
    "\n",
    "    # Define the base part of the results file name\n",
    "    results_file_path = os.path.join(save_dir, f\"{save_name_prefix}_ANOVAacrossElectrodes_allTimeWindows.txt\")\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(results_file_path, 'w') as file:\n",
    "        file.write(anova_results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"ANOVA results for all time windows saved to: {results_file_path}\")\n",
    "\n",
    "    # Print the results\n",
    "    print(anova_results)\n",
    "\n",
    "    return anova_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the ROIs with '_' as the separator\n",
    "rois_suffix = '_'.join(rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency vs congruency proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    perform_modular_anova_all_time_windows(df_for_anova, output_names_conditions, save_dir, f'congruency_congruencyProportion_{rois_suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do switch type vs switch proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    perform_modular_anova_all_time_windows(df_for_anova, output_names_conditions, save_dir, f'switchType_switchProportion_{rois_suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do congruency vs switch type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test the new across time windows anova 4/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cs_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    perform_modular_anova_all_time_windows(df_for_anova, output_names_conditions, save_dir, f'congruency_switchType_{rois_suffix}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay now do within-electrode anova too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_anova = []\n",
    "\n",
    "def process_and_append_trial_data_for_anova(time_averaged_lists, output_names_conditions):\n",
    "    for time_window, lists in time_averaged_lists.items():\n",
    "        for output_name, conditions in output_names_conditions.items():\n",
    "            for roi in rois:\n",
    "                sig_electrodes_per_subject = sig_electrodes_per_subject_roi[roi]\n",
    "                subjects_with_data = [subject for subject, electrodes in sig_electrodes_per_subject.items() if electrodes] # Skip over subjects without data\n",
    "                for subject_index, subject_data in enumerate(lists[output_name][roi]):\n",
    "                    subject_id = subjects_with_data[subject_index]\n",
    "\n",
    "                    if subject_id not in sig_electrodes_per_subject or not sig_electrodes_per_subject[subject_id]:\n",
    "                        continue\n",
    "\n",
    "                    for trial_index, trial_data in enumerate(subject_data):\n",
    "                        # Skip trials with any missing data or incorrect length\n",
    "                        if np.any(np.isnan(trial_data)) or len(trial_data) != len(sig_electrodes_per_subject[subject_id]):\n",
    "                            continue\n",
    "\n",
    "                        for electrode_index, electrode_name in enumerate(sig_electrodes_per_subject[subject_id]):\n",
    "                            activity = trial_data[electrode_index] if electrode_index < len(trial_data) else np.nan\n",
    "\n",
    "                            # Prepare the data dictionary\n",
    "                            data_dict = {\n",
    "                                'SubjectID': subject_id,\n",
    "                                'Electrode': electrode_name,\n",
    "                                'ROI': roi,\n",
    "                                'TimeWindow': time_window,\n",
    "                                'Trial': trial_index + 1,\n",
    "                                'Activity': activity\n",
    "                            }\n",
    "\n",
    "                            # Dynamically add condition types and their values\n",
    "                            data_dict.update(conditions)\n",
    "\n",
    "                            data_for_anova.append(data_dict)\n",
    "\n",
    "# Example usage with the `time_averaged_lists` dictionary\n",
    "time_averaged_lists = {\n",
    "    \"FirstHalfSecond\": output_data_timeAvg_firstHalfSecond_lists,\n",
    "    \"SecondHalfSecond\": output_data_timeAvg_secondHalfSecond_lists,\n",
    "    # \"FullSecond\": output_data_timeAvg_fullSecond_lists  # Uncomment or comment based on your needs\n",
    "}\n",
    "\n",
    "process_and_append_trial_data_for_anova(time_averaged_lists, output_names_conditions)\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_for_trial_level_anova = pd.DataFrame(data_for_anova)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_for_trial_level_anova is your DataFrame and it includes a 'SubjectID' column\n",
    "def perform_modular_within_electrode_anova_roi(df, output_names_conditions, save_dir, save_name):\n",
    "    '''\n",
    "    This gets if an electrode is significant for specific time windows. It does not get their interaction.\n",
    "    '''\n",
    "    import json\n",
    "    results = []\n",
    "    significant_effects_structure = {}\n",
    "\n",
    "    for subject_id in df['SubjectID'].unique():\n",
    "        for electrode in df['Electrode'].unique(): #this is wrong cuz then it only does dlpfc, fix this 4/1\n",
    "            for time_window in df['TimeWindow'].unique():\n",
    "                df_filtered = df[(df['SubjectID'] == subject_id) & \n",
    "                                 (df['Electrode'] == electrode) & \n",
    "                                 (df['TimeWindow'] == time_window)]\n",
    "                \n",
    "                if df_filtered.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Dynamically construct the formula based on condition keys present in the DataFrame\n",
    "                condition_keys = [key for key in output_names_conditions[next(iter(output_names_conditions))].keys()]\n",
    "                formula_terms = ' + '.join([f'C({key})' for key in condition_keys])\n",
    "                interaction_terms = ' * '.join([f'C({key})' for key in condition_keys])\n",
    "                formula = f'Activity ~ {formula_terms} + {interaction_terms}'\n",
    "\n",
    "                # Perform the ANOVA\n",
    "                model = ols(formula, data=df_filtered).fit()\n",
    "                anova_results = anova_lm(model, typ=2)\n",
    "                \n",
    "                # Append the results\n",
    "                results.append({\n",
    "                    'SubjectID': subject_id,\n",
    "                    'Electrode': electrode,\n",
    "                    'TimeWindow': time_window,\n",
    "                    'ANOVA_Results': anova_results\n",
    "                })\n",
    "    \n",
    "    # Join all the ROIs with '_' as the separator\n",
    "    rois_suffix = '_'.join(rois)\n",
    "\n",
    "    # Add the suffix '_onlySigElectrodes' to the base filename\n",
    "    allElectrodesFilename = f\"{save_name}_allElectrodes_{rois_suffix}.txt\"\n",
    "    onlySigElectrodesFilename = f\"{save_name}_onlySigElectrodes_{rois_suffix}.txt\"\n",
    "    significantEffectsStructureFilename = f\"{save_name}_significantEffectsStructure_{rois_suffix}.txt\"\n",
    "\n",
    "    # Define the full path for the results file\n",
    "    results_file_path = os.path.join(save_dir, allElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(results_file_path, 'w') as file:\n",
    "        file.write(results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"results saved to: {results_file_path}\")\n",
    "\n",
    "    # Now process the significant results, including the subject ID in the output\n",
    "    significant_results = []\n",
    "\n",
    "    for result in results:\n",
    "        anova_table = result['ANOVA_Results']\n",
    "        subject_id = result['SubjectID']\n",
    "        electrode = result['Electrode']\n",
    "        time_window = result['TimeWindow']\n",
    "        \n",
    "        significant_effects = anova_table[anova_table['PR(>F)'] < 0.05]\n",
    "        \n",
    "        if not significant_effects.empty:\n",
    "            print(f\"Significant effects found for Subject: {subject_id}, Electrode: {electrode}, Time Window: {time_window}\")\n",
    "            print(significant_effects)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            significant_results.append({\n",
    "                'SubjectID': subject_id,\n",
    "                'Electrode': electrode,\n",
    "                'TimeWindow': time_window,\n",
    "                'SignificantEffects': significant_effects\n",
    "            })\n",
    "\n",
    "        # Extract significant effects for the current result. Basically just get the p-value. 3/19.\n",
    "        sig_effects_just_p_values = extract_significant_effects(anova_table)\n",
    "        \n",
    "        if sig_effects_just_p_values:\n",
    "            # Ensure subject_id and electrode keys exist\n",
    "            if subject_id not in significant_effects_structure:\n",
    "                significant_effects_structure[subject_id] = {}\n",
    "            if electrode not in significant_effects_structure[subject_id]:\n",
    "                significant_effects_structure[subject_id][electrode] = {}\n",
    "            \n",
    "            # Assign the significant effects and their p-values to the correct structure\n",
    "            significant_effects_structure[subject_id][electrode][time_window] = sig_effects_just_p_values    \n",
    "\n",
    "    # Define the full path for the results file\n",
    "    significant_results_file_path = os.path.join(save_dir, onlySigElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(significant_results_file_path, 'w') as file:\n",
    "        file.write(significant_results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_results saved to: {significant_results_file_path}\")\n",
    "\n",
    "    significant_effects_structure_file_path = os.path.join(save_dir, significantEffectsStructureFilename)\n",
    "    # Save the ANOVA results to a json file (if this works, change the others to json files too)\n",
    "    with open(significant_effects_structure_file_path, 'w') as file:\n",
    "        json.dump(significant_effects_structure, file, indent=4)\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_effects_structure saved to: {significant_effects_structure_file_path}\")\n",
    "\n",
    "    return results, significant_results, significant_effects_structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming df_for_trial_level_anova is your DataFrame and it includes a 'SubjectID' column\n",
    "def perform_modular_within_electrode_anova_roi_timeWindowInteractions(df, output_names_conditions, save_dir, save_name):\n",
    "    '''\n",
    "    This gets if the main and interaction effect of time window is significant for an electrode. AKA is overall or condition-specific activity different across differnet time windows?\n",
    "    It does not tell you which time windows are significant. \n",
    "    '''\n",
    "    import json\n",
    "    results = []\n",
    "    significant_effects_structure = {}\n",
    "\n",
    "    for subject_id in df['SubjectID'].unique():\n",
    "        for electrode in df['Electrode'].unique(): #this is wrong cuz then it only does dlpfc, fix this 4/1\n",
    "                df_filtered = df[(df['SubjectID'] == subject_id) & \n",
    "                                 (df['Electrode'] == electrode)]\n",
    "                \n",
    "                if df_filtered.empty:\n",
    "                    continue\n",
    "                \n",
    "                # Dynamically construct the formula based on condition keys present in the DataFrame\n",
    "                condition_keys = [key for key in output_names_conditions[next(iter(output_names_conditions))].keys()]\n",
    "                formula_terms = ' + '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "                interaction_terms = ' * '.join([f'C({key})' for key in condition_keys] + ['C(TimeWindow)'])\n",
    "                formula = f'Activity ~ {formula_terms} + {interaction_terms}'\n",
    "\n",
    "                # Perform the ANOVA\n",
    "                model = ols(formula, data=df_filtered).fit()\n",
    "                anova_results = anova_lm(model, typ=2)\n",
    "                \n",
    "                # Append the results\n",
    "                results.append({\n",
    "                    'SubjectID': subject_id,\n",
    "                    'Electrode': electrode,\n",
    "                    'ANOVA_Results': anova_results\n",
    "                })\n",
    "    \n",
    "    # Join all the ROIs with '_' as the separator\n",
    "    rois_suffix = '_'.join(rois)\n",
    "\n",
    "    # Add the suffix '_onlySigElectrodes' to the base filename\n",
    "    allElectrodesFilename = f\"{save_name}_allElectrodes_{rois_suffix}.txt\"\n",
    "    onlySigElectrodesFilename = f\"{save_name}_onlySigElectrodes_{rois_suffix}.txt\"\n",
    "    significantEffectsStructureFilename = f\"{save_name}_significantEffectsStructure_{rois_suffix}.txt\"\n",
    "\n",
    "    # Define the full path for the results file\n",
    "    results_file_path = os.path.join(save_dir, allElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(results_file_path, 'w') as file:\n",
    "        file.write(results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"results saved to: {results_file_path}\")\n",
    "\n",
    "    # Now process the significant results, including the subject ID in the output\n",
    "    significant_results = []\n",
    "\n",
    "    for result in results:\n",
    "        anova_table = result['ANOVA_Results']\n",
    "        subject_id = result['SubjectID']\n",
    "        electrode = result['Electrode']\n",
    "        \n",
    "        significant_effects = anova_table[anova_table['PR(>F)'] < 0.05]\n",
    "        \n",
    "        if not significant_effects.empty:\n",
    "            print(f\"Significant effects found for Subject: {subject_id}, Electrode: {electrode}\")\n",
    "            print(significant_effects)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            significant_results.append({\n",
    "                'SubjectID': subject_id,\n",
    "                'Electrode': electrode,\n",
    "                'SignificantEffects': significant_effects\n",
    "            })\n",
    "\n",
    "        # Extract significant effects for the current result. Basically just get the p-value. 3/19.\n",
    "        sig_effects_just_p_values = extract_significant_effects(anova_table)\n",
    "        \n",
    "        if sig_effects_just_p_values:\n",
    "            # Ensure subject_id and electrode keys exist\n",
    "            if subject_id not in significant_effects_structure:\n",
    "                significant_effects_structure[subject_id] = {}\n",
    "            if electrode not in significant_effects_structure[subject_id]:\n",
    "                significant_effects_structure[subject_id][electrode] = {}\n",
    "            \n",
    "            # Assign the significant effects and their p-values to the correct structure\n",
    "            significant_effects_structure[subject_id][electrode] = sig_effects_just_p_values    \n",
    "\n",
    "    # Define the full path for the results file\n",
    "    significant_results_file_path = os.path.join(save_dir, onlySigElectrodesFilename)\n",
    "\n",
    "    # Save the ANOVA results to a text file\n",
    "    with open(significant_results_file_path, 'w') as file:\n",
    "        file.write(significant_results.__str__())\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_results saved to: {significant_results_file_path}\")\n",
    "\n",
    "    significant_effects_structure_file_path = os.path.join(save_dir, significantEffectsStructureFilename)\n",
    "    # Save the ANOVA results to a json file (if this works, change the others to json files too)\n",
    "    with open(significant_effects_structure_file_path, 'w') as file:\n",
    "        json.dump(significant_effects_structure, file, indent=4)\n",
    "\n",
    "    # Optionally, print the path to the saved file and/or return it\n",
    "    print(f\"significant_effects_structure saved to: {significant_effects_structure_file_path}\")\n",
    "\n",
    "    return results, significant_results, significant_effects_structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency as function of congruency proportion  \n",
    "maybe make the save_name based on the conditions..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results, significant_results, significant_effects_structure = perform_modular_within_electrode_anova_roi(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_congruencyProportion_ANOVAwithinElectrodes')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results_timeWindowInteraction, significant_results_timeWindowInteraction, significant_effects_structure_timeWindowInteraction = perform_modular_within_electrode_anova_roi_timeWindowInteractions(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_congruencyProportion_ANOVAwithinElectrodes_timeWindowInteractions')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switch type as function of switch proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results, significant_results. significant_effects_structure = perform_modular_within_electrode_anova_roi(df_for_trial_level_anova, output_names_conditions, save_dir, 'switchType_switchProportion_ANOVAwithinElectrodes')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_s25_fixationCrossBase_1sec_mirror' is not in output_names.\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results_timeWindowInteraction, significant_results_timeWindowInteraction, significant_effects_structure_timeWindowInteraction = perform_modular_within_electrode_anova_roi_timeWindowInteractions(df_for_trial_level_anova, output_names_conditions, save_dir, 'switchType_switchProportion_ANOVAwithinElectrodes_timeWindowInteractions')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_s25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency as function of switch type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4/4 do both perform_modular_within_electrode_anova_roi and perform_modular_within_electrode_anova_roi_timeWindowInteractions. This will tell us which time windows have significant activity in an electrode AND if there is significant differences in activity across time windows in an electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results, significant_results, significant_effects_structure = perform_modular_within_electrode_anova_roi(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_switchType_ANOVAwithinElectrodes')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    results_timeWindowInteraction, significant_results_timeWindowInteraction, significant_effects_structure_timeWindowInteraction = perform_modular_within_electrode_anova_roi_timeWindowInteractions(df_for_trial_level_anova, output_names_conditions, save_dir, 'congruency_switchType_ANOVAwithinElectrodes_timeWindowInteractions')\n",
    "else:\n",
    "    print(\"The required output name 'Stimulus_c25_fixationCrossBase_1sec_mirror' is not in output_names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot and QC stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot time perm cluster stats (don't run this immediately below cell if didn't do time perm cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_perm_cluster_results['dlpfc'])\n",
    "plt.xlabel('Timepoints')\n",
    "plt.ylabel('Significance (0 or 1)')\n",
    "plt.title('Permutation Test Significance Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot interaction effects (only do this when load in all four of them)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://matplotlib.org/stable/gallery/color/named_colors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # add the other conditions and give them condition names and colors too\n",
    "plotting_parameters = {\n",
    "    'Stimulus_r25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'repeat',\n",
    "        'color': 'red',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    'Stimulus_s25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'switch',\n",
    "        'color': 'green',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    'Stimulus_c25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'congruent',\n",
    "        'color': 'blue',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    'Stimulus_i25and75_fixationCrossBase_1sec_mirror': {\n",
    "        'condition_name': 'incongruent',\n",
    "        'color': 'orange',\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_ir_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"IR\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_is_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"IS\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_cr_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"CR\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_cs_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"CS\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_c25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"c25\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_c75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"c75\",\n",
    "        \"color\": \"red\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_i25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"i25\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_i75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"i75\",\n",
    "        \"color\": \"blue\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_s25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"s25\",\n",
    "        \"color\": \"green\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_s75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"s75\",\n",
    "        \"color\": \"green\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "    \"Stimulus_r25_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"r25\",\n",
    "        \"color\": \"pink\",\n",
    "        \"line_style\": \"--\"\n",
    "    },\n",
    "    \"Stimulus_r75_fixationCrossBase_1sec_mirror\": {\n",
    "        \"condition_name\": \"r75\",\n",
    "        \"color\": \"pink\",\n",
    "        \"line_style\": \"-\"\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "# # Save the dictionary to a file\n",
    "# with open('plotting_parameters.json', 'w') as file:\n",
    "#     json.dump(plotting_parameters, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plotting_parameters() #make plotting parameters. Modify colors and line types in misc_functions.\n",
    "\n",
    "# Load the dictionary from the file\n",
    "with open('plotting_parameters.json', 'r') as file:\n",
    "    plotting_parameters = json.load(file)\n",
    "\n",
    "print(plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "# Determine LAB_root based on the operating system\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "def plot_interact_effects_modular_roi(roi, save_dir, save_name, overall_averages, overall_sems, output_names, plotting_parameters):\n",
    "    # Base setup for directories and file paths\n",
    "    save_path = os.path.join(save_dir, f'avg_{roi}_{save_name}_interactEffects_zscore_roi.png')\n",
    "\n",
    "    # Initialize plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Dynamically select the first subject and use it to extract times\n",
    "    first_subject_id = next(iter(subjects_mne_objects))\n",
    "    example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "    times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "    overall_averages_for_plotting = {}\n",
    "    overall_sem_for_plotting = {}\n",
    "    # Initialize variables to store the global min and max values\n",
    "    global_min_val = float('inf')  # Set to infinity initially\n",
    "    global_max_val = float('-inf')  # Set to negative infinity initially\n",
    "    \n",
    "    # Generate labels and plot each condition\n",
    "    for index, output_name in enumerate(output_names):\n",
    "        # label = output_name.split(\"_\")[1]  # OR extract label from output name instead of plotting parameters dict. Up to you.\n",
    "        overall_averages_for_plotting[output_name] = overall_averages[roi][output_name]\n",
    "        overall_sem_for_plotting[output_name] = overall_sems[roi][output_name]\n",
    "\n",
    "        # Calculate the minimum value for this condition, including SEM\n",
    "        current_min_val = min(overall_averages_for_plotting[output_name] - overall_sem_for_plotting[output_name])\n",
    "        # Calculate the maximum value for this condition, including SEM\n",
    "        current_max_val = max(overall_averages_for_plotting[output_name] + overall_sem_for_plotting[output_name])\n",
    "\n",
    "        # Update the global min and max values if necessary\n",
    "        global_min_val = min(global_min_val, current_min_val)\n",
    "        global_max_val = max(global_max_val, current_max_val)\n",
    "\n",
    "        # Optionally, add a small margin to the range\n",
    "        margin = (global_max_val - global_min_val) * 0.05  # 5% of the range as margin\n",
    "        global_min_val -= margin\n",
    "        global_max_val += margin\n",
    "\n",
    "        label = plotting_parameters[output_name]['condition_name'] # extract label from plotting parameters dict\n",
    "        color = plotting_parameters[output_name]['color']\n",
    "        line_style = plotting_parameters[output_name]['line_style']\n",
    "\n",
    "        plt.plot(times, overall_averages_for_plotting[output_name], label=f'Average {roi} {label}', linestyle=line_style, color=color)\n",
    "        plt.fill_between(times, overall_averages_for_plotting[output_name] - overall_sem_for_plotting[output_name], overall_averages_for_plotting[output_name] + overall_sem_for_plotting[output_name], alpha=0.3, color=color)\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Z-score')\n",
    "    plt.title(f'Average {roi} Signal with Standard Error for {save_name}')\n",
    "    plt.legend()\n",
    "    # Adjust the y-axis limits\n",
    "    plt.ylim([global_min_val, global_max_val])\n",
    "    plt.savefig(save_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is just for congruent vs congruency proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('dlpfc', save_dir, 'congruency_congruencyProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('acc', save_dir, 'congruency_congruencyProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('parietal', save_dir, 'congruency_congruencyProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('dlpfc', save_dir, 'switchType_switchProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('acc', save_dir, 'switchType_switchProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('parietal', save_dir, 'switchType_switchProportion', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this just for congruency vs switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('dlpfc', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('acc', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('parietal', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType', overall_averages, overall_sems, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try to plot different groups of electrodes based on significance for effects 4/4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_electrodes_by_effect(effect_structure, effect_type):\n",
    "    '''\n",
    "    Extracts electrodes with significant specified effects.\n",
    "\n",
    "    :param effect_structure: Dictionary containing significant effects for each electrode and subject.\n",
    "    :param effect_type: Single string or list of strings specifying the effect(s) of interest (\"congruency\", \"switchType\", \"congruency:switchType\", etc).\n",
    "    :return: A dictionary mapping subject IDs to lists of electrodes with the specified significant effect(s).\n",
    "    '''\n",
    "    significant_electrodes = {}\n",
    "\n",
    "    # Ensure effect_type is a list to simplify the logic\n",
    "    if isinstance(effect_type, str):\n",
    "        effect_type = [effect_type]\n",
    "\n",
    "    for subject_id, electrodes in effect_structure.items():\n",
    "        significant_electrodes_for_subject = []  # Temporary list to hold significant electrodes for a subject\n",
    "        for electrode, effects in electrodes.items():\n",
    "            for effect, p_value in effects:  # Directly unpacking the tuples here\n",
    "                if effect in effect_type and p_value < 0.05:  # Check if effect is among those of interest\n",
    "                    significant_electrodes_for_subject.append(electrode)\n",
    "                    break  # Stop checking once a significant effect is found for this electrode\n",
    "        if significant_electrodes_for_subject:  # Only add to the dict if there are significant electrodes for the subject\n",
    "            significant_electrodes[subject_id] = significant_electrodes_for_subject\n",
    "    return significant_electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySigElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, 'congruency')\n",
    "switchTypeSigElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, 'switchType')\n",
    "congruencySwitchTypeInteractionSigElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, 'congruency:switchType')\n",
    "allEffectSensitiveElectrodes = get_significant_electrodes_by_effect(significant_effects_structure_timeWindowInteraction, ['congruency', 'switchType', 'congruency:switchType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allEffectSensitiveElectrodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remake overall averages but just for the chosen electrodes. I wonder if I should make this a function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time windows\n",
    "# define these based on epoch start and also sampling rate\n",
    "start_idx_firstHalfSecond, end_idx_firstHalfSecond = 2048, 3072 #define these based on the actual sampling rate variable in the future...i think i do this in another script somewhere.\n",
    "start_idx_secondHalfSecond, end_idx_secondHalfSecond = 3072, 4096\n",
    "start_idx_fullSecond, end_idx_fullSecond = 2048, 4096\n",
    "# Function to create a nested dictionary for each output_name with ROIs as keys\n",
    "def initialize_output_data(rois, output_names):\n",
    "    return {output_name: {roi: [] for roi in rois} for output_name in output_names}\n",
    "\n",
    "def is_dict_of_dicts(d):\n",
    "    \"\"\"Check if the input is a dictionary of dictionaries.\"\"\"\n",
    "    return isinstance(d, dict) and all(isinstance(val, dict) for val in d.values())\n",
    "\n",
    "def get_sig_electrodes(sig_electrodes, roi, sub):\n",
    "    \"\"\"Get significant electrodes based on the structure of sig_electrodes. Significant effects structure removes roi info, but sig_electrodes_per_subject_roi keeps it.\n",
    "    maybe I should make these consistent... 4/5\"\"\"\n",
    "    if is_dict_of_dicts(sig_electrodes):\n",
    "        return sig_electrodes[roi].get(sub, [])\n",
    "    else:\n",
    "        return sig_electrodes.get(sub, [])\n",
    "    \n",
    "# this massive function needs to be split up and replace its above non-function form once it works 4/5.\n",
    "def get_average_data_for_specific_electrodes(subjects, rois, output_names, sig_electrodes):\n",
    "    # Assuming output_names contains all four conditions\n",
    "    # Initializing dictionaries\n",
    "    output_data_trialAvg_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_trialStd_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_timeAvg_firstHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_timeAvg_secondHalfSecond_lists = initialize_output_data(rois, output_names)\n",
    "    output_data_timeAvg_fullSecond_lists = initialize_output_data(rois, output_names)\n",
    "\n",
    "    # Initialize a dictionary to hold mappings\n",
    "    overall_electrode_mapping = []\n",
    "\n",
    "    # Initialize a dictionary to hold mappings for each ROI\n",
    "    electrode_mapping_per_roi = {roi: [] for roi in rois}\n",
    "    for sub in subjects:\n",
    "        for roi in rois:\n",
    "            for output_name in output_names:\n",
    "                # Determine significant electrodes for the current ROI and subject. Hmm not sure if this will work if I have more than one ROI for the \n",
    "                # get_significant_electrodes_by_effect electrodes.. 4/5\n",
    "                sig_electrodes_this_sub = get_sig_electrodes(sig_electrodes, roi, sub)\n",
    "                print('sub', sub)\n",
    "                print('sig elecs:', sig_electrodes_this_sub)\n",
    "                \n",
    "                if not sig_electrodes_this_sub:  # Skip if no significant electrodes\n",
    "                    continue\n",
    "                            \n",
    "                for electrode in sig_electrodes_this_sub:\n",
    "                    # For each significant electrode, append a tuple to the mapping list\n",
    "                    # Tuple format: (Subject ID, ROI, Electrode Name, Index in List)\n",
    "                    # The index can be the current length of the list before appending\n",
    "                    index = len(overall_electrode_mapping)\n",
    "                    overall_electrode_mapping.append((sub, roi, electrode, output_name, index))  \n",
    "\n",
    "                    # For each significant electrode, append a tuple to the mapping list of the corresponding ROI\n",
    "                    # Tuple format: (Subject ID, Electrode Name, Index in List for this ROI)\n",
    "                    index = len(electrode_mapping_per_roi[roi])  # Get the current length of the list for this ROI\n",
    "                    electrode_mapping_per_roi[roi].append((sub, electrode, output_name, index))\n",
    "                    \n",
    "                # Load trial-level data for the current condition and pick significant electrodes\n",
    "                epochs = subjects_mne_objects[sub][output_name]['HG_ev1_rescaled'].copy().pick_channels(sig_electrodes_this_sub)\n",
    "                # print(epochs.get_data().shape)\n",
    "                # Calculate averages for each time window\n",
    "                trial_avg, trial_std, time_avg_firstHalfSecond = filter_and_average_epochs(epochs, start_idx_firstHalfSecond, end_idx_firstHalfSecond)\n",
    "                _, _, time_avg_secondHalfSecond = filter_and_average_epochs(epochs, start_idx_secondHalfSecond, end_idx_secondHalfSecond)\n",
    "                _, _, time_avg_fullSecond = filter_and_average_epochs(epochs, start_idx_fullSecond, end_idx_fullSecond)\n",
    "                print('time avg full second shape:', time_avg_fullSecond.shape)\n",
    "\n",
    "                # Append the results to their respective lists\n",
    "                output_data_trialAvg_lists[output_name][roi].append(trial_avg)\n",
    "                output_data_trialStd_lists[output_name][roi].append(trial_std)\n",
    "                output_data_timeAvg_firstHalfSecond_lists[output_name][roi].append(time_avg_firstHalfSecond)\n",
    "                output_data_timeAvg_secondHalfSecond_lists[output_name][roi].append(time_avg_secondHalfSecond)\n",
    "                output_data_timeAvg_fullSecond_lists[output_name][roi].append(time_avg_fullSecond)\n",
    "\n",
    "\n",
    "    # After collecting all data, concatenate across subjects for each roi and condition\n",
    "    concatenated_trialAvg_data = {}\n",
    "    concatenated_trialStd_data = {}\n",
    "\n",
    "    for roi in rois:\n",
    "        concatenated_trialAvg_data[roi] = {}\n",
    "        concatenated_trialStd_data[roi] = {}\n",
    "\n",
    "        for output_name in output_names:\n",
    "            concatenated_trialAvg_data[roi][output_name] = np.concatenate(output_data_trialAvg_lists[output_name][roi], axis=0)\n",
    "            concatenated_trialStd_data[roi][output_name] = np.concatenate(output_data_trialStd_lists[output_name][roi], axis=0)\n",
    "\n",
    "\n",
    "    # Calculate mean and SEM across electrodes for all time windows and rois\n",
    "    overall_averages = {}\n",
    "    overall_sems = {}\n",
    "    for roi in rois:\n",
    "        overall_averages[roi] = {}\n",
    "        overall_sems[roi] = {}\n",
    "        for output_name in output_names:\n",
    "            trialAvg_data = concatenated_trialAvg_data[roi][output_name]\n",
    "            overall_averages[roi][output_name] = np.nanmean(trialAvg_data, axis=0)\n",
    "            overall_sems[roi][output_name] = np.std(trialAvg_data, axis=0, ddof=1) / np.sqrt(trialAvg_data.shape[0])\n",
    "    \n",
    "    return concatenated_trialAvg_data, concatenated_trialStd_data, overall_averages, overall_sems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_trialAvg_data_congruencySigElectrodes, concatenated_trialStd_data_congruencySigElectrodes, congruencySigElectrodesAverage, congruencySigElectrodesSEM = get_average_data_for_specific_electrodes(subjects, rois, output_names, congruencySigElectrodes)\n",
    "concatenated_trialAvg_data_switchTypeSigElectrodes, concatenated_trialStd_data_switchTypeSigElectrodes, switchTypeSigElectrodesAverage, switchTypeSigElectrodesSEM = get_average_data_for_specific_electrodes(subjects, rois, output_names, switchTypeSigElectrodes)\n",
    "concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes, concatenated_trialStd_data_congruencySwitchTypeInteractionSigElectrodes, congruencySwitchTypeInteractionSigElectrodesAverage, congruencySwitchTypeInteractionSigElectrodesSEM = get_average_data_for_specific_electrodes(subjects, rois, output_names, congruencySwitchTypeInteractionSigElectrodes)\n",
    "concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes, concatenated_trialStd_data_congruencySwitchTypeInteractionSigElectrodes, allEffectSensitiveElectrodesAverage, allEffectSensitiveElectrodesSEM = get_average_data_for_specific_electrodes(subjects, rois, output_names, allEffectSensitiveElectrodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally plot the average traces for each output name for these chosen electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_congruencySigElectrodes', congruencySigElectrodesAverage, congruencySigElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_switchTypeSigElectrodes', switchTypeSigElectrodesAverage, switchTypeSigElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_congruencySwitchTypeInteractionSigElectrodes', congruencySwitchTypeInteractionSigElectrodesAverage, switchTypeSigElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    plot_interact_effects_modular_roi('lpfc', save_dir, 'congruency_switchType_allEffectSensitiveElectrodes', allEffectSensitiveElectrodesAverage, allEffectSensitiveElectrodesSEM, output_names, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot (ir - cr) vs (is - cs)  \n",
    "4/5 - functionize this stuff later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEM diff = sqrt(SEM1^2 + SEM2^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_ir_cr = {}  # Difference between IR and CR\n",
    "diff_is_cs = {}  # Difference between IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    diff_ir_cr[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "    diff_is_cs[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "sem_diff_ir_cr = {}\n",
    "sem_diff_is_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    sem_diff_ir_cr[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2))\n",
    "    sem_diff_is_cs[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2))\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, diff_ir_cr[roi], label='IR - CR', color='black', linestyle='-')\n",
    "ax.plot(times, diff_is_cs[roi], label='IS - CS', color='black', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, diff_ir_cr[roi] - sem_diff_ir_cr[roi], diff_ir_cr[roi] + sem_diff_ir_cr[roi], alpha=0.2, color='black')\n",
    "ax.fill_between(times, diff_is_cs[roi] - sem_diff_is_cs[roi], diff_is_cs[roi] + sem_diff_is_cs[roi], alpha=0.2, color='black')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "# ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "# ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's do switch cost as a function of congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySwitchTypeInteractionSigElectrodesAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_is_ir = {}  # Difference between IR and CR\n",
    "diff_cs_cr = {}  # Difference between IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    diff_is_ir[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror']\n",
    "    diff_cs_cr[roi] = congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'] - congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "sem_diff_is_ir = {}\n",
    "sem_diff_cs_cr = {}\n",
    "\n",
    "for roi in rois:\n",
    "    sem_diff_is_ir[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2))\n",
    "    sem_diff_cs_cr[roi] = np.sqrt(np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2))\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, diff_is_ir[roi], label='IS - IR', color='black', linestyle='-')\n",
    "ax.plot(times, diff_cs_cr[roi], label='CS - CR', color='black', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, diff_is_ir[roi] - sem_diff_is_ir[roi], diff_is_ir[roi] + sem_diff_is_ir[roi], alpha=0.2, color='black')\n",
    "ax.fill_between(times, diff_cs_cr[roi] - sem_diff_cs_cr[roi], diff_cs_cr[roi] + sem_diff_cs_cr[roi], alpha=0.2, color='black')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's also plot i vs c 4/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_is = {}  # Average of IR and IS\n",
    "avg_cr_cs = {}  # Average of CR and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_is[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_cr_cs[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_is = {}\n",
    "avg_sem_cr_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_is[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_cr_cs[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_cr_cs[roi], label='Congruent', color='red', linestyle='-')\n",
    "ax.plot(times, avg_ir_is[roi], label='Incongruent', color='red', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_is[roi] - avg_sem_ir_is[roi], avg_ir_is[roi] + avg_sem_ir_is[roi], alpha=0.2, color='red')\n",
    "ax.fill_between(times, avg_cr_cs[roi] - avg_sem_cr_cs[roi], avg_cr_cs[roi] + avg_sem_cr_cs[roi], alpha=0.2, color='red')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "# ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "# ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now lets do i - c for the switch type main effect electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_is = {}  # Average of IR and IS\n",
    "avg_cr_cs = {}  # Average of CR and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_is[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_cr_cs[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_is = {}\n",
    "avg_sem_cr_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_is[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_cr_cs[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_ir_is[roi], label='Congruent', color='red', linestyle='-')\n",
    "ax.plot(times, avg_cr_cs[roi], label='Incongruent', color='red', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_is[roi] - avg_sem_ir_is[roi], avg_ir_is[roi] + avg_sem_ir_is[roi], alpha=0.2, color='red')\n",
    "ax.fill_between(times, avg_cr_cs[roi] - avg_sem_cr_cs[roi], avg_cr_cs[roi] + avg_sem_cr_cs[roi], alpha=0.2, color='red')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now let's plot switch vs repeat for the switch type main effect electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_cr = {}  # Average of IR and CR\n",
    "avg_is_cs = {}  # Average of IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_cr[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_is_cs[roi] = (switchTypeSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] + switchTypeSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_cr = {}\n",
    "avg_sem_is_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_cr[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_is_cs[roi] = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_ir_cr[roi], label='Repeat', color='blue', linestyle='-')\n",
    "ax.plot(times, avg_is_cs[roi], label='Switch', color='blue', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_cr[roi] - avg_sem_ir_cr[roi], avg_ir_cr[roi] + avg_sem_ir_cr[roi], alpha=0.2, color='blue')\n",
    "ax.fill_between(times, avg_is_cs[roi] - avg_sem_is_cs[roi], avg_is_cs[roi] + avg_sem_is_cs[roi], alpha=0.2, color='blue')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "# ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "# ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "# ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interestingly, the switch vs repeat for congruency main effect electrodes is quite different too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ir_cr = {}  # Average of IR and CR\n",
    "avg_is_cs = {}  # Average of IS and CS\n",
    "\n",
    "for roi in rois:\n",
    "    avg_ir_cr[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_is_cs[roi] = (congruencySigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'] + congruencySigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "\n",
    "# assuming equal sample sizes, which i think we should have\n",
    "avg_sem_ir_cr = {}\n",
    "avg_sem_is_cs = {}\n",
    "\n",
    "for roi in rois:\n",
    "    avg_sem_ir_cr[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "    avg_sem_is_cs[roi] = np.sqrt((np.power(congruencySigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(congruencySigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "roi = 'lpfc'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(times, avg_ir_cr[roi], label='repeat', color='blue', linestyle='-')\n",
    "ax.plot(times, avg_is_cs[roi], label='switch', color='blue', linestyle='--')\n",
    "\n",
    "ax.fill_between(times, avg_ir_cr[roi] - avg_sem_ir_cr[roi], avg_ir_cr[roi] + avg_sem_ir_cr[roi], alpha=0.2, color='blue')\n",
    "ax.fill_between(times, avg_is_cs[roi] - avg_sem_is_cs[roi], avg_is_cs[roi] + avg_sem_is_cs[roi], alpha=0.2, color='blue')\n",
    "\n",
    "# # Overlay a dotted vertical line at time = 0.5\n",
    "# ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "# Remove top and right borders\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "# Make the x and y ticks bigger\n",
    "ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make bar plots windowed from 0 to 1 s of my two conditions 4/9  \n",
    "greg wants to see these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'times' array is in seconds and you want to average from 0 to 1 second\n",
    "# Find indices corresponding to 0 and 1 seconds in the 'times' array\n",
    "start_index = np.where(times >= 0)[0][0]\n",
    "end_index = np.where(times <= 1)[0][-1]\n",
    "\n",
    "# Calculate mean and SEM for the specified time window for both conditions. Will need to run the cell to make avg_cr_cs and avg_ir_is though. 4/9\n",
    "windowed_cr_cs = np.mean(avg_cr_cs[roi][start_index:end_index+1])\n",
    "windowed_ir_is = np.mean(avg_ir_is[roi][start_index:end_index+1])\n",
    "\n",
    "sem_cr_cs = np.std(avg_cr_cs[roi][start_index:end_index+1], ddof=1) / np.sqrt(len(avg_cr_cs[roi][start_index:end_index+1]))\n",
    "sem_ir_is = np.std(avg_ir_is[roi][start_index:end_index+1], ddof=1) / np.sqrt(len(avg_ir_is[roi][start_index:end_index+1]))\n",
    "\n",
    "# Prepare data for plotting\n",
    "conditions = ['Congruent', 'Incongruent']\n",
    "means = [windowed_cr_cs, windowed_ir_is]\n",
    "sems = [sem_cr_cs, sem_ir_is]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Make bars skinnier by setting the width parameter\n",
    "bars = ax.bar(conditions, means, yerr=sems, capsize=10, color=['pink', 'red'], width=0.4)\n",
    "\n",
    "ax.set_ylabel('Z-score', fontsize=20)\n",
    "# Increase the font size for x-tick labels\n",
    "ax.set_xticklabels(conditions, fontsize=20)\n",
    "# Adjust y-ticks font size\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "ax.set_title('Average Z-score From Baseline (0 to 1s)', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'times' array is in seconds and you want to average from 0 to 1 second\n",
    "# Find indices corresponding to 0 and 1 seconds in the 'times' array\n",
    "start_index = np.where(times >= 0)[0][0]\n",
    "end_index = np.where(times <= 1)[0][-1]\n",
    "\n",
    "# Calculate mean and SEM for the specified time window for both conditions. Will need to run the cell to make avg_cr_cs and avg_ir_is though. 4/9\n",
    "windowed_ir_cr = np.mean(avg_ir_cr[roi][start_index:end_index+1])\n",
    "windowed_is_cs = np.mean(avg_is_cs[roi][start_index:end_index+1])\n",
    "\n",
    "sem_ir_cr = np.std(avg_ir_cr[roi][start_index:end_index+1], ddof=1) / np.sqrt(len(avg_ir_cr[roi][start_index:end_index+1]))\n",
    "sem_is_cs = np.std(avg_is_cs[roi][start_index:end_index+1], ddof=1) / np.sqrt(len(avg_is_cs[roi][start_index:end_index+1]))\n",
    "\n",
    "# Prepare data for plotting\n",
    "conditions = ['Repeat', 'Switch']\n",
    "means = [windowed_ir_cr, windowed_is_cs]\n",
    "sems = [sem_ir_cr, sem_is_cs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Make bars skinnier by setting the width parameter\n",
    "bars = ax.bar(conditions, means, yerr=sems, capsize=10, color=['lightblue', 'blue'], width=0.4)\n",
    "\n",
    "ax.set_ylabel('Z-score', fontsize=20)\n",
    "# Increase the font size for x-tick labels\n",
    "ax.set_xticklabels(conditions, fontsize=20)\n",
    "# Adjust y-ticks font size\n",
    "ax.tick_params(axis='y', labelsize=20)\n",
    "\n",
    "ax.set_title('Average Z-score From Baseline (0 to 1s)', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "congruency effect by switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Calculate the mean difference between conditions for the specified time window\n",
    "mean_diff_ir_cr = np.mean(diff_ir_cr[roi][start_index:end_index + 1])\n",
    "mean_diff_is_cs = np.mean(diff_is_cs[roi][start_index:end_index + 1])\n",
    "\n",
    "# Calculate the SEM for the differences\n",
    "sem_diff_ir_cr = np.std(diff_ir_cr[roi][start_index:end_index + 1], ddof=1) / np.sqrt(end_index + 1 - start_index)\n",
    "sem_diff_is_cs = np.std(diff_is_cs[roi][start_index:end_index + 1], ddof=1) / np.sqrt(end_index + 1 - start_index)\n",
    "\n",
    "# Prepare data for plotting\n",
    "conditions = ['IR - CR', 'IS - CS']\n",
    "means = [mean_diff_ir_cr, mean_diff_is_cs]\n",
    "sems = [sem_diff_ir_cr, sem_diff_is_cs]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "# Make bars skinnier by setting the width parameter\n",
    "bars = ax.bar(conditions, means, yerr=sems, capsize=10, color=['grey', 'black'], width=0.4)\n",
    "\n",
    "ax.set_ylabel('Z-score', fontsize=20)\n",
    "# Set x-tick labels with fontsize without explicitly calling set_xticklabels to avoid warning\n",
    "ax.set_xticks(range(len(conditions)))\n",
    "ax.set_xticklabels(conditions, fontsize=18)\n",
    "# Adjust y-ticks font size\n",
    "ax.tick_params(axis='y', labelsize=18)\n",
    "\n",
    "ax.set_title('Interaction Effect (0 to 1 second)', fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "four bar plots like the behavioral plot 4/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySwitchTypeInteractionSigElectrodesAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Example data retrieval for each condition\n",
    "# Assuming 'roi' is defined and you have similar data for each condition\n",
    "conditions = ['IR', 'IS', 'CR', 'CS']\n",
    "data_conditions = {\n",
    "    'IR': congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'],\n",
    "    'IS': congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'],\n",
    "    'CR': congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'],\n",
    "    'CS': congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "}\n",
    "\n",
    "# Assume rois list and congruencySwitchTypeInteractionSigElectrodesAverage data are defined\n",
    "# We're focusing on a single ROI for simplicity; you can adapt this for multiple ROIs\n",
    "roi = 'lpfc'  # Example ROI\n",
    "\n",
    "# Extract the average Z-scores and SEMs for each condition\n",
    "means = [\n",
    "    congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'],\n",
    "    congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'],\n",
    "    congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'],\n",
    "    congruencySwitchTypeInteractionSigElectrodesAverage[roi]['Stimulus_is_fixationCrossBase_1sec_mirror']\n",
    "]\n",
    "\n",
    "sems = [\n",
    "    congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'],\n",
    "    congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'],\n",
    "    congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'],\n",
    "    congruencySwitchTypeInteractionSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror']\n",
    "]\n",
    "\n",
    "# Reorder for grouped plotting: Repeat (CR, IR) and Switch (CS, IS)\n",
    "means_reordered = [means[0], means[2], means[1], means[3]]\n",
    "sems_reordered = [sems[0], sems[2], sems[1], sems[3]]\n",
    "colors = ['pink', 'pink', 'red', 'red']  # Repeat Congruent, Switch Congruent, Repeat Incongruent, Switch Incongruent\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "bar_width = 0.35  # Width of the bars\n",
    "index = np.arange(2)  # Two groups: Repeat and Switch\n",
    "\n",
    "# Plotting the bars for each group\n",
    "for i in range(4):\n",
    "    ax.bar(index[i // 2] + (i % 2 - 0.5) * bar_width, means_reordered[i], yerr=sems_reordered[i],\n",
    "           capsize=5, color=colors[i], width=bar_width, label=('Congruent' if i < 2 else 'Incongruent') if i % 2 == 0 else \"\")\n",
    "\n",
    "ax.set_ylabel('Average Z-score', fontsize=14)\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(['Repeat', 'Switch'], fontsize=14)\n",
    "ax.tick_params(axis='y', labelsize=14)\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))  # Remove duplicates\n",
    "ax.legend(by_label.values(), by_label.keys(), fontsize=14)\n",
    "\n",
    "ax.set_title('Average Z-score From Baseline by Condition and Type', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot individual electrodes for interaction effects\n",
    "i think this will just work regardless of the output names 3/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test this new plot significance function that offsets for each significance bar 4/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significance(ax, times, sig_effects, y_offset=0.1):\n",
    "    \"\"\"\n",
    "    Plot significance bars for the effects on top of the existing axes, adjusted for time windows.\n",
    "\n",
    "    Parameters:\n",
    "    - ax: The matplotlib Axes object to plot on.\n",
    "    - times: Array of time points for the x-axis.\n",
    "    - sig_effects: Dictionary with time windows as keys and lists of tuples (effect, p-value) as values.\n",
    "    - y_offset: The vertical offset between different time window significance bars.\n",
    "    \"\"\"\n",
    "    y_pos_base = ax.get_ylim()[1]  # Get the top y-axis limit to place significance bars\n",
    "\n",
    "    time_windows = {\n",
    "        'FirstHalfSecond': (0, 0.5),\n",
    "        'SecondHalfSecond': (0.5, 1),\n",
    "        'FullSecond': (0, 1)\n",
    "    }\n",
    "\n",
    "    window_offsets = {window: 0 for window in time_windows}  # Initialize offsets for each time window\n",
    "\n",
    "    # Sort time windows to ensure 'FullSecond' bars are plotted last (on top)\n",
    "    for time_window, effects in sorted(sig_effects.items(), key=lambda x: x[0] == 'FullSecond'):\n",
    "        base_y_pos = y_pos_base + y_offset * list(time_windows).index(time_window)\n",
    "        for effect, p_value in effects:\n",
    "            start_time, end_time = time_windows[time_window]\n",
    "            # Adjust y_pos based on how many bars have already been plotted in this window\n",
    "            y_pos = base_y_pos + y_offset * window_offsets[time_window]\n",
    "\n",
    "            # Update the color selection logic as per your requirement\n",
    "            color = 'black'  # Default color for unmatched conditions\n",
    "            if 'congruency' in effect:\n",
    "                color = 'red'\n",
    "            elif 'congruencyProportion' in effect:\n",
    "                color = 'green'\n",
    "            elif 'switchType' in effect:\n",
    "                color = 'blue'\n",
    "            elif 'switchProportion' in effect:\n",
    "                color = 'yellow'\n",
    "            elif 'congruency:congruencyProportion' in effect:\n",
    "                color = 'purple'\n",
    "            elif 'switchType:switchProportion' in effect:\n",
    "                color = 'yellowgreen'\n",
    "            elif 'congruency:switchType' in effect:\n",
    "                color = 'black'\n",
    "\n",
    "            num_asterisks = '*' * (1 if p_value < 0.05 else 2 if p_value < 0.01 else 3)\n",
    "            ax.plot([start_time, end_time], [y_pos, y_pos], color=color, lw=4)\n",
    "            ax.text((start_time + end_time) / 2, y_pos, num_asterisks, ha='center', va='bottom', color=color)\n",
    "\n",
    "            window_offsets[time_window] += 1  # Increment the offset for this time window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1):\n",
    "    \"\"\"\n",
    "    Plot significance bars for the effects on top of the existing axes, adjusted for time windows.\n",
    "\n",
    "    Parameters:\n",
    "    - ax: The matplotlib Axes object to plot on.\n",
    "    - times: Array of time points for the x-axis.\n",
    "    - sig_effects: Dictionary with time windows as keys and lists of tuples (effect, p-value) as values.\n",
    "    - y_offset: The vertical offset between different time window significance bars.\n",
    "    \"\"\"\n",
    "    y_pos_base = ax.get_ylim()[1]  # Get the top y-axis limit to place significance bars\n",
    "\n",
    "    time_windows = {\n",
    "        'FirstHalfSecond': (0, 0.5),\n",
    "        'SecondHalfSecond': (0.5, 1),\n",
    "        'FullSecond': (0, 1)\n",
    "    }\n",
    "\n",
    "    window_offsets = {window: 0 for window in time_windows}  # Initialize offsets for each time window\n",
    "\n",
    "    # Sort time windows to ensure 'FullSecond' bars are plotted last (on top)\n",
    "    for time_window, effects in sorted(sig_effects.items(), key=lambda x: x[0] == 'FullSecond'):\n",
    "        base_y_pos = y_pos_base + y_offset * list(time_windows).index(time_window)\n",
    "        y_pos = base_y_pos\n",
    "        for effect, p_value in effects:\n",
    "            if 'congruency:switchType' in effect:\n",
    "                start_time, end_time = time_windows[time_window]\n",
    "                # Adjust y_pos based on how many bars have already been plotted in this window\n",
    "                y_pos = base_y_pos + y_offset * window_offsets[time_window]\n",
    "\n",
    "                # Update the color selection logic as per your requirement\n",
    "                color = 'black'  # Default color for unmatched conditions\n",
    "\n",
    "                num_asterisks = '*' * (1 if p_value < 0.05 else 2 if p_value < 0.01 else 3)\n",
    "                ax.plot([start_time, end_time], [y_pos, y_pos], color=color, lw=4)\n",
    "                ax.text((start_time + end_time) / 2, y_pos, num_asterisks, ha='center', va='bottom', color=color)\n",
    "\n",
    "                window_offsets[time_window] += 1  # Increment the offset for this time window\n",
    "            else:\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "congruencySwitchTypeInteractionSigElectrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "channels = None\n",
    "\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    if os.name == 'nt':  # windows\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "    else:  # mac\n",
    "        LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                \"CoganLab\")\n",
    "\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times\n",
    "\n",
    "# # Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "# times = HG_ev1_evoke_rescaled_D0057_c.times  # Modify as needed to match your data\n",
    "\n",
    "# port over the plot_electrodes_grid_whole_brain_analysis here, but replace wherever the save name is wholebrainanalysis with the roi names. 3/25.\n",
    "def plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        for output_name in output_names:\n",
    "            color = plotting_parameters[output_name]['color']\n",
    "            line_style = plotting_parameters[output_name]['line_style']\n",
    "            ax.plot(times, data[output_name], label=f'{roi}_{output_name}', color=color, linestyle=line_style)\n",
    "            ax.fill_between(times, \n",
    "                            data[output_name] - np.std(data[output_name], ddof=1) / np.sqrt(len(data[output_name])),\n",
    "                            data[output_name] + np.std(data[output_name], ddof=1) / np.sqrt(len(data[output_name])), alpha=0.3)\n",
    "\n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Z-score')\n",
    "\n",
    "        # Retrieve significant effects for the current subject and electrode\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            # Adjust y_offset based on plotting needs. This used to not be assigned to a variable. 3/20.\n",
    "            plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test looping over subjects and electrodes as a function 4/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, roi, concatenated_trialAvg_data, output_names, grid_size, save_dir, save_name, times, plotting_parameters):\n",
    "    electrodes_data = []\n",
    "    electrode_counter = 0\n",
    "    grid_num = 0\n",
    "\n",
    "    # Load in significant effects structure\n",
    "    significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "    with open(significant_effects_structure_file_path, 'r') as file:\n",
    "        significant_effects_structure = json.load(file)\n",
    "\n",
    "    for sub in subjects:\n",
    "        if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "            for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "                electrode_data = {}\n",
    "                for output_name in output_names:\n",
    "                    # Ensure the index is correctly used here for your data structure\n",
    "                    electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "                electrodes_data.append((electrode_data, sub, electrode))\n",
    "                electrode_counter += 1\n",
    "                if len(electrodes_data) == grid_size:\n",
    "                    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                    electrodes_data = []  # Reset for the next grid\n",
    "                    grid_num += 1\n",
    "\n",
    "    # Plot remaining electrodes in the last grid\n",
    "    if electrodes_data:\n",
    "        plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'dlpfc', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'acc', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parietal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'parietal', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_electrodes_grid_roi_loop(subjects, sig_electrodes_per_subject_roi, 'lpfc', concatenated_trialAvg_data, output_names, 16, save_dir, save_name, times, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "awful godforsaken code to get individual electrode plots for congruency main effects, switch main effects, and interaction effects for lpfc 4/8  \n",
    "replace with function later after CNS...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAB_root = None\n",
    "channels = None\n",
    "\n",
    "if LAB_root is None:\n",
    "    HOME = os.path.expanduser(\"~\")\n",
    "    if os.name == 'nt':  # windows\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "    else:  # mac\n",
    "        LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                \"CoganLab\")\n",
    "\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "\n",
    "# Dynamically select the first subject and use it to extract times\n",
    "first_subject_id = next(iter(subjects_mne_objects))\n",
    "example_output_name = next(iter(subjects_mne_objects[first_subject_id]))\n",
    "times = subjects_mne_objects[first_subject_id][example_output_name]['HG_ev1_evoke_rescaled'].times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "\n",
    "def plot_electrodes_grid_roi_switchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate S and R for the electrode\n",
    "        avg_ir_cr = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "        avg_is_cs = (data['Stimulus_is_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "        # avg_sem_is_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "        # avg_sem_cr_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "        # Plotting S and R\n",
    "        ax.plot(times, avg_ir_cr, label='repeat', color='blue', linestyle='-')\n",
    "        ax.plot(times, avg_is_cs, label='switch', color='blue', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_electrodes_grid_roi_congruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate I-C for the electrode\n",
    "        avg_ir_is = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "        avg_cr_cs = (data['Stimulus_cr_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "        # avg_sem_is_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_ir_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cr_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "        # avg_sem_cr_cs = np.sqrt((np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_is_fixationCrossBase_1sec_mirror'], 2) + np.power(switchTypeSigElectrodesSEM[roi]['Stimulus_cs_fixationCrossBase_1sec_mirror'], 2)) / 2)\n",
    "\n",
    "        # Plotting I-C difference\n",
    "        ax.plot(times, avg_cr_cs, label='congruent', color='red', linestyle='-')\n",
    "        ax.plot(times, avg_ir_is, label='incongruent', color='red', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "\n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_electrodes_grid_roi_congruencyEffectSwitchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate congruency effect as a function of switch type for the electrode\n",
    "\n",
    "        avg_diff_ir_cr = data['Stimulus_ir_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "        avg_diff_is_cs = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "\n",
    "        ax.plot(times, avg_diff_ir_cr, label='IR - CR', color='black', linestyle='-')\n",
    "        ax.plot(times, avg_diff_is_cs, label='IS - CS', color='black', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1) #change back to plot_significance after poster 4/8\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def plot_electrodes_grid_roi_switchCostCongruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        # Calculate congruency effect as a function of switch type for the electrode\n",
    "\n",
    "        avg_diff_is_ir = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_ir_fixationCrossBase_1sec_mirror']\n",
    "        avg_diff_cs_cr = data['Stimulus_cs_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "\n",
    "        ax.plot(times, avg_diff_is_ir, label='IS - IR', color='black', linestyle='-')\n",
    "        ax.plot(times, avg_diff_cs_cr, label='CS - CR', color='black', linestyle='--')\n",
    "        \n",
    "        # Overlay a dotted vertical line at time = 0.5\n",
    "        ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "        # Remove top and right borders\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        \n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time from Stimulus Onset (s)')\n",
    "        ax.set_ylabel('Z-score From Baseline')\n",
    "\n",
    "        # Retrieve and plot significant effects\n",
    "        sig_effects = significant_effects_structure.get(sub, {}).get(electrode, {})\n",
    "        if sig_effects:\n",
    "            plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1) #change back to plot_significance after poster 4/8\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{save_name}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try this for lpfc 4/8  \n",
    "just for poster, clean this up!! this is hella hard-coded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySigElectrodesCongruencyComparison'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access congruencySigElectrodes for sub\n",
    "    # If sub is not a key, congruencySigElectrodes_for_sub will be None\n",
    "    congruencySigElectrodes_for_sub = congruencySigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if congruencySigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in congruencySigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_congruencySigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_congruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_congruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay now do individual for switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'switchTypeSigElectrodesSwitchTypeComparison'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access switchType for sub\n",
    "    # If sub is not a key, switchTypeSigElectrodes_for_sub will be None\n",
    "    switchTypeSigElectrodes_for_sub = switchTypeSigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if switchTypeSigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in switchTypeSigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_switchTypeSigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_switchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_switchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now do individual for interaction (congruency effect by switch type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySwitchTypeInteractionSigElectrodesSwitchTypeComparison'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access switchType for sub\n",
    "    # If sub is not a key, switchTypeSigElectrodes_for_sub will be None\n",
    "    congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if congruencySwitchTypeInteractionSigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in congruencySwitchTypeInteractionSigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_congruencyEffectSwitchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_congruencyEffectSwitchTypeWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now do individual for interaction (switch cost by congruency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "save_name = 'switchCostCongruencyInteractionSigElectrodes'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "for sub in subjects:\n",
    "\n",
    "    # Use .get() to safely access switchType for sub\n",
    "    # If sub is not a key, switchTypeSigElectrodes_for_sub will be None\n",
    "    congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "    # Check if congruencySigElectrodes_for_sub is None (i.e., if sub was not a key in congruencySigElectrodes)\n",
    "    if congruencySwitchTypeInteractionSigElectrodes_for_sub is None:\n",
    "        continue  # Skip this sub and move to the next one\n",
    "\n",
    "    # If we reach here, it means congruencySigElectrodes_for_sub is not None, and we can safely use it\n",
    "    for electrode in congruencySwitchTypeInteractionSigElectrodes_for_sub:\n",
    "        electrode_data = {}\n",
    "        for output_name in output_names:\n",
    "            electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_counter]\n",
    "\n",
    "        electrodes_data.append((electrode_data, sub, electrode))\n",
    "        electrode_counter += 1\n",
    "        if len(electrodes_data) == grid_size:\n",
    "            plot_electrodes_grid_roi_switchCostCongruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "            electrodes_data = []  # Reset for the next grid\n",
    "            grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi_switchCostCongruencyWithInteractionOutputNames(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "okay once we choose the electrodes we want, plot the single example electrode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_congruency(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "    avg_ir_is = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_is_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_cr_cs = (data['Stimulus_cr_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "    \n",
    "    ax.plot(times, avg_cr_cs, label='Congruent', color='red', linestyle='-')\n",
    "    ax.plot(times, avg_ir_is, label='Incongruent', color='red', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    # ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    # ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0063', 'RMMF13'\n",
    "roi = 'lpfc'\n",
    "electrode_index = 5 # right now just manually count this from the grid plot BUT make this real after CNS 4/9\n",
    "\n",
    "save_name = 'congruencySigElectrodesCongruencyComparison'\n",
    "congruencySigElectrodes_for_sub = congruencySigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_congruencySigElectrodes[roi][output_name][electrode_index]\n",
    "\n",
    "plot_single_electrode_data_congruency(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for switchType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_switchType(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "    avg_ir_cr = (data['Stimulus_ir_fixationCrossBase_1sec_mirror'] + data['Stimulus_cr_fixationCrossBase_1sec_mirror']) / 2\n",
    "    avg_is_cs = (data['Stimulus_is_fixationCrossBase_1sec_mirror'] + data['Stimulus_cs_fixationCrossBase_1sec_mirror']) / 2\n",
    "    \n",
    "    ax.plot(times, avg_ir_cr, label='Repeat', color='blue', linestyle='-')\n",
    "    ax.plot(times, avg_is_cs, label='Switch', color='blue', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    # ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    # ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0059', 'LMMF9'\n",
    "roi = 'lpfc'\n",
    "electrode_index = 1 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "\n",
    "save_name = 'switchTypeSigElectrodesCongruencyComparison'\n",
    "switchTypeSigElectrodes_for_sub = switchTypeSigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_switchTypeSigElectrodes[roi][output_name][electrode_index]\n",
    "\n",
    "plot_single_electrode_data_switchType(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for interaction effect, congruency effect by switch type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_interaction_effect(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "\n",
    "    avg_diff_ir_cr = data['Stimulus_ir_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "    avg_diff_is_cs = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_cs_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "    ax.plot(times, avg_diff_ir_cr, label='IR - CR', color='black', linestyle='-')\n",
    "    ax.plot(times, avg_diff_is_cs, label='IS - CS', color='black', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    # ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    # ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    # ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=24)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=24)  # Adjust y-axis tick label size\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0094', 'LFAI9'\n",
    "electrode_index = 8 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySwitchTypeInteractionSigElectrodesSwitchTypeComparison'\n",
    "congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_index]\n",
    "plot_single_electrode_data_interaction_effect(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interaction effect for switch cost by congruency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_single_electrode_data_interaction_effect(data, times, electrode, subject_id, sig_effects, save_dir, save_name):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))  # A more focused figure size\n",
    "\n",
    "    avg_diff_is_ir = data['Stimulus_is_fixationCrossBase_1sec_mirror'] - data['Stimulus_ir_fixationCrossBase_1sec_mirror']\n",
    "    avg_diff_cs_cr = data['Stimulus_cs_fixationCrossBase_1sec_mirror'] - data['Stimulus_cr_fixationCrossBase_1sec_mirror']\n",
    "\n",
    "    ax.plot(times, avg_diff_is_ir, label='IS - IR', color='black', linestyle='-')\n",
    "    ax.plot(times, avg_diff_cs_cr, label='CS - CR', color='black', linestyle='--')\n",
    "\n",
    "    # ax.axvline(x=0.5, color='k', linestyle='--', linewidth=1)\n",
    "    # Remove top and right borders\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    ax.set_xlabel('Time from Stimulus Onset (s)', fontsize=20)\n",
    "    ax.set_ylabel('Z-score Difference', fontsize=20)\n",
    "    ax.legend(fontsize=20, loc='upper left')\n",
    "\n",
    "    # Make the x and y ticks bigger\n",
    "    ax.tick_params(axis='x', labelsize=20)  # Adjust x-axis tick label size\n",
    "    ax.tick_params(axis='y', labelsize=20)  # Adjust y-axis tick label size\n",
    "\n",
    "    # Incorporate significance plotting\n",
    "    if sig_effects:\n",
    "        plot_significance_justInteraction_delete_after_poster(ax, times, sig_effects, y_offset=0.1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_dir and save_name:\n",
    "        fig.savefig(os.path.join(save_dir, f'{save_name}_{subject_id}_{electrode}.png'))\n",
    "    plt.close(fig)\n",
    "\n",
    "# Example usage setup\n",
    "sub, example_elec = 'D0094', 'LFAI9'\n",
    "electrode_index = 8 # right now just manually get this from the grid plot BUT make this real after CNS 4/9\n",
    "roi = 'lpfc'\n",
    "save_name = 'congruencySwitchTypeInteractionSigElectrodesSwitchTypeComparison'\n",
    "congruencySwitchTypeInteractionSigElectrodes_for_sub = congruencySwitchTypeInteractionSigElectrodes.get(sub)\n",
    "\n",
    "# Load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'congruency_switchType_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# Extract significant effects for the specific electrode and subject\n",
    "sig_effects = significant_effects_structure.get(sub, {}).get(example_elec, {})\n",
    "\n",
    "electrode_data = {}\n",
    "for output_name in output_names:\n",
    "    electrode_data[output_name] = concatenated_trialAvg_data_congruencySwitchTypeInteractionSigElectrodes[roi][output_name][electrode_index]\n",
    "plot_single_electrode_data_interaction_effect(electrode_data, times, example_elec, sub, sig_effects, save_dir, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old way of looping without a function 4/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'dlpfc'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# DUDE MAKE THE SIG ELECTRODES PER SUBJECT INTO A DICTIONARY. Bad code is bad.\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'acc'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# DUDE MAKE THE SIG ELECTRODES PER SUBJECT INTO A DICTIONARY. Bad code is bad.\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parietal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'parietal'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "# DUDE MAKE THE SIG ELECTRODES PER SUBJECT INTO A DICTIONARY. Bad code is bad.\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lpfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "roi = 'lpfc'\n",
    "if 'Stimulus_c25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_congruencyProportion' # i think this will be congruency x con prop if i load in c25?\n",
    "elif 'Stimulus_s25_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'switchType_switchProportion' # i think if there's no c25, but there is s25, then i am doing switch x switch prop? 3/17\n",
    "elif 'Stimulus_cr_fixationCrossBase_1sec_mirror' in output_names:\n",
    "    save_name = 'congruency_switchType'\n",
    "\n",
    "# load in significant effects structure\n",
    "significant_effects_structure_file_path = os.path.join(save_dir, f'{save_name}_ANOVAwithinElectrodes_significantEffectsStructure_{roi}.txt')\n",
    "with open(significant_effects_structure_file_path, 'r') as file:\n",
    "    significant_effects_structure = json.load(file)\n",
    "\n",
    "for sub in subjects:\n",
    "    if sub in sig_electrodes_per_subject_roi[roi]:\n",
    "        for electrode in sig_electrodes_per_subject_roi[roi][sub]:\n",
    "            \n",
    "            electrode_data = {}\n",
    "            for output_name in output_names:\n",
    "                electrode_data[output_name] = concatenated_trialAvg_data[roi][output_name][electrode_counter]\n",
    "\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid_roi(electrodes_data, significant_effects_structure, grid_num, roi, output_names, times, save_dir, save_name, plotting_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
