{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Example of High Gamma Filter\n",
        "\n",
        "Below is a code sample for extracting high gamma power from a raw data file, followed by permutation cluster stats on that high gamma power data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 199,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import ieeg.viz.utils\n",
        "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, outliers_to_nan\n",
        "from ieeg.io import raw_from_layout, get_data\n",
        "from ieeg.timefreq.utils import crop_pad\n",
        "from ieeg.calc import stats, scaling\n",
        "from ieeg.process import parallelize\n",
        "from ieeg.timefreq import gamma\n",
        "from ieeg.calc.scaling import rescale\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "from bids import BIDSLayout\n",
        "import mne\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 200,
      "metadata": {},
      "outputs": [],
      "source": [
        "def relabel_axes(old_min, old_max, new_min, new_max):\n",
        "    scale = (new_max - new_min) / (old_max - old_min)\n",
        "\n",
        "    def format_func(value, tick_number):\n",
        "        return new_min + value * scale\n",
        "\n",
        "    plt.gca().xaxis.set_major_formatter(ticker.FuncFormatter(format_func))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### grab the data and set up variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "LAB_root = \"D:\\Box\\Box\\CoganLab\" #this is just for jims pc, delete this if using on another computer\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "for sub in subjects:\n",
        "\n",
        "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                            extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "    if not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "    # do filtering now\n",
        "    ## Crop raw data to minimize processing time\n",
        "    good = crop_empty_data(filt)\n",
        "\n",
        "    ## remove bad channels\n",
        "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "    good.drop_channels(good.info['bads'])\n",
        "    good.load_data()\n",
        "\n",
        "    # CAR\n",
        "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "    # make baseline \n",
        "    # make stimulus baseline EpochsTFR\n",
        "    times=[-1, 0.5]\n",
        "    trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10) #this removes trial outliers BUT breaks the shape because different stimulus epochs will then have different trial numbers\n",
        "    HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "    data_dict = {}  # make something to store all the outputs\n",
        "\n",
        "    for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "        times = [None, None]\n",
        "        times[0] = t[0] - 0.5\n",
        "        times[1] = t[1] + 0.5\n",
        "        trials = trial_ieeg(good, event, times, preload=True)\n",
        "        outliers_to_nan(trials, outliers=10)\n",
        "        HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "        crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "        HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore')\n",
        "        # HG_ev1.resample(100)\n",
        "        # HG_ev1.filenames = good.filenames\n",
        "\n",
        "        # Store the variable in the dictionary with the desired name\n",
        "        data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "        data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "        \n",
        "    resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "    stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "    # Plot the evoked data\n",
        "    fig = resp_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "    fig.savefig(save_dir + '_HG_ev1_Response_rescaled_zscore_no_outliers.png')\n",
        "\n",
        "    fig = stim_evoke_rescaled.plot(unit=False, scalings=dict(sEEG=1))  # 1 because z-score is unit-less and requires no scaling\n",
        "    fig.savefig(save_dir + '_HG_ev1_Stimulus_rescaled_zscore_no_outliers.png')\n",
        "\n",
        "    # decimate for stats\n",
        "    resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "    stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "    HG_base.decimate(2)\n",
        "    resp.decimate(2)\n",
        "    stim.decimate(2)\n",
        "\n",
        "    # do permutation cluster\n",
        "    resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "                                n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "                                n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "    \n",
        "    # plot stats\n",
        "    plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "    plt.imshow(stim_mask, aspect='auto')  # hold on from matlab\n",
        "    relabel_axes(0, 2500, -1000, 1500)\n",
        "    plt.savefig(save_dir + '_stimulus_stats_big.png', dpi=300)\n",
        "\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    plt.imshow(resp_mask, aspect='auto')\n",
        "    relabel_axes(0, 2500, -1000, 1500)\n",
        "    plt.savefig(save_dir + '_response_stats_big.png', dpi=300)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'derivatives/clean': BIDS Layout: ...alLocal\\BIDS\\derivatives\\clean | Subjects: 6 | Sessions: 0 | Runs: 24}"
            ]
          },
          "execution_count": 204,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layout.derivatives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### for testing with a single subject"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "# get box directory depending on OS\n",
        "if os.name == 'nt': # windows\n",
        "    LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
        "else: # mac\n",
        "    LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
        "\n",
        "layout = get_data(\"GlobalLocal\", root=LAB_root)\n",
        "\n",
        "\n",
        "\n",
        "print(layout.derivatives)\n",
        "print(layout.derivatives.keys())\n",
        "\n",
        "# raw = raw_from_layout(layout, subject=sub,\n",
        "#                         extension='.edf', preload=True)\n",
        "subjects = layout.get(return_type=\"id\", target=\"subject\")\n",
        "sub = 'D0059'\n",
        "\n",
        "filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
        "                        extension='.edf', desc='clean', preload=False) #get line-noise filtered data\n",
        "\n",
        "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "\n",
        "# do filtering now\n",
        "## Crop raw data to minimize processing time\n",
        "good = crop_empty_data(filt)\n",
        "\n",
        "## remove bad channels\n",
        "good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
        "good.drop_channels(good.info['bads'])\n",
        "good.load_data()\n",
        "\n",
        "# CAR\n",
        "ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
        "good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
        "\n",
        "\n",
        "# make baseline \n",
        "# make stimulus baseline EpochsTFR\n",
        "times=[-1, 0.5]\n",
        "\n",
        "trials = trial_ieeg(good, \"Stimulus\", times, preload=True)\n",
        "outliers_to_nan(trials, outliers=10)\n",
        "HG_base = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "crop_pad(HG_base, \"0.5s\")\n",
        "\n",
        "data_dict = {}  # Create an empty dictionary\n",
        "\n",
        "for event, t in zip((\"Stimulus\", \"Response\"), ((-1, 1.5), (-1, 1.5))):\n",
        "    times = [None, None]\n",
        "    times[0] = t[0] - 0.5\n",
        "    times[1] = t[1] + 0.5\n",
        "    trials = trial_ieeg(good, event, times, preload=True)\n",
        "    outliers_to_nan(trials, outliers=10)\n",
        "    HG_ev1 = gamma.extract(trials, copy=False, n_jobs=1)\n",
        "    crop_pad(HG_ev1, \"0.5s\")\n",
        "\n",
        "    HG_ev1_rescaled = rescale(HG_ev1, HG_base, copy=True, mode='zscore') #removed .average() part. Check with Aaron if this is okay.\n",
        "    # HG_ev1.resample(100)\n",
        "    # HG_ev1.filenames = good.filenames\n",
        "\n",
        "    # Store the variable in the dictionary with the desired name\n",
        "    data_dict[f\"HG_ev1_{event}\"] = HG_ev1\n",
        "    data_dict[f\"HG_ev1_{event}_rescaled\"] = HG_ev1_rescaled\n",
        "\n",
        "resp_evoke = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "resp_evoke_rescaled = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "stim_evoke_rescaled = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=0))\n",
        "\n",
        "# this is broken cuz it's trying to use the .average method from mne that has shape requirements\n",
        "# resp_evoke_channel_avg = data_dict[\"HG_ev1_Response\"].average(method=lambda x: np.nanmean(x, axis=(0, 1)))\n",
        "# resp_evoke_rescaled_channel_avg = data_dict[\"HG_ev1_Response_rescaled\"].average(method=lambda x: np.nanmean(x, axis=(0, 1)))\n",
        "# stim_evoke_channel_avg = data_dict[\"HG_ev1_Stimulus\"].average(method=lambda x: np.nanmean(x, axis=(0, 1)))\n",
        "# stim_evoke_rescaled_channel_avg = data_dict[\"HG_ev1_Stimulus_rescaled\"].average(method=lambda x: np.nanmean(x, axis=(0, 1)))\n",
        "\n",
        "# # # Manually interpolate NaN values\n",
        "# resp_evoke.data = np.where(np.isnan(resp_evoke.data), np.interp(resp_evoke.times, resp_evoke.times[~np.isnan(resp_evoke.data[0])], resp_evoke.data[0, ~np.isnan(resp_evoke.data[0])]), resp_evoke.data)\n",
        "\n",
        "# # Exclude time points with NaN values\n",
        "# valid_time_points = ~np.isnan(resp_evoke.data[0])  # Filter time points without NaNs\n",
        "# resp_evoke = resp_evoke.crop(tmin=resp_evoke.times[valid_time_points][0], tmax=resp_evoke.times[valid_time_points][-1])\n",
        "\n",
        "# Plot the evoked data\n",
        "fig = resp_evoke_rescaled.plot()\n",
        "# fig.add_channels([resp_evoke_rescaled_channel_avg])\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Response_rescaled_zscore_test.png')\n",
        "\n",
        "fig = stim_evoke_rescaled.plot()\n",
        "# fig.add_channels([stim_evoke_rescaled_channel_avg])\n",
        "\n",
        "fig.savefig(save_dir + '_HG_ev1_Stimulus_rescaled_zscore_test.png')\n",
        "\n",
        "# decimate for stats\n",
        "resp = data_dict[\"HG_ev1_Response\"] #i think it shouldn't be the rescaled data because that is already divided by baseline, right? So it shouldn't be significantly different than baseline.\n",
        "stim = data_dict[\"HG_ev1_Stimulus\"]\n",
        "HG_base.decimate(2)\n",
        "resp.decimate(2)\n",
        "stim.decimate(2)\n",
        "\n",
        "# import scipy\n",
        "resp_mask = stats.time_perm_cluster(resp._data, HG_base._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "stim_mask = stats.time_perm_cluster(stim._data, HG_base._data, 0.05, axis=0,\n",
        "                            n_perm=1000, n_jobs=6, ignore_adjacency=1)\n",
        "\n",
        "# plot stats\n",
        "plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "plt.imshow(stim_mask, aspect='auto')\n",
        "# hold on from matlab\n",
        "# plt.imshow(x) #plot multiple things like this\n",
        "\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_stimulus_stats_big.png', dpi=300)\n",
        "\n",
        "plt.figure(figsize=(16, 8))  # Adjust the width and height as needed\n",
        "plt.imshow(resp_mask, aspect='auto')\n",
        "relabel_axes(0, 2500, -1000, 1500)\n",
        "plt.savefig(save_dir + '_response_stats_big.png', dpi=300)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'EvokedArray' object has no attribute 'duration'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[202], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m resp_evoke_rescaled\u001b[39m.\u001b[39;49mduration\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'EvokedArray' object has no attribute 'duration'"
          ]
        }
      ],
      "source": [
        "resp_evoke_rescaled.duration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
