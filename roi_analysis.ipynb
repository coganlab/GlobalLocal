{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.path)\n",
    "sys.path.append(\"C:/Users/jz421/Desktop/GlobalLocal/IEEG_Pipelines/\") #need to do this cuz otherwise ieeg isn't added to path...\n",
    "\n",
    "from ieeg.navigate import channel_outlier_marker, trial_ieeg, crop_empty_data, \\\n",
    "    outliers_to_nan\n",
    "from ieeg.io import raw_from_layout, get_data\n",
    "from ieeg.timefreq.utils import crop_pad\n",
    "from ieeg.timefreq import gamma\n",
    "from ieeg.calc.scaling import rescale\n",
    "import mne\n",
    "import os\n",
    "import numpy as np\n",
    "from ieeg.calc.reshape import make_data_same\n",
    "from ieeg.calc.stats import time_perm_cluster\n",
    "from ieeg.viz.mri import gen_labels\n",
    "\n",
    "from misc_functions import calculate_RTs, save_channels_to_file, save_sig_chans, load_sig_chans\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict, defaultdict\n",
    "import json\n",
    "from misc_functions import load_sig_chans, channel_names_to_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the outer dictionary.\n",
    "subjects_electrodestoROIs_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### make subjects rois to electrodes dict. Don't need to run this more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['D0057','D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
    "\n",
    "for sub in subjects:\n",
    "    # sub = 'D0059'\n",
    "    task = 'GlobalLocal'\n",
    "    output_name = \"Response_fixationCrossBase_1sec_mirror\"\n",
    "    events = [\"Response\"]\n",
    "    times = (-1,1.5)\n",
    "    base_times = [-1,0]\n",
    "    LAB_root = None\n",
    "    channels = None\n",
    "    full_trial_base = False\n",
    "\n",
    "\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        if os.name == 'nt':  # windows\n",
    "            LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\")\n",
    "        else:  # mac\n",
    "            LAB_root = os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\",\n",
    "                                    \"CoganLab\")\n",
    "\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    filt = raw_from_layout(layout.derivatives['derivatives/clean'], subject=sub,\n",
    "                        extension='.edf', desc='clean', preload=False)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    good = crop_empty_data(filt)\n",
    "    # %%\n",
    "\n",
    "    print(f\"good channels before dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels before dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.info['bads'] = channel_outlier_marker(good, 3, 2)\n",
    "    print(\"Bad channels in 'good':\", good.info['bads'])\n",
    "\n",
    "    filt.drop_channels(good.info['bads'])  # this has to come first cuz if you drop from good first, then good.info['bads'] is just empty\n",
    "    good.drop_channels(good.info['bads'])\n",
    "\n",
    "    print(\"Bad channels in 'good' after dropping once:\", good.info['bads'])\n",
    "\n",
    "    print(f\"good channels after dropping bads: {len(good.ch_names)}\")\n",
    "    print(f\"filt channels after dropping bads: {len(filt.ch_names)}\")\n",
    "\n",
    "    good.load_data()\n",
    "\n",
    "    # If channels is None, use all channels\n",
    "    if channels is None:\n",
    "        channels = good.ch_names\n",
    "    else:\n",
    "        # Validate the provided channels\n",
    "        invalid_channels = [ch for ch in channels if ch not in good.ch_names]\n",
    "        if invalid_channels:\n",
    "            raise ValueError(\n",
    "                f\"The following channels are not valid: {invalid_channels}\")\n",
    "\n",
    "        # Use only the specified channels\n",
    "        good.pick_channels(channels)\n",
    "\n",
    "    ch_type = filt.get_channel_types(only_data_chs=True)[0]\n",
    "    good.set_eeg_reference(ref_channels=\"average\", ch_type=ch_type)\n",
    "\n",
    "    default_dict = gen_labels(good.info)\n",
    "    \n",
    "    # Create rawROI_dict for the subject\n",
    "    rawROI_dict = defaultdict(list)\n",
    "    for key, value in default_dict.items():\n",
    "        rawROI_dict[value].append(key)\n",
    "    rawROI_dict = dict(rawROI_dict)\n",
    "\n",
    "    # Filter out keys containing \"White-Matter\"\n",
    "    filtROI_dict = {key: value for key, value in rawROI_dict.items() if \"White-Matter\" not in key}\n",
    "\n",
    "    # Store the dictionaries in the subjects dictionary\n",
    "    subjects_electrodestoROIs_dict[sub] = {\n",
    "        'default_dict': dict(default_dict),\n",
    "        'rawROI_dict': dict(rawROI_dict),\n",
    "        'filtROI_dict': dict(filtROI_dict)\n",
    "    }\n",
    "\n",
    "\n",
    "# Save to a JSON file\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "with open(filename, 'w') as file:\n",
    "    json.dump(subjects_electrodestoROIs_dict, file, indent=4)\n",
    "\n",
    "print(f\"Saved subjects_dict to {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load subjects electrodes to rois dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from a JSON file\n",
    "filename = 'subjects_electrodestoROIs_dict.json'\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    subjects_electrodestoROIs_dict = json.load(file)\n",
    "\n",
    "print(f\"Loaded data from {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load high gamma data so we can do roi analysis on it\n",
    "once we have more subjects, turn this into a function and loop over all subjects.  \n",
    "this code is a crime against humanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_mne_objects(sub, output_name, task, LAB_root=None):\n",
    "    \"\"\"\n",
    "    Load MNE objects for a given subject and output name.\n",
    "\n",
    "    Parameters:\n",
    "    - sub (str): Subject identifier.\n",
    "    - output_name (str): Output name used in the file naming.\n",
    "    - task (str): Task identifier.\n",
    "    - LAB_root (str, optional): Root directory for the lab. If None, it will be determined based on the OS.\n",
    "\n",
    "    Returns:\n",
    "    A dictionary containing loaded MNE objects.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine LAB_root based on the operating system\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "    \n",
    "    # Ensure save directory exists\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    # Define file paths\n",
    "    HG_ev1_file = f'{save_dir}/{sub}_{output_name}_HG_ev1-epo.fif'\n",
    "    HG_base_file = f'{save_dir}/{sub}_{output_name}_HG_base-epo.fif'\n",
    "    HG_ev1_rescaled_file = f'{save_dir}/{sub}_{output_name}_HG_ev1_rescaled-epo.fif'\n",
    "\n",
    "    # Load the objects\n",
    "    HG_ev1 = mne.read_epochs(HG_ev1_file)\n",
    "    HG_base = mne.read_epochs(HG_base_file)\n",
    "    HG_ev1_rescaled = mne.read_epochs(HG_ev1_rescaled_file)\n",
    "    HG_ev1_evoke = HG_ev1.average(method=lambda x: np.nanmean(x, axis=0))\n",
    "    HG_ev1_evoke_rescaled = HG_ev1_rescaled.average(method=lambda x: np.nanmean(x, axis=0))\n",
    "\n",
    "    return {\n",
    "        'HG_ev1': HG_ev1,\n",
    "        'HG_base': HG_base,\n",
    "        'HG_ev1_rescaled': HG_ev1_rescaled,\n",
    "        'HG_ev1_evoke': HG_ev1_evoke,\n",
    "        'HG_ev1_evoke_rescaled': HG_ev1_evoke_rescaled\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "# sub = 'D0057'\n",
    "# output_name = \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\"\n",
    "# task = 'GlobalLocal'\n",
    "loaded_objects_D0057_i = load_mne_objects('D0057', \"Stimulus_c25_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "loaded_objects_D0057_c = load_mne_objects('D0057', \"Stimulus_c75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "# loaded_objects_D0059_i = load_mne_objects('D0059', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "# loaded_objects_D0059_c = load_mne_objects('D0059', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "# loaded_objects_D0063_i = load_mne_objects('D0063', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "# loaded_objects_D0063_c = load_mne_objects('D0063', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "# loaded_objects_D0065_i = load_mne_objects('D0065', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "# loaded_objects_D0065_c = load_mne_objects('D0065', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "# loaded_objects_D0069_i = load_mne_objects('D0069', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "# loaded_objects_D0069_c = load_mne_objects('D0069', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "# loaded_objects_D0071_i = load_mne_objects('D0071', \"Stimulus_i25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "# loaded_objects_D0071_c = load_mne_objects('D0071', \"Stimulus_c25and75_fixationCrossBase_1sec_mirror\", 'GlobalLocal')\n",
    "\n",
    "\n",
    "# Access the objects\n",
    "HG_ev1_D0057_i = loaded_objects_D0057_i['HG_ev1']\n",
    "HG_base_D0057_i = loaded_objects_D0057_i['HG_base']\n",
    "HG_ev1_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_i = loaded_objects_D0057_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "HG_ev1_D0057_c = loaded_objects_D0057_c['HG_ev1']\n",
    "HG_base_D0057_c = loaded_objects_D0057_c['HG_base']\n",
    "HG_ev1_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_rescaled']\n",
    "HG_ev1_evoke_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke']\n",
    "HG_ev1_evoke_rescaled_D0057_c = loaded_objects_D0057_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0059_i = loaded_objects_D0059_i['HG_ev1']\n",
    "# HG_base_D0059_i = loaded_objects_D0059_i['HG_base']\n",
    "# HG_ev1_rescaled_D0059_i = loaded_objects_D0059_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0059_i = loaded_objects_D0059_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0059_i = loaded_objects_D0059_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0059_c = loaded_objects_D0059_c['HG_ev1']\n",
    "# HG_base_D0059_c = loaded_objects_D0059_c['HG_base']\n",
    "# HG_ev1_rescaled_D0059_c = loaded_objects_D0059_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0059_c = loaded_objects_D0059_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0059_c = loaded_objects_D0059_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0063_i = loaded_objects_D0063_i['HG_ev1']\n",
    "# HG_base_D0063_i = loaded_objects_D0063_i['HG_base']\n",
    "# HG_ev1_rescaled_D0063_i = loaded_objects_D0063_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0063_i = loaded_objects_D0063_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0063_i = loaded_objects_D0063_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0063_c = loaded_objects_D0063_c['HG_ev1']\n",
    "# HG_base_D0063_c = loaded_objects_D0063_c['HG_base']\n",
    "# HG_ev1_rescaled_D0063_c = loaded_objects_D0063_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0063_c = loaded_objects_D0063_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0063_c = loaded_objects_D0063_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0065_i = loaded_objects_D0065_i['HG_ev1']\n",
    "# HG_base_D0065_i = loaded_objects_D0065_i['HG_base']\n",
    "# HG_ev1_rescaled_D0065_i = loaded_objects_D0065_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0065_i = loaded_objects_D0065_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0065_i = loaded_objects_D0065_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0065_c = loaded_objects_D0065_c['HG_ev1']\n",
    "# HG_base_D0065_c = loaded_objects_D0065_c['HG_base']\n",
    "# HG_ev1_rescaled_D0065_c = loaded_objects_D0065_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0065_c = loaded_objects_D0065_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0065_c = loaded_objects_D0065_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0069_i = loaded_objects_D0069_i['HG_ev1']\n",
    "# HG_base_D0069_i = loaded_objects_D0069_i['HG_base']\n",
    "# HG_ev1_rescaled_D0069_i = loaded_objects_D0069_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0069_i = loaded_objects_D0069_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0069_i = loaded_objects_D0069_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0069_c = loaded_objects_D0069_c['HG_ev1']\n",
    "# HG_base_D0069_c = loaded_objects_D0069_c['HG_base']\n",
    "# HG_ev1_rescaled_D0069_c = loaded_objects_D0069_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0069_c = loaded_objects_D0069_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0069_c = loaded_objects_D0069_c['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0071_i = loaded_objects_D0071_i['HG_ev1']\n",
    "# HG_base_D0071_i = loaded_objects_D0071_i['HG_base']\n",
    "# HG_ev1_rescaled_D0071_i = loaded_objects_D0071_i['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0071_i = loaded_objects_D0071_i['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0071_i = loaded_objects_D0071_i['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# HG_ev1_D0071_c = loaded_objects_D0071_c['HG_ev1']\n",
    "# HG_base_D0071_c = loaded_objects_D0071_c['HG_base']\n",
    "# HG_ev1_rescaled_D0071_c = loaded_objects_D0071_c['HG_ev1_rescaled']\n",
    "# HG_ev1_evoke_D0071_c = loaded_objects_D0071_c['HG_ev1_evoke']\n",
    "# HG_ev1_evoke_rescaled_D0071_c = loaded_objects_D0071_c['HG_ev1_evoke_rescaled']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load evoked and stuff for all subjects in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "def create_subjects_mne_objects_dict(subjects, output_names, task, LAB_root=None):\n",
    "    subjects_mne_objects = {}\n",
    "\n",
    "    for sub in subjects:\n",
    "        print(f\"Loading data for subject: {sub}\")  # Debugging print\n",
    "        sub_mne_objects = {}\n",
    "        for output_name in output_names:\n",
    "            print(f\"  Loading output: {output_name}\")  # Debugging print\n",
    "            mne_objects = load_mne_objects(sub, output_name, task, LAB_root)\n",
    "\n",
    "            # Debugging prints for data shapes\n",
    "            print(f\"    HG_ev1 shape: {mne_objects['HG_ev1'].get_data().shape}\")\n",
    "            print(f\"    HG_base shape: {mne_objects['HG_base'].get_data().shape}\")\n",
    "            print(f\"    HG_ev1_rescaled shape: {mne_objects['HG_ev1_rescaled'].get_data().shape}\")\n",
    "            print(f\"    HG_ev1_evoke shape: {mne_objects['HG_ev1_evoke'].data.shape}\")\n",
    "            print(f\"    HG_ev1_evoke_rescaled shape: {mne_objects['HG_ev1_evoke_rescaled'].data.shape}\")\n",
    "\n",
    "            sub_mne_objects[output_name] = mne_objects\n",
    "        subjects_mne_objects[sub] = sub_mne_objects\n",
    "\n",
    "    return subjects_mne_objects\n",
    "\n",
    "# Example usage\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
    "output_names = [\"Stimulus_i25_fixationCrossBase_1sec_mirror\", \"Stimulus_i75_fixationCrossBase_1sec_mirror\"]\n",
    "task = 'GlobalLocal'\n",
    "\n",
    "subjects_mne_objects = create_subjects_mne_objects_dict(subjects, output_names, task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjects_mne_objects['D0057'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])\n",
    "print(subjects_mne_objects['D0059'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])\n",
    "print(subjects_mne_objects['D0063'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])\n",
    "print(subjects_mne_objects['D0065'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load stimulus significant channels. Compare ROI electrodes in next cell to these to see if they're included.\n",
    "\n",
    "maybe do response significant channels too/instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_chans(sub, task, LAB_root=None):\n",
    "    # Determine LAB_root based on the operating system\n",
    "    if LAB_root is None:\n",
    "        HOME = os.path.expanduser(\"~\")\n",
    "        LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "    # Get data layout\n",
    "    layout = get_data(task, root=LAB_root)\n",
    "    save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs', sub)\n",
    "\n",
    "    stim_filename = f'{save_dir}\\\\sig_chans_{sub}_Stimulus_fixationCrossBase_1sec_mirror.json'\n",
    "    stim_sig_chans = load_sig_chans(stim_filename)\n",
    "    return stim_sig_chans\n",
    "\n",
    "\n",
    "# List of subjects\n",
    "subjects = ['D0057', 'D0059', 'D0063', 'D0065', 'D0069', 'D0071']\n",
    "\n",
    "# Initialize an empty dictionary to store significant channels per subject\n",
    "sig_chans_per_subject = {}\n",
    "\n",
    "# Populate the dictionary using get_sig_chans for each subject\n",
    "for sub in subjects:\n",
    "    sig_chans_per_subject[sub] = get_sig_chans(sub, 'GlobalLocal')\n",
    "\n",
    "# Now sig_chans_per_subject dictionary is populated with significant channels for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the significant electrodes across subjects for each ROI of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dlPFC based on Yamagishi et al 2016 definition is G_front_middle, G_front_sup, S_front_inf, S_front_middle, S_front_sup\n",
    "ACC based on Destrieux et al 2010 definition is G_and_S_cingul-Ant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_electrodes_by_roi(subjects_electrodes_dict, sig_chans_per_subject, roi_list):\n",
    "    \"\"\"\n",
    "    Filters electrodes based on specified ROIs and returns significant electrodes for each subject.\n",
    "\n",
    "    Args:\n",
    "    subjects_electrodes_dict (dict): A dictionary with subjects as keys and electrode-to-ROI mappings as values.\n",
    "    sig_chans_per_subject (dict): A dictionary with subjects as keys and lists of significant channels as values.\n",
    "    roi_list (list): A list of ROIs to filter electrodes.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with subjects as keys and lists of significant electrodes in specified ROIs as values.\n",
    "    \"\"\"\n",
    "    filtered_electrodes_per_subject = {}\n",
    "\n",
    "    for sub, electrodes_dict in subjects_electrodes_dict.items():\n",
    "        filtered = {key: value for key, value in electrodes_dict['filtROI_dict'].items() \n",
    "                    if any(roi in key for roi in roi_list)}\n",
    "\n",
    "        # Aggregate electrodes into a list for each subject\n",
    "        filtered_electrodes = []\n",
    "        for electrodes in filtered.values():\n",
    "            filtered_electrodes.extend(electrodes)\n",
    "\n",
    "        filtered_electrodes_per_subject[sub] = filtered_electrodes\n",
    "        print(f'For subject {sub}, {\", \".join(roi_list)} electrodes are: {filtered_electrodes}')\n",
    "\n",
    "    # Now filter for significant electrodes\n",
    "    sig_filtered_electrodes_per_subject = {}\n",
    "\n",
    "    for sub, filtered_electrodes in filtered_electrodes_per_subject.items():\n",
    "        # Retrieve the list of significant channels for the subject\n",
    "        sig_chans = sig_chans_per_subject.get(sub, [])\n",
    "\n",
    "        # Find the intersection of filtered electrodes and significant channels for the subject\n",
    "        sig_filtered_electrodes = [elec for elec in filtered_electrodes if elec in sig_chans]\n",
    "\n",
    "        # Store the significant filtered electrodes for the subject\n",
    "        sig_filtered_electrodes_per_subject[sub] = sig_filtered_electrodes\n",
    "        print(f\"Subject {sub} significant {', '.join(roi_list)} electrodes: {sig_filtered_electrodes}\")\n",
    "\n",
    "    return filtered_electrodes_per_subject, sig_filtered_electrodes_per_subject\n",
    "\n",
    "# Example usage:\n",
    "dlpfc_rois = [\"G_front_middle\", \"G_front_sup\", \"S_front_inf\", \"S_front_middle\", \"S_front_sup\"] #dorsolateral prefrontal cortex\n",
    "acc_rois = [\"G_and_S_cingul-Ant\", \"G_and_S_cingul-Mid-Ant\"] #anterior cingulate cortex\n",
    "parietal_rois = [\"G_parietal_sup\", \"S_intrapariet_and_P_trans\", \"G_pariet_inf-Angular\", \"G_pariet_inf-Supramar\"] #superior parietal lobule, intraparietal sulcus, and inferior parietal lobule (split into angular gyrus and supramarginal gyrus)\n",
    "dlpfc_electrodes_per_subject, sig_dlpfc_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, dlpfc_rois)\n",
    "acc_electrodes_per_subject, sig_acc_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, acc_rois)\n",
    "parietal_electrodes_per_subject, sig_parietal_electrodes_per_subject = filter_electrodes_by_roi(subjects_electrodestoROIs_dict, sig_chans_per_subject, parietal_rois)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get total number of electrodes (make this modular with roi later once everything works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_entries = 0\n",
    "for sub in sig_dlpfc_electrodes_per_subject:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(sig_dlpfc_electrodes_per_subject[sub])\n",
    "\n",
    "print(\"Total number of sig dlpfc electrodes across all subjects:\", total_entries)\n",
    "\n",
    "total_entries = 0\n",
    "for sub in sig_acc_electrodes_per_subject:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(sig_acc_electrodes_per_subject[sub])\n",
    "\n",
    "print(\"Total number of sig acc electrodes across all subjects:\", total_entries)\n",
    "\n",
    "total_entries = 0\n",
    "for sub in sig_parietal_electrodes_per_subject:\n",
    "    # Since each subject's entry is a list, directly add its length\n",
    "    total_entries += len(sig_parietal_electrodes_per_subject[sub])\n",
    "\n",
    "print(\"Total number of sig parietal electrodes across all subjects:\", total_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### do stats\n",
    "\n",
    "current approach is to run time_perm_cluster on significant dlpfc electrodes for each subject, comparing congruent and incongruent conditions. Then, average p-values across all subjects. Discuss this with Greg, probably wrong approach.\n",
    "\n",
    "**1/23 new approach is to average across all trials for sig dlpfc electrodes, comparing incongruent and congruent conditions. Then, run stats on this new avg electrode value x time array.\n",
    "\n",
    "Also, I'm using HG_ev1_rescaled instead of HG_ev1 to compare congruent and incongruent, so that they're normalized with a common baseline. I think this is better than comparing the raw HG traces directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this is 1/23 new approach of avg across trials first\n",
    "\n",
    "do stats and plotting together. Stats needs trial avg data, plotting just needs congruent_data without trial averaging (initially at least)  \n",
    "this code is so bad right now, turn into a function later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subjects_mne_objects['D0057'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])\n",
    "print(subjects_mne_objects['D0059'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])\n",
    "print(subjects_mne_objects['D0063'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])\n",
    "print(subjects_mne_objects['D0065'][output_names[1]]['HG_ev1_rescaled'].info['ch_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wtf why are there only like the sig dlpfc electrodes being stored in HG_ev1_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store data\n",
    "output_0_data_trialAvg_list_dlpfc = []\n",
    "output_1_data_trialAvg_list_dlpfc = []\n",
    "output_0_data_trialAvg_list_acc = []\n",
    "output_1_data_trialAvg_list_acc = []\n",
    "output_0_data_trialAvg_list_parietal = []\n",
    "output_1_data_trialAvg_list_parietal = []\n",
    "\n",
    "for sub in subjects:\n",
    "    # Skip this subject if no dlpfc electrodes\n",
    "    if not sig_dlpfc_electrodes_per_subject[sub]:\n",
    "        continue\n",
    "\n",
    "    # Load trial-level data for each condition and pick significant DLPFC electrodes\n",
    "    output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n",
    "    output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].pick_channels(sig_dlpfc_electrodes_per_subject[sub])\n",
    "\n",
    "    # Average across the trials dimension, ignoring NaNs\n",
    "    output_0_data_trialAvg_list_dlpfc.append(np.nanmean(output_0_epochs.get_data(), axis=0))\n",
    "    output_1_data_trialAvg_list_dlpfc.append(np.nanmean(output_1_epochs.get_data(), axis=0))\n",
    "\n",
    "# do for acc\n",
    "for sub in subjects:\n",
    "    # Skip this subject if no dlpfc electrodes\n",
    "    if not sig_acc_electrodes_per_subject[sub]:\n",
    "        continue\n",
    "\n",
    "    # Load trial-level data for each condition and pick significant DLPFC electrodes\n",
    "    output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].pick_channels(sig_acc_electrodes_per_subject[sub])\n",
    "    output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].pick_channels(sig_acc_electrodes_per_subject[sub])\n",
    "\n",
    "    # Average across the trials dimension, ignoring NaNs\n",
    "    output_0_data_trialAvg_list_acc.append(np.nanmean(output_0_epochs.get_data(), axis=0))\n",
    "    output_1_data_trialAvg_list_acc.append(np.nanmean(output_1_epochs.get_data(), axis=0))\n",
    "\n",
    "#do for parietal\n",
    "for sub in subjects:\n",
    "    # Skip this subject if no dlpfc electrodes\n",
    "    if not sig_parietal_electrodes_per_subject[sub]:\n",
    "        continue\n",
    "\n",
    "    # Load trial-level data for each condition and pick significant DLPFC electrodes\n",
    "    output_0_epochs = subjects_mne_objects[sub][output_names[0]]['HG_ev1_rescaled'].pick_channels(sig_parietal_electrodes_per_subject[sub])\n",
    "    output_1_epochs = subjects_mne_objects[sub][output_names[1]]['HG_ev1_rescaled'].pick_channels(sig_parietal_electrodes_per_subject[sub])\n",
    "\n",
    "    # Average across the trials dimension, ignoring NaNs\n",
    "    output_0_data_trialAvg_list_parietal.append(np.nanmean(output_0_epochs.get_data(), axis=0))\n",
    "    output_1_data_trialAvg_list_parietal.append(np.nanmean(output_1_epochs.get_data(), axis=0))\n",
    "\n",
    "# Concatenate data across all subjects\n",
    "output_0_data_trialAvg_dlpfc = np.concatenate(output_0_data_trialAvg_list_dlpfc, axis=0)\n",
    "output_1_data_trialAvg_dlpfc = np.concatenate(output_1_data_trialAvg_list_dlpfc, axis=0)\n",
    "\n",
    "output_0_data_trialAvg_acc = np.concatenate(output_0_data_trialAvg_list_acc, axis=0)\n",
    "output_1_data_trialAvg_acc = np.concatenate(output_1_data_trialAvg_list_acc, axis=0)\n",
    "\n",
    "output_0_data_trialAvg_parietal = np.concatenate(output_0_data_trialAvg_list_parietal, axis=0)\n",
    "output_1_data_trialAvg_parietal = np.concatenate(output_1_data_trialAvg_list_parietal, axis=0)\n",
    "\n",
    "# Calculate mean and SEM across electrodes\n",
    "overall_average_dlpfc_output_0 = np.nanmean(output_0_data_trialAvg_dlpfc, axis=0)\n",
    "overall_sem_dlpfc_output_0 = np.std(output_0_data_trialAvg_dlpfc, axis=0, ddof=1) / np.sqrt(output_0_data_trialAvg_dlpfc.shape[0])\n",
    "overall_average_dlpfc_output_1 = np.nanmean(output_1_data_trialAvg_dlpfc, axis=0)\n",
    "overall_sem_dlpfc_output_1 = np.std(output_1_data_trialAvg_dlpfc, axis=0, ddof=1) / np.sqrt(output_1_data_trialAvg_dlpfc.shape[0])\n",
    "\n",
    "overall_average_acc_output_0 = np.nanmean(output_0_data_trialAvg_acc, axis=0)\n",
    "overall_sem_acc_output_0 = np.std(output_0_data_trialAvg_acc, axis=0, ddof=1) / np.sqrt(output_0_data_trialAvg_acc.shape[0])\n",
    "overall_average_acc_output_1 = np.nanmean(output_1_data_trialAvg_acc, axis=0)\n",
    "overall_sem_acc_output_1 = np.std(output_1_data_trialAvg_acc, axis=0, ddof=1) / np.sqrt(output_1_data_trialAvg_acc.shape[0])\n",
    "\n",
    "overall_average_parietal_output_0 = np.nanmean(output_0_data_trialAvg_parietal, axis=0)\n",
    "overall_sem_parietal_output_0 = np.std(output_0_data_trialAvg_parietal, axis=0, ddof=1) / np.sqrt(output_0_data_trialAvg_parietal.shape[0])\n",
    "overall_average_parietal_output_1 = np.nanmean(output_1_data_trialAvg_parietal, axis=0)\n",
    "overall_sem_parietal_output_1 = np.std(output_1_data_trialAvg_parietal, axis=0, ddof=1) / np.sqrt(output_1_data_trialAvg_parietal.shape[0])\n",
    "\n",
    "\n",
    "# Run the permutation test\n",
    "mat_dlpfc = time_perm_cluster(output_0_data_trialAvg_dlpfc, output_1_data_trialAvg_dlpfc, 0.05, n_jobs=6)\n",
    "mat_acc = time_perm_cluster(output_0_data_trialAvg_acc, output_1_data_trialAvg_acc, 0.05, n_jobs=6)\n",
    "mat_parietal = time_perm_cluster(output_0_data_trialAvg_parietal, output_1_data_trialAvg_parietal, 0.05, n_jobs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try to do the stats in a more modular way\n",
    "this is broken right now don't use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def process_roi_data(subjects_mne_objects, output_names, sig_electrodes_per_roi, roi_name):\n",
    "    output_data_trialAvg_list = {output: [] for output in output_names}\n",
    "\n",
    "    for sub, sig_electrodes in sig_electrodes_per_roi.items():\n",
    "        if not sig_electrodes:  # Skip if no significant electrodes for this ROI in the subject\n",
    "            continue\n",
    "\n",
    "        for output in output_names:\n",
    "            try:\n",
    "                epochs = subjects_mne_objects[sub][output]['HG_ev1_rescaled'].pick_channels(sig_electrodes)\n",
    "                output_data_trialAvg_list[output].append(np.nanmean(epochs.get_data(), axis=0))\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {roi_name} in subject {sub}, output {output}: {e}\")\n",
    "\n",
    "    # Concatenate and compute averages and SEMs\n",
    "    results = {}\n",
    "    for output in output_names:\n",
    "        if output_data_trialAvg_list[output]:  # Check if list is not empty\n",
    "            concatenated_data = np.concatenate(output_data_trialAvg_list[output], axis=0)\n",
    "            results[output] = {\n",
    "                'average': np.nanmean(concatenated_data, axis=0),\n",
    "                'sem': np.std(concatenated_data, axis=0, ddof=1) / np.sqrt(concatenated_data.shape[0])\n",
    "            }\n",
    "    return results\n",
    "\n",
    "# Process data for each ROI\n",
    "results_dlpfc = process_roi_data(subjects_mne_objects, output_names, sig_dlpfc_electrodes_per_subject, 'dlPFC')\n",
    "results_acc = process_roi_data(subjects_mne_objects, output_names, sig_acc_electrodes_per_subject, 'ACC')\n",
    "results_parietal = process_roi_data(subjects_mne_objects, output_names, sig_parietal_electrodes_per_subject, 'Parietal')\n",
    "\n",
    "# Run permutation tests\n",
    "mat_dlpfc = time_perm_cluster(results_dlpfc['output_0']['average'], results_dlpfc['output_1']['average'], 0.05, n_jobs=6)\n",
    "mat_acc = time_perm_cluster(results_acc['output_0']['average'], results_acc['output_1']['average'], 0.05, n_jobs=6)\n",
    "mat_parietal = time_perm_cluster(results_parietal['output_0']['average'], results_parietal['output_1']['average'], 0.05, n_jobs=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot and QC stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if no significant differences.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mat)\n",
    "plt.xlabel('Timepoints')\n",
    "plt.ylabel('Significance (0 or 1)')\n",
    "plt.title('Permutation Test Significance Over Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try a basic t-test as a sanity check (ok its also not significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "p_values = np.array([ttest_ind(output_0_data_trialAvg[:, tp], output_1_data_trialAvg[:, tp]).pvalue for tp in range(output_0_data_trialAvg.shape[1])])\n",
    "significance = p_values < 0.05  # Apply a significance threshold, e.g., p < 0.05\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(output_0_data_trialAvg.shape[1]), significance, label='Significance (p < 0.05)')\n",
    "plt.xlabel('Time Point')\n",
    "plt.ylabel('Significance (True/False)')\n",
    "plt.title('Statistical Significance Over Time')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot dlpfc inc vs. con, avg across all subjects (or whatever conditions you wanna compare, just use the proper output names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine LAB_root based on the operating system\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "LAB_root = os.path.join(HOME, \"Box\", \"CoganLab\") if os.name == 'nt' else os.path.join(HOME, \"Library\", \"CloudStorage\", \"Box-Box\", \"CoganLab\")\n",
    "\n",
    "# Get data layout\n",
    "layout = get_data(task, root=LAB_root)\n",
    "save_dir = os.path.join(layout.root, 'derivatives', 'freqFilt', 'figs')\n",
    "save_path = os.path.join(save_dir, 'avg_dlpfc_placeholder_zscore.png')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "HG_ev1_evoke_rescaled_D0063_c = subjects_mne_objects['D0063'][output_names[0]]['HG_ev1_evoke_rescaled']\n",
    "\n",
    "# Use the times from your evoked data (assuming these are representative for all subjects)\n",
    "times = HG_ev1_evoke_rescaled_D0063_c.times  # Modify as needed to match your data\n",
    "\n",
    "# Plot overall_average_dlpfc of the 0th output with SEM shading\n",
    "plt.plot(times, overall_average_dlpfc_output_0, label='Average dlpfc repeat')\n",
    "plt.fill_between(times, overall_average_dlpfc_output_0 - overall_sem_dlpfc_output_0, \n",
    "                 overall_average_dlpfc_output_0 + overall_sem_dlpfc_output_0, alpha=0.3)\n",
    "\n",
    "# Plot overall_average_dlpfc of the 1st output with SEM shading\n",
    "plt.plot(times, overall_average_dlpfc_output_1, label='Average dlpfc switch')\n",
    "plt.fill_between(times, overall_average_dlpfc_output_1 - overall_sem_dlpfc_output_1, \n",
    "                 overall_average_dlpfc_output_1 + overall_sem_dlpfc_output_1, alpha=0.3)\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Z-score')\n",
    "plt.title('Average dlPFC Signal with Standard Error (switch vs repeat)')\n",
    "plt.legend()\n",
    "plt.savefig(save_path)  # Modify save_dir as necessary\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot individual electrodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_electrodes_grid(electrodes_data, grid_num, save_dir, roi, output_names, times):\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(20, 12))  # Adjust figure size as needed\n",
    "    axes = axes.flatten()  # Flatten the axes array for easy indexing\n",
    "\n",
    "    for i, (data, sub, electrode) in enumerate(electrodes_data):\n",
    "        ax = axes[i]\n",
    "        ax.plot(times, data['output_0'], label=f'{roi} {output_names[0]}')\n",
    "        ax.fill_between(times, \n",
    "                        data['output_0'] - np.std(data['output_0'], ddof=1) / np.sqrt(len(data['output_0'])),\n",
    "                        data['output_0'] + np.std(data['output_0'], ddof=1) / np.sqrt(len(data['output_0'])), alpha=0.3)\n",
    "        ax.plot(times, data['output_1'], label=f'{roi} {output_names[1]}')\n",
    "        ax.fill_between(times, \n",
    "                        data['output_1'] - np.std(data['output_1'], ddof=1) / np.sqrt(len(data['output_1'])),\n",
    "                        data['output_1'] + np.std(data['output_1'], ddof=1) / np.sqrt(len(data['output_1'])), alpha=0.3)\n",
    "        ax.set_title(f'Subject {sub}, Electrode {electrode}')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_ylabel('Z-score')\n",
    "\n",
    "    # Create the legend at the top center of the figure\n",
    "    handles, labels = ax.get_legend_handles_labels()  # Get handles and labels from the last subplot\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=2)\n",
    "\n",
    "    plt.tight_layout()  # Adjust the layout to make room for the legend\n",
    "    plt.savefig(os.path.join(save_dir, f'{roi}_{output_names[0]}_{output_names[1]}_electrodes_plot_grid_{grid_num+1}.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Example Usage\n",
    "electrodes_data = []\n",
    "electrode_counter = 0\n",
    "grid_size = 16  # Number of electrodes per grid\n",
    "grid_num = 0\n",
    "\n",
    "for sub in subjects:\n",
    "    if sub in sig_dlpfc_electrodes_per_subject:\n",
    "        for electrode in sig_dlpfc_electrodes_per_subject[sub]:\n",
    "            electrode_data = {\n",
    "                'output_0': output_0_data_trialAvg[electrode_counter],\n",
    "                'output_1': output_1_data_trialAvg[electrode_counter]\n",
    "            }\n",
    "            electrodes_data.append((electrode_data, sub, electrode))\n",
    "            electrode_counter += 1\n",
    "\n",
    "            if len(electrodes_data) == grid_size:\n",
    "                plot_electrodes_grid(electrodes_data, grid_num, save_dir, 'dlPFC', output_names, times)\n",
    "                electrodes_data = []  # Reset for the next grid\n",
    "                grid_num += 1\n",
    "\n",
    "# Plot remaining electrodes in the last grid\n",
    "if electrodes_data:\n",
    "    plot_electrodes_grid(electrodes_data, grid_num, save_dir, 'dlPFC', output_names, times)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ieeg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
